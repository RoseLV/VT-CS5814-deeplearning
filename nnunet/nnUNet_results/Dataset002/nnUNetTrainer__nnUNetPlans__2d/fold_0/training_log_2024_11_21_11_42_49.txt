
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-11-21 11:42:49.503793: do_dummy_2d_data_aug: False 
2024-11-21 11:42:49.512870: Using splits from existing split file: /home/ran/deeplearning/nnUNet_preprocessed/Dataset002/splits_final.json 
2024-11-21 11:42:49.514278: The split file contains 5 splits. 
2024-11-21 11:42:49.514313: Desired fold for training: 0 
2024-11-21 11:42:49.514338: This split has 2400 training and 600 validation cases. 
2024-11-21 11:42:52.358845: Using torch.compile... 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 49, 'patch_size': [256, 256], 'median_image_size_in_voxels': [255.0, 256.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 255, 256], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 195.0, 'mean': 54.957254538859154, 'median': 52.0, 'min': 0.0, 'percentile_00_5': 6.0, 'percentile_99_5': 149.0, 'std': 23.969446116031435}, '1': {'max': 233.0, 'mean': 82.23498287918395, 'median': 80.0, 'min': 0.0, 'percentile_00_5': 12.0, 'percentile_99_5': 165.0, 'std': 30.701570648596835}, '2': {'max': 247.0, 'mean': 53.10329666338049, 'median': 49.0, 'min': 1.0, 'percentile_00_5': 7.0, 'percentile_99_5': 152.0, 'std': 23.771808202696253}}} 
 
2024-11-21 11:42:52.909973: unpacking dataset... 
2024-11-21 11:42:57.384896: unpacking done... 
2024-11-21 11:42:57.396475: Unable to plot network architecture: nnUNet_compile is enabled! 
2024-11-21 11:42:57.406291:  
2024-11-21 11:42:57.406415: Epoch 0 
2024-11-21 11:42:57.406548: Current learning rate: 0.01 
2024-11-21 11:44:44.684284: train_loss -0.4703 
2024-11-21 11:44:44.684393: val_loss -0.7651 
2024-11-21 11:44:44.684441: Pseudo dice [np.float32(0.8011)] 
2024-11-21 11:44:44.684536: Epoch time: 107.28 s 
2024-11-21 11:44:44.684598: Yayy! New best EMA pseudo Dice: 0.8011000156402588 
2024-11-21 11:44:45.818497:  
2024-11-21 11:44:45.818668: Epoch 1 
2024-11-21 11:44:45.818737: Current learning rate: 0.00999 
2024-11-21 11:45:38.061327: train_loss -0.7946 
2024-11-21 11:45:38.061440: val_loss -0.832 
2024-11-21 11:45:38.061495: Pseudo dice [np.float32(0.8605)] 
2024-11-21 11:45:38.061567: Epoch time: 52.24 s 
2024-11-21 11:45:38.061746: Yayy! New best EMA pseudo Dice: 0.8069999814033508 
2024-11-21 11:45:39.402056:  
2024-11-21 11:45:39.402233: Epoch 2 
2024-11-21 11:45:39.402320: Current learning rate: 0.00998 
2024-11-21 11:46:32.021722: train_loss -0.8416 
2024-11-21 11:46:32.021849: val_loss -0.8385 
2024-11-21 11:46:32.021971: Pseudo dice [np.float32(0.8626)] 
2024-11-21 11:46:32.022063: Epoch time: 52.62 s 
2024-11-21 11:46:32.022122: Yayy! New best EMA pseudo Dice: 0.8126000165939331 
2024-11-21 11:46:33.730394:  
2024-11-21 11:46:33.730574: Epoch 3 
2024-11-21 11:46:33.730642: Current learning rate: 0.00997 
2024-11-21 11:47:26.189083: train_loss -0.8506 
2024-11-21 11:47:26.189266: val_loss -0.8518 
2024-11-21 11:47:26.189367: Pseudo dice [np.float32(0.8766)] 
2024-11-21 11:47:26.189496: Epoch time: 52.46 s 
2024-11-21 11:47:26.189559: Yayy! New best EMA pseudo Dice: 0.8190000057220459 
2024-11-21 11:47:27.395454:  
2024-11-21 11:47:27.395715: Epoch 4 
2024-11-21 11:47:27.395853: Current learning rate: 0.00996 
2024-11-21 11:48:19.495233: train_loss -0.8591 
2024-11-21 11:48:19.495394: val_loss -0.8494 
2024-11-21 11:48:19.495446: Pseudo dice [np.float32(0.8734)] 
2024-11-21 11:48:19.495532: Epoch time: 52.1 s 
2024-11-21 11:48:19.495599: Yayy! New best EMA pseudo Dice: 0.824400007724762 
2024-11-21 11:48:20.849902:  
2024-11-21 11:48:20.850036: Epoch 5 
2024-11-21 11:48:20.850125: Current learning rate: 0.00995 
2024-11-21 11:49:13.013217: train_loss -0.8738 
2024-11-21 11:49:13.013352: val_loss -0.8633 
2024-11-21 11:49:13.013404: Pseudo dice [np.float32(0.8835)] 
2024-11-21 11:49:13.013504: Epoch time: 52.16 s 
2024-11-21 11:49:13.013583: Yayy! New best EMA pseudo Dice: 0.830299973487854 
2024-11-21 11:49:14.265712:  
2024-11-21 11:49:14.265853: Epoch 6 
2024-11-21 11:49:14.265920: Current learning rate: 0.00995 
2024-11-21 11:50:06.755170: train_loss -0.8785 
2024-11-21 11:50:06.755319: val_loss -0.8727 
2024-11-21 11:50:06.755433: Pseudo dice [np.float32(0.8915)] 
2024-11-21 11:50:06.755514: Epoch time: 52.49 s 
2024-11-21 11:50:06.755595: Yayy! New best EMA pseudo Dice: 0.8364999890327454 
2024-11-21 11:50:08.082614:  
2024-11-21 11:50:08.082793: Epoch 7 
2024-11-21 11:50:08.082879: Current learning rate: 0.00994 
2024-11-21 11:51:00.619734: train_loss -0.8841 
2024-11-21 11:51:00.619897: val_loss -0.8758 
2024-11-21 11:51:00.619963: Pseudo dice [np.float32(0.8958)] 
2024-11-21 11:51:00.620034: Epoch time: 52.54 s 
2024-11-21 11:51:00.620094: Yayy! New best EMA pseudo Dice: 0.8424000144004822 
2024-11-21 11:51:01.948692:  
2024-11-21 11:51:01.948856: Epoch 8 
2024-11-21 11:51:01.948978: Current learning rate: 0.00993 
2024-11-21 11:51:54.377142: train_loss -0.8829 
2024-11-21 11:51:54.377256: val_loss -0.8686 
2024-11-21 11:51:54.377304: Pseudo dice [np.float32(0.8871)] 
2024-11-21 11:51:54.377359: Epoch time: 52.43 s 
2024-11-21 11:51:54.377406: Yayy! New best EMA pseudo Dice: 0.8468999862670898 
2024-11-21 11:51:55.776531:  
2024-11-21 11:51:55.776718: Epoch 9 
2024-11-21 11:51:55.776803: Current learning rate: 0.00992 
2024-11-21 11:52:48.258329: train_loss -0.889 
2024-11-21 11:52:48.258459: val_loss -0.8698 
2024-11-21 11:52:48.258551: Pseudo dice [np.float32(0.89)] 
2024-11-21 11:52:48.258630: Epoch time: 52.48 s 
2024-11-21 11:52:48.258676: Yayy! New best EMA pseudo Dice: 0.8511999845504761 
2024-11-21 11:52:49.518631:  
2024-11-21 11:52:49.518814: Epoch 10 
2024-11-21 11:52:49.518886: Current learning rate: 0.00991 
2024-11-21 11:53:41.835311: train_loss -0.8895 
2024-11-21 11:53:41.835441: val_loss -0.8722 
2024-11-21 11:53:41.835511: Pseudo dice [np.float32(0.8906)] 
2024-11-21 11:53:41.835580: Epoch time: 52.32 s 
2024-11-21 11:53:41.835638: Yayy! New best EMA pseudo Dice: 0.8550999760627747 
2024-11-21 11:53:43.105664:  
2024-11-21 11:53:43.105845: Epoch 11 
2024-11-21 11:53:43.105927: Current learning rate: 0.0099 
2024-11-21 11:54:35.550654: train_loss -0.8877 
2024-11-21 11:54:35.550771: val_loss -0.8725 
2024-11-21 11:54:35.550822: Pseudo dice [np.float32(0.891)] 
2024-11-21 11:54:35.550877: Epoch time: 52.45 s 
2024-11-21 11:54:35.550922: Yayy! New best EMA pseudo Dice: 0.8586999773979187 
2024-11-21 11:54:36.835902:  
2024-11-21 11:54:36.836110: Epoch 12 
2024-11-21 11:54:36.836213: Current learning rate: 0.00989 
2024-11-21 11:55:29.183019: train_loss -0.8912 
2024-11-21 11:55:29.183154: val_loss -0.8805 
2024-11-21 11:55:29.183206: Pseudo dice [np.float32(0.8976)] 
2024-11-21 11:55:29.183262: Epoch time: 52.35 s 
2024-11-21 11:55:29.183309: Yayy! New best EMA pseudo Dice: 0.8626000285148621 
2024-11-21 11:55:30.458609:  
2024-11-21 11:55:30.458838: Epoch 13 
2024-11-21 11:55:30.458911: Current learning rate: 0.00988 
2024-11-21 11:56:22.726972: train_loss -0.8951 
2024-11-21 11:56:22.727090: val_loss -0.8775 
2024-11-21 11:56:22.727142: Pseudo dice [np.float32(0.8957)] 
2024-11-21 11:56:22.727198: Epoch time: 52.27 s 
2024-11-21 11:56:22.727246: Yayy! New best EMA pseudo Dice: 0.8658999800682068 
2024-11-21 11:56:24.022482:  
2024-11-21 11:56:24.022687: Epoch 14 
2024-11-21 11:56:24.022773: Current learning rate: 0.00987 
2024-11-21 11:57:16.199584: train_loss -0.8983 
2024-11-21 11:57:16.199744: val_loss -0.8802 
2024-11-21 11:57:16.199805: Pseudo dice [np.float32(0.8969)] 
2024-11-21 11:57:16.199873: Epoch time: 52.18 s 
2024-11-21 11:57:16.199929: Yayy! New best EMA pseudo Dice: 0.8690000176429749 
2024-11-21 11:57:17.454767:  
2024-11-21 11:57:17.454937: Epoch 15 
2024-11-21 11:57:17.455030: Current learning rate: 0.00986 
2024-11-21 11:58:10.173767: train_loss -0.9038 
2024-11-21 11:58:10.173927: val_loss -0.8848 
2024-11-21 11:58:10.174037: Pseudo dice [np.float32(0.8995)] 
2024-11-21 11:58:10.174111: Epoch time: 52.72 s 
2024-11-21 11:58:10.174171: Yayy! New best EMA pseudo Dice: 0.8720999956130981 
2024-11-21 11:58:11.482720:  
2024-11-21 11:58:11.482960: Epoch 16 
2024-11-21 11:58:11.483033: Current learning rate: 0.00986 
2024-11-21 11:59:04.036464: train_loss -0.9073 
2024-11-21 11:59:04.036700: val_loss -0.8884 
2024-11-21 11:59:04.036753: Pseudo dice [np.float32(0.905)] 
2024-11-21 11:59:04.036813: Epoch time: 52.55 s 
2024-11-21 11:59:04.036864: Yayy! New best EMA pseudo Dice: 0.8754000067710876 
2024-11-21 11:59:05.327924:  
2024-11-21 11:59:05.328112: Epoch 17 
2024-11-21 11:59:05.328196: Current learning rate: 0.00985 
2024-11-21 11:59:57.876746: train_loss -0.9075 
2024-11-21 11:59:57.876874: val_loss -0.8885 
2024-11-21 11:59:57.876923: Pseudo dice [np.float32(0.9036)] 
2024-11-21 11:59:57.877004: Epoch time: 52.55 s 
2024-11-21 11:59:57.877048: Yayy! New best EMA pseudo Dice: 0.8781999945640564 
2024-11-21 11:59:59.106051:  
2024-11-21 11:59:59.106232: Epoch 18 
2024-11-21 11:59:59.106307: Current learning rate: 0.00984 
2024-11-21 12:00:51.330204: train_loss -0.911 
2024-11-21 12:00:51.330322: val_loss -0.8871 
2024-11-21 12:00:51.330374: Pseudo dice [np.float32(0.9028)] 
2024-11-21 12:00:51.330431: Epoch time: 52.22 s 
2024-11-21 12:00:51.330505: Yayy! New best EMA pseudo Dice: 0.8805999755859375 
2024-11-21 12:00:52.671934:  
2024-11-21 12:00:52.672107: Epoch 19 
2024-11-21 12:00:52.672195: Current learning rate: 0.00983 
2024-11-21 12:01:45.100709: train_loss -0.9086 
2024-11-21 12:01:45.100849: val_loss -0.8871 
2024-11-21 12:01:45.100900: Pseudo dice [np.float32(0.9003)] 
2024-11-21 12:01:45.100955: Epoch time: 52.43 s 
2024-11-21 12:01:45.100999: Yayy! New best EMA pseudo Dice: 0.8826000094413757 
2024-11-21 12:01:46.446105:  
2024-11-21 12:01:46.446250: Epoch 20 
2024-11-21 12:01:46.446332: Current learning rate: 0.00982 
2024-11-21 12:02:38.629736: train_loss -0.9129 
2024-11-21 12:02:38.629880: val_loss -0.8853 
2024-11-21 12:02:38.629931: Pseudo dice [np.float32(0.9018)] 
2024-11-21 12:02:38.630016: Epoch time: 52.18 s 
2024-11-21 12:02:38.630073: Yayy! New best EMA pseudo Dice: 0.8845000267028809 
2024-11-21 12:02:39.920383:  
2024-11-21 12:02:39.920555: Epoch 21 
2024-11-21 12:02:39.920650: Current learning rate: 0.00981 
2024-11-21 12:03:32.283648: train_loss -0.914 
2024-11-21 12:03:32.283763: val_loss -0.8914 
2024-11-21 12:03:32.283863: Pseudo dice [np.float32(0.905)] 
2024-11-21 12:03:32.283984: Epoch time: 52.36 s 
2024-11-21 12:03:32.284047: Yayy! New best EMA pseudo Dice: 0.8866000175476074 
2024-11-21 12:03:33.588175:  
2024-11-21 12:03:33.588314: Epoch 22 
2024-11-21 12:03:33.588383: Current learning rate: 0.0098 
2024-11-21 12:04:26.029585: train_loss -0.9142 
2024-11-21 12:04:26.029757: val_loss -0.8799 
2024-11-21 12:04:26.029808: Pseudo dice [np.float32(0.8949)] 
2024-11-21 12:04:26.029985: Epoch time: 52.44 s 
2024-11-21 12:04:26.030058: Yayy! New best EMA pseudo Dice: 0.8873999714851379 
2024-11-21 12:04:27.291303:  
2024-11-21 12:04:27.291442: Epoch 23 
2024-11-21 12:04:27.291540: Current learning rate: 0.00979 
2024-11-21 12:05:19.354107: train_loss -0.911 
2024-11-21 12:05:19.354221: val_loss -0.8895 
2024-11-21 12:05:19.354271: Pseudo dice [np.float32(0.9052)] 
2024-11-21 12:05:19.354325: Epoch time: 52.06 s 
2024-11-21 12:05:19.354399: Yayy! New best EMA pseudo Dice: 0.88919997215271 
2024-11-21 12:05:20.579795:  
2024-11-21 12:05:20.579981: Epoch 24 
2024-11-21 12:05:20.580055: Current learning rate: 0.00978 
2024-11-21 12:06:12.643519: train_loss -0.9147 
2024-11-21 12:06:12.643660: val_loss -0.882 
2024-11-21 12:06:12.643747: Pseudo dice [np.float32(0.8968)] 
2024-11-21 12:06:12.643835: Epoch time: 52.06 s 
2024-11-21 12:06:12.643924: Yayy! New best EMA pseudo Dice: 0.8899000287055969 
2024-11-21 12:06:14.123816:  
2024-11-21 12:06:14.123945: Epoch 25 
2024-11-21 12:06:14.124018: Current learning rate: 0.00977 
2024-11-21 12:07:06.117539: train_loss -0.9162 
2024-11-21 12:07:06.117668: val_loss -0.8887 
2024-11-21 12:07:06.117719: Pseudo dice [np.float32(0.9038)] 
2024-11-21 12:07:06.117773: Epoch time: 51.99 s 
2024-11-21 12:07:06.117817: Yayy! New best EMA pseudo Dice: 0.8913000226020813 
2024-11-21 12:07:07.582286:  
2024-11-21 12:07:07.582443: Epoch 26 
2024-11-21 12:07:07.582515: Current learning rate: 0.00977 
2024-11-21 12:07:59.662729: train_loss -0.9184 
2024-11-21 12:07:59.662901: val_loss -0.8955 
2024-11-21 12:07:59.662985: Pseudo dice [np.float32(0.91)] 
2024-11-21 12:07:59.663074: Epoch time: 52.08 s 
2024-11-21 12:07:59.663132: Yayy! New best EMA pseudo Dice: 0.8931999802589417 
2024-11-21 12:08:00.876397:  
2024-11-21 12:08:00.876604: Epoch 27 
2024-11-21 12:08:00.876673: Current learning rate: 0.00976 
2024-11-21 12:08:52.926244: train_loss -0.9188 
2024-11-21 12:08:52.926383: val_loss -0.8894 
2024-11-21 12:08:52.926431: Pseudo dice [np.float32(0.9053)] 
2024-11-21 12:08:52.926514: Epoch time: 52.05 s 
2024-11-21 12:08:52.926589: Yayy! New best EMA pseudo Dice: 0.8944000005722046 
2024-11-21 12:08:54.252532:  
2024-11-21 12:08:54.252666: Epoch 28 
2024-11-21 12:08:54.252747: Current learning rate: 0.00975 
2024-11-21 12:09:46.520596: train_loss -0.9206 
2024-11-21 12:09:46.520724: val_loss -0.8931 
2024-11-21 12:09:46.520775: Pseudo dice [np.float32(0.9064)] 
2024-11-21 12:09:46.520830: Epoch time: 52.27 s 
2024-11-21 12:09:46.520875: Yayy! New best EMA pseudo Dice: 0.8956000208854675 
2024-11-21 12:09:47.788417:  
2024-11-21 12:09:47.788708: Epoch 29 
2024-11-21 12:09:47.788804: Current learning rate: 0.00974 
2024-11-21 12:10:39.694511: train_loss -0.9191 
2024-11-21 12:10:39.694649: val_loss -0.8945 
2024-11-21 12:10:39.694695: Pseudo dice [np.float32(0.9072)] 
2024-11-21 12:10:39.694768: Epoch time: 51.91 s 
2024-11-21 12:10:39.694945: Yayy! New best EMA pseudo Dice: 0.8967999815940857 
2024-11-21 12:10:41.009051:  
2024-11-21 12:10:41.009266: Epoch 30 
2024-11-21 12:10:41.009351: Current learning rate: 0.00973 
2024-11-21 12:11:33.132389: train_loss -0.9231 
2024-11-21 12:11:33.132510: val_loss -0.8877 
2024-11-21 12:11:33.132558: Pseudo dice [np.float32(0.9027)] 
2024-11-21 12:11:33.132610: Epoch time: 52.12 s 
2024-11-21 12:11:33.132653: Yayy! New best EMA pseudo Dice: 0.8974000215530396 
2024-11-21 12:11:34.421824:  
2024-11-21 12:11:34.421975: Epoch 31 
2024-11-21 12:11:34.422042: Current learning rate: 0.00972 
2024-11-21 12:12:26.397904: train_loss -0.9168 
2024-11-21 12:12:26.398020: val_loss -0.8865 
2024-11-21 12:12:26.398069: Pseudo dice [np.float32(0.9028)] 
2024-11-21 12:12:26.398123: Epoch time: 51.98 s 
2024-11-21 12:12:26.398167: Yayy! New best EMA pseudo Dice: 0.8978999853134155 
2024-11-21 12:12:27.733983:  
2024-11-21 12:12:27.734112: Epoch 32 
2024-11-21 12:12:27.734181: Current learning rate: 0.00971 
2024-11-21 12:13:19.987961: train_loss -0.9096 
2024-11-21 12:13:19.988067: val_loss -0.8761 
2024-11-21 12:13:19.988114: Pseudo dice [np.float32(0.8897)] 
2024-11-21 12:13:19.988165: Epoch time: 52.25 s 
2024-11-21 12:13:21.033282:  
2024-11-21 12:13:21.033464: Epoch 33 
2024-11-21 12:13:21.033569: Current learning rate: 0.0097 
2024-11-21 12:14:12.975092: train_loss -0.9141 
2024-11-21 12:14:12.975219: val_loss -0.8878 
2024-11-21 12:14:12.975281: Pseudo dice [np.float32(0.9002)] 
2024-11-21 12:14:12.975346: Epoch time: 51.94 s 
2024-11-21 12:14:13.851939:  
2024-11-21 12:14:13.852076: Epoch 34 
2024-11-21 12:14:13.852145: Current learning rate: 0.00969 
2024-11-21 12:15:06.569395: train_loss -0.9183 
2024-11-21 12:15:06.569549: val_loss -0.8862 
2024-11-21 12:15:06.569598: Pseudo dice [np.float32(0.901)] 
2024-11-21 12:15:06.569650: Epoch time: 52.72 s 
2024-11-21 12:15:07.638352:  
2024-11-21 12:15:07.638533: Epoch 35 
2024-11-21 12:15:07.638623: Current learning rate: 0.00968 
2024-11-21 12:15:59.956242: train_loss -0.9186 
2024-11-21 12:15:59.956393: val_loss -0.8961 
2024-11-21 12:15:59.957257: Pseudo dice [np.float32(0.9088)] 
2024-11-21 12:15:59.957330: Epoch time: 52.32 s 
2024-11-21 12:15:59.957391: Yayy! New best EMA pseudo Dice: 0.8988999724388123 
2024-11-21 12:16:01.280281:  
2024-11-21 12:16:01.280456: Epoch 36 
2024-11-21 12:16:01.280552: Current learning rate: 0.00968 
2024-11-21 12:16:53.493705: train_loss -0.9219 
2024-11-21 12:16:53.493880: val_loss -0.891 
2024-11-21 12:16:53.493986: Pseudo dice [np.float32(0.9044)] 
2024-11-21 12:16:53.494057: Epoch time: 52.21 s 
2024-11-21 12:16:53.494118: Yayy! New best EMA pseudo Dice: 0.899399995803833 
2024-11-21 12:16:55.028357:  
2024-11-21 12:16:55.028516: Epoch 37 
2024-11-21 12:16:55.028585: Current learning rate: 0.00967 
2024-11-21 12:17:47.287126: train_loss -0.9231 
2024-11-21 12:17:47.287275: val_loss -0.891 
2024-11-21 12:17:47.287323: Pseudo dice [np.float32(0.907)] 
2024-11-21 12:17:47.287375: Epoch time: 52.26 s 
2024-11-21 12:17:47.287419: Yayy! New best EMA pseudo Dice: 0.9002000093460083 
2024-11-21 12:17:48.593221:  
2024-11-21 12:17:48.593370: Epoch 38 
2024-11-21 12:17:48.593438: Current learning rate: 0.00966 
2024-11-21 12:18:40.692025: train_loss -0.9251 
2024-11-21 12:18:40.692163: val_loss -0.8899 
2024-11-21 12:18:40.692215: Pseudo dice [np.float32(0.9031)] 
2024-11-21 12:18:40.692273: Epoch time: 52.1 s 
2024-11-21 12:18:40.692320: Yayy! New best EMA pseudo Dice: 0.9004999995231628 
2024-11-21 12:18:42.071930:  
2024-11-21 12:18:42.072157: Epoch 39 
2024-11-21 12:18:42.072241: Current learning rate: 0.00965 
2024-11-21 12:19:34.221397: train_loss -0.9274 
2024-11-21 12:19:34.221581: val_loss -0.8871 
2024-11-21 12:19:34.221730: Pseudo dice [np.float32(0.9026)] 
2024-11-21 12:19:34.221785: Epoch time: 52.15 s 
2024-11-21 12:19:34.221830: Yayy! New best EMA pseudo Dice: 0.9006999731063843 
2024-11-21 12:19:35.534055:  
2024-11-21 12:19:35.534348: Epoch 40 
2024-11-21 12:19:35.534434: Current learning rate: 0.00964 
2024-11-21 12:20:27.700203: train_loss -0.9265 
2024-11-21 12:20:27.700344: val_loss -0.8864 
2024-11-21 12:20:27.700411: Pseudo dice [np.float32(0.9011)] 
2024-11-21 12:20:27.700518: Epoch time: 52.17 s 
2024-11-21 12:20:27.700662: Yayy! New best EMA pseudo Dice: 0.9006999731063843 
2024-11-21 12:20:29.059302:  
2024-11-21 12:20:29.059485: Epoch 41 
2024-11-21 12:20:29.059587: Current learning rate: 0.00963 
2024-11-21 12:21:21.379129: train_loss -0.9258 
2024-11-21 12:21:21.379268: val_loss -0.8889 
2024-11-21 12:21:21.379329: Pseudo dice [np.float32(0.9033)] 
2024-11-21 12:21:21.379395: Epoch time: 52.32 s 
2024-11-21 12:21:21.379449: Yayy! New best EMA pseudo Dice: 0.9010000228881836 
2024-11-21 12:21:22.590287:  
2024-11-21 12:21:22.590406: Epoch 42 
2024-11-21 12:21:22.590508: Current learning rate: 0.00962 
2024-11-21 12:22:14.633308: train_loss -0.9266 
2024-11-21 12:22:14.633437: val_loss -0.8868 
2024-11-21 12:22:14.633525: Pseudo dice [np.float32(0.9019)] 
2024-11-21 12:22:14.633632: Epoch time: 52.04 s 
2024-11-21 12:22:14.633705: Yayy! New best EMA pseudo Dice: 0.9010999798774719 
2024-11-21 12:22:15.933097:  
2024-11-21 12:22:15.933264: Epoch 43 
2024-11-21 12:22:15.933348: Current learning rate: 0.00961 
2024-11-21 12:23:08.081407: train_loss -0.9241 
2024-11-21 12:23:08.081579: val_loss -0.8928 
2024-11-21 12:23:08.081703: Pseudo dice [np.float32(0.907)] 
2024-11-21 12:23:08.081802: Epoch time: 52.15 s 
2024-11-21 12:23:08.081917: Yayy! New best EMA pseudo Dice: 0.9017000198364258 
2024-11-21 12:23:09.294312:  
2024-11-21 12:23:09.294513: Epoch 44 
2024-11-21 12:23:09.294580: Current learning rate: 0.0096 
2024-11-21 12:24:01.414773: train_loss -0.9276 
2024-11-21 12:24:01.414899: val_loss -0.8898 
2024-11-21 12:24:01.414947: Pseudo dice [np.float32(0.9049)] 
2024-11-21 12:24:01.415000: Epoch time: 52.12 s 
2024-11-21 12:24:01.415043: Yayy! New best EMA pseudo Dice: 0.9020000100135803 
2024-11-21 12:24:02.657720:  
2024-11-21 12:24:02.657949: Epoch 45 
2024-11-21 12:24:02.658051: Current learning rate: 0.00959 
2024-11-21 12:24:54.719445: train_loss -0.9276 
2024-11-21 12:24:54.719753: val_loss -0.8894 
2024-11-21 12:24:54.719803: Pseudo dice [np.float32(0.9028)] 
2024-11-21 12:24:54.719859: Epoch time: 52.06 s 
2024-11-21 12:24:54.719904: Yayy! New best EMA pseudo Dice: 0.9021000266075134 
2024-11-21 12:24:55.993631:  
2024-11-21 12:24:55.993828: Epoch 46 
2024-11-21 12:24:55.993903: Current learning rate: 0.00959 
2024-11-21 12:25:48.555128: train_loss -0.9277 
2024-11-21 12:25:48.555258: val_loss -0.888 
2024-11-21 12:25:48.555309: Pseudo dice [np.float32(0.9036)] 
2024-11-21 12:25:48.555377: Epoch time: 52.56 s 
2024-11-21 12:25:48.555421: Yayy! New best EMA pseudo Dice: 0.9021999835968018 
2024-11-21 12:25:49.827242:  
2024-11-21 12:25:49.827362: Epoch 47 
2024-11-21 12:25:49.827441: Current learning rate: 0.00958 
2024-11-21 12:26:42.176590: train_loss -0.9277 
2024-11-21 12:26:42.176734: val_loss -0.8901 
2024-11-21 12:26:42.176787: Pseudo dice [np.float32(0.906)] 
2024-11-21 12:26:42.176844: Epoch time: 52.35 s 
2024-11-21 12:26:42.176892: Yayy! New best EMA pseudo Dice: 0.9025999903678894 
2024-11-21 12:26:43.803300:  
2024-11-21 12:26:43.803452: Epoch 48 
2024-11-21 12:26:43.803581: Current learning rate: 0.00957 
2024-11-21 12:27:36.155977: train_loss -0.931 
2024-11-21 12:27:36.156102: val_loss -0.8956 
2024-11-21 12:27:36.156161: Pseudo dice [np.float32(0.9095)] 
2024-11-21 12:27:36.156254: Epoch time: 52.35 s 
2024-11-21 12:27:36.156308: Yayy! New best EMA pseudo Dice: 0.9032999873161316 
2024-11-21 12:27:37.421041:  
2024-11-21 12:27:37.421189: Epoch 49 
2024-11-21 12:27:37.421258: Current learning rate: 0.00956 
2024-11-21 12:28:29.579176: train_loss -0.9304 
2024-11-21 12:28:29.579304: val_loss -0.8957 
2024-11-21 12:28:29.579368: Pseudo dice [np.float32(0.9089)] 
2024-11-21 12:28:29.579436: Epoch time: 52.16 s 
2024-11-21 12:28:29.812437: Yayy! New best EMA pseudo Dice: 0.9039000272750854 
2024-11-21 12:28:31.205262:  
2024-11-21 12:28:31.205492: Epoch 50 
2024-11-21 12:28:31.205585: Current learning rate: 0.00955 
2024-11-21 12:29:23.415810: train_loss -0.9329 
2024-11-21 12:29:23.415942: val_loss -0.894 
2024-11-21 12:29:23.416028: Pseudo dice [np.float32(0.9067)] 
2024-11-21 12:29:23.416109: Epoch time: 52.21 s 
2024-11-21 12:29:23.416170: Yayy! New best EMA pseudo Dice: 0.9041000008583069 
2024-11-21 12:29:24.688988:  
2024-11-21 12:29:24.689131: Epoch 51 
2024-11-21 12:29:24.689201: Current learning rate: 0.00954 
2024-11-21 12:30:16.925389: train_loss -0.9319 
2024-11-21 12:30:16.925618: val_loss -0.8941 
2024-11-21 12:30:16.925688: Pseudo dice [np.float32(0.908)] 
2024-11-21 12:30:16.925761: Epoch time: 52.24 s 
2024-11-21 12:30:16.925848: Yayy! New best EMA pseudo Dice: 0.9045000076293945 
2024-11-21 12:30:18.255707:  
2024-11-21 12:30:18.255893: Epoch 52 
2024-11-21 12:30:18.255981: Current learning rate: 0.00953 
2024-11-21 12:31:10.396610: train_loss -0.9313 
2024-11-21 12:31:10.396746: val_loss -0.8935 
2024-11-21 12:31:10.396795: Pseudo dice [np.float32(0.9066)] 
2024-11-21 12:31:10.396850: Epoch time: 52.14 s 
2024-11-21 12:31:10.396893: Yayy! New best EMA pseudo Dice: 0.904699981212616 
2024-11-21 12:31:11.649723:  
2024-11-21 12:31:11.649964: Epoch 53 
2024-11-21 12:31:11.650034: Current learning rate: 0.00952 
2024-11-21 12:32:03.973041: train_loss -0.9324 
2024-11-21 12:32:03.973171: val_loss -0.897 
2024-11-21 12:32:03.973233: Pseudo dice [np.float32(0.911)] 
2024-11-21 12:32:03.973299: Epoch time: 52.32 s 
2024-11-21 12:32:03.973356: Yayy! New best EMA pseudo Dice: 0.9053999781608582 
2024-11-21 12:32:05.276906:  
2024-11-21 12:32:05.277071: Epoch 54 
2024-11-21 12:32:05.277153: Current learning rate: 0.00951 
2024-11-21 12:32:57.414287: train_loss -0.9326 
2024-11-21 12:32:57.414416: val_loss -0.8956 
2024-11-21 12:32:57.414466: Pseudo dice [np.float32(0.9099)] 
2024-11-21 12:32:57.414577: Epoch time: 52.14 s 
2024-11-21 12:32:57.414648: Yayy! New best EMA pseudo Dice: 0.9057999849319458 
2024-11-21 12:32:58.649317:  
2024-11-21 12:32:58.649456: Epoch 55 
2024-11-21 12:32:58.649591: Current learning rate: 0.0095 
2024-11-21 12:33:50.950335: train_loss -0.9346 
2024-11-21 12:33:50.950465: val_loss -0.8961 
2024-11-21 12:33:50.950536: Pseudo dice [np.float32(0.9098)] 
2024-11-21 12:33:50.950611: Epoch time: 52.3 s 
2024-11-21 12:33:50.950673: Yayy! New best EMA pseudo Dice: 0.9061999917030334 
2024-11-21 12:33:52.269300:  
2024-11-21 12:33:52.269488: Epoch 56 
2024-11-21 12:33:52.269574: Current learning rate: 0.00949 
2024-11-21 12:34:44.474434: train_loss -0.9345 
2024-11-21 12:34:44.474634: val_loss -0.8989 
2024-11-21 12:34:44.474716: Pseudo dice [np.float32(0.9122)] 
2024-11-21 12:34:44.474871: Epoch time: 52.21 s 
2024-11-21 12:34:44.474985: Yayy! New best EMA pseudo Dice: 0.9067999720573425 
2024-11-21 12:34:45.815271:  
2024-11-21 12:34:45.815434: Epoch 57 
2024-11-21 12:34:45.815565: Current learning rate: 0.00949 
2024-11-21 12:35:38.371107: train_loss -0.9343 
2024-11-21 12:35:38.371339: val_loss -0.9007 
2024-11-21 12:35:38.371404: Pseudo dice [np.float32(0.915)] 
2024-11-21 12:35:38.371479: Epoch time: 52.56 s 
2024-11-21 12:35:38.371541: Yayy! New best EMA pseudo Dice: 0.9075999855995178 
2024-11-21 12:35:39.747100:  
2024-11-21 12:35:39.747276: Epoch 58 
2024-11-21 12:35:39.747364: Current learning rate: 0.00948 
2024-11-21 12:36:32.063313: train_loss -0.9301 
2024-11-21 12:36:32.063450: val_loss -0.889 
2024-11-21 12:36:32.063600: Pseudo dice [np.float32(0.9049)] 
2024-11-21 12:36:32.063731: Epoch time: 52.32 s 
2024-11-21 12:36:33.002223:  
2024-11-21 12:36:33.002420: Epoch 59 
2024-11-21 12:36:33.002510: Current learning rate: 0.00947 
2024-11-21 12:37:25.134494: train_loss -0.9315 
2024-11-21 12:37:25.134622: val_loss -0.8947 
2024-11-21 12:37:25.134684: Pseudo dice [np.float32(0.909)] 
2024-11-21 12:37:25.134753: Epoch time: 52.13 s 
2024-11-21 12:37:26.378977:  
2024-11-21 12:37:26.379129: Epoch 60 
2024-11-21 12:37:26.379198: Current learning rate: 0.00946 
2024-11-21 12:38:18.895316: train_loss -0.9347 
2024-11-21 12:38:18.895430: val_loss -0.8966 
2024-11-21 12:38:18.895510: Pseudo dice [np.float32(0.9112)] 
2024-11-21 12:38:18.895654: Epoch time: 52.52 s 
2024-11-21 12:38:18.895700: Yayy! New best EMA pseudo Dice: 0.9078999757766724 
2024-11-21 12:38:20.190817:  
2024-11-21 12:38:20.191005: Epoch 61 
2024-11-21 12:38:20.191075: Current learning rate: 0.00945 
2024-11-21 12:39:12.482230: train_loss -0.9357 
2024-11-21 12:39:12.482347: val_loss -0.9011 
2024-11-21 12:39:12.482399: Pseudo dice [np.float32(0.9153)] 
2024-11-21 12:39:12.482462: Epoch time: 52.29 s 
2024-11-21 12:39:12.482565: Yayy! New best EMA pseudo Dice: 0.9085999727249146 
2024-11-21 12:39:13.778429:  
2024-11-21 12:39:13.778639: Epoch 62 
2024-11-21 12:39:13.778709: Current learning rate: 0.00944 
2024-11-21 12:40:05.886848: train_loss -0.9355 
2024-11-21 12:40:05.886996: val_loss -0.8924 
2024-11-21 12:40:05.887049: Pseudo dice [np.float32(0.9055)] 
2024-11-21 12:40:05.887123: Epoch time: 52.11 s 
2024-11-21 12:40:06.877199:  
2024-11-21 12:40:06.877349: Epoch 63 
2024-11-21 12:40:06.877491: Current learning rate: 0.00943 
2024-11-21 12:40:59.139985: train_loss -0.9366 
2024-11-21 12:40:59.140102: val_loss -0.8956 
2024-11-21 12:40:59.140151: Pseudo dice [np.float32(0.9098)] 
2024-11-21 12:40:59.140204: Epoch time: 52.26 s 
2024-11-21 12:41:00.160298:  
2024-11-21 12:41:00.160483: Epoch 64 
2024-11-21 12:41:00.160587: Current learning rate: 0.00942 
2024-11-21 12:41:52.237164: train_loss -0.9346 
2024-11-21 12:41:52.237291: val_loss -0.901 
2024-11-21 12:41:52.237354: Pseudo dice [np.float32(0.9159)] 
2024-11-21 12:41:52.237421: Epoch time: 52.08 s 
2024-11-21 12:41:52.237486: Yayy! New best EMA pseudo Dice: 0.9092000126838684 
2024-11-21 12:41:53.570049:  
2024-11-21 12:41:53.570251: Epoch 65 
2024-11-21 12:41:53.570332: Current learning rate: 0.00941 
2024-11-21 12:42:45.770654: train_loss -0.9374 
2024-11-21 12:42:45.770788: val_loss -0.8976 
2024-11-21 12:42:45.770835: Pseudo dice [np.float32(0.9102)] 
2024-11-21 12:42:45.770890: Epoch time: 52.2 s 
2024-11-21 12:42:45.770933: Yayy! New best EMA pseudo Dice: 0.9093000292778015 
2024-11-21 12:42:47.008010:  
2024-11-21 12:42:47.008179: Epoch 66 
2024-11-21 12:42:47.008256: Current learning rate: 0.0094 
2024-11-21 12:43:39.567318: train_loss -0.9361 
2024-11-21 12:43:39.567477: val_loss -0.8928 
2024-11-21 12:43:39.567543: Pseudo dice [np.float32(0.9058)] 
2024-11-21 12:43:39.567610: Epoch time: 52.56 s 
2024-11-21 12:43:40.497359:  
2024-11-21 12:43:40.497533: Epoch 67 
2024-11-21 12:43:40.497601: Current learning rate: 0.00939 
2024-11-21 12:44:33.205375: train_loss -0.9381 
2024-11-21 12:44:33.205547: val_loss -0.8988 
2024-11-21 12:44:33.205634: Pseudo dice [np.float32(0.9123)] 
2024-11-21 12:44:33.205687: Epoch time: 52.71 s 
2024-11-21 12:44:34.117706:  
2024-11-21 12:44:34.117839: Epoch 68 
2024-11-21 12:44:34.117906: Current learning rate: 0.00939 
2024-11-21 12:45:26.382460: train_loss -0.9368 
2024-11-21 12:45:26.382637: val_loss -0.897 
2024-11-21 12:45:26.382685: Pseudo dice [np.float32(0.9091)] 
2024-11-21 12:45:26.382737: Epoch time: 52.27 s 
2024-11-21 12:45:27.342331:  
2024-11-21 12:45:27.342540: Epoch 69 
2024-11-21 12:45:27.342632: Current learning rate: 0.00938 
2024-11-21 12:46:19.369800: train_loss -0.938 
2024-11-21 12:46:19.369976: val_loss -0.8904 
2024-11-21 12:46:19.370031: Pseudo dice [np.float32(0.9066)] 
2024-11-21 12:46:19.370085: Epoch time: 52.03 s 
2024-11-21 12:46:20.320059:  
2024-11-21 12:46:20.320226: Epoch 70 
2024-11-21 12:46:20.320370: Current learning rate: 0.00937 
2024-11-21 12:47:12.481747: train_loss -0.939 
2024-11-21 12:47:12.481916: val_loss -0.8985 
2024-11-21 12:47:12.481966: Pseudo dice [np.float32(0.9103)] 
2024-11-21 12:47:12.482090: Epoch time: 52.16 s 
2024-11-21 12:47:13.803809:  
2024-11-21 12:47:13.803989: Epoch 71 
2024-11-21 12:47:13.804079: Current learning rate: 0.00936 
2024-11-21 12:48:06.014241: train_loss -0.9396 
2024-11-21 12:48:06.014348: val_loss -0.9013 
2024-11-21 12:48:06.014394: Pseudo dice [np.float32(0.9136)] 
2024-11-21 12:48:06.014444: Epoch time: 52.21 s 
2024-11-21 12:48:06.014552: Yayy! New best EMA pseudo Dice: 0.909600019454956 
2024-11-21 12:48:07.309203:  
2024-11-21 12:48:07.309355: Epoch 72 
2024-11-21 12:48:07.309425: Current learning rate: 0.00935 
2024-11-21 12:48:59.692451: train_loss -0.9401 
2024-11-21 12:48:59.692627: val_loss -0.8881 
2024-11-21 12:48:59.692680: Pseudo dice [np.float32(0.9031)] 
2024-11-21 12:48:59.692744: Epoch time: 52.38 s 
2024-11-21 12:49:00.725326:  
2024-11-21 12:49:00.725503: Epoch 73 
2024-11-21 12:49:00.725606: Current learning rate: 0.00934 
2024-11-21 12:49:52.914505: train_loss -0.9381 
2024-11-21 12:49:52.914643: val_loss -0.8968 
2024-11-21 12:49:52.914764: Pseudo dice [np.float32(0.9108)] 
2024-11-21 12:49:52.914873: Epoch time: 52.19 s 
2024-11-21 12:49:53.934236:  
2024-11-21 12:49:53.934427: Epoch 74 
2024-11-21 12:49:53.934522: Current learning rate: 0.00933 
2024-11-21 12:50:46.317817: train_loss -0.939 
2024-11-21 12:50:46.317944: val_loss -0.8996 
2024-11-21 12:50:46.317994: Pseudo dice [np.float32(0.9123)] 
2024-11-21 12:50:46.318069: Epoch time: 52.38 s 
2024-11-21 12:50:47.333072:  
2024-11-21 12:50:47.333278: Epoch 75 
2024-11-21 12:50:47.333382: Current learning rate: 0.00932 
2024-11-21 12:51:39.631333: train_loss -0.9392 
2024-11-21 12:51:39.631459: val_loss -0.9019 
2024-11-21 12:51:39.631556: Pseudo dice [np.float32(0.9137)] 
2024-11-21 12:51:39.631613: Epoch time: 52.3 s 
2024-11-21 12:51:39.631658: Yayy! New best EMA pseudo Dice: 0.9099000096321106 
2024-11-21 12:51:40.966760:  
2024-11-21 12:51:40.966912: Epoch 76 
2024-11-21 12:51:40.966979: Current learning rate: 0.00931 
2024-11-21 12:52:32.899901: train_loss -0.9416 
2024-11-21 12:52:32.900050: val_loss -0.8983 
2024-11-21 12:52:32.900114: Pseudo dice [np.float32(0.912)] 
2024-11-21 12:52:32.900182: Epoch time: 51.93 s 
2024-11-21 12:52:32.900241: Yayy! New best EMA pseudo Dice: 0.910099983215332 
2024-11-21 12:52:34.277100:  
2024-11-21 12:52:34.277281: Epoch 77 
2024-11-21 12:52:34.277403: Current learning rate: 0.0093 
2024-11-21 12:53:26.455446: train_loss -0.9418 
2024-11-21 12:53:26.455656: val_loss -0.8952 
2024-11-21 12:53:26.455705: Pseudo dice [np.float32(0.9083)] 
2024-11-21 12:53:26.455761: Epoch time: 52.18 s 
2024-11-21 12:53:27.464973:  
2024-11-21 12:53:27.465108: Epoch 78 
2024-11-21 12:53:27.465209: Current learning rate: 0.0093 
2024-11-21 12:54:19.800580: train_loss -0.941 
2024-11-21 12:54:19.800733: val_loss -0.8991 
2024-11-21 12:54:19.800799: Pseudo dice [np.float32(0.9137)] 
2024-11-21 12:54:19.800868: Epoch time: 52.34 s 
2024-11-21 12:54:19.800927: Yayy! New best EMA pseudo Dice: 0.9103000164031982 
2024-11-21 12:54:21.129059:  
2024-11-21 12:54:21.129229: Epoch 79 
2024-11-21 12:54:21.129316: Current learning rate: 0.00929 
2024-11-21 12:55:13.332430: train_loss -0.9434 
2024-11-21 12:55:13.332589: val_loss -0.8987 
2024-11-21 12:55:13.332694: Pseudo dice [np.float32(0.9117)] 
2024-11-21 12:55:13.332763: Epoch time: 52.2 s 
2024-11-21 12:55:13.332821: Yayy! New best EMA pseudo Dice: 0.9103999733924866 
2024-11-21 12:55:14.839642:  
2024-11-21 12:55:14.839787: Epoch 80 
2024-11-21 12:55:14.839853: Current learning rate: 0.00928 
2024-11-21 12:56:06.594223: train_loss -0.9399 
2024-11-21 12:56:06.594360: val_loss -0.898 
2024-11-21 12:56:06.594408: Pseudo dice [np.float32(0.9119)] 
2024-11-21 12:56:06.594460: Epoch time: 51.76 s 
2024-11-21 12:56:06.594563: Yayy! New best EMA pseudo Dice: 0.9106000065803528 
2024-11-21 12:56:07.915107:  
2024-11-21 12:56:07.915242: Epoch 81 
2024-11-21 12:56:07.915308: Current learning rate: 0.00927 
2024-11-21 12:56:59.531894: train_loss -0.938 
2024-11-21 12:56:59.532015: val_loss -0.8933 
2024-11-21 12:56:59.532102: Pseudo dice [np.float32(0.9058)] 
2024-11-21 12:56:59.532205: Epoch time: 51.62 s 
2024-11-21 12:57:00.980278:  
2024-11-21 12:57:00.980489: Epoch 82 
2024-11-21 12:57:00.980613: Current learning rate: 0.00926 
2024-11-21 12:57:52.719380: train_loss -0.9409 
2024-11-21 12:57:52.719526: val_loss -0.9009 
2024-11-21 12:57:52.719603: Pseudo dice [np.float32(0.9158)] 
2024-11-21 12:57:52.719673: Epoch time: 51.74 s 
2024-11-21 12:57:52.719732: Yayy! New best EMA pseudo Dice: 0.9107000231742859 
2024-11-21 12:57:53.968560:  
2024-11-21 12:57:53.968787: Epoch 83 
2024-11-21 12:57:53.968889: Current learning rate: 0.00925 
2024-11-21 12:58:45.932738: train_loss -0.9426 
2024-11-21 12:58:45.932867: val_loss -0.8961 
2024-11-21 12:58:45.932919: Pseudo dice [np.float32(0.9098)] 
2024-11-21 12:58:45.932972: Epoch time: 51.96 s 
2024-11-21 12:58:46.926558:  
2024-11-21 12:58:46.926750: Epoch 84 
2024-11-21 12:58:46.926831: Current learning rate: 0.00924 
2024-11-21 12:59:38.756510: train_loss -0.9434 
2024-11-21 12:59:38.756647: val_loss -0.8924 
2024-11-21 12:59:38.756730: Pseudo dice [np.float32(0.906)] 
2024-11-21 12:59:38.756785: Epoch time: 51.83 s 
2024-11-21 12:59:39.735151:  
2024-11-21 12:59:39.735387: Epoch 85 
2024-11-21 12:59:39.735476: Current learning rate: 0.00923 
2024-11-21 13:00:31.745608: train_loss -0.9399 
2024-11-21 13:00:31.745725: val_loss -0.893 
2024-11-21 13:00:31.745778: Pseudo dice [np.float32(0.9072)] 
2024-11-21 13:00:31.745836: Epoch time: 52.01 s 
2024-11-21 13:00:32.689304:  
2024-11-21 13:00:32.689502: Epoch 86 
2024-11-21 13:00:32.689603: Current learning rate: 0.00922 
2024-11-21 13:01:24.515606: train_loss -0.9342 
2024-11-21 13:01:24.515728: val_loss -0.9005 
2024-11-21 13:01:24.515778: Pseudo dice [np.float32(0.9147)] 
2024-11-21 13:01:24.515831: Epoch time: 51.83 s 
2024-11-21 13:01:25.574306:  
2024-11-21 13:01:25.574502: Epoch 87 
2024-11-21 13:01:25.574619: Current learning rate: 0.00921 
2024-11-21 13:02:17.652195: train_loss -0.9398 
2024-11-21 13:02:17.652351: val_loss -0.8907 
2024-11-21 13:02:17.652403: Pseudo dice [np.float32(0.9061)] 
2024-11-21 13:02:17.652455: Epoch time: 52.08 s 
2024-11-21 13:02:18.585507:  
2024-11-21 13:02:18.585675: Epoch 88 
2024-11-21 13:02:18.585743: Current learning rate: 0.0092 
2024-11-21 13:03:10.275769: train_loss -0.9399 
2024-11-21 13:03:10.275890: val_loss -0.8939 
2024-11-21 13:03:10.275942: Pseudo dice [np.float32(0.9088)] 
2024-11-21 13:03:10.275998: Epoch time: 51.69 s 
2024-11-21 13:03:11.317989:  
2024-11-21 13:03:11.318225: Epoch 89 
2024-11-21 13:03:11.318320: Current learning rate: 0.0092 
2024-11-21 13:04:03.389541: train_loss -0.942 
2024-11-21 13:04:03.389679: val_loss -0.8985 
2024-11-21 13:04:03.389727: Pseudo dice [np.float32(0.9107)] 
2024-11-21 13:04:03.389781: Epoch time: 52.07 s 
2024-11-21 13:04:04.358654:  
2024-11-21 13:04:04.358885: Epoch 90 
2024-11-21 13:04:04.359043: Current learning rate: 0.00919 
2024-11-21 13:04:56.640642: train_loss -0.9423 
2024-11-21 13:04:56.640806: val_loss -0.9049 
2024-11-21 13:04:56.640872: Pseudo dice [np.float32(0.9167)] 
2024-11-21 13:04:56.640944: Epoch time: 52.28 s 
2024-11-21 13:04:57.594270:  
2024-11-21 13:04:57.594455: Epoch 91 
2024-11-21 13:04:57.594546: Current learning rate: 0.00918 
2024-11-21 13:05:49.848231: train_loss -0.9437 
2024-11-21 13:05:49.848377: val_loss -0.8991 
2024-11-21 13:05:49.848440: Pseudo dice [np.float32(0.9119)] 
2024-11-21 13:05:49.848529: Epoch time: 52.25 s 
2024-11-21 13:05:49.848602: Yayy! New best EMA pseudo Dice: 0.9107000231742859 
2024-11-21 13:05:51.050672:  
2024-11-21 13:05:51.050847: Epoch 92 
2024-11-21 13:05:51.050914: Current learning rate: 0.00917 
2024-11-21 13:06:43.191659: train_loss -0.943 
2024-11-21 13:06:43.191793: val_loss -0.8942 
2024-11-21 13:06:43.191842: Pseudo dice [np.float32(0.9071)] 
2024-11-21 13:06:43.191895: Epoch time: 52.14 s 
2024-11-21 13:06:44.138361:  
2024-11-21 13:06:44.138623: Epoch 93 
2024-11-21 13:06:44.138692: Current learning rate: 0.00916 
2024-11-21 13:07:36.587823: train_loss -0.9382 
2024-11-21 13:07:36.587959: val_loss -0.8921 
2024-11-21 13:07:36.588022: Pseudo dice [np.float32(0.9063)] 
2024-11-21 13:07:36.588088: Epoch time: 52.45 s 
2024-11-21 13:07:37.508902:  
2024-11-21 13:07:37.509102: Epoch 94 
2024-11-21 13:07:37.509224: Current learning rate: 0.00915 
2024-11-21 13:08:29.920689: train_loss -0.9387 
2024-11-21 13:08:29.920858: val_loss -0.8863 
2024-11-21 13:08:29.920936: Pseudo dice [np.float32(0.9035)] 
2024-11-21 13:08:29.921024: Epoch time: 52.41 s 
2024-11-21 13:08:31.168121:  
2024-11-21 13:08:31.168345: Epoch 95 
2024-11-21 13:08:31.168438: Current learning rate: 0.00914 
2024-11-21 13:09:23.322586: train_loss -0.9354 
2024-11-21 13:09:23.322742: val_loss -0.9014 
2024-11-21 13:09:23.322804: Pseudo dice [np.float32(0.9147)] 
2024-11-21 13:09:23.322871: Epoch time: 52.16 s 
2024-11-21 13:09:24.261392:  
2024-11-21 13:09:24.261590: Epoch 96 
2024-11-21 13:09:24.261657: Current learning rate: 0.00913 
2024-11-21 13:10:16.357045: train_loss -0.9378 
2024-11-21 13:10:16.357173: val_loss -0.887 
2024-11-21 13:10:16.357237: Pseudo dice [np.float32(0.9022)] 
2024-11-21 13:10:16.357308: Epoch time: 52.1 s 
2024-11-21 13:10:17.331306:  
2024-11-21 13:10:17.331556: Epoch 97 
2024-11-21 13:10:17.331644: Current learning rate: 0.00912 
2024-11-21 13:11:09.508717: train_loss -0.9392 
2024-11-21 13:11:09.508904: val_loss -0.8958 
2024-11-21 13:11:09.508970: Pseudo dice [np.float32(0.9078)] 
2024-11-21 13:11:09.509040: Epoch time: 52.18 s 
2024-11-21 13:11:10.481263:  
2024-11-21 13:11:10.481415: Epoch 98 
2024-11-21 13:11:10.481531: Current learning rate: 0.00911 
2024-11-21 13:12:02.497592: train_loss -0.9429 
2024-11-21 13:12:02.497720: val_loss -0.8896 
2024-11-21 13:12:02.498613: Pseudo dice [np.float32(0.9044)] 
2024-11-21 13:12:02.498671: Epoch time: 52.02 s 
2024-11-21 13:12:03.437164:  
2024-11-21 13:12:03.437344: Epoch 99 
2024-11-21 13:12:03.437436: Current learning rate: 0.0091 
2024-11-21 13:12:55.658995: train_loss -0.9436 
2024-11-21 13:12:55.659127: val_loss -0.8987 
2024-11-21 13:12:55.659179: Pseudo dice [np.float32(0.9126)] 
2024-11-21 13:12:55.659235: Epoch time: 52.22 s 
2024-11-21 13:12:56.989843:  
2024-11-21 13:12:56.989985: Epoch 100 
2024-11-21 13:12:56.990075: Current learning rate: 0.0091 
2024-11-21 13:13:48.902430: train_loss -0.9431 
2024-11-21 13:13:48.902600: val_loss -0.8998 
2024-11-21 13:13:48.902647: Pseudo dice [np.float32(0.9133)] 
2024-11-21 13:13:48.902700: Epoch time: 51.91 s 
2024-11-21 13:13:49.838994:  
2024-11-21 13:13:49.839179: Epoch 101 
2024-11-21 13:13:49.839264: Current learning rate: 0.00909 
2024-11-21 13:14:42.181609: train_loss -0.9442 
2024-11-21 13:14:42.181739: val_loss -0.8933 
2024-11-21 13:14:42.181802: Pseudo dice [np.float32(0.9069)] 
2024-11-21 13:14:42.181871: Epoch time: 52.34 s 
2024-11-21 13:14:43.158950:  
2024-11-21 13:14:43.159132: Epoch 102 
2024-11-21 13:14:43.159215: Current learning rate: 0.00908 
2024-11-21 13:15:35.054829: train_loss -0.9427 
2024-11-21 13:15:35.055039: val_loss -0.8891 
2024-11-21 13:15:35.055090: Pseudo dice [np.float32(0.9047)] 
2024-11-21 13:15:35.055145: Epoch time: 51.9 s 
2024-11-21 13:15:36.099555:  
2024-11-21 13:15:36.099750: Epoch 103 
2024-11-21 13:15:36.099839: Current learning rate: 0.00907 
2024-11-21 13:16:28.428267: train_loss -0.9449 
2024-11-21 13:16:28.428422: val_loss -0.8978 
2024-11-21 13:16:28.428496: Pseudo dice [np.float32(0.912)] 
2024-11-21 13:16:28.428565: Epoch time: 52.33 s 
2024-11-21 13:16:29.341897:  
2024-11-21 13:16:29.342034: Epoch 104 
2024-11-21 13:16:29.342129: Current learning rate: 0.00906 
2024-11-21 13:17:21.475028: train_loss -0.9454 
2024-11-21 13:17:21.475139: val_loss -0.9017 
2024-11-21 13:17:21.475189: Pseudo dice [np.float32(0.9142)] 
2024-11-21 13:17:21.475262: Epoch time: 52.13 s 
2024-11-21 13:17:22.380791:  
2024-11-21 13:17:22.380969: Epoch 105 
2024-11-21 13:17:22.381037: Current learning rate: 0.00905 
2024-11-21 13:18:14.575033: train_loss -0.9447 
2024-11-21 13:18:14.575166: val_loss -0.8996 
2024-11-21 13:18:14.575216: Pseudo dice [np.float32(0.9131)] 
2024-11-21 13:18:14.575271: Epoch time: 52.2 s 
2024-11-21 13:18:15.575966:  
2024-11-21 13:18:15.576197: Epoch 106 
2024-11-21 13:18:15.576277: Current learning rate: 0.00904 
2024-11-21 13:19:08.102413: train_loss -0.9484 
2024-11-21 13:19:08.102591: val_loss -0.8987 
2024-11-21 13:19:08.102674: Pseudo dice [np.float32(0.9116)] 
2024-11-21 13:19:08.102782: Epoch time: 52.53 s 
2024-11-21 13:19:09.323997:  
2024-11-21 13:19:09.324224: Epoch 107 
2024-11-21 13:19:09.324295: Current learning rate: 0.00903 
2024-11-21 13:20:01.870567: train_loss -0.9463 
2024-11-21 13:20:01.870701: val_loss -0.8998 
2024-11-21 13:20:01.870787: Pseudo dice [np.float32(0.9132)] 
2024-11-21 13:20:01.870885: Epoch time: 52.55 s 
2024-11-21 13:20:02.803893:  
2024-11-21 13:20:02.804050: Epoch 108 
2024-11-21 13:20:02.804139: Current learning rate: 0.00902 
2024-11-21 13:20:55.057132: train_loss -0.9457 
2024-11-21 13:20:55.057235: val_loss -0.8974 
2024-11-21 13:20:55.057285: Pseudo dice [np.float32(0.9109)] 
2024-11-21 13:20:55.057337: Epoch time: 52.25 s 
2024-11-21 13:20:56.032914:  
2024-11-21 13:20:56.033056: Epoch 109 
2024-11-21 13:20:56.033123: Current learning rate: 0.00901 
2024-11-21 13:21:48.734513: train_loss -0.9439 
2024-11-21 13:21:48.734649: val_loss -0.8938 
2024-11-21 13:21:48.734714: Pseudo dice [np.float32(0.9079)] 
2024-11-21 13:21:48.734809: Epoch time: 52.7 s 
2024-11-21 13:21:49.657398:  
2024-11-21 13:21:49.657570: Epoch 110 
2024-11-21 13:21:49.657689: Current learning rate: 0.009 
2024-11-21 13:22:41.849973: train_loss -0.9443 
2024-11-21 13:22:41.850151: val_loss -0.8885 
2024-11-21 13:22:41.850203: Pseudo dice [np.float32(0.9028)] 
2024-11-21 13:22:41.850258: Epoch time: 52.19 s 
2024-11-21 13:22:42.783875:  
2024-11-21 13:22:42.784031: Epoch 111 
2024-11-21 13:22:42.784116: Current learning rate: 0.009 
2024-11-21 13:23:35.280447: train_loss -0.942 
2024-11-21 13:23:35.280715: val_loss -0.9006 
2024-11-21 13:23:35.280765: Pseudo dice [np.float32(0.9133)] 
2024-11-21 13:23:35.280820: Epoch time: 52.5 s 
2024-11-21 13:23:36.184917:  
2024-11-21 13:23:36.185103: Epoch 112 
2024-11-21 13:23:36.185185: Current learning rate: 0.00899 
2024-11-21 13:24:28.567641: train_loss -0.9456 
2024-11-21 13:24:28.567760: val_loss -0.9038 
2024-11-21 13:24:28.567846: Pseudo dice [np.float32(0.9159)] 
2024-11-21 13:24:28.567902: Epoch time: 52.38 s 
2024-11-21 13:24:29.496668:  
2024-11-21 13:24:29.496865: Epoch 113 
2024-11-21 13:24:29.496948: Current learning rate: 0.00898 
2024-11-21 13:25:21.878387: train_loss -0.9464 
2024-11-21 13:25:21.878527: val_loss -0.9024 
2024-11-21 13:25:21.878576: Pseudo dice [np.float32(0.9155)] 
2024-11-21 13:25:21.878632: Epoch time: 52.38 s 
2024-11-21 13:25:21.878677: Yayy! New best EMA pseudo Dice: 0.9108999967575073 
2024-11-21 13:25:23.186548:  
2024-11-21 13:25:23.186806: Epoch 114 
2024-11-21 13:25:23.186880: Current learning rate: 0.00897 
2024-11-21 13:26:15.486291: train_loss -0.9445 
2024-11-21 13:26:15.486433: val_loss -0.8922 
2024-11-21 13:26:15.486527: Pseudo dice [np.float32(0.9051)] 
2024-11-21 13:26:15.486583: Epoch time: 52.3 s 
2024-11-21 13:26:16.490734:  
2024-11-21 13:26:16.490936: Epoch 115 
2024-11-21 13:26:16.491036: Current learning rate: 0.00896 
2024-11-21 13:27:09.176929: train_loss -0.9461 
2024-11-21 13:27:09.177065: val_loss -0.8996 
2024-11-21 13:27:09.177115: Pseudo dice [np.float32(0.9109)] 
2024-11-21 13:27:09.177193: Epoch time: 52.69 s 
2024-11-21 13:27:10.075190:  
2024-11-21 13:27:10.075318: Epoch 116 
2024-11-21 13:27:10.075436: Current learning rate: 0.00895 
2024-11-21 13:28:02.438857: train_loss -0.9474 
2024-11-21 13:28:02.438983: val_loss -0.8998 
2024-11-21 13:28:02.439033: Pseudo dice [np.float32(0.9118)] 
2024-11-21 13:28:02.439103: Epoch time: 52.36 s 
2024-11-21 13:28:03.339149:  
2024-11-21 13:28:03.339345: Epoch 117 
2024-11-21 13:28:03.339483: Current learning rate: 0.00894 
2024-11-21 13:28:55.297046: train_loss -0.9485 
2024-11-21 13:28:55.297165: val_loss -0.8977 
2024-11-21 13:28:55.297212: Pseudo dice [np.float32(0.9108)] 
2024-11-21 13:28:55.297263: Epoch time: 51.96 s 
2024-11-21 13:28:56.233196:  
2024-11-21 13:28:56.233326: Epoch 118 
2024-11-21 13:28:56.233395: Current learning rate: 0.00893 
2024-11-21 13:29:48.633333: train_loss -0.9498 
2024-11-21 13:29:48.633440: val_loss -0.8923 
2024-11-21 13:29:48.633523: Pseudo dice [np.float32(0.9064)] 
2024-11-21 13:29:48.633622: Epoch time: 52.4 s 
2024-11-21 13:29:49.848150:  
2024-11-21 13:29:49.848325: Epoch 119 
2024-11-21 13:29:49.848399: Current learning rate: 0.00892 
2024-11-21 13:30:42.094539: train_loss -0.9481 
2024-11-21 13:30:42.094666: val_loss -0.8933 
2024-11-21 13:30:42.094728: Pseudo dice [np.float32(0.9077)] 
2024-11-21 13:30:42.094828: Epoch time: 52.25 s 
2024-11-21 13:30:43.004831:  
2024-11-21 13:30:43.004971: Epoch 120 
2024-11-21 13:30:43.005038: Current learning rate: 0.00891 
2024-11-21 13:31:35.041762: train_loss -0.9449 
2024-11-21 13:31:35.041927: val_loss -0.8945 
2024-11-21 13:31:35.041991: Pseudo dice [np.float32(0.9079)] 
2024-11-21 13:31:35.042059: Epoch time: 52.04 s 
2024-11-21 13:31:36.026074:  
2024-11-21 13:31:36.026431: Epoch 121 
2024-11-21 13:31:36.026521: Current learning rate: 0.0089 
2024-11-21 13:32:28.285360: train_loss -0.9444 
2024-11-21 13:32:28.285490: val_loss -0.9014 
2024-11-21 13:32:28.285553: Pseudo dice [np.float32(0.9128)] 
2024-11-21 13:32:28.285620: Epoch time: 52.26 s 
2024-11-21 13:32:29.274022:  
2024-11-21 13:32:29.274261: Epoch 122 
2024-11-21 13:32:29.274328: Current learning rate: 0.00889 
2024-11-21 13:33:21.206716: train_loss -0.9447 
2024-11-21 13:33:21.206830: val_loss -0.904 
2024-11-21 13:33:21.206877: Pseudo dice [np.float32(0.9153)] 
2024-11-21 13:33:21.206928: Epoch time: 51.93 s 
2024-11-21 13:33:22.261048:  
2024-11-21 13:33:22.261220: Epoch 123 
2024-11-21 13:33:22.261303: Current learning rate: 0.00889 
2024-11-21 13:34:14.477475: train_loss -0.9441 
2024-11-21 13:34:14.477664: val_loss -0.899 
2024-11-21 13:34:14.477720: Pseudo dice [np.float32(0.9125)] 
2024-11-21 13:34:14.477793: Epoch time: 52.22 s 
2024-11-21 13:34:15.408635:  
2024-11-21 13:34:15.408799: Epoch 124 
2024-11-21 13:34:15.408900: Current learning rate: 0.00888 
2024-11-21 13:35:07.678814: train_loss -0.9465 
2024-11-21 13:35:07.678952: val_loss -0.8956 
2024-11-21 13:35:07.679050: Pseudo dice [np.float32(0.9103)] 
2024-11-21 13:35:07.679168: Epoch time: 52.27 s 
2024-11-21 13:35:08.648558:  
2024-11-21 13:35:08.648735: Epoch 125 
2024-11-21 13:35:08.648819: Current learning rate: 0.00887 
2024-11-21 13:36:00.706119: train_loss -0.9494 
2024-11-21 13:36:00.706253: val_loss -0.9017 
2024-11-21 13:36:00.706302: Pseudo dice [np.float32(0.914)] 
2024-11-21 13:36:00.706378: Epoch time: 52.06 s 
2024-11-21 13:36:00.706436: Yayy! New best EMA pseudo Dice: 0.9110000133514404 
2024-11-21 13:36:02.098453:  
2024-11-21 13:36:02.098670: Epoch 126 
2024-11-21 13:36:02.098766: Current learning rate: 0.00886 
2024-11-21 13:36:54.113991: train_loss -0.9447 
2024-11-21 13:36:54.114108: val_loss -0.9019 
2024-11-21 13:36:54.114189: Pseudo dice [np.float32(0.914)] 
2024-11-21 13:36:54.114258: Epoch time: 52.02 s 
2024-11-21 13:36:54.114329: Yayy! New best EMA pseudo Dice: 0.911300003528595 
2024-11-21 13:36:55.518109:  
2024-11-21 13:36:55.518258: Epoch 127 
2024-11-21 13:36:55.518326: Current learning rate: 0.00885 
2024-11-21 13:37:47.677014: train_loss -0.9442 
2024-11-21 13:37:47.677145: val_loss -0.8786 
2024-11-21 13:37:47.677254: Pseudo dice [np.float32(0.8929)] 
2024-11-21 13:37:47.677328: Epoch time: 52.16 s 
2024-11-21 13:37:48.777913:  
2024-11-21 13:37:48.778169: Epoch 128 
2024-11-21 13:37:48.778254: Current learning rate: 0.00884 
2024-11-21 13:38:40.774865: train_loss -0.9409 
2024-11-21 13:38:40.774989: val_loss -0.8952 
2024-11-21 13:38:40.775054: Pseudo dice [np.float32(0.9079)] 
2024-11-21 13:38:40.775120: Epoch time: 52.0 s 
2024-11-21 13:38:41.722055:  
2024-11-21 13:38:41.722211: Epoch 129 
2024-11-21 13:38:41.722309: Current learning rate: 0.00883 
2024-11-21 13:39:33.667153: train_loss -0.9453 
2024-11-21 13:39:33.667268: val_loss -0.9002 
2024-11-21 13:39:33.667345: Pseudo dice [np.float32(0.9141)] 
2024-11-21 13:39:33.667413: Epoch time: 51.95 s 
2024-11-21 13:39:34.642172:  
2024-11-21 13:39:34.642376: Epoch 130 
2024-11-21 13:39:34.642459: Current learning rate: 0.00882 
2024-11-21 13:40:26.952856: train_loss -0.9474 
2024-11-21 13:40:26.952982: val_loss -0.8998 
2024-11-21 13:40:26.953044: Pseudo dice [np.float32(0.9126)] 
2024-11-21 13:40:26.953162: Epoch time: 52.31 s 
2024-11-21 13:40:28.199159:  
2024-11-21 13:40:28.199302: Epoch 131 
2024-11-21 13:40:28.199369: Current learning rate: 0.00881 
2024-11-21 13:41:20.784271: train_loss -0.9485 
2024-11-21 13:41:20.784382: val_loss -0.896 
2024-11-21 13:41:20.784433: Pseudo dice [np.float32(0.9098)] 
2024-11-21 13:41:20.784517: Epoch time: 52.59 s 
2024-11-21 13:41:21.747506:  
2024-11-21 13:41:21.747933: Epoch 132 
2024-11-21 13:41:21.748004: Current learning rate: 0.0088 
2024-11-21 13:42:14.062671: train_loss -0.9494 
2024-11-21 13:42:14.062800: val_loss -0.8972 
2024-11-21 13:42:14.062865: Pseudo dice [np.float32(0.9085)] 
2024-11-21 13:42:14.062934: Epoch time: 52.32 s 
2024-11-21 13:42:15.044977:  
2024-11-21 13:42:15.045223: Epoch 133 
2024-11-21 13:42:15.045337: Current learning rate: 0.00879 
2024-11-21 13:43:07.216531: train_loss -0.95 
2024-11-21 13:43:07.216667: val_loss -0.895 
2024-11-21 13:43:07.216716: Pseudo dice [np.float32(0.9077)] 
2024-11-21 13:43:07.216769: Epoch time: 52.17 s 
2024-11-21 13:43:08.089876:  
2024-11-21 13:43:08.090038: Epoch 134 
2024-11-21 13:43:08.090103: Current learning rate: 0.00879 
2024-11-21 13:44:00.430207: train_loss -0.9464 
2024-11-21 13:44:00.430325: val_loss -0.8965 
2024-11-21 13:44:00.430375: Pseudo dice [np.float32(0.9107)] 
2024-11-21 13:44:00.430429: Epoch time: 52.34 s 
2024-11-21 13:44:01.461777:  
2024-11-21 13:44:01.461946: Epoch 135 
2024-11-21 13:44:01.462030: Current learning rate: 0.00878 
2024-11-21 13:44:53.894609: train_loss -0.9475 
2024-11-21 13:44:53.894742: val_loss -0.9027 
2024-11-21 13:44:53.894792: Pseudo dice [np.float32(0.9163)] 
2024-11-21 13:44:53.894845: Epoch time: 52.43 s 
2024-11-21 13:44:54.898455:  
2024-11-21 13:44:54.898666: Epoch 136 
2024-11-21 13:44:54.898736: Current learning rate: 0.00877 
2024-11-21 13:45:47.135714: train_loss -0.9476 
2024-11-21 13:45:47.135821: val_loss -0.8995 
2024-11-21 13:45:47.135866: Pseudo dice [np.float32(0.9111)] 
2024-11-21 13:45:47.135917: Epoch time: 52.24 s 
2024-11-21 13:45:48.176570:  
2024-11-21 13:45:48.176765: Epoch 137 
2024-11-21 13:45:48.176852: Current learning rate: 0.00876 
2024-11-21 13:46:40.223131: train_loss -0.9231 
2024-11-21 13:46:40.223267: val_loss -0.8723 
2024-11-21 13:46:40.223332: Pseudo dice [np.float32(0.891)] 
2024-11-21 13:46:40.223403: Epoch time: 52.05 s 
2024-11-21 13:46:41.255255:  
2024-11-21 13:46:41.255444: Epoch 138 
2024-11-21 13:46:41.255604: Current learning rate: 0.00875 
2024-11-21 13:47:33.602181: train_loss -0.9179 
2024-11-21 13:47:33.602308: val_loss -0.8782 
2024-11-21 13:47:33.602407: Pseudo dice [np.float32(0.8972)] 
2024-11-21 13:47:33.602505: Epoch time: 52.35 s 
2024-11-21 13:47:34.654423:  
2024-11-21 13:47:34.654569: Epoch 139 
2024-11-21 13:47:34.654644: Current learning rate: 0.00874 
2024-11-21 13:48:26.884842: train_loss -0.9327 
2024-11-21 13:48:26.884956: val_loss -0.8958 
2024-11-21 13:48:26.885005: Pseudo dice [np.float32(0.9097)] 
2024-11-21 13:48:26.885059: Epoch time: 52.23 s 
2024-11-21 13:48:27.782703:  
2024-11-21 13:48:27.782868: Epoch 140 
2024-11-21 13:48:27.782939: Current learning rate: 0.00873 
2024-11-21 13:49:20.032625: train_loss -0.9388 
2024-11-21 13:49:20.032774: val_loss -0.881 
2024-11-21 13:49:20.032852: Pseudo dice [np.float32(0.8974)] 
2024-11-21 13:49:20.032939: Epoch time: 52.25 s 
2024-11-21 13:49:21.005882:  
2024-11-21 13:49:21.006026: Epoch 141 
2024-11-21 13:49:21.006093: Current learning rate: 0.00872 
2024-11-21 13:50:13.491155: train_loss -0.9412 
2024-11-21 13:50:13.491306: val_loss -0.8908 
2024-11-21 13:50:13.491356: Pseudo dice [np.float32(0.9041)] 
2024-11-21 13:50:13.491413: Epoch time: 52.49 s 
2024-11-21 13:50:14.788820:  
2024-11-21 13:50:14.789124: Epoch 142 
2024-11-21 13:50:14.789228: Current learning rate: 0.00871 
2024-11-21 13:51:07.075763: train_loss -0.9445 
2024-11-21 13:51:07.075879: val_loss -0.8903 
2024-11-21 13:51:07.075932: Pseudo dice [np.float32(0.9056)] 
2024-11-21 13:51:07.075985: Epoch time: 52.29 s 
2024-11-21 13:51:08.073433:  
2024-11-21 13:51:08.073673: Epoch 143 
2024-11-21 13:51:08.073753: Current learning rate: 0.0087 
2024-11-21 13:52:00.617341: train_loss -0.946 
2024-11-21 13:52:00.617460: val_loss -0.8973 
2024-11-21 13:52:00.617516: Pseudo dice [np.float32(0.9111)] 
2024-11-21 13:52:00.617569: Epoch time: 52.54 s 
2024-11-21 13:52:01.716123:  
2024-11-21 13:52:01.716259: Epoch 144 
2024-11-21 13:52:01.716328: Current learning rate: 0.00869 
2024-11-21 13:52:53.790174: train_loss -0.948 
2024-11-21 13:52:53.790297: val_loss -0.8998 
2024-11-21 13:52:53.790343: Pseudo dice [np.float32(0.913)] 
2024-11-21 13:52:53.790393: Epoch time: 52.07 s 
2024-11-21 13:52:54.665111:  
2024-11-21 13:52:54.665252: Epoch 145 
2024-11-21 13:52:54.665328: Current learning rate: 0.00868 
2024-11-21 13:53:46.677931: train_loss -0.9485 
2024-11-21 13:53:46.678061: val_loss -0.8962 
2024-11-21 13:53:46.678124: Pseudo dice [np.float32(0.9089)] 
2024-11-21 13:53:46.678193: Epoch time: 52.01 s 
2024-11-21 13:53:47.697838:  
2024-11-21 13:53:47.698003: Epoch 146 
2024-11-21 13:53:47.698071: Current learning rate: 0.00868 
2024-11-21 13:54:39.783627: train_loss -0.9509 
2024-11-21 13:54:39.783742: val_loss -0.894 
2024-11-21 13:54:39.783789: Pseudo dice [np.float32(0.9079)] 
2024-11-21 13:54:39.783841: Epoch time: 52.09 s 
2024-11-21 13:54:40.796992:  
2024-11-21 13:54:40.797169: Epoch 147 
2024-11-21 13:54:40.797254: Current learning rate: 0.00867 
2024-11-21 13:55:33.227923: train_loss -0.9512 
2024-11-21 13:55:33.228051: val_loss -0.9004 
2024-11-21 13:55:33.228115: Pseudo dice [np.float32(0.9144)] 
2024-11-21 13:55:33.228182: Epoch time: 52.43 s 
2024-11-21 13:55:34.249606:  
2024-11-21 13:55:34.249829: Epoch 148 
2024-11-21 13:55:34.249942: Current learning rate: 0.00866 
2024-11-21 13:56:26.509889: train_loss -0.9513 
2024-11-21 13:56:26.510008: val_loss -0.894 
2024-11-21 13:56:26.510071: Pseudo dice [np.float32(0.9071)] 
2024-11-21 13:56:26.510140: Epoch time: 52.26 s 
2024-11-21 13:56:27.497725:  
2024-11-21 13:56:27.497921: Epoch 149 
2024-11-21 13:56:27.498011: Current learning rate: 0.00865 
2024-11-21 13:57:19.602480: train_loss -0.9526 
2024-11-21 13:57:19.602678: val_loss -0.8967 
2024-11-21 13:57:19.602752: Pseudo dice [np.float32(0.9095)] 
2024-11-21 13:57:19.602806: Epoch time: 52.11 s 
2024-11-21 13:57:20.964769:  
2024-11-21 13:57:20.964945: Epoch 150 
2024-11-21 13:57:20.965057: Current learning rate: 0.00864 
2024-11-21 13:58:13.553287: train_loss -0.9509 
2024-11-21 13:58:13.553438: val_loss -0.9 
2024-11-21 13:58:13.553523: Pseudo dice [np.float32(0.9139)] 
2024-11-21 13:58:13.553596: Epoch time: 52.59 s 
2024-11-21 13:58:14.539001:  
2024-11-21 13:58:14.539197: Epoch 151 
2024-11-21 13:58:14.539284: Current learning rate: 0.00863 
2024-11-21 13:59:07.021118: train_loss -0.9491 
2024-11-21 13:59:07.021244: val_loss -0.8981 
2024-11-21 13:59:07.021306: Pseudo dice [np.float32(0.9116)] 
2024-11-21 13:59:07.021373: Epoch time: 52.48 s 
2024-11-21 13:59:07.989478:  
2024-11-21 13:59:07.989707: Epoch 152 
2024-11-21 13:59:07.989779: Current learning rate: 0.00862 
2024-11-21 14:00:00.193362: train_loss -0.9515 
2024-11-21 14:00:00.193501: val_loss -0.8998 
2024-11-21 14:00:00.193570: Pseudo dice [np.float32(0.9123)] 
2024-11-21 14:00:00.193625: Epoch time: 52.2 s 
2024-11-21 14:00:01.171654:  
2024-11-21 14:00:01.171875: Epoch 153 
2024-11-21 14:00:01.171947: Current learning rate: 0.00861 
2024-11-21 14:00:53.536309: train_loss -0.9525 
2024-11-21 14:00:53.536456: val_loss -0.8959 
2024-11-21 14:00:53.536555: Pseudo dice [np.float32(0.9098)] 
2024-11-21 14:00:53.536626: Epoch time: 52.37 s 
2024-11-21 14:00:54.816303:  
2024-11-21 14:00:54.816475: Epoch 154 
2024-11-21 14:00:54.816602: Current learning rate: 0.0086 
2024-11-21 14:01:47.448387: train_loss -0.9524 
2024-11-21 14:01:47.448539: val_loss -0.8953 
2024-11-21 14:01:47.448613: Pseudo dice [np.float32(0.9084)] 
2024-11-21 14:01:47.448663: Epoch time: 52.63 s 
2024-11-21 14:01:48.439026:  
2024-11-21 14:01:48.439206: Epoch 155 
2024-11-21 14:01:48.439293: Current learning rate: 0.00859 
2024-11-21 14:02:40.491251: train_loss -0.952 
2024-11-21 14:02:40.491364: val_loss -0.8965 
2024-11-21 14:02:40.491412: Pseudo dice [np.float32(0.9095)] 
2024-11-21 14:02:40.491464: Epoch time: 52.05 s 
2024-11-21 14:02:41.462242:  
2024-11-21 14:02:41.462428: Epoch 156 
2024-11-21 14:02:41.462529: Current learning rate: 0.00858 
2024-11-21 14:03:33.634911: train_loss -0.9536 
2024-11-21 14:03:33.635100: val_loss -0.9063 
2024-11-21 14:03:33.635211: Pseudo dice [np.float32(0.9181)] 
2024-11-21 14:03:33.635388: Epoch time: 52.17 s 
2024-11-21 14:03:34.749954:  
2024-11-21 14:03:34.750160: Epoch 157 
2024-11-21 14:03:34.750245: Current learning rate: 0.00858 
2024-11-21 14:04:27.139009: train_loss -0.9547 
2024-11-21 14:04:27.139126: val_loss -0.8959 
2024-11-21 14:04:27.139175: Pseudo dice [np.float32(0.9119)] 
2024-11-21 14:04:27.139231: Epoch time: 52.39 s 
2024-11-21 14:04:28.183688:  
2024-11-21 14:04:28.183924: Epoch 158 
2024-11-21 14:04:28.184152: Current learning rate: 0.00857 
2024-11-21 14:05:20.335639: train_loss -0.9544 
2024-11-21 14:05:20.335751: val_loss -0.8901 
2024-11-21 14:05:20.335799: Pseudo dice [np.float32(0.9041)] 
2024-11-21 14:05:20.335851: Epoch time: 52.15 s 
2024-11-21 14:05:21.260378:  
2024-11-21 14:05:21.260526: Epoch 159 
2024-11-21 14:05:21.260593: Current learning rate: 0.00856 
2024-11-21 14:06:13.549008: train_loss -0.9535 
2024-11-21 14:06:13.549126: val_loss -0.8992 
2024-11-21 14:06:13.549177: Pseudo dice [np.float32(0.9116)] 
2024-11-21 14:06:13.549231: Epoch time: 52.29 s 
2024-11-21 14:06:14.558976:  
2024-11-21 14:06:14.559119: Epoch 160 
2024-11-21 14:06:14.559187: Current learning rate: 0.00855 
2024-11-21 14:07:07.210380: train_loss -0.9514 
2024-11-21 14:07:07.210544: val_loss -0.8984 
2024-11-21 14:07:07.210595: Pseudo dice [np.float32(0.911)] 
2024-11-21 14:07:07.210649: Epoch time: 52.65 s 
2024-11-21 14:07:08.234979:  
2024-11-21 14:07:08.235121: Epoch 161 
2024-11-21 14:07:08.235191: Current learning rate: 0.00854 
2024-11-21 14:08:00.617060: train_loss -0.9495 
2024-11-21 14:08:00.617198: val_loss -0.8986 
2024-11-21 14:08:00.617248: Pseudo dice [np.float32(0.9111)] 
2024-11-21 14:08:00.617304: Epoch time: 52.38 s 
2024-11-21 14:08:01.671937:  
2024-11-21 14:08:01.672109: Epoch 162 
2024-11-21 14:08:01.672194: Current learning rate: 0.00853 
2024-11-21 14:08:53.958975: train_loss -0.9509 
2024-11-21 14:08:53.959103: val_loss -0.8866 
2024-11-21 14:08:53.959150: Pseudo dice [np.float32(0.9033)] 
2024-11-21 14:08:53.959202: Epoch time: 52.29 s 
2024-11-21 14:08:55.021349:  
2024-11-21 14:08:55.021510: Epoch 163 
2024-11-21 14:08:55.021634: Current learning rate: 0.00852 
2024-11-21 14:09:47.409917: train_loss -0.9493 
2024-11-21 14:09:47.410029: val_loss -0.882 
2024-11-21 14:09:47.410080: Pseudo dice [np.float32(0.9012)] 
2024-11-21 14:09:47.410136: Epoch time: 52.39 s 
2024-11-21 14:09:48.383212:  
2024-11-21 14:09:48.383387: Epoch 164 
2024-11-21 14:09:48.383480: Current learning rate: 0.00851 
2024-11-21 14:10:40.820448: train_loss -0.9452 
2024-11-21 14:10:40.820622: val_loss -0.8916 
2024-11-21 14:10:40.820701: Pseudo dice [np.float32(0.9064)] 
2024-11-21 14:10:40.820805: Epoch time: 52.44 s 
2024-11-21 14:10:42.203854:  
2024-11-21 14:10:42.204049: Epoch 165 
2024-11-21 14:10:42.204119: Current learning rate: 0.0085 
2024-11-21 14:11:34.540028: train_loss -0.9477 
2024-11-21 14:11:34.540141: val_loss -0.8971 
2024-11-21 14:11:34.540191: Pseudo dice [np.float32(0.9108)] 
2024-11-21 14:11:34.540243: Epoch time: 52.34 s 
2024-11-21 14:11:35.484837:  
2024-11-21 14:11:35.484976: Epoch 166 
2024-11-21 14:11:35.485056: Current learning rate: 0.00849 
2024-11-21 14:12:27.998868: train_loss -0.9486 
2024-11-21 14:12:27.999064: val_loss -0.8952 
2024-11-21 14:12:27.999114: Pseudo dice [np.float32(0.9092)] 
2024-11-21 14:12:27.999166: Epoch time: 52.51 s 
2024-11-21 14:12:28.940228:  
2024-11-21 14:12:28.940373: Epoch 167 
2024-11-21 14:12:28.940445: Current learning rate: 0.00848 
2024-11-21 14:13:21.311761: train_loss -0.9528 
2024-11-21 14:13:21.311935: val_loss -0.8982 
2024-11-21 14:13:21.312014: Pseudo dice [np.float32(0.9123)] 
2024-11-21 14:13:21.312081: Epoch time: 52.37 s 
2024-11-21 14:13:22.266283:  
2024-11-21 14:13:22.266478: Epoch 168 
2024-11-21 14:13:22.266563: Current learning rate: 0.00847 
2024-11-21 14:14:14.709994: train_loss -0.9532 
2024-11-21 14:14:14.710134: val_loss -0.8936 
2024-11-21 14:14:14.710198: Pseudo dice [np.float32(0.9087)] 
2024-11-21 14:14:14.710250: Epoch time: 52.44 s 
2024-11-21 14:14:15.662219:  
2024-11-21 14:14:15.662360: Epoch 169 
2024-11-21 14:14:15.662457: Current learning rate: 0.00847 
2024-11-21 14:15:07.995436: train_loss -0.954 
2024-11-21 14:15:07.995577: val_loss -0.9085 
2024-11-21 14:15:07.995644: Pseudo dice [np.float32(0.9207)] 
2024-11-21 14:15:07.995715: Epoch time: 52.33 s 
2024-11-21 14:15:09.093091:  
2024-11-21 14:15:09.093239: Epoch 170 
2024-11-21 14:15:09.093310: Current learning rate: 0.00846 
2024-11-21 14:16:01.316239: train_loss -0.9536 
2024-11-21 14:16:01.316365: val_loss -0.8984 
2024-11-21 14:16:01.316430: Pseudo dice [np.float32(0.9108)] 
2024-11-21 14:16:01.316507: Epoch time: 52.22 s 
2024-11-21 14:16:02.399620:  
2024-11-21 14:16:02.399804: Epoch 171 
2024-11-21 14:16:02.399891: Current learning rate: 0.00845 
2024-11-21 14:16:54.598884: train_loss -0.9537 
2024-11-21 14:16:54.598990: val_loss -0.9047 
2024-11-21 14:16:54.599037: Pseudo dice [np.float32(0.9162)] 
2024-11-21 14:16:54.599089: Epoch time: 52.2 s 
2024-11-21 14:16:55.649606:  
2024-11-21 14:16:55.649773: Epoch 172 
2024-11-21 14:16:55.649855: Current learning rate: 0.00844 
2024-11-21 14:17:47.698991: train_loss -0.9556 
2024-11-21 14:17:47.699099: val_loss -0.8835 
2024-11-21 14:17:47.699147: Pseudo dice [np.float32(0.8996)] 
2024-11-21 14:17:47.699200: Epoch time: 52.05 s 
2024-11-21 14:17:48.749527:  
2024-11-21 14:17:48.749702: Epoch 173 
2024-11-21 14:17:48.749785: Current learning rate: 0.00843 
2024-11-21 14:18:41.016081: train_loss -0.9541 
2024-11-21 14:18:41.016195: val_loss -0.8969 
2024-11-21 14:18:41.016269: Pseudo dice [np.float32(0.9097)] 
2024-11-21 14:18:41.016389: Epoch time: 52.27 s 
2024-11-21 14:18:41.945783:  
2024-11-21 14:18:41.945982: Epoch 174 
2024-11-21 14:18:41.946053: Current learning rate: 0.00842 
2024-11-21 14:19:34.295640: train_loss -0.9535 
2024-11-21 14:19:34.295795: val_loss -0.9003 
2024-11-21 14:19:34.295859: Pseudo dice [np.float32(0.9149)] 
2024-11-21 14:19:34.295926: Epoch time: 52.35 s 
2024-11-21 14:19:35.278551:  
2024-11-21 14:19:35.278713: Epoch 175 
2024-11-21 14:19:35.278795: Current learning rate: 0.00841 
2024-11-21 14:20:27.555020: train_loss -0.9546 
2024-11-21 14:20:27.555142: val_loss -0.8967 
2024-11-21 14:20:27.555192: Pseudo dice [np.float32(0.9104)] 
2024-11-21 14:20:27.555247: Epoch time: 52.28 s 
2024-11-21 14:20:28.838562:  
2024-11-21 14:20:28.838766: Epoch 176 
2024-11-21 14:20:28.838852: Current learning rate: 0.0084 
2024-11-21 14:21:21.106426: train_loss -0.9551 
2024-11-21 14:21:21.106546: val_loss -0.898 
2024-11-21 14:21:21.106596: Pseudo dice [np.float32(0.912)] 
2024-11-21 14:21:21.106650: Epoch time: 52.27 s 
2024-11-21 14:21:22.137838:  
2024-11-21 14:21:22.137978: Epoch 177 
2024-11-21 14:21:22.138050: Current learning rate: 0.00839 
2024-11-21 14:22:14.478695: train_loss -0.9523 
2024-11-21 14:22:14.478834: val_loss -0.896 
2024-11-21 14:22:14.478884: Pseudo dice [np.float32(0.9096)] 
2024-11-21 14:22:14.478938: Epoch time: 52.34 s 
2024-11-21 14:22:15.480867:  
2024-11-21 14:22:15.481056: Epoch 178 
2024-11-21 14:22:15.481154: Current learning rate: 0.00838 
2024-11-21 14:23:07.647024: train_loss -0.9451 
2024-11-21 14:23:07.647156: val_loss -0.8865 
2024-11-21 14:23:07.647260: Pseudo dice [np.float32(0.9014)] 
2024-11-21 14:23:07.647323: Epoch time: 52.17 s 
2024-11-21 14:23:08.687363:  
2024-11-21 14:23:08.687552: Epoch 179 
2024-11-21 14:23:08.687658: Current learning rate: 0.00837 
2024-11-21 14:24:00.663433: train_loss -0.9504 
2024-11-21 14:24:00.663640: val_loss -0.8951 
2024-11-21 14:24:00.663746: Pseudo dice [np.float32(0.908)] 
2024-11-21 14:24:00.663817: Epoch time: 51.98 s 
2024-11-21 14:24:01.679477:  
2024-11-21 14:24:01.679664: Epoch 180 
2024-11-21 14:24:01.679785: Current learning rate: 0.00836 
2024-11-21 14:24:53.651739: train_loss -0.9487 
2024-11-21 14:24:53.651855: val_loss -0.8977 
2024-11-21 14:24:53.651902: Pseudo dice [np.float32(0.9111)] 
2024-11-21 14:24:53.651954: Epoch time: 51.97 s 
2024-11-21 14:24:54.632560:  
2024-11-21 14:24:54.632731: Epoch 181 
2024-11-21 14:24:54.632798: Current learning rate: 0.00836 
2024-11-21 14:25:46.684001: train_loss -0.9524 
2024-11-21 14:25:46.684132: val_loss -0.8965 
2024-11-21 14:25:46.684194: Pseudo dice [np.float32(0.9095)] 
2024-11-21 14:25:46.684261: Epoch time: 52.05 s 
2024-11-21 14:25:47.725314:  
2024-11-21 14:25:47.725514: Epoch 182 
2024-11-21 14:25:47.725601: Current learning rate: 0.00835 
2024-11-21 14:26:40.094015: train_loss -0.9491 
2024-11-21 14:26:40.094156: val_loss -0.8988 
2024-11-21 14:26:40.094226: Pseudo dice [np.float32(0.9118)] 
2024-11-21 14:26:40.094295: Epoch time: 52.37 s 
2024-11-21 14:26:41.007685:  
2024-11-21 14:26:41.007851: Epoch 183 
2024-11-21 14:26:41.007919: Current learning rate: 0.00834 
2024-11-21 14:27:33.411426: train_loss -0.9455 
2024-11-21 14:27:33.411627: val_loss -0.898 
2024-11-21 14:27:33.411707: Pseudo dice [np.float32(0.911)] 
2024-11-21 14:27:33.411802: Epoch time: 52.4 s 
2024-11-21 14:27:34.468168:  
2024-11-21 14:27:34.468342: Epoch 184 
2024-11-21 14:27:34.468428: Current learning rate: 0.00833 
2024-11-21 14:28:26.642905: train_loss -0.9481 
2024-11-21 14:28:26.643030: val_loss -0.8871 
2024-11-21 14:28:26.643078: Pseudo dice [np.float32(0.9031)] 
2024-11-21 14:28:26.643132: Epoch time: 52.18 s 
2024-11-21 14:28:27.606070:  
2024-11-21 14:28:27.606211: Epoch 185 
2024-11-21 14:28:27.606339: Current learning rate: 0.00832 
2024-11-21 14:29:19.763458: train_loss -0.9483 
2024-11-21 14:29:19.763669: val_loss -0.893 
2024-11-21 14:29:19.763719: Pseudo dice [np.float32(0.9077)] 
2024-11-21 14:29:19.763770: Epoch time: 52.16 s 
2024-11-21 14:29:20.698869:  
2024-11-21 14:29:20.698998: Epoch 186 
2024-11-21 14:29:20.699064: Current learning rate: 0.00831 
2024-11-21 14:30:12.935269: train_loss -0.9382 
2024-11-21 14:30:12.935402: val_loss -0.8807 
2024-11-21 14:30:12.935453: Pseudo dice [np.float32(0.8963)] 
2024-11-21 14:30:12.935559: Epoch time: 52.24 s 
2024-11-21 14:30:13.954842:  
2024-11-21 14:30:13.955027: Epoch 187 
2024-11-21 14:30:13.955136: Current learning rate: 0.0083 
2024-11-21 14:31:06.157042: train_loss -0.9323 
2024-11-21 14:31:06.157173: val_loss -0.8846 
2024-11-21 14:31:06.157221: Pseudo dice [np.float32(0.9007)] 
2024-11-21 14:31:06.157274: Epoch time: 52.2 s 
2024-11-21 14:31:07.393387:  
2024-11-21 14:31:07.393606: Epoch 188 
2024-11-21 14:31:07.393675: Current learning rate: 0.00829 
2024-11-21 14:31:59.627674: train_loss -0.9378 
2024-11-21 14:31:59.627819: val_loss -0.897 
2024-11-21 14:31:59.627893: Pseudo dice [np.float32(0.9101)] 
2024-11-21 14:31:59.627963: Epoch time: 52.24 s 
2024-11-21 14:32:00.732890:  
2024-11-21 14:32:00.733089: Epoch 189 
2024-11-21 14:32:00.733175: Current learning rate: 0.00828 
2024-11-21 14:32:53.128849: train_loss -0.9459 
2024-11-21 14:32:53.129032: val_loss -0.8878 
2024-11-21 14:32:53.129095: Pseudo dice [np.float32(0.9028)] 
2024-11-21 14:32:53.129162: Epoch time: 52.4 s 
2024-11-21 14:32:54.135708:  
2024-11-21 14:32:54.135858: Epoch 190 
2024-11-21 14:32:54.135930: Current learning rate: 0.00827 
2024-11-21 14:33:46.388668: train_loss -0.948 
2024-11-21 14:33:46.388826: val_loss -0.8903 
2024-11-21 14:33:46.388927: Pseudo dice [np.float32(0.9051)] 
2024-11-21 14:33:46.389033: Epoch time: 52.25 s 
2024-11-21 14:33:47.324617:  
2024-11-21 14:33:47.324768: Epoch 191 
2024-11-21 14:33:47.324835: Current learning rate: 0.00826 
2024-11-21 14:34:39.606172: train_loss -0.949 
2024-11-21 14:34:39.606328: val_loss -0.9006 
2024-11-21 14:34:39.606393: Pseudo dice [np.float32(0.914)] 
2024-11-21 14:34:39.606461: Epoch time: 52.28 s 
2024-11-21 14:34:40.681823:  
2024-11-21 14:34:40.682077: Epoch 192 
2024-11-21 14:34:40.682195: Current learning rate: 0.00825 
2024-11-21 14:35:32.974948: train_loss -0.9526 
2024-11-21 14:35:32.975080: val_loss -0.8948 
2024-11-21 14:35:32.975127: Pseudo dice [np.float32(0.909)] 
2024-11-21 14:35:32.975179: Epoch time: 52.29 s 
2024-11-21 14:35:33.920760:  
2024-11-21 14:35:33.920933: Epoch 193 
2024-11-21 14:35:33.921053: Current learning rate: 0.00824 
2024-11-21 14:36:25.788863: train_loss -0.9526 
2024-11-21 14:36:25.788997: val_loss -0.8892 
2024-11-21 14:36:25.789053: Pseudo dice [np.float32(0.904)] 
2024-11-21 14:36:25.789134: Epoch time: 51.87 s 
2024-11-21 14:36:26.822015:  
2024-11-21 14:36:26.822156: Epoch 194 
2024-11-21 14:36:26.822242: Current learning rate: 0.00824 
2024-11-21 14:37:19.143789: train_loss -0.9525 
2024-11-21 14:37:19.143903: val_loss -0.887 
2024-11-21 14:37:19.143953: Pseudo dice [np.float32(0.9011)] 
2024-11-21 14:37:19.144006: Epoch time: 52.32 s 
2024-11-21 14:37:20.248940:  
2024-11-21 14:37:20.249079: Epoch 195 
2024-11-21 14:37:20.249146: Current learning rate: 0.00823 
2024-11-21 14:38:12.611823: train_loss -0.9517 
2024-11-21 14:38:12.611942: val_loss -0.8968 
2024-11-21 14:38:12.611998: Pseudo dice [np.float32(0.9098)] 
2024-11-21 14:38:12.612058: Epoch time: 52.36 s 
2024-11-21 14:38:13.691474:  
2024-11-21 14:38:13.691731: Epoch 196 
2024-11-21 14:38:13.691800: Current learning rate: 0.00822 
2024-11-21 14:39:06.018150: train_loss -0.953 
2024-11-21 14:39:06.018278: val_loss -0.8983 
2024-11-21 14:39:06.018339: Pseudo dice [np.float32(0.912)] 
2024-11-21 14:39:06.018405: Epoch time: 52.33 s 
2024-11-21 14:39:06.957175:  
2024-11-21 14:39:06.957316: Epoch 197 
2024-11-21 14:39:06.957382: Current learning rate: 0.00821 
2024-11-21 14:39:59.206047: train_loss -0.9552 
2024-11-21 14:39:59.206181: val_loss -0.9001 
2024-11-21 14:39:59.206230: Pseudo dice [np.float32(0.9134)] 
2024-11-21 14:39:59.206281: Epoch time: 52.25 s 
2024-11-21 14:40:00.163651:  
2024-11-21 14:40:00.163823: Epoch 198 
2024-11-21 14:40:00.163903: Current learning rate: 0.0082 
2024-11-21 14:40:52.712752: train_loss -0.9528 
2024-11-21 14:40:52.712906: val_loss -0.8887 
2024-11-21 14:40:52.713006: Pseudo dice [np.float32(0.9036)] 
2024-11-21 14:40:52.713109: Epoch time: 52.55 s 
2024-11-21 14:40:54.091020:  
2024-11-21 14:40:54.091195: Epoch 199 
2024-11-21 14:40:54.091277: Current learning rate: 0.00819 
2024-11-21 14:41:46.329675: train_loss -0.9517 
2024-11-21 14:41:46.329971: val_loss -0.891 
2024-11-21 14:41:46.330038: Pseudo dice [np.float32(0.9049)] 
2024-11-21 14:41:46.330106: Epoch time: 52.24 s 
2024-11-21 14:41:47.619153:  
2024-11-21 14:41:47.619308: Epoch 200 
2024-11-21 14:41:47.619374: Current learning rate: 0.00818 
2024-11-21 14:42:40.126031: train_loss -0.9518 
2024-11-21 14:42:40.126260: val_loss -0.8976 
2024-11-21 14:42:40.126354: Pseudo dice [np.float32(0.9108)] 
2024-11-21 14:42:40.126406: Epoch time: 52.51 s 
2024-11-21 14:42:41.140090:  
2024-11-21 14:42:41.140310: Epoch 201 
2024-11-21 14:42:41.140395: Current learning rate: 0.00817 
2024-11-21 14:43:33.529162: train_loss -0.9537 
2024-11-21 14:43:33.529276: val_loss -0.8951 
2024-11-21 14:43:33.529326: Pseudo dice [np.float32(0.9094)] 
2024-11-21 14:43:33.529378: Epoch time: 52.39 s 
2024-11-21 14:43:34.558826:  
2024-11-21 14:43:34.559009: Epoch 202 
2024-11-21 14:43:34.559100: Current learning rate: 0.00816 
2024-11-21 14:44:26.871122: train_loss -0.9559 
2024-11-21 14:44:26.871254: val_loss -0.8939 
2024-11-21 14:44:26.871343: Pseudo dice [np.float32(0.9085)] 
2024-11-21 14:44:26.871518: Epoch time: 52.31 s 
2024-11-21 14:44:27.938824:  
2024-11-21 14:44:27.939003: Epoch 203 
2024-11-21 14:44:27.939105: Current learning rate: 0.00815 
2024-11-21 14:45:20.413588: train_loss -0.9559 
2024-11-21 14:45:20.413713: val_loss -0.8973 
2024-11-21 14:45:20.413775: Pseudo dice [np.float32(0.9104)] 
2024-11-21 14:45:20.413842: Epoch time: 52.48 s 
2024-11-21 14:45:21.419899:  
2024-11-21 14:45:21.420050: Epoch 204 
2024-11-21 14:45:21.420116: Current learning rate: 0.00814 
2024-11-21 14:46:13.606550: train_loss -0.955 
2024-11-21 14:46:13.606684: val_loss -0.8993 
2024-11-21 14:46:13.606735: Pseudo dice [np.float32(0.9104)] 
2024-11-21 14:46:13.606790: Epoch time: 52.19 s 
2024-11-21 14:46:14.607798:  
2024-11-21 14:46:14.607930: Epoch 205 
2024-11-21 14:46:14.608009: Current learning rate: 0.00813 
2024-11-21 14:47:06.969615: train_loss -0.9568 
2024-11-21 14:47:06.969753: val_loss -0.8947 
2024-11-21 14:47:06.969806: Pseudo dice [np.float32(0.9089)] 
2024-11-21 14:47:06.969863: Epoch time: 52.36 s 
2024-11-21 14:47:07.949150:  
2024-11-21 14:47:07.949295: Epoch 206 
2024-11-21 14:47:07.949361: Current learning rate: 0.00813 
2024-11-21 14:48:00.326174: train_loss -0.9564 
2024-11-21 14:48:00.326335: val_loss -0.8997 
2024-11-21 14:48:00.326438: Pseudo dice [np.float32(0.9114)] 
2024-11-21 14:48:00.326513: Epoch time: 52.38 s 
2024-11-21 14:48:01.285914:  
2024-11-21 14:48:01.286054: Epoch 207 
2024-11-21 14:48:01.286120: Current learning rate: 0.00812 
2024-11-21 14:48:53.642003: train_loss -0.9571 
2024-11-21 14:48:53.642118: val_loss -0.8994 
2024-11-21 14:48:53.642168: Pseudo dice [np.float32(0.9123)] 
2024-11-21 14:48:53.642221: Epoch time: 52.36 s 
2024-11-21 14:48:54.572282:  
2024-11-21 14:48:54.572418: Epoch 208 
2024-11-21 14:48:54.572529: Current learning rate: 0.00811 
2024-11-21 14:49:47.233251: train_loss -0.9573 
2024-11-21 14:49:47.233367: val_loss -0.8959 
2024-11-21 14:49:47.233418: Pseudo dice [np.float32(0.9105)] 
2024-11-21 14:49:47.233497: Epoch time: 52.66 s 
2024-11-21 14:49:48.165813:  
2024-11-21 14:49:48.165948: Epoch 209 
2024-11-21 14:49:48.166016: Current learning rate: 0.0081 
2024-11-21 14:50:40.465959: train_loss -0.9591 
2024-11-21 14:50:40.466083: val_loss -0.8906 
2024-11-21 14:50:40.466166: Pseudo dice [np.float32(0.9054)] 
2024-11-21 14:50:40.466220: Epoch time: 52.3 s 
2024-11-21 14:50:41.757747:  
2024-11-21 14:50:41.757875: Epoch 210 
2024-11-21 14:50:41.757954: Current learning rate: 0.00809 
2024-11-21 14:51:34.081105: train_loss -0.958 
2024-11-21 14:51:34.081221: val_loss -0.9016 
2024-11-21 14:51:34.081301: Pseudo dice [np.float32(0.9136)] 
2024-11-21 14:51:34.081373: Epoch time: 52.32 s 
2024-11-21 14:51:35.104028:  
2024-11-21 14:51:35.104189: Epoch 211 
2024-11-21 14:51:35.104275: Current learning rate: 0.00808 
2024-11-21 14:52:27.234204: train_loss -0.9576 
2024-11-21 14:52:27.234362: val_loss -0.8954 
2024-11-21 14:52:27.234428: Pseudo dice [np.float32(0.9112)] 
2024-11-21 14:52:27.234502: Epoch time: 52.13 s 
2024-11-21 14:52:28.155640:  
2024-11-21 14:52:28.155867: Epoch 212 
2024-11-21 14:52:28.155951: Current learning rate: 0.00807 
2024-11-21 14:53:20.495189: train_loss -0.9577 
2024-11-21 14:53:20.495327: val_loss -0.8971 
2024-11-21 14:53:20.495377: Pseudo dice [np.float32(0.9092)] 
2024-11-21 14:53:20.495431: Epoch time: 52.34 s 
2024-11-21 14:53:21.440065:  
2024-11-21 14:53:21.440219: Epoch 213 
2024-11-21 14:53:21.440285: Current learning rate: 0.00806 
2024-11-21 14:54:13.566371: train_loss -0.9588 
2024-11-21 14:54:13.566483: val_loss -0.8978 
2024-11-21 14:54:13.566609: Pseudo dice [np.float32(0.9102)] 
2024-11-21 14:54:13.566662: Epoch time: 52.13 s 
2024-11-21 14:54:14.514713:  
2024-11-21 14:54:14.514863: Epoch 214 
2024-11-21 14:54:14.514982: Current learning rate: 0.00805 
2024-11-21 14:55:06.954782: train_loss -0.9591 
2024-11-21 14:55:06.954918: val_loss -0.897 
2024-11-21 14:55:06.955053: Pseudo dice [np.float32(0.9104)] 
2024-11-21 14:55:06.955126: Epoch time: 52.44 s 
2024-11-21 14:55:07.931135:  
2024-11-21 14:55:07.931299: Epoch 215 
2024-11-21 14:55:07.931386: Current learning rate: 0.00804 
2024-11-21 14:56:00.243998: train_loss -0.96 
2024-11-21 14:56:00.244144: val_loss -0.8983 
2024-11-21 14:56:00.244212: Pseudo dice [np.float32(0.912)] 
2024-11-21 14:56:00.244267: Epoch time: 52.31 s 
2024-11-21 14:56:01.207835:  
2024-11-21 14:56:01.207964: Epoch 216 
2024-11-21 14:56:01.208032: Current learning rate: 0.00803 
2024-11-21 14:56:53.704857: train_loss -0.9589 
2024-11-21 14:56:53.704986: val_loss -0.898 
2024-11-21 14:56:53.705041: Pseudo dice [np.float32(0.9111)] 
2024-11-21 14:56:53.705097: Epoch time: 52.5 s 
2024-11-21 14:56:54.609025:  
2024-11-21 14:56:54.609173: Epoch 217 
2024-11-21 14:56:54.609240: Current learning rate: 0.00802 
2024-11-21 14:57:46.635510: train_loss -0.9587 
2024-11-21 14:57:46.635654: val_loss -0.8962 
2024-11-21 14:57:46.635704: Pseudo dice [np.float32(0.9104)] 
2024-11-21 14:57:46.635757: Epoch time: 52.03 s 
2024-11-21 14:57:47.600008:  
2024-11-21 14:57:47.600170: Epoch 218 
2024-11-21 14:57:47.600257: Current learning rate: 0.00801 
2024-11-21 14:58:39.924200: train_loss -0.958 
2024-11-21 14:58:39.924310: val_loss -0.8962 
2024-11-21 14:58:39.924355: Pseudo dice [np.float32(0.9098)] 
2024-11-21 14:58:39.924406: Epoch time: 52.32 s 
2024-11-21 14:58:40.876280:  
2024-11-21 14:58:40.876431: Epoch 219 
2024-11-21 14:58:40.876546: Current learning rate: 0.00801 
2024-11-21 14:59:33.403812: train_loss -0.959 
2024-11-21 14:59:33.403924: val_loss -0.8966 
2024-11-21 14:59:33.403973: Pseudo dice [np.float32(0.9105)] 
2024-11-21 14:59:33.404027: Epoch time: 52.53 s 
2024-11-21 14:59:34.332880:  
2024-11-21 14:59:34.333020: Epoch 220 
2024-11-21 14:59:34.333088: Current learning rate: 0.008 
2024-11-21 15:00:26.833357: train_loss -0.9595 
2024-11-21 15:00:26.833516: val_loss -0.8985 
2024-11-21 15:00:26.833586: Pseudo dice [np.float32(0.9122)] 
2024-11-21 15:00:26.833660: Epoch time: 52.5 s 
2024-11-21 15:00:27.897164:  
2024-11-21 15:00:27.897305: Epoch 221 
2024-11-21 15:00:27.897376: Current learning rate: 0.00799 
2024-11-21 15:01:20.127918: train_loss -0.96 
2024-11-21 15:01:20.128079: val_loss -0.9011 
2024-11-21 15:01:20.128144: Pseudo dice [np.float32(0.9141)] 
2024-11-21 15:01:20.128211: Epoch time: 52.23 s 
2024-11-21 15:01:21.405121:  
2024-11-21 15:01:21.405267: Epoch 222 
2024-11-21 15:01:21.405342: Current learning rate: 0.00798 
2024-11-21 15:02:13.766858: train_loss -0.9594 
2024-11-21 15:02:13.766980: val_loss -0.8917 
2024-11-21 15:02:13.767060: Pseudo dice [np.float32(0.9087)] 
2024-11-21 15:02:13.767117: Epoch time: 52.36 s 
2024-11-21 15:02:14.771165:  
2024-11-21 15:02:14.771486: Epoch 223 
2024-11-21 15:02:14.771571: Current learning rate: 0.00797 
2024-11-21 15:03:07.119159: train_loss -0.9607 
2024-11-21 15:03:07.119280: val_loss -0.8947 
2024-11-21 15:03:07.119332: Pseudo dice [np.float32(0.9094)] 
2024-11-21 15:03:07.119385: Epoch time: 52.35 s 
2024-11-21 15:03:08.050209:  
2024-11-21 15:03:08.050385: Epoch 224 
2024-11-21 15:03:08.050478: Current learning rate: 0.00796 
2024-11-21 15:04:00.198673: train_loss -0.9606 
2024-11-21 15:04:00.198796: val_loss -0.903 
2024-11-21 15:04:00.198880: Pseudo dice [np.float32(0.9164)] 
2024-11-21 15:04:00.198935: Epoch time: 52.15 s 
2024-11-21 15:04:01.132370:  
2024-11-21 15:04:01.132569: Epoch 225 
2024-11-21 15:04:01.132652: Current learning rate: 0.00795 
2024-11-21 15:04:53.408835: train_loss -0.9597 
2024-11-21 15:04:53.408948: val_loss -0.8963 
2024-11-21 15:04:53.408998: Pseudo dice [np.float32(0.9095)] 
2024-11-21 15:04:53.409088: Epoch time: 52.28 s 
2024-11-21 15:04:54.324436:  
2024-11-21 15:04:54.324618: Epoch 226 
2024-11-21 15:04:54.324723: Current learning rate: 0.00794 
2024-11-21 15:05:46.523217: train_loss -0.9599 
2024-11-21 15:05:46.523389: val_loss -0.902 
2024-11-21 15:05:46.523459: Pseudo dice [np.float32(0.9139)] 
2024-11-21 15:05:46.523560: Epoch time: 52.2 s 
2024-11-21 15:05:47.445662:  
2024-11-21 15:05:47.445817: Epoch 227 
2024-11-21 15:05:47.445886: Current learning rate: 0.00793 
2024-11-21 15:06:39.852201: train_loss -0.9583 
2024-11-21 15:06:39.852355: val_loss -0.9008 
2024-11-21 15:06:39.852422: Pseudo dice [np.float32(0.9128)] 
2024-11-21 15:06:39.852498: Epoch time: 52.41 s 
2024-11-21 15:06:40.750056:  
2024-11-21 15:06:40.750204: Epoch 228 
2024-11-21 15:06:40.750272: Current learning rate: 0.00792 
2024-11-21 15:07:32.887558: train_loss -0.9587 
2024-11-21 15:07:32.887717: val_loss -0.9005 
2024-11-21 15:07:32.887786: Pseudo dice [np.float32(0.9137)] 
2024-11-21 15:07:32.887855: Epoch time: 52.14 s 
2024-11-21 15:07:32.887927: Yayy! New best EMA pseudo Dice: 0.9114999771118164 
2024-11-21 15:07:34.178914:  
2024-11-21 15:07:34.179057: Epoch 229 
2024-11-21 15:07:34.179126: Current learning rate: 0.00791 
2024-11-21 15:08:26.120002: train_loss -0.9596 
2024-11-21 15:08:26.120121: val_loss -0.9009 
2024-11-21 15:08:26.120173: Pseudo dice [np.float32(0.9137)] 
2024-11-21 15:08:26.120224: Epoch time: 51.94 s 
2024-11-21 15:08:26.120268: Yayy! New best EMA pseudo Dice: 0.9117000102996826 
2024-11-21 15:08:27.434936:  
2024-11-21 15:08:27.435110: Epoch 230 
2024-11-21 15:08:27.435198: Current learning rate: 0.0079 
2024-11-21 15:09:20.359608: train_loss -0.9592 
2024-11-21 15:09:20.359739: val_loss -0.8951 
2024-11-21 15:09:20.359805: Pseudo dice [np.float32(0.9101)] 
2024-11-21 15:09:20.359876: Epoch time: 52.93 s 
2024-11-21 15:09:21.279831:  
2024-11-21 15:09:21.280061: Epoch 231 
2024-11-21 15:09:21.280145: Current learning rate: 0.00789 
2024-11-21 15:10:13.677967: train_loss -0.9592 
2024-11-21 15:10:13.678086: val_loss -0.8991 
2024-11-21 15:10:13.678137: Pseudo dice [np.float32(0.913)] 
2024-11-21 15:10:13.678189: Epoch time: 52.4 s 
2024-11-21 15:10:14.590632:  
2024-11-21 15:10:14.590769: Epoch 232 
2024-11-21 15:10:14.590838: Current learning rate: 0.00789 
2024-11-21 15:11:07.062210: train_loss -0.9601 
2024-11-21 15:11:07.062422: val_loss -0.8993 
2024-11-21 15:11:07.062497: Pseudo dice [np.float32(0.9135)] 
2024-11-21 15:11:07.062582: Epoch time: 52.47 s 
2024-11-21 15:11:07.062626: Yayy! New best EMA pseudo Dice: 0.911899983882904 
2024-11-21 15:11:08.343609:  
2024-11-21 15:11:08.343752: Epoch 233 
2024-11-21 15:11:08.343819: Current learning rate: 0.00788 
2024-11-21 15:12:00.958688: train_loss -0.96 
2024-11-21 15:12:00.958795: val_loss -0.894 
2024-11-21 15:12:00.958843: Pseudo dice [np.float32(0.9083)] 
2024-11-21 15:12:00.958894: Epoch time: 52.62 s 
2024-11-21 15:12:01.853314:  
2024-11-21 15:12:01.853476: Epoch 234 
2024-11-21 15:12:01.853565: Current learning rate: 0.00787 
2024-11-21 15:12:54.450304: train_loss -0.9605 
2024-11-21 15:12:54.450448: val_loss -0.8907 
2024-11-21 15:12:54.450544: Pseudo dice [np.float32(0.9053)] 
2024-11-21 15:12:54.450656: Epoch time: 52.6 s 
2024-11-21 15:12:55.649985:  
2024-11-21 15:12:55.650234: Epoch 235 
2024-11-21 15:12:55.650343: Current learning rate: 0.00786 
2024-11-21 15:13:47.789785: train_loss -0.958 
2024-11-21 15:13:47.789952: val_loss -0.9007 
2024-11-21 15:13:47.790017: Pseudo dice [np.float32(0.9144)] 
2024-11-21 15:13:47.790086: Epoch time: 52.14 s 
2024-11-21 15:13:48.660962:  
2024-11-21 15:13:48.661116: Epoch 236 
2024-11-21 15:13:48.661184: Current learning rate: 0.00785 
2024-11-21 15:14:40.937005: train_loss -0.9534 
2024-11-21 15:14:40.937143: val_loss -0.886 
2024-11-21 15:14:40.937238: Pseudo dice [np.float32(0.9012)] 
2024-11-21 15:14:40.937306: Epoch time: 52.28 s 
2024-11-21 15:14:41.912923:  
2024-11-21 15:14:41.913115: Epoch 237 
2024-11-21 15:14:41.913199: Current learning rate: 0.00784 
2024-11-21 15:15:34.276902: train_loss -0.9537 
2024-11-21 15:15:34.277035: val_loss -0.8921 
2024-11-21 15:15:34.277119: Pseudo dice [np.float32(0.9049)] 
2024-11-21 15:15:34.277211: Epoch time: 52.36 s 
2024-11-21 15:15:35.236427:  
2024-11-21 15:15:35.236639: Epoch 238 
2024-11-21 15:15:35.236721: Current learning rate: 0.00783 
2024-11-21 15:16:27.905003: train_loss -0.9548 
2024-11-21 15:16:27.905124: val_loss -0.8984 
2024-11-21 15:16:27.905206: Pseudo dice [np.float32(0.9123)] 
2024-11-21 15:16:27.905263: Epoch time: 52.67 s 
2024-11-21 15:16:28.861661:  
2024-11-21 15:16:28.861929: Epoch 239 
2024-11-21 15:16:28.862049: Current learning rate: 0.00782 
2024-11-21 15:17:21.102515: train_loss -0.9563 
2024-11-21 15:17:21.102651: val_loss -0.8954 
2024-11-21 15:17:21.102733: Pseudo dice [np.float32(0.9103)] 
2024-11-21 15:17:21.102785: Epoch time: 52.24 s 
2024-11-21 15:17:21.977063:  
2024-11-21 15:17:21.977202: Epoch 240 
2024-11-21 15:17:21.977282: Current learning rate: 0.00781 
2024-11-21 15:18:14.361811: train_loss -0.9591 
2024-11-21 15:18:14.361934: val_loss -0.8974 
2024-11-21 15:18:14.361999: Pseudo dice [np.float32(0.9102)] 
2024-11-21 15:18:14.362071: Epoch time: 52.39 s 
2024-11-21 15:18:15.339651:  
2024-11-21 15:18:15.339814: Epoch 241 
2024-11-21 15:18:15.339888: Current learning rate: 0.0078 
2024-11-21 15:19:07.556403: train_loss -0.9598 
2024-11-21 15:19:07.556576: val_loss -0.895 
2024-11-21 15:19:07.556631: Pseudo dice [np.float32(0.9079)] 
2024-11-21 15:19:07.556689: Epoch time: 52.22 s 
2024-11-21 15:19:08.493393:  
2024-11-21 15:19:08.493629: Epoch 242 
2024-11-21 15:19:08.493708: Current learning rate: 0.00779 
2024-11-21 15:20:00.664595: train_loss -0.9599 
2024-11-21 15:20:00.664813: val_loss -0.9014 
2024-11-21 15:20:00.664896: Pseudo dice [np.float32(0.9132)] 
2024-11-21 15:20:00.664990: Epoch time: 52.17 s 
2024-11-21 15:20:01.700938:  
2024-11-21 15:20:01.701134: Epoch 243 
2024-11-21 15:20:01.701240: Current learning rate: 0.00778 
2024-11-21 15:20:53.816301: train_loss -0.9601 
2024-11-21 15:20:53.816412: val_loss -0.8917 
2024-11-21 15:20:53.816463: Pseudo dice [np.float32(0.9066)] 
2024-11-21 15:20:53.816583: Epoch time: 52.12 s 
2024-11-21 15:20:54.785527:  
2024-11-21 15:20:54.785694: Epoch 244 
2024-11-21 15:20:54.785777: Current learning rate: 0.00777 
2024-11-21 15:21:46.937043: train_loss -0.9596 
2024-11-21 15:21:46.937234: val_loss -0.902 
2024-11-21 15:21:46.937298: Pseudo dice [np.float32(0.9147)] 
2024-11-21 15:21:46.937365: Epoch time: 52.15 s 
2024-11-21 15:21:47.858284:  
2024-11-21 15:21:47.858443: Epoch 245 
2024-11-21 15:21:47.858545: Current learning rate: 0.00777 
2024-11-21 15:22:39.971870: train_loss -0.9601 
2024-11-21 15:22:39.971998: val_loss -0.8972 
2024-11-21 15:22:39.972062: Pseudo dice [np.float32(0.9105)] 
2024-11-21 15:22:39.972134: Epoch time: 52.11 s 
2024-11-21 15:22:40.937433:  
2024-11-21 15:22:40.937721: Epoch 246 
2024-11-21 15:22:40.937806: Current learning rate: 0.00776 
2024-11-21 15:23:33.302632: train_loss -0.9587 
2024-11-21 15:23:33.302762: val_loss -0.8973 
2024-11-21 15:23:33.302846: Pseudo dice [np.float32(0.9121)] 
2024-11-21 15:23:33.302918: Epoch time: 52.37 s 
2024-11-21 15:23:34.593458:  
2024-11-21 15:23:34.593577: Epoch 247 
2024-11-21 15:23:34.593770: Current learning rate: 0.00775 
2024-11-21 15:24:26.577699: train_loss -0.9593 
2024-11-21 15:24:26.577893: val_loss -0.8953 
2024-11-21 15:24:26.577989: Pseudo dice [np.float32(0.91)] 
2024-11-21 15:24:26.578090: Epoch time: 51.99 s 
2024-11-21 15:24:27.446109:  
2024-11-21 15:24:27.446300: Epoch 248 
2024-11-21 15:24:27.446365: Current learning rate: 0.00774 
2024-11-21 15:25:19.897100: train_loss -0.9598 
2024-11-21 15:25:19.897254: val_loss -0.8962 
2024-11-21 15:25:19.897304: Pseudo dice [np.float32(0.9095)] 
2024-11-21 15:25:19.897356: Epoch time: 52.45 s 
2024-11-21 15:25:20.829604:  
2024-11-21 15:25:20.829943: Epoch 249 
2024-11-21 15:25:20.830086: Current learning rate: 0.00773 
2024-11-21 15:26:13.286054: train_loss -0.9607 
2024-11-21 15:26:13.286167: val_loss -0.8945 
2024-11-21 15:26:13.286215: Pseudo dice [np.float32(0.9085)] 
2024-11-21 15:26:13.286267: Epoch time: 52.46 s 
2024-11-21 15:26:14.480920:  
2024-11-21 15:26:14.481100: Epoch 250 
2024-11-21 15:26:14.481168: Current learning rate: 0.00772 
2024-11-21 15:27:06.884678: train_loss -0.9608 
2024-11-21 15:27:06.884824: val_loss -0.9002 
2024-11-21 15:27:06.884875: Pseudo dice [np.float32(0.913)] 
2024-11-21 15:27:06.884931: Epoch time: 52.4 s 
2024-11-21 15:27:07.791324:  
2024-11-21 15:27:07.791466: Epoch 251 
2024-11-21 15:27:07.791587: Current learning rate: 0.00771 
2024-11-21 15:28:00.166087: train_loss -0.9617 
2024-11-21 15:28:00.166222: val_loss -0.8927 
2024-11-21 15:28:00.166291: Pseudo dice [np.float32(0.9079)] 
2024-11-21 15:28:00.166345: Epoch time: 52.38 s 
2024-11-21 15:28:01.170082:  
2024-11-21 15:28:01.170229: Epoch 252 
2024-11-21 15:28:01.170299: Current learning rate: 0.0077 
2024-11-21 15:28:53.437315: train_loss -0.9622 
2024-11-21 15:28:53.437442: val_loss -0.8919 
2024-11-21 15:28:53.437513: Pseudo dice [np.float32(0.9073)] 
2024-11-21 15:28:53.437581: Epoch time: 52.27 s 
2024-11-21 15:28:54.395673:  
2024-11-21 15:28:54.395869: Epoch 253 
2024-11-21 15:28:54.395952: Current learning rate: 0.00769 
2024-11-21 15:29:46.657067: train_loss -0.9626 
2024-11-21 15:29:46.657244: val_loss -0.8961 
2024-11-21 15:29:46.657303: Pseudo dice [np.float32(0.9101)] 
2024-11-21 15:29:46.657358: Epoch time: 52.26 s 
2024-11-21 15:29:47.660931:  
2024-11-21 15:29:47.661109: Epoch 254 
2024-11-21 15:29:47.661177: Current learning rate: 0.00768 
2024-11-21 15:30:40.064716: train_loss -0.9624 
2024-11-21 15:30:40.064881: val_loss -0.8954 
2024-11-21 15:30:40.064934: Pseudo dice [np.float32(0.9078)] 
2024-11-21 15:30:40.064987: Epoch time: 52.4 s 
2024-11-21 15:30:40.996118:  
2024-11-21 15:30:40.996270: Epoch 255 
2024-11-21 15:30:40.996336: Current learning rate: 0.00767 
2024-11-21 15:31:33.589826: train_loss -0.9623 
2024-11-21 15:31:33.589951: val_loss -0.8969 
2024-11-21 15:31:33.590001: Pseudo dice [np.float32(0.9102)] 
2024-11-21 15:31:33.590054: Epoch time: 52.59 s 
2024-11-21 15:31:34.517995:  
2024-11-21 15:31:34.518134: Epoch 256 
2024-11-21 15:31:34.518210: Current learning rate: 0.00766 
2024-11-21 15:32:26.674725: train_loss -0.9611 
2024-11-21 15:32:26.674848: val_loss -0.8905 
2024-11-21 15:32:26.674954: Pseudo dice [np.float32(0.9045)] 
2024-11-21 15:32:26.675022: Epoch time: 52.16 s 
2024-11-21 15:32:27.723589:  
2024-11-21 15:32:27.723741: Epoch 257 
2024-11-21 15:32:27.723844: Current learning rate: 0.00765 
2024-11-21 15:33:20.073140: train_loss -0.9577 
2024-11-21 15:33:20.073264: val_loss -0.8991 
2024-11-21 15:33:20.073315: Pseudo dice [np.float32(0.9121)] 
2024-11-21 15:33:20.073371: Epoch time: 52.35 s 
2024-11-21 15:33:21.004483:  
2024-11-21 15:33:21.004625: Epoch 258 
2024-11-21 15:33:21.004696: Current learning rate: 0.00764 
2024-11-21 15:34:13.670431: train_loss -0.9571 
2024-11-21 15:34:13.670597: val_loss -0.8963 
2024-11-21 15:34:13.670647: Pseudo dice [np.float32(0.9097)] 
2024-11-21 15:34:13.670699: Epoch time: 52.67 s 
2024-11-21 15:34:14.890221:  
2024-11-21 15:34:14.890372: Epoch 259 
2024-11-21 15:34:14.890444: Current learning rate: 0.00764 
2024-11-21 15:35:07.318991: train_loss -0.9602 
2024-11-21 15:35:07.319117: val_loss -0.9 
2024-11-21 15:35:07.319178: Pseudo dice [np.float32(0.912)] 
2024-11-21 15:35:07.319246: Epoch time: 52.43 s 
2024-11-21 15:35:08.245716:  
2024-11-21 15:35:08.245977: Epoch 260 
2024-11-21 15:35:08.246078: Current learning rate: 0.00763 
2024-11-21 15:36:00.696248: train_loss -0.9595 
2024-11-21 15:36:00.696364: val_loss -0.8911 
2024-11-21 15:36:00.696458: Pseudo dice [np.float32(0.9043)] 
2024-11-21 15:36:00.696537: Epoch time: 52.45 s 
2024-11-21 15:36:01.639575:  
2024-11-21 15:36:01.639740: Epoch 261 
2024-11-21 15:36:01.639822: Current learning rate: 0.00762 
2024-11-21 15:36:54.180551: train_loss -0.9558 
2024-11-21 15:36:54.180701: val_loss -0.89 
2024-11-21 15:36:54.180779: Pseudo dice [np.float32(0.9064)] 
2024-11-21 15:36:54.180849: Epoch time: 52.54 s 
2024-11-21 15:36:55.137633:  
2024-11-21 15:36:55.137783: Epoch 262 
2024-11-21 15:36:55.137851: Current learning rate: 0.00761 
2024-11-21 15:37:47.645279: train_loss -0.9563 
2024-11-21 15:37:47.645463: val_loss -0.8918 
2024-11-21 15:37:47.645525: Pseudo dice [np.float32(0.9059)] 
2024-11-21 15:37:47.645585: Epoch time: 52.51 s 
2024-11-21 15:37:48.552808:  
2024-11-21 15:37:48.552960: Epoch 263 
2024-11-21 15:37:48.553031: Current learning rate: 0.0076 
2024-11-21 15:38:41.131976: train_loss -0.9561 
2024-11-21 15:38:41.132098: val_loss -0.8835 
2024-11-21 15:38:41.132146: Pseudo dice [np.float32(0.8995)] 
2024-11-21 15:38:41.132199: Epoch time: 52.58 s 
2024-11-21 15:38:42.075235:  
2024-11-21 15:38:42.075378: Epoch 264 
2024-11-21 15:38:42.075446: Current learning rate: 0.00759 
2024-11-21 15:39:34.738804: train_loss -0.9583 
2024-11-21 15:39:34.738926: val_loss -0.8859 
2024-11-21 15:39:34.739081: Pseudo dice [np.float32(0.8998)] 
2024-11-21 15:39:34.739138: Epoch time: 52.66 s 
2024-11-21 15:39:35.737406:  
2024-11-21 15:39:35.737624: Epoch 265 
2024-11-21 15:39:35.737756: Current learning rate: 0.00758 
2024-11-21 15:40:28.190665: train_loss -0.9557 
2024-11-21 15:40:28.190796: val_loss -0.8909 
2024-11-21 15:40:28.190844: Pseudo dice [np.float32(0.9059)] 
2024-11-21 15:40:28.190896: Epoch time: 52.45 s 
2024-11-21 15:40:29.112434:  
2024-11-21 15:40:29.112625: Epoch 266 
2024-11-21 15:40:29.112699: Current learning rate: 0.00757 
2024-11-21 15:41:21.870024: train_loss -0.9565 
2024-11-21 15:41:21.870182: val_loss -0.8985 
2024-11-21 15:41:21.870232: Pseudo dice [np.float32(0.911)] 
2024-11-21 15:41:21.870293: Epoch time: 52.76 s 
2024-11-21 15:41:22.835178:  
2024-11-21 15:41:22.835317: Epoch 267 
2024-11-21 15:41:22.835383: Current learning rate: 0.00756 
2024-11-21 15:42:15.346069: train_loss -0.9583 
2024-11-21 15:42:15.346185: val_loss -0.8881 
2024-11-21 15:42:15.346260: Pseudo dice [np.float32(0.9028)] 
2024-11-21 15:42:15.346315: Epoch time: 52.51 s 
2024-11-21 15:42:16.301047:  
2024-11-21 15:42:16.301216: Epoch 268 
2024-11-21 15:42:16.301323: Current learning rate: 0.00755 
2024-11-21 15:43:08.407412: train_loss -0.9554 
2024-11-21 15:43:08.407525: val_loss -0.8933 
2024-11-21 15:43:08.407574: Pseudo dice [np.float32(0.9081)] 
2024-11-21 15:43:08.407626: Epoch time: 52.11 s 
2024-11-21 15:43:09.268205:  
2024-11-21 15:43:09.268340: Epoch 269 
2024-11-21 15:43:09.268409: Current learning rate: 0.00754 
2024-11-21 15:44:01.821177: train_loss -0.9558 
2024-11-21 15:44:01.821312: val_loss -0.8957 
2024-11-21 15:44:01.821363: Pseudo dice [np.float32(0.9098)] 
2024-11-21 15:44:01.821419: Epoch time: 52.55 s 
2024-11-21 15:44:02.808836:  
2024-11-21 15:44:02.808981: Epoch 270 
2024-11-21 15:44:02.809052: Current learning rate: 0.00753 
2024-11-21 15:44:54.768090: train_loss -0.9582 
2024-11-21 15:44:54.768220: val_loss -0.8967 
2024-11-21 15:44:54.768270: Pseudo dice [np.float32(0.9088)] 
2024-11-21 15:44:54.768324: Epoch time: 51.96 s 
2024-11-21 15:44:56.020025:  
2024-11-21 15:44:56.020186: Epoch 271 
2024-11-21 15:44:56.020313: Current learning rate: 0.00752 
2024-11-21 15:45:48.082012: train_loss -0.9588 
2024-11-21 15:45:48.082145: val_loss -0.8914 
2024-11-21 15:45:48.082225: Pseudo dice [np.float32(0.9054)] 
2024-11-21 15:45:48.082320: Epoch time: 52.06 s 
2024-11-21 15:45:49.100374:  
2024-11-21 15:45:49.100579: Epoch 272 
2024-11-21 15:45:49.100670: Current learning rate: 0.00751 
2024-11-21 15:46:41.296958: train_loss -0.9572 
2024-11-21 15:46:41.297085: val_loss -0.8932 
2024-11-21 15:46:41.297150: Pseudo dice [np.float32(0.9069)] 
2024-11-21 15:46:41.297219: Epoch time: 52.2 s 
2024-11-21 15:46:42.271237:  
2024-11-21 15:46:42.271377: Epoch 273 
2024-11-21 15:46:42.271447: Current learning rate: 0.00751 
2024-11-21 15:47:34.658303: train_loss -0.958 
2024-11-21 15:47:34.658459: val_loss -0.8965 
2024-11-21 15:47:34.658572: Pseudo dice [np.float32(0.9108)] 
2024-11-21 15:47:34.658644: Epoch time: 52.39 s 
2024-11-21 15:47:35.682443:  
2024-11-21 15:47:35.682684: Epoch 274 
2024-11-21 15:47:35.682786: Current learning rate: 0.0075 
2024-11-21 15:48:27.993945: train_loss -0.9605 
2024-11-21 15:48:27.994058: val_loss -0.8962 
2024-11-21 15:48:27.994108: Pseudo dice [np.float32(0.909)] 
2024-11-21 15:48:27.994160: Epoch time: 52.31 s 
2024-11-21 15:48:29.009936:  
2024-11-21 15:48:29.010120: Epoch 275 
2024-11-21 15:48:29.010204: Current learning rate: 0.00749 
2024-11-21 15:49:21.595164: train_loss -0.9614 
2024-11-21 15:49:21.595293: val_loss -0.8906 
2024-11-21 15:49:21.595356: Pseudo dice [np.float32(0.905)] 
2024-11-21 15:49:21.595423: Epoch time: 52.59 s 
2024-11-21 15:49:22.580137:  
2024-11-21 15:49:22.580250: Epoch 276 
2024-11-21 15:49:22.580355: Current learning rate: 0.00748 
2024-11-21 15:50:15.104056: train_loss -0.9597 
2024-11-21 15:50:15.104198: val_loss -0.8903 
2024-11-21 15:50:15.104313: Pseudo dice [np.float32(0.9049)] 
2024-11-21 15:50:15.104376: Epoch time: 52.52 s 
2024-11-21 15:50:16.024149:  
2024-11-21 15:50:16.024294: Epoch 277 
2024-11-21 15:50:16.024396: Current learning rate: 0.00747 
2024-11-21 15:51:08.464576: train_loss -0.9574 
2024-11-21 15:51:08.464725: val_loss -0.8901 
2024-11-21 15:51:08.464787: Pseudo dice [np.float32(0.9028)] 
2024-11-21 15:51:08.464854: Epoch time: 52.44 s 
2024-11-21 15:51:09.433273:  
2024-11-21 15:51:09.433407: Epoch 278 
2024-11-21 15:51:09.433500: Current learning rate: 0.00746 
2024-11-21 15:52:02.178863: train_loss -0.959 
2024-11-21 15:52:02.178980: val_loss -0.8959 
2024-11-21 15:52:02.179028: Pseudo dice [np.float32(0.9092)] 
2024-11-21 15:52:02.179081: Epoch time: 52.75 s 
2024-11-21 15:52:03.173932:  
2024-11-21 15:52:03.174078: Epoch 279 
2024-11-21 15:52:03.174196: Current learning rate: 0.00745 
2024-11-21 15:52:55.635634: train_loss -0.9595 
2024-11-21 15:52:55.635797: val_loss -0.8889 
2024-11-21 15:52:55.635851: Pseudo dice [np.float32(0.9042)] 
2024-11-21 15:52:55.635908: Epoch time: 52.46 s 
2024-11-21 15:52:56.666685:  
2024-11-21 15:52:56.666861: Epoch 280 
2024-11-21 15:52:56.666961: Current learning rate: 0.00744 
2024-11-21 15:53:49.137786: train_loss -0.9597 
2024-11-21 15:53:49.137919: val_loss -0.8929 
2024-11-21 15:53:49.138006: Pseudo dice [np.float32(0.9069)] 
2024-11-21 15:53:49.138078: Epoch time: 52.47 s 
2024-11-21 15:53:50.092089:  
2024-11-21 15:53:50.092284: Epoch 281 
2024-11-21 15:53:50.092369: Current learning rate: 0.00743 
2024-11-21 15:54:42.402040: train_loss -0.9618 
2024-11-21 15:54:42.402171: val_loss -0.8953 
2024-11-21 15:54:42.402235: Pseudo dice [np.float32(0.9111)] 
2024-11-21 15:54:42.402305: Epoch time: 52.31 s 
2024-11-21 15:54:43.335403:  
2024-11-21 15:54:43.335541: Epoch 282 
2024-11-21 15:54:43.335613: Current learning rate: 0.00742 
2024-11-21 15:55:35.849769: train_loss -0.9622 
2024-11-21 15:55:35.849902: val_loss -0.8942 
2024-11-21 15:55:35.850009: Pseudo dice [np.float32(0.9091)] 
2024-11-21 15:55:35.850098: Epoch time: 52.52 s 
2024-11-21 15:55:37.179648:  
2024-11-21 15:55:37.179818: Epoch 283 
2024-11-21 15:55:37.179918: Current learning rate: 0.00741 
2024-11-21 15:56:29.680984: train_loss -0.9619 
2024-11-21 15:56:29.681101: val_loss -0.893 
2024-11-21 15:56:29.681147: Pseudo dice [np.float32(0.9074)] 
2024-11-21 15:56:29.681197: Epoch time: 52.5 s 
2024-11-21 15:56:30.622586:  
2024-11-21 15:56:30.622869: Epoch 284 
2024-11-21 15:56:30.622971: Current learning rate: 0.0074 
2024-11-21 15:57:23.001385: train_loss -0.9609 
2024-11-21 15:57:23.001612: val_loss -0.8968 
2024-11-21 15:57:23.001678: Pseudo dice [np.float32(0.911)] 
2024-11-21 15:57:23.001748: Epoch time: 52.38 s 
2024-11-21 15:57:24.010081:  
2024-11-21 15:57:24.010278: Epoch 285 
2024-11-21 15:57:24.010379: Current learning rate: 0.00739 
2024-11-21 15:58:16.678526: train_loss -0.9611 
2024-11-21 15:58:16.678662: val_loss -0.8953 
2024-11-21 15:58:16.678801: Pseudo dice [np.float32(0.9088)] 
2024-11-21 15:58:16.678885: Epoch time: 52.67 s 
2024-11-21 15:58:17.565255:  
2024-11-21 15:58:17.565409: Epoch 286 
2024-11-21 15:58:17.565541: Current learning rate: 0.00738 
2024-11-21 15:59:10.370552: train_loss -0.9593 
2024-11-21 15:59:10.370687: val_loss -0.8963 
2024-11-21 15:59:10.370739: Pseudo dice [np.float32(0.9113)] 
2024-11-21 15:59:10.370795: Epoch time: 52.81 s 
2024-11-21 15:59:11.384040:  
2024-11-21 15:59:11.384192: Epoch 287 
2024-11-21 15:59:11.384299: Current learning rate: 0.00738 
2024-11-21 16:00:04.079336: train_loss -0.9606 
2024-11-21 16:00:04.079446: val_loss -0.9011 
2024-11-21 16:00:04.079536: Pseudo dice [np.float32(0.9126)] 
2024-11-21 16:00:04.079609: Epoch time: 52.7 s 
2024-11-21 16:00:05.038585:  
2024-11-21 16:00:05.038812: Epoch 288 
2024-11-21 16:00:05.038947: Current learning rate: 0.00737 
2024-11-21 16:00:56.985900: train_loss -0.9623 
2024-11-21 16:00:56.986031: val_loss -0.9032 
2024-11-21 16:00:56.986082: Pseudo dice [np.float32(0.9158)] 
2024-11-21 16:00:56.986153: Epoch time: 51.95 s 
2024-11-21 16:00:57.962817:  
2024-11-21 16:00:57.963077: Epoch 289 
2024-11-21 16:00:57.963186: Current learning rate: 0.00736 
2024-11-21 16:01:50.085340: train_loss -0.9609 
2024-11-21 16:01:50.085502: val_loss -0.8978 
2024-11-21 16:01:50.085648: Pseudo dice [np.float32(0.9112)] 
2024-11-21 16:01:50.085699: Epoch time: 52.12 s 
2024-11-21 16:01:51.017969:  
2024-11-21 16:01:51.018112: Epoch 290 
2024-11-21 16:01:51.018179: Current learning rate: 0.00735 
2024-11-21 16:02:43.668989: train_loss -0.9619 
2024-11-21 16:02:43.669105: val_loss -0.898 
2024-11-21 16:02:43.669193: Pseudo dice [np.float32(0.9117)] 
2024-11-21 16:02:43.669270: Epoch time: 52.65 s 
2024-11-21 16:02:44.694303:  
2024-11-21 16:02:44.694487: Epoch 291 
2024-11-21 16:02:44.694575: Current learning rate: 0.00734 
2024-11-21 16:03:37.202774: train_loss -0.962 
2024-11-21 16:03:37.202978: val_loss -0.8934 
2024-11-21 16:03:37.203051: Pseudo dice [np.float32(0.9073)] 
2024-11-21 16:03:37.203177: Epoch time: 52.51 s 
2024-11-21 16:03:38.172817:  
2024-11-21 16:03:38.173027: Epoch 292 
2024-11-21 16:03:38.173157: Current learning rate: 0.00733 
2024-11-21 16:04:30.297955: train_loss -0.9628 
2024-11-21 16:04:30.298073: val_loss -0.8988 
2024-11-21 16:04:30.298125: Pseudo dice [np.float32(0.9111)] 
2024-11-21 16:04:30.298180: Epoch time: 52.13 s 
2024-11-21 16:04:31.272549:  
2024-11-21 16:04:31.272671: Epoch 293 
2024-11-21 16:04:31.272746: Current learning rate: 0.00732 
2024-11-21 16:05:23.515535: train_loss -0.9633 
2024-11-21 16:05:23.515650: val_loss -0.8958 
2024-11-21 16:05:23.515716: Pseudo dice [np.float32(0.9085)] 
2024-11-21 16:05:23.515768: Epoch time: 52.24 s 
2024-11-21 16:05:24.387036:  
2024-11-21 16:05:24.387194: Epoch 294 
2024-11-21 16:05:24.387270: Current learning rate: 0.00731 
2024-11-21 16:06:16.814188: train_loss -0.9636 
2024-11-21 16:06:16.814300: val_loss -0.9014 
2024-11-21 16:06:16.814351: Pseudo dice [np.float32(0.9155)] 
2024-11-21 16:06:16.814405: Epoch time: 52.43 s 
2024-11-21 16:06:17.759415:  
2024-11-21 16:06:17.759654: Epoch 295 
2024-11-21 16:06:17.759737: Current learning rate: 0.0073 
2024-11-21 16:07:10.531191: train_loss -0.9615 
2024-11-21 16:07:10.531313: val_loss -0.8943 
2024-11-21 16:07:10.531363: Pseudo dice [np.float32(0.9094)] 
2024-11-21 16:07:10.531434: Epoch time: 52.77 s 
2024-11-21 16:07:11.422934:  
2024-11-21 16:07:11.423156: Epoch 296 
2024-11-21 16:07:11.423247: Current learning rate: 0.00729 
2024-11-21 16:08:04.121041: train_loss -0.9622 
2024-11-21 16:08:04.121166: val_loss -0.897 
2024-11-21 16:08:04.121223: Pseudo dice [np.float32(0.9105)] 
2024-11-21 16:08:04.121294: Epoch time: 52.7 s 
2024-11-21 16:08:05.067748:  
2024-11-21 16:08:05.067893: Epoch 297 
2024-11-21 16:08:05.067990: Current learning rate: 0.00728 
2024-11-21 16:08:57.815111: train_loss -0.9621 
2024-11-21 16:08:57.815259: val_loss -0.898 
2024-11-21 16:08:57.815312: Pseudo dice [np.float32(0.9123)] 
2024-11-21 16:08:57.815370: Epoch time: 52.75 s 
2024-11-21 16:08:58.760594:  
2024-11-21 16:08:58.760926: Epoch 298 
2024-11-21 16:08:58.761025: Current learning rate: 0.00727 
2024-11-21 16:09:51.266842: train_loss -0.9612 
2024-11-21 16:09:51.266963: val_loss -0.8962 
2024-11-21 16:09:51.267040: Pseudo dice [np.float32(0.9102)] 
2024-11-21 16:09:51.267123: Epoch time: 52.51 s 
2024-11-21 16:09:52.224029:  
2024-11-21 16:09:52.224204: Epoch 299 
2024-11-21 16:09:52.224271: Current learning rate: 0.00726 
2024-11-21 16:10:44.818532: train_loss -0.9616 
2024-11-21 16:10:44.818667: val_loss -0.8929 
2024-11-21 16:10:44.818730: Pseudo dice [np.float32(0.908)] 
2024-11-21 16:10:44.818798: Epoch time: 52.6 s 
2024-11-21 16:10:46.177180:  
2024-11-21 16:10:46.177315: Epoch 300 
2024-11-21 16:10:46.177430: Current learning rate: 0.00725 
2024-11-21 16:11:38.625862: train_loss -0.9624 
2024-11-21 16:11:38.625981: val_loss -0.8885 
2024-11-21 16:11:38.626050: Pseudo dice [np.float32(0.9045)] 
2024-11-21 16:11:38.626104: Epoch time: 52.45 s 
2024-11-21 16:11:39.547219:  
2024-11-21 16:11:39.547390: Epoch 301 
2024-11-21 16:11:39.547462: Current learning rate: 0.00724 
2024-11-21 16:12:31.872268: train_loss -0.9618 
2024-11-21 16:12:31.872421: val_loss -0.8952 
2024-11-21 16:12:31.872492: Pseudo dice [np.float32(0.9092)] 
2024-11-21 16:12:31.872561: Epoch time: 52.33 s 
2024-11-21 16:12:32.853365:  
2024-11-21 16:12:32.853549: Epoch 302 
2024-11-21 16:12:32.853633: Current learning rate: 0.00724 
2024-11-21 16:13:25.022938: train_loss -0.962 
2024-11-21 16:13:25.023078: val_loss -0.9003 
2024-11-21 16:13:25.023144: Pseudo dice [np.float32(0.9145)] 
2024-11-21 16:13:25.023210: Epoch time: 52.17 s 
2024-11-21 16:13:26.005249:  
2024-11-21 16:13:26.005415: Epoch 303 
2024-11-21 16:13:26.005538: Current learning rate: 0.00723 
2024-11-21 16:14:18.331429: train_loss -0.9611 
2024-11-21 16:14:18.331599: val_loss -0.8966 
2024-11-21 16:14:18.331667: Pseudo dice [np.float32(0.9081)] 
2024-11-21 16:14:18.331721: Epoch time: 52.33 s 
2024-11-21 16:14:19.323636:  
2024-11-21 16:14:19.323821: Epoch 304 
2024-11-21 16:14:19.323906: Current learning rate: 0.00722 
2024-11-21 16:15:11.773334: train_loss -0.9588 
2024-11-21 16:15:11.773504: val_loss -0.9004 
2024-11-21 16:15:11.773585: Pseudo dice [np.float32(0.9136)] 
2024-11-21 16:15:11.773640: Epoch time: 52.45 s 
2024-11-21 16:15:12.722545:  
2024-11-21 16:15:12.722762: Epoch 305 
2024-11-21 16:15:12.722860: Current learning rate: 0.00721 
2024-11-21 16:16:05.052842: train_loss -0.9615 
2024-11-21 16:16:05.052963: val_loss -0.8905 
2024-11-21 16:16:05.053011: Pseudo dice [np.float32(0.9048)] 
2024-11-21 16:16:05.053064: Epoch time: 52.33 s 
2024-11-21 16:16:06.037960:  
2024-11-21 16:16:06.038118: Epoch 306 
2024-11-21 16:16:06.038188: Current learning rate: 0.0072 
2024-11-21 16:16:58.540901: train_loss -0.9594 
2024-11-21 16:16:58.541026: val_loss -0.8923 
2024-11-21 16:16:58.541075: Pseudo dice [np.float32(0.9063)] 
2024-11-21 16:16:58.541128: Epoch time: 52.5 s 
2024-11-21 16:16:59.802354:  
2024-11-21 16:16:59.802528: Epoch 307 
2024-11-21 16:16:59.802617: Current learning rate: 0.00719 
2024-11-21 16:17:51.956840: train_loss -0.9596 
2024-11-21 16:17:51.956990: val_loss -0.8929 
2024-11-21 16:17:51.957052: Pseudo dice [np.float32(0.9066)] 
2024-11-21 16:17:51.957119: Epoch time: 52.16 s 
2024-11-21 16:17:52.953552:  
2024-11-21 16:17:52.953727: Epoch 308 
2024-11-21 16:17:52.953809: Current learning rate: 0.00718 
2024-11-21 16:18:45.153688: train_loss -0.9539 
2024-11-21 16:18:45.153840: val_loss -0.8825 
2024-11-21 16:18:45.153956: Pseudo dice [np.float32(0.9005)] 
2024-11-21 16:18:45.154041: Epoch time: 52.2 s 
2024-11-21 16:18:46.170724:  
2024-11-21 16:18:46.170913: Epoch 309 
2024-11-21 16:18:46.170997: Current learning rate: 0.00717 
2024-11-21 16:19:38.743770: train_loss -0.9468 
2024-11-21 16:19:38.743935: val_loss -0.8863 
2024-11-21 16:19:38.743999: Pseudo dice [np.float32(0.9009)] 
2024-11-21 16:19:38.744068: Epoch time: 52.57 s 
2024-11-21 16:19:39.717896:  
2024-11-21 16:19:39.718104: Epoch 310 
2024-11-21 16:19:39.718173: Current learning rate: 0.00716 
2024-11-21 16:20:31.789641: train_loss -0.9406 
2024-11-21 16:20:31.789768: val_loss -0.8865 
2024-11-21 16:20:31.789900: Pseudo dice [np.float32(0.9024)] 
2024-11-21 16:20:31.789965: Epoch time: 52.07 s 
2024-11-21 16:20:32.718743:  
2024-11-21 16:20:32.718875: Epoch 311 
2024-11-21 16:20:32.718942: Current learning rate: 0.00715 
2024-11-21 16:21:25.134356: train_loss -0.9402 
2024-11-21 16:21:25.134495: val_loss -0.8799 
2024-11-21 16:21:25.134562: Pseudo dice [np.float32(0.8961)] 
2024-11-21 16:21:25.134633: Epoch time: 52.42 s 
2024-11-21 16:21:26.104883:  
2024-11-21 16:21:26.105027: Epoch 312 
2024-11-21 16:21:26.105096: Current learning rate: 0.00714 
2024-11-21 16:22:18.588138: train_loss -0.938 
2024-11-21 16:22:18.588273: val_loss -0.8896 
2024-11-21 16:22:18.588332: Pseudo dice [np.float32(0.9015)] 
2024-11-21 16:22:18.588391: Epoch time: 52.48 s 
2024-11-21 16:22:19.585105:  
2024-11-21 16:22:19.585279: Epoch 313 
2024-11-21 16:22:19.585387: Current learning rate: 0.00713 
2024-11-21 16:23:11.867061: train_loss -0.9482 
2024-11-21 16:23:11.867174: val_loss -0.8951 
2024-11-21 16:23:11.867228: Pseudo dice [np.float32(0.9095)] 
2024-11-21 16:23:11.867281: Epoch time: 52.28 s 
2024-11-21 16:23:12.902926:  
2024-11-21 16:23:12.903109: Epoch 314 
2024-11-21 16:23:12.903193: Current learning rate: 0.00712 
2024-11-21 16:24:05.111061: train_loss -0.947 
2024-11-21 16:24:05.111187: val_loss -0.896 
2024-11-21 16:24:05.111255: Pseudo dice [np.float32(0.9106)] 
2024-11-21 16:24:05.111327: Epoch time: 52.21 s 
2024-11-21 16:24:06.131412:  
2024-11-21 16:24:06.131582: Epoch 315 
2024-11-21 16:24:06.131713: Current learning rate: 0.00711 
2024-11-21 16:24:58.411680: train_loss -0.9543 
2024-11-21 16:24:58.411786: val_loss -0.8986 
2024-11-21 16:24:58.411835: Pseudo dice [np.float32(0.9128)] 
2024-11-21 16:24:58.411894: Epoch time: 52.28 s 
2024-11-21 16:24:59.339670:  
2024-11-21 16:24:59.339889: Epoch 316 
2024-11-21 16:24:59.339971: Current learning rate: 0.0071 
2024-11-21 16:25:51.767389: train_loss -0.9562 
2024-11-21 16:25:51.767592: val_loss -0.8847 
2024-11-21 16:25:51.767659: Pseudo dice [np.float32(0.8997)] 
2024-11-21 16:25:51.767711: Epoch time: 52.43 s 
2024-11-21 16:25:52.781948:  
2024-11-21 16:25:52.782123: Epoch 317 
2024-11-21 16:25:52.782194: Current learning rate: 0.0071 
2024-11-21 16:26:45.231181: train_loss -0.9578 
2024-11-21 16:26:45.231296: val_loss -0.9017 
2024-11-21 16:26:45.231344: Pseudo dice [np.float32(0.9148)] 
2024-11-21 16:26:45.231396: Epoch time: 52.45 s 
2024-11-21 16:26:46.200982:  
2024-11-21 16:26:46.201097: Epoch 318 
2024-11-21 16:26:46.201175: Current learning rate: 0.00709 
2024-11-21 16:27:38.403829: train_loss -0.9587 
2024-11-21 16:27:38.403987: val_loss -0.8942 
2024-11-21 16:27:38.404075: Pseudo dice [np.float32(0.907)] 
2024-11-21 16:27:38.404166: Epoch time: 52.2 s 
2024-11-21 16:27:39.620518:  
2024-11-21 16:27:39.620704: Epoch 319 
2024-11-21 16:27:39.620797: Current learning rate: 0.00708 
2024-11-21 16:28:32.006400: train_loss -0.9597 
2024-11-21 16:28:32.006595: val_loss -0.8964 
2024-11-21 16:28:32.006647: Pseudo dice [np.float32(0.9097)] 
2024-11-21 16:28:32.006713: Epoch time: 52.39 s 
2024-11-21 16:28:33.027917:  
2024-11-21 16:28:33.028120: Epoch 320 
2024-11-21 16:28:33.028188: Current learning rate: 0.00707 
2024-11-21 16:29:25.379175: train_loss -0.9588 
2024-11-21 16:29:25.379293: val_loss -0.8899 
2024-11-21 16:29:25.379345: Pseudo dice [np.float32(0.9058)] 
2024-11-21 16:29:25.379400: Epoch time: 52.35 s 
2024-11-21 16:29:26.342414:  
2024-11-21 16:29:26.342607: Epoch 321 
2024-11-21 16:29:26.342699: Current learning rate: 0.00706 
2024-11-21 16:30:18.911674: train_loss -0.9584 
2024-11-21 16:30:18.911802: val_loss -0.8926 
2024-11-21 16:30:18.911959: Pseudo dice [np.float32(0.9059)] 
2024-11-21 16:30:18.912031: Epoch time: 52.57 s 
2024-11-21 16:30:19.854261:  
2024-11-21 16:30:19.854443: Epoch 322 
2024-11-21 16:30:19.854530: Current learning rate: 0.00705 
2024-11-21 16:31:12.513074: train_loss -0.9608 
2024-11-21 16:31:12.513252: val_loss -0.8987 
2024-11-21 16:31:12.513384: Pseudo dice [np.float32(0.9109)] 
2024-11-21 16:31:12.513453: Epoch time: 52.66 s 
2024-11-21 16:31:13.471517:  
2024-11-21 16:31:13.471864: Epoch 323 
2024-11-21 16:31:13.471979: Current learning rate: 0.00704 
2024-11-21 16:32:05.611144: train_loss -0.9618 
2024-11-21 16:32:05.611361: val_loss -0.8921 
2024-11-21 16:32:05.611427: Pseudo dice [np.float32(0.9086)] 
2024-11-21 16:32:05.611504: Epoch time: 52.14 s 
2024-11-21 16:32:06.646539:  
2024-11-21 16:32:06.646706: Epoch 324 
2024-11-21 16:32:06.646797: Current learning rate: 0.00703 
2024-11-21 16:32:58.768123: train_loss -0.9608 
2024-11-21 16:32:58.768237: val_loss -0.8994 
2024-11-21 16:32:58.768284: Pseudo dice [np.float32(0.912)] 
2024-11-21 16:32:58.768369: Epoch time: 52.12 s 
2024-11-21 16:32:59.792892:  
2024-11-21 16:32:59.793029: Epoch 325 
2024-11-21 16:32:59.793095: Current learning rate: 0.00702 
2024-11-21 16:33:52.228307: train_loss -0.9627 
2024-11-21 16:33:52.228440: val_loss -0.9012 
2024-11-21 16:33:52.228509: Pseudo dice [np.float32(0.9142)] 
2024-11-21 16:33:52.228577: Epoch time: 52.44 s 
2024-11-21 16:33:53.202116:  
2024-11-21 16:33:53.202247: Epoch 326 
2024-11-21 16:33:53.202341: Current learning rate: 0.00701 
2024-11-21 16:34:45.724531: train_loss -0.9628 
2024-11-21 16:34:45.724643: val_loss -0.9006 
2024-11-21 16:34:45.724691: Pseudo dice [np.float32(0.9144)] 
2024-11-21 16:34:45.724746: Epoch time: 52.52 s 
2024-11-21 16:34:46.711679:  
2024-11-21 16:34:46.711864: Epoch 327 
2024-11-21 16:34:46.711990: Current learning rate: 0.007 
2024-11-21 16:35:38.977084: train_loss -0.9628 
2024-11-21 16:35:38.977245: val_loss -0.9038 
2024-11-21 16:35:38.977310: Pseudo dice [np.float32(0.9161)] 
2024-11-21 16:35:38.977379: Epoch time: 52.27 s 
2024-11-21 16:35:39.964962:  
2024-11-21 16:35:39.965125: Epoch 328 
2024-11-21 16:35:39.965198: Current learning rate: 0.00699 
2024-11-21 16:36:32.265898: train_loss -0.9644 
2024-11-21 16:36:32.266016: val_loss -0.9038 
2024-11-21 16:36:32.266067: Pseudo dice [np.float32(0.9169)] 
2024-11-21 16:36:32.266123: Epoch time: 52.3 s 
2024-11-21 16:36:33.186875:  
2024-11-21 16:36:33.187034: Epoch 329 
2024-11-21 16:36:33.187105: Current learning rate: 0.00698 
2024-11-21 16:37:25.390350: train_loss -0.9648 
2024-11-21 16:37:25.390526: val_loss -0.8976 
2024-11-21 16:37:25.390631: Pseudo dice [np.float32(0.9114)] 
2024-11-21 16:37:25.390690: Epoch time: 52.2 s 
2024-11-21 16:37:26.355714:  
2024-11-21 16:37:26.355940: Epoch 330 
2024-11-21 16:37:26.356027: Current learning rate: 0.00697 
2024-11-21 16:38:18.902788: train_loss -0.9641 
2024-11-21 16:38:18.902898: val_loss -0.895 
2024-11-21 16:38:18.902945: Pseudo dice [np.float32(0.9077)] 
2024-11-21 16:38:18.902995: Epoch time: 52.55 s 
2024-11-21 16:38:20.166275:  
2024-11-21 16:38:20.166434: Epoch 331 
2024-11-21 16:38:20.166586: Current learning rate: 0.00696 
2024-11-21 16:39:12.345943: train_loss -0.9618 
2024-11-21 16:39:12.346075: val_loss -0.9026 
2024-11-21 16:39:12.346140: Pseudo dice [np.float32(0.9158)] 
2024-11-21 16:39:12.346206: Epoch time: 52.18 s 
2024-11-21 16:39:13.405556:  
2024-11-21 16:39:13.405728: Epoch 332 
2024-11-21 16:39:13.405814: Current learning rate: 0.00696 
2024-11-21 16:40:05.667654: train_loss -0.9626 
2024-11-21 16:40:05.667771: val_loss -0.9012 
2024-11-21 16:40:05.667837: Pseudo dice [np.float32(0.9141)] 
2024-11-21 16:40:05.667908: Epoch time: 52.26 s 
2024-11-21 16:40:06.651602:  
2024-11-21 16:40:06.651829: Epoch 333 
2024-11-21 16:40:06.651953: Current learning rate: 0.00695 
2024-11-21 16:40:59.378585: train_loss -0.9631 
2024-11-21 16:40:59.378737: val_loss -0.8995 
2024-11-21 16:40:59.378787: Pseudo dice [np.float32(0.9138)] 
2024-11-21 16:40:59.378842: Epoch time: 52.73 s 
2024-11-21 16:41:00.277587:  
2024-11-21 16:41:00.277733: Epoch 334 
2024-11-21 16:41:00.277814: Current learning rate: 0.00694 
2024-11-21 16:41:52.647598: train_loss -0.963 
2024-11-21 16:41:52.647711: val_loss -0.9023 
2024-11-21 16:41:52.647758: Pseudo dice [np.float32(0.9162)] 
2024-11-21 16:41:52.647811: Epoch time: 52.37 s 
2024-11-21 16:41:52.647855: Yayy! New best EMA pseudo Dice: 0.9120000004768372 
2024-11-21 16:41:53.986595:  
2024-11-21 16:41:53.986760: Epoch 335 
2024-11-21 16:41:53.986825: Current learning rate: 0.00693 
2024-11-21 16:42:46.511609: train_loss -0.9647 
2024-11-21 16:42:46.511758: val_loss -0.8935 
2024-11-21 16:42:46.511823: Pseudo dice [np.float32(0.9073)] 
2024-11-21 16:42:46.511891: Epoch time: 52.53 s 
2024-11-21 16:42:47.521866:  
2024-11-21 16:42:47.522009: Epoch 336 
2024-11-21 16:42:47.522097: Current learning rate: 0.00692 
2024-11-21 16:43:40.213283: train_loss -0.9649 
2024-11-21 16:43:40.213467: val_loss -0.8988 
2024-11-21 16:43:40.213528: Pseudo dice [np.float32(0.9122)] 
2024-11-21 16:43:40.213587: Epoch time: 52.69 s 
2024-11-21 16:43:41.172306:  
2024-11-21 16:43:41.172455: Epoch 337 
2024-11-21 16:43:41.172581: Current learning rate: 0.00691 
2024-11-21 16:44:33.764531: train_loss -0.9642 
2024-11-21 16:44:33.764692: val_loss -0.8991 
2024-11-21 16:44:33.764740: Pseudo dice [np.float32(0.9131)] 
2024-11-21 16:44:33.764792: Epoch time: 52.59 s 
2024-11-21 16:44:34.742229:  
2024-11-21 16:44:34.742367: Epoch 338 
2024-11-21 16:44:34.742433: Current learning rate: 0.0069 
2024-11-21 16:45:27.359551: train_loss -0.9647 
2024-11-21 16:45:27.359699: val_loss -0.8932 
2024-11-21 16:45:27.359760: Pseudo dice [np.float32(0.908)] 
2024-11-21 16:45:27.359818: Epoch time: 52.62 s 
2024-11-21 16:45:28.275891:  
2024-11-21 16:45:28.276051: Epoch 339 
2024-11-21 16:45:28.276147: Current learning rate: 0.00689 
2024-11-21 16:46:20.630840: train_loss -0.9647 
2024-11-21 16:46:20.630969: val_loss -0.8974 
2024-11-21 16:46:20.631023: Pseudo dice [np.float32(0.9115)] 
2024-11-21 16:46:20.631082: Epoch time: 52.36 s 
2024-11-21 16:46:21.565373:  
2024-11-21 16:46:21.565515: Epoch 340 
2024-11-21 16:46:21.565589: Current learning rate: 0.00688 
2024-11-21 16:47:14.087126: train_loss -0.9657 
2024-11-21 16:47:14.087252: val_loss -0.897 
2024-11-21 16:47:14.087303: Pseudo dice [np.float32(0.9112)] 
2024-11-21 16:47:14.087388: Epoch time: 52.52 s 
2024-11-21 16:47:15.031396:  
2024-11-21 16:47:15.031593: Epoch 341 
2024-11-21 16:47:15.031660: Current learning rate: 0.00687 
2024-11-21 16:48:07.657397: train_loss -0.9651 
2024-11-21 16:48:07.657574: val_loss -0.8893 
2024-11-21 16:48:07.657622: Pseudo dice [np.float32(0.9042)] 
2024-11-21 16:48:07.657674: Epoch time: 52.63 s 
2024-11-21 16:48:08.948514:  
2024-11-21 16:48:08.948687: Epoch 342 
2024-11-21 16:48:08.948753: Current learning rate: 0.00686 
2024-11-21 16:49:01.206620: train_loss -0.9617 
2024-11-21 16:49:01.206757: val_loss -0.8948 
2024-11-21 16:49:01.206807: Pseudo dice [np.float32(0.9081)] 
2024-11-21 16:49:01.206859: Epoch time: 52.26 s 
2024-11-21 16:49:02.144951:  
2024-11-21 16:49:02.145096: Epoch 343 
2024-11-21 16:49:02.145164: Current learning rate: 0.00685 
2024-11-21 16:49:54.627163: train_loss -0.9588 
2024-11-21 16:49:54.627280: val_loss -0.8935 
2024-11-21 16:49:54.627333: Pseudo dice [np.float32(0.9082)] 
2024-11-21 16:49:54.627388: Epoch time: 52.48 s 
2024-11-21 16:49:55.592643:  
2024-11-21 16:49:55.592776: Epoch 344 
2024-11-21 16:49:55.592844: Current learning rate: 0.00684 
2024-11-21 16:50:48.100852: train_loss -0.958 
2024-11-21 16:50:48.101068: val_loss -0.8972 
2024-11-21 16:50:48.101137: Pseudo dice [np.float32(0.9112)] 
2024-11-21 16:50:48.101193: Epoch time: 52.51 s 
2024-11-21 16:50:49.071974:  
2024-11-21 16:50:49.072140: Epoch 345 
2024-11-21 16:50:49.072212: Current learning rate: 0.00683 
2024-11-21 16:51:41.635493: train_loss -0.9623 
2024-11-21 16:51:41.635616: val_loss -0.8961 
2024-11-21 16:51:41.635666: Pseudo dice [np.float32(0.9095)] 
2024-11-21 16:51:41.635720: Epoch time: 52.56 s 
2024-11-21 16:51:42.587292:  
2024-11-21 16:51:42.587647: Epoch 346 
2024-11-21 16:51:42.587739: Current learning rate: 0.00682 
2024-11-21 16:52:34.934304: train_loss -0.9646 
2024-11-21 16:52:34.934424: val_loss -0.8969 
2024-11-21 16:52:34.934503: Pseudo dice [np.float32(0.9087)] 
2024-11-21 16:52:34.934589: Epoch time: 52.35 s 
2024-11-21 16:52:35.918576:  
2024-11-21 16:52:35.918717: Epoch 347 
2024-11-21 16:52:35.918792: Current learning rate: 0.00681 
2024-11-21 16:53:28.432411: train_loss -0.9646 
2024-11-21 16:53:28.432631: val_loss -0.905 
2024-11-21 16:53:28.432714: Pseudo dice [np.float32(0.9185)] 
2024-11-21 16:53:28.432784: Epoch time: 52.51 s 
2024-11-21 16:53:29.431967:  
2024-11-21 16:53:29.432117: Epoch 348 
2024-11-21 16:53:29.432184: Current learning rate: 0.0068 
2024-11-21 16:54:21.965855: train_loss -0.9616 
2024-11-21 16:54:21.966004: val_loss -0.8955 
2024-11-21 16:54:21.966063: Pseudo dice [np.float32(0.909)] 
2024-11-21 16:54:21.966137: Epoch time: 52.53 s 
2024-11-21 16:54:22.887009:  
2024-11-21 16:54:22.887161: Epoch 349 
2024-11-21 16:54:22.887242: Current learning rate: 0.0068 
2024-11-21 16:55:15.756599: train_loss -0.9593 
2024-11-21 16:55:15.756715: val_loss -0.8836 
2024-11-21 16:55:15.756815: Pseudo dice [np.float32(0.8997)] 
2024-11-21 16:55:15.756871: Epoch time: 52.87 s 
2024-11-21 16:55:17.100594:  
2024-11-21 16:55:17.100749: Epoch 350 
2024-11-21 16:55:17.100820: Current learning rate: 0.00679 
2024-11-21 16:56:09.422300: train_loss -0.9478 
2024-11-21 16:56:09.422415: val_loss -0.8837 
2024-11-21 16:56:09.422462: Pseudo dice [np.float32(0.8987)] 
2024-11-21 16:56:09.422558: Epoch time: 52.32 s 
2024-11-21 16:56:10.397653:  
2024-11-21 16:56:10.397831: Epoch 351 
2024-11-21 16:56:10.397914: Current learning rate: 0.00678 
2024-11-21 16:57:02.937304: train_loss -0.9459 
2024-11-21 16:57:02.937434: val_loss -0.8856 
2024-11-21 16:57:02.937531: Pseudo dice [np.float32(0.9002)] 
2024-11-21 16:57:02.937613: Epoch time: 52.54 s 
2024-11-21 16:57:03.989201:  
2024-11-21 16:57:03.989366: Epoch 352 
2024-11-21 16:57:03.989480: Current learning rate: 0.00677 
2024-11-21 16:57:56.653291: train_loss -0.9531 
2024-11-21 16:57:56.653427: val_loss -0.8849 
2024-11-21 16:57:56.653523: Pseudo dice [np.float32(0.8998)] 
2024-11-21 16:57:56.653579: Epoch time: 52.67 s 
2024-11-21 16:57:57.658787:  
2024-11-21 16:57:57.658976: Epoch 353 
2024-11-21 16:57:57.659042: Current learning rate: 0.00676 
2024-11-21 16:58:49.950262: train_loss -0.9541 
2024-11-21 16:58:49.950484: val_loss -0.8822 
2024-11-21 16:58:49.950562: Pseudo dice [np.float32(0.8966)] 
2024-11-21 16:58:49.950632: Epoch time: 52.29 s 
2024-11-21 16:58:51.245988:  
2024-11-21 16:58:51.246184: Epoch 354 
2024-11-21 16:58:51.246252: Current learning rate: 0.00675 
2024-11-21 16:59:43.492279: train_loss -0.9478 
2024-11-21 16:59:43.492402: val_loss -0.8757 
2024-11-21 16:59:43.492465: Pseudo dice [np.float32(0.8929)] 
2024-11-21 16:59:43.492594: Epoch time: 52.25 s 
2024-11-21 16:59:44.496791:  
2024-11-21 16:59:44.496945: Epoch 355 
2024-11-21 16:59:44.497012: Current learning rate: 0.00674 
2024-11-21 17:00:37.033400: train_loss -0.9526 
2024-11-21 17:00:37.033556: val_loss -0.8966 
2024-11-21 17:00:37.033643: Pseudo dice [np.float32(0.9095)] 
2024-11-21 17:00:37.033696: Epoch time: 52.54 s 
2024-11-21 17:00:37.977105:  
2024-11-21 17:00:37.977243: Epoch 356 
2024-11-21 17:00:37.977319: Current learning rate: 0.00673 
2024-11-21 17:01:30.298972: train_loss -0.9567 
2024-11-21 17:01:30.299088: val_loss -0.895 
2024-11-21 17:01:30.299136: Pseudo dice [np.float32(0.9094)] 
2024-11-21 17:01:30.299187: Epoch time: 52.32 s 
2024-11-21 17:01:31.232890:  
2024-11-21 17:01:31.233064: Epoch 357 
2024-11-21 17:01:31.233135: Current learning rate: 0.00672 
2024-11-21 17:02:23.763078: train_loss -0.9582 
2024-11-21 17:02:23.763197: val_loss -0.885 
2024-11-21 17:02:23.763250: Pseudo dice [np.float32(0.9)] 
2024-11-21 17:02:23.763302: Epoch time: 52.53 s 
2024-11-21 17:02:24.725922:  
2024-11-21 17:02:24.726070: Epoch 358 
2024-11-21 17:02:24.726138: Current learning rate: 0.00671 
2024-11-21 17:03:17.260916: train_loss -0.9588 
2024-11-21 17:03:17.261041: val_loss -0.8934 
2024-11-21 17:03:17.261095: Pseudo dice [np.float32(0.9075)] 
2024-11-21 17:03:17.261150: Epoch time: 52.54 s 
2024-11-21 17:03:18.271562:  
2024-11-21 17:03:18.271796: Epoch 359 
2024-11-21 17:03:18.271869: Current learning rate: 0.0067 
2024-11-21 17:04:10.958641: train_loss -0.9614 
2024-11-21 17:04:10.958786: val_loss -0.8944 
2024-11-21 17:04:10.958850: Pseudo dice [np.float32(0.9082)] 
2024-11-21 17:04:10.958918: Epoch time: 52.69 s 
2024-11-21 17:04:11.918533:  
2024-11-21 17:04:11.918750: Epoch 360 
2024-11-21 17:04:11.918818: Current learning rate: 0.00669 
2024-11-21 17:05:04.412340: train_loss -0.9625 
2024-11-21 17:05:04.412487: val_loss -0.8965 
2024-11-21 17:05:04.412537: Pseudo dice [np.float32(0.9098)] 
2024-11-21 17:05:04.412591: Epoch time: 52.49 s 
2024-11-21 17:05:05.404293:  
2024-11-21 17:05:05.404510: Epoch 361 
2024-11-21 17:05:05.404596: Current learning rate: 0.00668 
2024-11-21 17:05:57.826985: train_loss -0.963 
2024-11-21 17:05:57.827095: val_loss -0.8955 
2024-11-21 17:05:57.827160: Pseudo dice [np.float32(0.9094)] 
2024-11-21 17:05:57.827213: Epoch time: 52.42 s 
2024-11-21 17:05:58.809820:  
2024-11-21 17:05:58.809992: Epoch 362 
2024-11-21 17:05:58.810076: Current learning rate: 0.00667 
2024-11-21 17:06:51.016906: train_loss -0.9634 
2024-11-21 17:06:51.017033: val_loss -0.9014 
2024-11-21 17:06:51.017084: Pseudo dice [np.float32(0.9135)] 
2024-11-21 17:06:51.017137: Epoch time: 52.21 s 
2024-11-21 17:06:52.020195:  
2024-11-21 17:06:52.020395: Epoch 363 
2024-11-21 17:06:52.020487: Current learning rate: 0.00666 
2024-11-21 17:07:44.751685: train_loss -0.9635 
2024-11-21 17:07:44.751806: val_loss -0.8955 
2024-11-21 17:07:44.751859: Pseudo dice [np.float32(0.909)] 
2024-11-21 17:07:44.751912: Epoch time: 52.73 s 
2024-11-21 17:07:45.749076:  
2024-11-21 17:07:45.749198: Epoch 364 
2024-11-21 17:07:45.749269: Current learning rate: 0.00665 
2024-11-21 17:08:38.127329: train_loss -0.9628 
2024-11-21 17:08:38.127457: val_loss -0.8916 
2024-11-21 17:08:38.127550: Pseudo dice [np.float32(0.9066)] 
2024-11-21 17:08:38.127669: Epoch time: 52.38 s 
2024-11-21 17:08:39.428317:  
2024-11-21 17:08:39.428511: Epoch 365 
2024-11-21 17:08:39.428606: Current learning rate: 0.00665 
2024-11-21 17:09:31.576277: train_loss -0.9612 
2024-11-21 17:09:31.576402: val_loss -0.8835 
2024-11-21 17:09:31.576467: Pseudo dice [np.float32(0.9012)] 
2024-11-21 17:09:31.576569: Epoch time: 52.15 s 
2024-11-21 17:09:32.625386:  
2024-11-21 17:09:32.625552: Epoch 366 
2024-11-21 17:09:32.625657: Current learning rate: 0.00664 
2024-11-21 17:10:25.209392: train_loss -0.959 
2024-11-21 17:10:25.209560: val_loss -0.8977 
2024-11-21 17:10:25.209630: Pseudo dice [np.float32(0.9126)] 
2024-11-21 17:10:25.209699: Epoch time: 52.59 s 
2024-11-21 17:10:26.113820:  
2024-11-21 17:10:26.114023: Epoch 367 
2024-11-21 17:10:26.114132: Current learning rate: 0.00663 
2024-11-21 17:11:18.696937: train_loss -0.9634 
2024-11-21 17:11:18.697083: val_loss -0.8949 
2024-11-21 17:11:18.697926: Pseudo dice [np.float32(0.908)] 
2024-11-21 17:11:18.697983: Epoch time: 52.58 s 
2024-11-21 17:11:19.616737:  
2024-11-21 17:11:19.616885: Epoch 368 
2024-11-21 17:11:19.616950: Current learning rate: 0.00662 
2024-11-21 17:12:11.929146: train_loss -0.9639 
2024-11-21 17:12:11.929256: val_loss -0.9001 
2024-11-21 17:12:11.929303: Pseudo dice [np.float32(0.9129)] 
2024-11-21 17:12:11.929355: Epoch time: 52.31 s 
2024-11-21 17:12:12.866497:  
2024-11-21 17:12:12.866645: Epoch 369 
2024-11-21 17:12:12.866713: Current learning rate: 0.00661 
2024-11-21 17:13:05.165842: train_loss -0.9637 
2024-11-21 17:13:05.165978: val_loss -0.8956 
2024-11-21 17:13:05.166895: Pseudo dice [np.float32(0.9097)] 
2024-11-21 17:13:05.166969: Epoch time: 52.3 s 
2024-11-21 17:13:06.320485:  
2024-11-21 17:13:06.320791: Epoch 370 
2024-11-21 17:13:06.320886: Current learning rate: 0.0066 
2024-11-21 17:13:58.744691: train_loss -0.9653 
2024-11-21 17:13:58.744812: val_loss -0.8991 
2024-11-21 17:13:58.744860: Pseudo dice [np.float32(0.9113)] 
2024-11-21 17:13:58.744913: Epoch time: 52.43 s 
2024-11-21 17:13:59.700191:  
2024-11-21 17:13:59.700379: Epoch 371 
2024-11-21 17:13:59.700465: Current learning rate: 0.00659 
2024-11-21 17:14:52.152209: train_loss -0.9652 
2024-11-21 17:14:52.152346: val_loss -0.8939 
2024-11-21 17:14:52.152411: Pseudo dice [np.float32(0.9072)] 
2024-11-21 17:14:52.152487: Epoch time: 52.45 s 
2024-11-21 17:14:53.118137:  
2024-11-21 17:14:53.118355: Epoch 372 
2024-11-21 17:14:53.118442: Current learning rate: 0.00658 
2024-11-21 17:15:45.326231: train_loss -0.9666 
2024-11-21 17:15:45.326364: val_loss -0.8942 
2024-11-21 17:15:45.326429: Pseudo dice [np.float32(0.9095)] 
2024-11-21 17:15:45.326505: Epoch time: 52.21 s 
2024-11-21 17:15:46.366066:  
2024-11-21 17:15:46.366291: Epoch 373 
2024-11-21 17:15:46.366402: Current learning rate: 0.00657 
2024-11-21 17:16:38.712052: train_loss -0.9665 
2024-11-21 17:16:38.712176: val_loss -0.8972 
2024-11-21 17:16:38.712239: Pseudo dice [np.float32(0.9112)] 
2024-11-21 17:16:38.712306: Epoch time: 52.35 s 
2024-11-21 17:16:39.605559:  
2024-11-21 17:16:39.605700: Epoch 374 
2024-11-21 17:16:39.605765: Current learning rate: 0.00656 
2024-11-21 17:17:32.042950: train_loss -0.9667 
2024-11-21 17:17:32.043062: val_loss -0.8995 
2024-11-21 17:17:32.043140: Pseudo dice [np.float32(0.9135)] 
2024-11-21 17:17:32.043195: Epoch time: 52.44 s 
2024-11-21 17:17:33.084512:  
2024-11-21 17:17:33.084688: Epoch 375 
2024-11-21 17:17:33.084773: Current learning rate: 0.00655 
2024-11-21 17:18:25.397149: train_loss -0.9659 
2024-11-21 17:18:25.397272: val_loss -0.8978 
2024-11-21 17:18:25.397396: Pseudo dice [np.float32(0.9126)] 
2024-11-21 17:18:25.397478: Epoch time: 52.31 s 
2024-11-21 17:18:26.411373:  
2024-11-21 17:18:26.411549: Epoch 376 
2024-11-21 17:18:26.411642: Current learning rate: 0.00654 
2024-11-21 17:19:18.793853: train_loss -0.9663 
2024-11-21 17:19:18.793967: val_loss -0.896 
2024-11-21 17:19:18.794017: Pseudo dice [np.float32(0.9081)] 
2024-11-21 17:19:18.794107: Epoch time: 52.38 s 
2024-11-21 17:19:20.058074:  
2024-11-21 17:19:20.058277: Epoch 377 
2024-11-21 17:19:20.058361: Current learning rate: 0.00653 
2024-11-21 17:20:12.617678: train_loss -0.9661 
2024-11-21 17:20:12.617812: val_loss -0.9002 
2024-11-21 17:20:12.617864: Pseudo dice [np.float32(0.9136)] 
2024-11-21 17:20:12.617919: Epoch time: 52.56 s 
2024-11-21 17:20:13.597370:  
2024-11-21 17:20:13.597566: Epoch 378 
2024-11-21 17:20:13.597675: Current learning rate: 0.00652 
2024-11-21 17:21:06.312859: train_loss -0.9655 
2024-11-21 17:21:06.312979: val_loss -0.8941 
2024-11-21 17:21:06.313888: Pseudo dice [np.float32(0.9087)] 
2024-11-21 17:21:06.313942: Epoch time: 52.72 s 
2024-11-21 17:21:07.254890:  
2024-11-21 17:21:07.255053: Epoch 379 
2024-11-21 17:21:07.255121: Current learning rate: 0.00651 
2024-11-21 17:21:59.727702: train_loss -0.9662 
2024-11-21 17:21:59.727825: val_loss -0.9006 
2024-11-21 17:21:59.727875: Pseudo dice [np.float32(0.9143)] 
2024-11-21 17:21:59.727928: Epoch time: 52.47 s 
2024-11-21 17:22:00.655720:  
2024-11-21 17:22:00.655921: Epoch 380 
2024-11-21 17:22:00.656008: Current learning rate: 0.0065 
2024-11-21 17:22:53.154560: train_loss -0.964 
2024-11-21 17:22:53.154703: val_loss -0.8996 
2024-11-21 17:22:53.154757: Pseudo dice [np.float32(0.9122)] 
2024-11-21 17:22:53.154816: Epoch time: 52.5 s 
2024-11-21 17:22:54.129591:  
2024-11-21 17:22:54.129839: Epoch 381 
2024-11-21 17:22:54.129967: Current learning rate: 0.00649 
2024-11-21 17:23:46.653479: train_loss -0.9652 
2024-11-21 17:23:46.653613: val_loss -0.8951 
2024-11-21 17:23:46.653707: Pseudo dice [np.float32(0.9082)] 
2024-11-21 17:23:46.653778: Epoch time: 52.52 s 
2024-11-21 17:23:47.646775:  
2024-11-21 17:23:47.646941: Epoch 382 
2024-11-21 17:23:47.647177: Current learning rate: 0.00648 
2024-11-21 17:24:39.913104: train_loss -0.9662 
2024-11-21 17:24:39.913241: val_loss -0.9031 
2024-11-21 17:24:39.913292: Pseudo dice [np.float32(0.9154)] 
2024-11-21 17:24:39.913348: Epoch time: 52.27 s 
2024-11-21 17:24:40.972129:  
2024-11-21 17:24:40.972314: Epoch 383 
2024-11-21 17:24:40.972386: Current learning rate: 0.00648 
2024-11-21 17:25:33.249606: train_loss -0.9659 
2024-11-21 17:25:33.249763: val_loss -0.8923 
2024-11-21 17:25:33.249827: Pseudo dice [np.float32(0.9072)] 
2024-11-21 17:25:33.249894: Epoch time: 52.28 s 
2024-11-21 17:25:34.281908:  
2024-11-21 17:25:34.282176: Epoch 384 
2024-11-21 17:25:34.282249: Current learning rate: 0.00647 
2024-11-21 17:26:26.622892: train_loss -0.9668 
2024-11-21 17:26:26.623088: val_loss -0.8947 
2024-11-21 17:26:26.623184: Pseudo dice [np.float32(0.9085)] 
2024-11-21 17:26:26.623307: Epoch time: 52.34 s 
2024-11-21 17:26:27.707941:  
2024-11-21 17:26:27.708111: Epoch 385 
2024-11-21 17:26:27.708198: Current learning rate: 0.00646 
2024-11-21 17:27:20.081484: train_loss -0.9665 
2024-11-21 17:27:20.081618: val_loss -0.9004 
2024-11-21 17:27:20.081686: Pseudo dice [np.float32(0.9139)] 
2024-11-21 17:27:20.081756: Epoch time: 52.37 s 
2024-11-21 17:27:21.138032:  
2024-11-21 17:27:21.138244: Epoch 386 
2024-11-21 17:27:21.138331: Current learning rate: 0.00645 
2024-11-21 17:28:13.363905: train_loss -0.966 
2024-11-21 17:28:13.364141: val_loss -0.9005 
2024-11-21 17:28:13.364201: Pseudo dice [np.float32(0.9146)] 
2024-11-21 17:28:13.364258: Epoch time: 52.23 s 
2024-11-21 17:28:14.318791:  
2024-11-21 17:28:14.318930: Epoch 387 
2024-11-21 17:28:14.318997: Current learning rate: 0.00644 
2024-11-21 17:29:06.502198: train_loss -0.9657 
2024-11-21 17:29:06.502324: val_loss -0.9028 
2024-11-21 17:29:06.502377: Pseudo dice [np.float32(0.9159)] 
2024-11-21 17:29:06.502433: Epoch time: 52.18 s 
2024-11-21 17:29:07.823794:  
2024-11-21 17:29:07.823971: Epoch 388 
2024-11-21 17:29:07.824060: Current learning rate: 0.00643 
2024-11-21 17:30:00.470086: train_loss -0.965 
2024-11-21 17:30:00.470204: val_loss -0.8955 
2024-11-21 17:30:00.470252: Pseudo dice [np.float32(0.9095)] 
2024-11-21 17:30:00.470305: Epoch time: 52.65 s 
2024-11-21 17:30:01.476130:  
2024-11-21 17:30:01.476420: Epoch 389 
2024-11-21 17:30:01.476519: Current learning rate: 0.00642 
2024-11-21 17:30:54.011020: train_loss -0.966 
2024-11-21 17:30:54.011136: val_loss -0.8986 
2024-11-21 17:30:54.011184: Pseudo dice [np.float32(0.911)] 
2024-11-21 17:30:54.011237: Epoch time: 52.54 s 
2024-11-21 17:30:54.982630:  
2024-11-21 17:30:54.982785: Epoch 390 
2024-11-21 17:30:54.982853: Current learning rate: 0.00641 
2024-11-21 17:31:47.268641: train_loss -0.9667 
2024-11-21 17:31:47.268776: val_loss -0.8943 
2024-11-21 17:31:47.268826: Pseudo dice [np.float32(0.9076)] 
2024-11-21 17:31:47.268879: Epoch time: 52.29 s 
2024-11-21 17:31:48.295707:  
2024-11-21 17:31:48.295892: Epoch 391 
2024-11-21 17:31:48.295961: Current learning rate: 0.0064 
2024-11-21 17:32:40.735175: train_loss -0.9669 
2024-11-21 17:32:40.735292: val_loss -0.8993 
2024-11-21 17:32:40.735341: Pseudo dice [np.float32(0.913)] 
2024-11-21 17:32:40.735393: Epoch time: 52.44 s 
2024-11-21 17:32:41.716114:  
2024-11-21 17:32:41.716293: Epoch 392 
2024-11-21 17:32:41.716375: Current learning rate: 0.00639 
2024-11-21 17:33:34.485968: train_loss -0.9666 
2024-11-21 17:33:34.486127: val_loss -0.8989 
2024-11-21 17:33:34.486248: Pseudo dice [np.float32(0.9128)] 
2024-11-21 17:33:34.486332: Epoch time: 52.77 s 
2024-11-21 17:33:35.457029:  
2024-11-21 17:33:35.457222: Epoch 393 
2024-11-21 17:33:35.457333: Current learning rate: 0.00638 
2024-11-21 17:34:27.882687: train_loss -0.9675 
2024-11-21 17:34:27.882803: val_loss -0.9015 
2024-11-21 17:34:27.882854: Pseudo dice [np.float32(0.9149)] 
2024-11-21 17:34:27.882905: Epoch time: 52.43 s 
2024-11-21 17:34:28.859283:  
2024-11-21 17:34:28.859635: Epoch 394 
2024-11-21 17:34:28.859711: Current learning rate: 0.00637 
2024-11-21 17:35:21.108437: train_loss -0.9669 
2024-11-21 17:35:21.108613: val_loss -0.902 
2024-11-21 17:35:21.108679: Pseudo dice [np.float32(0.9135)] 
2024-11-21 17:35:21.108747: Epoch time: 52.25 s 
2024-11-21 17:35:22.127598:  
2024-11-21 17:35:22.127771: Epoch 395 
2024-11-21 17:35:22.127866: Current learning rate: 0.00636 
2024-11-21 17:36:14.257143: train_loss -0.9669 
2024-11-21 17:36:14.257260: val_loss -0.896 
2024-11-21 17:36:14.257309: Pseudo dice [np.float32(0.909)] 
2024-11-21 17:36:14.257362: Epoch time: 52.13 s 
2024-11-21 17:36:15.203972:  
2024-11-21 17:36:15.204184: Epoch 396 
2024-11-21 17:36:15.204270: Current learning rate: 0.00635 
2024-11-21 17:37:07.537794: train_loss -0.9677 
2024-11-21 17:37:07.537984: val_loss -0.9007 
2024-11-21 17:37:07.538047: Pseudo dice [np.float32(0.9144)] 
2024-11-21 17:37:07.538114: Epoch time: 52.33 s 
2024-11-21 17:37:08.550908:  
2024-11-21 17:37:08.551090: Epoch 397 
2024-11-21 17:37:08.551182: Current learning rate: 0.00634 
2024-11-21 17:38:00.905616: train_loss -0.9671 
2024-11-21 17:38:00.905755: val_loss -0.9051 
2024-11-21 17:38:00.905843: Pseudo dice [np.float32(0.9176)] 
2024-11-21 17:38:00.905939: Epoch time: 52.36 s 
2024-11-21 17:38:00.905993: Yayy! New best EMA pseudo Dice: 0.9124000072479248 
2024-11-21 17:38:02.337011:  
2024-11-21 17:38:02.337153: Epoch 398 
2024-11-21 17:38:02.337245: Current learning rate: 0.00633 
2024-11-21 17:38:54.322059: train_loss -0.9674 
2024-11-21 17:38:54.322175: val_loss -0.9007 
2024-11-21 17:38:54.322257: Pseudo dice [np.float32(0.9141)] 
2024-11-21 17:38:54.322313: Epoch time: 51.99 s 
2024-11-21 17:38:54.322359: Yayy! New best EMA pseudo Dice: 0.9125000238418579 
2024-11-21 17:38:55.922407:  
2024-11-21 17:38:55.922743: Epoch 399 
2024-11-21 17:38:55.922845: Current learning rate: 0.00632 
2024-11-21 17:39:48.365927: train_loss -0.9684 
2024-11-21 17:39:48.366175: val_loss -0.899 
2024-11-21 17:39:48.366278: Pseudo dice [np.float32(0.9132)] 
2024-11-21 17:39:48.366349: Epoch time: 52.44 s 
2024-11-21 17:39:48.756651: Yayy! New best EMA pseudo Dice: 0.9125999808311462 
2024-11-21 17:39:50.096906:  
2024-11-21 17:39:50.097057: Epoch 400 
2024-11-21 17:39:50.097141: Current learning rate: 0.00631 
2024-11-21 17:40:42.527084: train_loss -0.9683 
2024-11-21 17:40:42.527196: val_loss -0.896 
2024-11-21 17:40:42.527248: Pseudo dice [np.float32(0.9091)] 
2024-11-21 17:40:42.527310: Epoch time: 52.43 s 
2024-11-21 17:40:43.614577:  
2024-11-21 17:40:43.614771: Epoch 401 
2024-11-21 17:40:43.614853: Current learning rate: 0.0063 
2024-11-21 17:41:36.125922: train_loss -0.9669 
2024-11-21 17:41:36.126050: val_loss -0.8952 
2024-11-21 17:41:36.126102: Pseudo dice [np.float32(0.9113)] 
2024-11-21 17:41:36.126158: Epoch time: 52.51 s 
2024-11-21 17:41:37.120762:  
2024-11-21 17:41:37.120922: Epoch 402 
2024-11-21 17:41:37.120990: Current learning rate: 0.0063 
2024-11-21 17:42:29.661870: train_loss -0.967 
2024-11-21 17:42:29.662127: val_loss -0.8984 
2024-11-21 17:42:29.662257: Pseudo dice [np.float32(0.9123)] 
2024-11-21 17:42:29.662327: Epoch time: 52.54 s 
2024-11-21 17:42:30.694888:  
2024-11-21 17:42:30.695022: Epoch 403 
2024-11-21 17:42:30.695100: Current learning rate: 0.00629 
2024-11-21 17:43:22.807368: train_loss -0.968 
2024-11-21 17:43:22.807490: val_loss -0.8983 
2024-11-21 17:43:22.807539: Pseudo dice [np.float32(0.9129)] 
2024-11-21 17:43:22.807610: Epoch time: 52.11 s 
2024-11-21 17:43:23.840863:  
2024-11-21 17:43:23.841147: Epoch 404 
2024-11-21 17:43:23.841242: Current learning rate: 0.00628 
2024-11-21 17:44:16.147690: train_loss -0.9676 
2024-11-21 17:44:16.147831: val_loss -0.8985 
2024-11-21 17:44:16.147897: Pseudo dice [np.float32(0.9123)] 
2024-11-21 17:44:16.147967: Epoch time: 52.31 s 
2024-11-21 17:44:17.165232:  
2024-11-21 17:44:17.165388: Epoch 405 
2024-11-21 17:44:17.165459: Current learning rate: 0.00627 
2024-11-21 17:45:09.710398: train_loss -0.967 
2024-11-21 17:45:09.710559: val_loss -0.9015 
2024-11-21 17:45:09.710632: Pseudo dice [np.float32(0.9157)] 
2024-11-21 17:45:09.710687: Epoch time: 52.55 s 
2024-11-21 17:45:10.672658:  
2024-11-21 17:45:10.672899: Epoch 406 
2024-11-21 17:45:10.672998: Current learning rate: 0.00626 
2024-11-21 17:46:02.985457: train_loss -0.9663 
2024-11-21 17:46:02.985620: val_loss -0.8916 
2024-11-21 17:46:02.985685: Pseudo dice [np.float32(0.9058)] 
2024-11-21 17:46:02.985755: Epoch time: 52.31 s 
2024-11-21 17:46:04.006608:  
2024-11-21 17:46:04.006780: Epoch 407 
2024-11-21 17:46:04.006865: Current learning rate: 0.00625 
2024-11-21 17:46:56.392037: train_loss -0.9673 
2024-11-21 17:46:56.392219: val_loss -0.8908 
2024-11-21 17:46:56.392334: Pseudo dice [np.float32(0.9052)] 
2024-11-21 17:46:56.392409: Epoch time: 52.39 s 
2024-11-21 17:46:57.477284:  
2024-11-21 17:46:57.477460: Epoch 408 
2024-11-21 17:46:57.477539: Current learning rate: 0.00624 
2024-11-21 17:47:49.533121: train_loss -0.9666 
2024-11-21 17:47:49.533252: val_loss -0.8973 
2024-11-21 17:47:49.533300: Pseudo dice [np.float32(0.9112)] 
2024-11-21 17:47:49.533352: Epoch time: 52.06 s 
2024-11-21 17:47:50.504412:  
2024-11-21 17:47:50.504727: Epoch 409 
2024-11-21 17:47:50.504847: Current learning rate: 0.00623 
2024-11-21 17:48:42.823541: train_loss -0.9662 
2024-11-21 17:48:42.823696: val_loss -0.9006 
2024-11-21 17:48:42.823746: Pseudo dice [np.float32(0.9151)] 
2024-11-21 17:48:42.823800: Epoch time: 52.32 s 
2024-11-21 17:48:44.087461:  
2024-11-21 17:48:44.087692: Epoch 410 
2024-11-21 17:48:44.087785: Current learning rate: 0.00622 
2024-11-21 17:49:36.301609: train_loss -0.9678 
2024-11-21 17:49:36.301769: val_loss -0.8971 
2024-11-21 17:49:36.301821: Pseudo dice [np.float32(0.9095)] 
2024-11-21 17:49:36.301891: Epoch time: 52.21 s 
2024-11-21 17:49:37.252645:  
2024-11-21 17:49:37.252953: Epoch 411 
2024-11-21 17:49:37.253102: Current learning rate: 0.00621 
2024-11-21 17:50:29.633877: train_loss -0.9688 
2024-11-21 17:50:29.634007: val_loss -0.9006 
2024-11-21 17:50:29.634057: Pseudo dice [np.float32(0.9146)] 
2024-11-21 17:50:29.634108: Epoch time: 52.38 s 
2024-11-21 17:50:30.629487:  
2024-11-21 17:50:30.629683: Epoch 412 
2024-11-21 17:50:30.629768: Current learning rate: 0.0062 
2024-11-21 17:51:23.082344: train_loss -0.9672 
2024-11-21 17:51:23.082491: val_loss -0.8978 
2024-11-21 17:51:23.082588: Pseudo dice [np.float32(0.9121)] 
2024-11-21 17:51:23.082662: Epoch time: 52.45 s 
2024-11-21 17:51:23.947069:  
2024-11-21 17:51:23.947218: Epoch 413 
2024-11-21 17:51:23.947293: Current learning rate: 0.00619 
2024-11-21 17:52:16.515363: train_loss -0.9675 
2024-11-21 17:52:16.515529: val_loss -0.8995 
2024-11-21 17:52:16.515608: Pseudo dice [np.float32(0.9142)] 
2024-11-21 17:52:16.515663: Epoch time: 52.57 s 
2024-11-21 17:52:17.511722:  
2024-11-21 17:52:17.511899: Epoch 414 
2024-11-21 17:52:17.511972: Current learning rate: 0.00618 
2024-11-21 17:53:09.859278: train_loss -0.9685 
2024-11-21 17:53:09.859398: val_loss -0.9016 
2024-11-21 17:53:09.859486: Pseudo dice [np.float32(0.9154)] 
2024-11-21 17:53:09.859577: Epoch time: 52.35 s 
2024-11-21 17:53:10.798809:  
2024-11-21 17:53:10.798990: Epoch 415 
2024-11-21 17:53:10.799075: Current learning rate: 0.00617 
2024-11-21 17:54:03.092897: train_loss -0.9686 
2024-11-21 17:54:03.093058: val_loss -0.9043 
2024-11-21 17:54:03.093112: Pseudo dice [np.float32(0.9159)] 
2024-11-21 17:54:03.093171: Epoch time: 52.29 s 
2024-11-21 17:54:03.093221: Yayy! New best EMA pseudo Dice: 0.9126999974250793 
2024-11-21 17:54:04.455882:  
2024-11-21 17:54:04.456043: Epoch 416 
2024-11-21 17:54:04.456120: Current learning rate: 0.00616 
2024-11-21 17:54:56.857922: train_loss -0.9682 
2024-11-21 17:54:56.858052: val_loss -0.9016 
2024-11-21 17:54:56.858122: Pseudo dice [np.float32(0.9134)] 
2024-11-21 17:54:56.858175: Epoch time: 52.4 s 
2024-11-21 17:54:56.858217: Yayy! New best EMA pseudo Dice: 0.9128000140190125 
2024-11-21 17:54:58.125531:  
2024-11-21 17:54:58.125912: Epoch 417 
2024-11-21 17:54:58.126018: Current learning rate: 0.00615 
2024-11-21 17:55:50.565666: train_loss -0.9684 
2024-11-21 17:55:50.565788: val_loss -0.896 
2024-11-21 17:55:50.565840: Pseudo dice [np.float32(0.9095)] 
2024-11-21 17:55:50.565897: Epoch time: 52.44 s 
2024-11-21 17:55:51.516298:  
2024-11-21 17:55:51.516436: Epoch 418 
2024-11-21 17:55:51.516552: Current learning rate: 0.00614 
2024-11-21 17:56:43.935409: train_loss -0.968 
2024-11-21 17:56:43.935539: val_loss -0.8956 
2024-11-21 17:56:43.935588: Pseudo dice [np.float32(0.9098)] 
2024-11-21 17:56:43.935640: Epoch time: 52.42 s 
2024-11-21 17:56:44.841385:  
2024-11-21 17:56:44.841568: Epoch 419 
2024-11-21 17:56:44.841669: Current learning rate: 0.00613 
2024-11-21 17:57:37.137790: train_loss -0.9687 
2024-11-21 17:57:37.137946: val_loss -0.8983 
2024-11-21 17:57:37.138010: Pseudo dice [np.float32(0.9129)] 
2024-11-21 17:57:37.138079: Epoch time: 52.3 s 
2024-11-21 17:57:38.203073:  
2024-11-21 17:57:38.203212: Epoch 420 
2024-11-21 17:57:38.203315: Current learning rate: 0.00612 
2024-11-21 17:58:30.035688: train_loss -0.9693 
2024-11-21 17:58:30.035899: val_loss -0.9017 
2024-11-21 17:58:30.035964: Pseudo dice [np.float32(0.915)] 
2024-11-21 17:58:30.036035: Epoch time: 51.83 s 
2024-11-21 17:58:31.085695:  
2024-11-21 17:58:31.085917: Epoch 421 
2024-11-21 17:58:31.086185: Current learning rate: 0.00612 
2024-11-21 17:59:23.268033: train_loss -0.9689 
2024-11-21 17:59:23.268176: val_loss -0.9028 
2024-11-21 17:59:23.268227: Pseudo dice [np.float32(0.9162)] 
2024-11-21 17:59:23.268281: Epoch time: 52.18 s 
2024-11-21 17:59:23.268327: Yayy! New best EMA pseudo Dice: 0.9128999710083008 
2024-11-21 17:59:24.872082:  
2024-11-21 17:59:24.872235: Epoch 422 
2024-11-21 17:59:24.872303: Current learning rate: 0.00611 
2024-11-21 18:00:17.124439: train_loss -0.9692 
2024-11-21 18:00:17.124640: val_loss -0.8977 
2024-11-21 18:00:17.124689: Pseudo dice [np.float32(0.9117)] 
2024-11-21 18:00:17.124742: Epoch time: 52.25 s 
2024-11-21 18:00:18.058487:  
2024-11-21 18:00:18.058631: Epoch 423 
2024-11-21 18:00:18.058697: Current learning rate: 0.0061 
2024-11-21 18:01:10.237029: train_loss -0.9671 
2024-11-21 18:01:10.237193: val_loss -0.8965 
2024-11-21 18:01:10.237261: Pseudo dice [np.float32(0.9108)] 
2024-11-21 18:01:10.237332: Epoch time: 52.18 s 
2024-11-21 18:01:11.245837:  
2024-11-21 18:01:11.246014: Epoch 424 
2024-11-21 18:01:11.246099: Current learning rate: 0.00609 
2024-11-21 18:02:03.695427: train_loss -0.9638 
2024-11-21 18:02:03.695620: val_loss -0.8976 
2024-11-21 18:02:03.695672: Pseudo dice [np.float32(0.9114)] 
2024-11-21 18:02:03.695733: Epoch time: 52.45 s 
2024-11-21 18:02:04.638261:  
2024-11-21 18:02:04.638445: Epoch 425 
2024-11-21 18:02:04.638538: Current learning rate: 0.00608 
2024-11-21 18:02:56.959122: train_loss -0.9658 
2024-11-21 18:02:56.959251: val_loss -0.9028 
2024-11-21 18:02:56.959312: Pseudo dice [np.float32(0.9161)] 
2024-11-21 18:02:56.959378: Epoch time: 52.32 s 
2024-11-21 18:02:57.847659:  
2024-11-21 18:02:57.847849: Epoch 426 
2024-11-21 18:02:57.847922: Current learning rate: 0.00607 
2024-11-21 18:03:50.296104: train_loss -0.9666 
2024-11-21 18:03:50.296228: val_loss -0.89 
2024-11-21 18:03:50.297140: Pseudo dice [np.float32(0.9053)] 
2024-11-21 18:03:50.297209: Epoch time: 52.45 s 
2024-11-21 18:03:51.267875:  
2024-11-21 18:03:51.268088: Epoch 427 
2024-11-21 18:03:51.268175: Current learning rate: 0.00606 
2024-11-21 18:04:43.367244: train_loss -0.9675 
2024-11-21 18:04:43.367379: val_loss -0.8972 
2024-11-21 18:04:43.367431: Pseudo dice [np.float32(0.9126)] 
2024-11-21 18:04:43.367521: Epoch time: 52.1 s 
2024-11-21 18:04:44.380401:  
2024-11-21 18:04:44.380661: Epoch 428 
2024-11-21 18:04:44.380777: Current learning rate: 0.00605 
2024-11-21 18:05:36.908381: train_loss -0.9682 
2024-11-21 18:05:36.908521: val_loss -0.8975 
2024-11-21 18:05:36.908592: Pseudo dice [np.float32(0.9115)] 
2024-11-21 18:05:36.908665: Epoch time: 52.53 s 
2024-11-21 18:05:37.870654:  
2024-11-21 18:05:37.870865: Epoch 429 
2024-11-21 18:05:37.870964: Current learning rate: 0.00604 
2024-11-21 18:06:30.325347: train_loss -0.969 
2024-11-21 18:06:30.325509: val_loss -0.8952 
2024-11-21 18:06:30.325574: Pseudo dice [np.float32(0.9087)] 
2024-11-21 18:06:30.325641: Epoch time: 52.46 s 
2024-11-21 18:06:31.311569:  
2024-11-21 18:06:31.311751: Epoch 430 
2024-11-21 18:06:31.311822: Current learning rate: 0.00603 
2024-11-21 18:07:23.592367: train_loss -0.9679 
2024-11-21 18:07:23.592528: val_loss -0.8977 
2024-11-21 18:07:23.592600: Pseudo dice [np.float32(0.9131)] 
2024-11-21 18:07:23.592653: Epoch time: 52.28 s 
2024-11-21 18:07:24.588673:  
2024-11-21 18:07:24.588804: Epoch 431 
2024-11-21 18:07:24.588874: Current learning rate: 0.00602 
2024-11-21 18:08:17.179278: train_loss -0.9691 
2024-11-21 18:08:17.179396: val_loss -0.8961 
2024-11-21 18:08:17.179447: Pseudo dice [np.float32(0.9093)] 
2024-11-21 18:08:17.179542: Epoch time: 52.59 s 
2024-11-21 18:08:18.088179:  
2024-11-21 18:08:18.088325: Epoch 432 
2024-11-21 18:08:18.088435: Current learning rate: 0.00601 
2024-11-21 18:09:10.995468: train_loss -0.9687 
2024-11-21 18:09:10.995623: val_loss -0.8961 
2024-11-21 18:09:10.995693: Pseudo dice [np.float32(0.9102)] 
2024-11-21 18:09:10.995779: Epoch time: 52.91 s 
2024-11-21 18:09:12.255326:  
2024-11-21 18:09:12.255503: Epoch 433 
2024-11-21 18:09:12.255621: Current learning rate: 0.006 
2024-11-21 18:10:04.927043: train_loss -0.9688 
2024-11-21 18:10:04.927294: val_loss -0.899 
2024-11-21 18:10:04.927355: Pseudo dice [np.float32(0.9127)] 
2024-11-21 18:10:04.927409: Epoch time: 52.67 s 
2024-11-21 18:10:05.843717:  
2024-11-21 18:10:05.843867: Epoch 434 
2024-11-21 18:10:05.843934: Current learning rate: 0.00599 
2024-11-21 18:10:58.223088: train_loss -0.9691 
2024-11-21 18:10:58.223189: val_loss -0.8972 
2024-11-21 18:10:58.223234: Pseudo dice [np.float32(0.913)] 
2024-11-21 18:10:58.223284: Epoch time: 52.38 s 
2024-11-21 18:10:59.141667:  
2024-11-21 18:10:59.141811: Epoch 435 
2024-11-21 18:10:59.141887: Current learning rate: 0.00598 
2024-11-21 18:11:51.714872: train_loss -0.9696 
2024-11-21 18:11:51.714990: val_loss -0.8986 
2024-11-21 18:11:51.715059: Pseudo dice [np.float32(0.9126)] 
2024-11-21 18:11:51.715113: Epoch time: 52.57 s 
2024-11-21 18:11:52.659312:  
2024-11-21 18:11:52.659467: Epoch 436 
2024-11-21 18:11:52.659576: Current learning rate: 0.00597 
2024-11-21 18:12:45.264440: train_loss -0.9684 
2024-11-21 18:12:45.264625: val_loss -0.8967 
2024-11-21 18:12:45.264896: Pseudo dice [np.float32(0.9109)] 
2024-11-21 18:12:45.264989: Epoch time: 52.61 s 
2024-11-21 18:12:46.217310:  
2024-11-21 18:12:46.217476: Epoch 437 
2024-11-21 18:12:46.217570: Current learning rate: 0.00596 
2024-11-21 18:13:38.620114: train_loss -0.9677 
2024-11-21 18:13:38.620241: val_loss -0.8963 
2024-11-21 18:13:38.620293: Pseudo dice [np.float32(0.9101)] 
2024-11-21 18:13:38.620348: Epoch time: 52.4 s 
2024-11-21 18:13:39.577364:  
2024-11-21 18:13:39.577540: Epoch 438 
2024-11-21 18:13:39.577645: Current learning rate: 0.00595 
2024-11-21 18:14:32.085530: train_loss -0.9679 
2024-11-21 18:14:32.085695: val_loss -0.8958 
2024-11-21 18:14:32.085759: Pseudo dice [np.float32(0.9095)] 
2024-11-21 18:14:32.085833: Epoch time: 52.51 s 
2024-11-21 18:14:33.123288:  
2024-11-21 18:14:33.123622: Epoch 439 
2024-11-21 18:14:33.123771: Current learning rate: 0.00594 
2024-11-21 18:15:25.190127: train_loss -0.9687 
2024-11-21 18:15:25.190244: val_loss -0.895 
2024-11-21 18:15:25.190294: Pseudo dice [np.float32(0.9096)] 
2024-11-21 18:15:25.190394: Epoch time: 52.07 s 
2024-11-21 18:15:26.126916:  
2024-11-21 18:15:26.127084: Epoch 440 
2024-11-21 18:15:26.127168: Current learning rate: 0.00593 
2024-11-21 18:16:18.374242: train_loss -0.9672 
2024-11-21 18:16:18.374361: val_loss -0.8907 
2024-11-21 18:16:18.374409: Pseudo dice [np.float32(0.9054)] 
2024-11-21 18:16:18.374462: Epoch time: 52.25 s 
2024-11-21 18:16:19.298733:  
2024-11-21 18:16:19.298952: Epoch 441 
2024-11-21 18:16:19.299036: Current learning rate: 0.00592 
2024-11-21 18:17:11.573945: train_loss -0.9681 
2024-11-21 18:17:11.574061: val_loss -0.8955 
2024-11-21 18:17:11.574109: Pseudo dice [np.float32(0.9081)] 
2024-11-21 18:17:11.574161: Epoch time: 52.28 s 
2024-11-21 18:17:12.481668:  
2024-11-21 18:17:12.481834: Epoch 442 
2024-11-21 18:17:12.481919: Current learning rate: 0.00592 
2024-11-21 18:18:04.782906: train_loss -0.968 
2024-11-21 18:18:04.783023: val_loss -0.9003 
2024-11-21 18:18:04.783072: Pseudo dice [np.float32(0.9135)] 
2024-11-21 18:18:04.783144: Epoch time: 52.3 s 
2024-11-21 18:18:05.792851:  
2024-11-21 18:18:05.793013: Epoch 443 
2024-11-21 18:18:05.793089: Current learning rate: 0.00591 
2024-11-21 18:18:58.317891: train_loss -0.9682 
2024-11-21 18:18:58.318010: val_loss -0.8968 
2024-11-21 18:18:58.318062: Pseudo dice [np.float32(0.91)] 
2024-11-21 18:18:58.318117: Epoch time: 52.53 s 
2024-11-21 18:18:59.262830:  
2024-11-21 18:18:59.263000: Epoch 444 
2024-11-21 18:18:59.263085: Current learning rate: 0.0059 
2024-11-21 18:19:51.776529: train_loss -0.9673 
2024-11-21 18:19:51.776658: val_loss -0.8919 
2024-11-21 18:19:51.776722: Pseudo dice [np.float32(0.9075)] 
2024-11-21 18:19:51.776791: Epoch time: 52.51 s 
2024-11-21 18:19:53.048918:  
2024-11-21 18:19:53.049089: Epoch 445 
2024-11-21 18:19:53.049159: Current learning rate: 0.00589 
2024-11-21 18:20:45.614888: train_loss -0.9682 
2024-11-21 18:20:45.615198: val_loss -0.892 
2024-11-21 18:20:45.615264: Pseudo dice [np.float32(0.9072)] 
2024-11-21 18:20:45.615331: Epoch time: 52.57 s 
2024-11-21 18:20:46.549062:  
2024-11-21 18:20:46.549309: Epoch 446 
2024-11-21 18:20:46.549384: Current learning rate: 0.00588 
2024-11-21 18:21:39.064987: train_loss -0.969 
2024-11-21 18:21:39.065100: val_loss -0.8987 
2024-11-21 18:21:39.065146: Pseudo dice [np.float32(0.9125)] 
2024-11-21 18:21:39.065197: Epoch time: 52.52 s 
2024-11-21 18:21:39.989056:  
2024-11-21 18:21:39.989210: Epoch 447 
2024-11-21 18:21:39.989278: Current learning rate: 0.00587 
2024-11-21 18:22:32.478521: train_loss -0.9693 
2024-11-21 18:22:32.478651: val_loss -0.8937 
2024-11-21 18:22:32.478701: Pseudo dice [np.float32(0.9072)] 
2024-11-21 18:22:32.478755: Epoch time: 52.49 s 
2024-11-21 18:22:33.456402:  
2024-11-21 18:22:33.456584: Epoch 448 
2024-11-21 18:22:33.456665: Current learning rate: 0.00586 
2024-11-21 18:23:25.892775: train_loss -0.9678 
2024-11-21 18:23:25.892921: val_loss -0.8917 
2024-11-21 18:23:25.892971: Pseudo dice [np.float32(0.9077)] 
2024-11-21 18:23:25.893025: Epoch time: 52.44 s 
2024-11-21 18:23:26.838708:  
2024-11-21 18:23:26.838875: Epoch 449 
2024-11-21 18:23:26.838957: Current learning rate: 0.00585 
2024-11-21 18:24:19.127667: train_loss -0.9616 
2024-11-21 18:24:19.127811: val_loss -0.8876 
2024-11-21 18:24:19.127858: Pseudo dice [np.float32(0.9031)] 
2024-11-21 18:24:19.127910: Epoch time: 52.29 s 
2024-11-21 18:24:20.411418:  
2024-11-21 18:24:20.411618: Epoch 450 
2024-11-21 18:24:20.411700: Current learning rate: 0.00584 
2024-11-21 18:25:12.818981: train_loss -0.9613 
2024-11-21 18:25:12.819144: val_loss -0.8971 
2024-11-21 18:25:12.819209: Pseudo dice [np.float32(0.9107)] 
2024-11-21 18:25:12.819279: Epoch time: 52.41 s 
2024-11-21 18:25:13.725389:  
2024-11-21 18:25:13.725594: Epoch 451 
2024-11-21 18:25:13.725667: Current learning rate: 0.00583 
2024-11-21 18:26:05.915461: train_loss -0.9628 
2024-11-21 18:26:05.915600: val_loss -0.8894 
2024-11-21 18:26:05.915666: Pseudo dice [np.float32(0.904)] 
2024-11-21 18:26:05.915737: Epoch time: 52.19 s 
2024-11-21 18:26:06.917290:  
2024-11-21 18:26:06.917618: Epoch 452 
2024-11-21 18:26:06.917728: Current learning rate: 0.00582 
2024-11-21 18:26:59.434808: train_loss -0.9623 
2024-11-21 18:26:59.434946: val_loss -0.8954 
2024-11-21 18:26:59.435012: Pseudo dice [np.float32(0.9091)] 
2024-11-21 18:26:59.435082: Epoch time: 52.52 s 
2024-11-21 18:27:00.403854:  
2024-11-21 18:27:00.404032: Epoch 453 
2024-11-21 18:27:00.404124: Current learning rate: 0.00581 
2024-11-21 18:27:52.885906: train_loss -0.9628 
2024-11-21 18:27:52.886074: val_loss -0.8981 
2024-11-21 18:27:52.886942: Pseudo dice [np.float32(0.9123)] 
2024-11-21 18:27:52.887026: Epoch time: 52.48 s 
2024-11-21 18:27:53.854662:  
2024-11-21 18:27:53.854845: Epoch 454 
2024-11-21 18:27:53.854917: Current learning rate: 0.0058 
2024-11-21 18:28:46.702211: train_loss -0.964 
2024-11-21 18:28:46.702363: val_loss -0.8929 
2024-11-21 18:28:46.702428: Pseudo dice [np.float32(0.9052)] 
2024-11-21 18:28:46.702538: Epoch time: 52.85 s 
2024-11-21 18:28:47.548490:  
2024-11-21 18:28:47.548852: Epoch 455 
2024-11-21 18:28:47.548986: Current learning rate: 0.00579 
2024-11-21 18:29:39.807714: train_loss -0.9642 
2024-11-21 18:29:39.807862: val_loss -0.8928 
2024-11-21 18:29:39.807925: Pseudo dice [np.float32(0.9076)] 
2024-11-21 18:29:39.807991: Epoch time: 52.26 s 
2024-11-21 18:29:40.741144:  
2024-11-21 18:29:40.741368: Epoch 456 
2024-11-21 18:29:40.741452: Current learning rate: 0.00578 
2024-11-21 18:30:33.065171: train_loss -0.9635 
2024-11-21 18:30:33.065272: val_loss -0.8889 
2024-11-21 18:30:33.065321: Pseudo dice [np.float32(0.9038)] 
2024-11-21 18:30:33.065393: Epoch time: 52.33 s 
2024-11-21 18:30:34.039855:  
2024-11-21 18:30:34.040101: Epoch 457 
2024-11-21 18:30:34.040167: Current learning rate: 0.00577 
2024-11-21 18:31:26.528248: train_loss -0.9614 
2024-11-21 18:31:26.528369: val_loss -0.894 
2024-11-21 18:31:26.528422: Pseudo dice [np.float32(0.9087)] 
2024-11-21 18:31:26.528508: Epoch time: 52.49 s 
2024-11-21 18:31:27.840596:  
2024-11-21 18:31:27.840748: Epoch 458 
2024-11-21 18:31:27.840820: Current learning rate: 0.00576 
2024-11-21 18:32:20.270571: train_loss -0.9617 
2024-11-21 18:32:20.270728: val_loss -0.8892 
2024-11-21 18:32:20.270859: Pseudo dice [np.float32(0.905)] 
2024-11-21 18:32:20.270944: Epoch time: 52.43 s 
2024-11-21 18:32:21.164983:  
2024-11-21 18:32:21.165137: Epoch 459 
2024-11-21 18:32:21.165217: Current learning rate: 0.00575 
2024-11-21 18:33:13.319731: train_loss -0.9592 
2024-11-21 18:33:13.319892: val_loss -0.8884 
2024-11-21 18:33:13.319953: Pseudo dice [np.float32(0.9045)] 
2024-11-21 18:33:13.320065: Epoch time: 52.16 s 
2024-11-21 18:33:14.366996:  
2024-11-21 18:33:14.367486: Epoch 460 
2024-11-21 18:33:14.367570: Current learning rate: 0.00574 
2024-11-21 18:34:06.350925: train_loss -0.9515 
2024-11-21 18:34:06.351086: val_loss -0.8899 
2024-11-21 18:34:06.351139: Pseudo dice [np.float32(0.9053)] 
2024-11-21 18:34:06.351195: Epoch time: 51.98 s 
2024-11-21 18:34:07.275831:  
2024-11-21 18:34:07.276171: Epoch 461 
2024-11-21 18:34:07.276257: Current learning rate: 0.00573 
2024-11-21 18:34:59.927743: train_loss -0.9585 
2024-11-21 18:34:59.927875: val_loss -0.8936 
2024-11-21 18:34:59.927930: Pseudo dice [np.float32(0.9095)] 
2024-11-21 18:34:59.927980: Epoch time: 52.65 s 
2024-11-21 18:35:00.860911:  
2024-11-21 18:35:00.861046: Epoch 462 
2024-11-21 18:35:00.861113: Current learning rate: 0.00572 
2024-11-21 18:35:53.243250: train_loss -0.9612 
2024-11-21 18:35:53.243386: val_loss -0.8924 
2024-11-21 18:35:53.243437: Pseudo dice [np.float32(0.9063)] 
2024-11-21 18:35:53.243523: Epoch time: 52.38 s 
2024-11-21 18:35:54.186573:  
2024-11-21 18:35:54.186772: Epoch 463 
2024-11-21 18:35:54.186871: Current learning rate: 0.00571 
2024-11-21 18:36:46.723624: train_loss -0.9581 
2024-11-21 18:36:46.723769: val_loss -0.8873 
2024-11-21 18:36:46.723819: Pseudo dice [np.float32(0.9028)] 
2024-11-21 18:36:46.723891: Epoch time: 52.54 s 
2024-11-21 18:36:47.687128:  
2024-11-21 18:36:47.687267: Epoch 464 
2024-11-21 18:36:47.687335: Current learning rate: 0.0057 
2024-11-21 18:37:40.048304: train_loss -0.9528 
2024-11-21 18:37:40.048420: val_loss -0.8874 
2024-11-21 18:37:40.048467: Pseudo dice [np.float32(0.9027)] 
2024-11-21 18:37:40.048567: Epoch time: 52.36 s 
2024-11-21 18:37:40.950205:  
2024-11-21 18:37:40.950327: Epoch 465 
2024-11-21 18:37:40.950424: Current learning rate: 0.0057 
2024-11-21 18:38:33.342128: train_loss -0.9566 
2024-11-21 18:38:33.342252: val_loss -0.8924 
2024-11-21 18:38:33.342316: Pseudo dice [np.float32(0.9068)] 
2024-11-21 18:38:33.342389: Epoch time: 52.39 s 
2024-11-21 18:38:34.320282:  
2024-11-21 18:38:34.320415: Epoch 466 
2024-11-21 18:38:34.320542: Current learning rate: 0.00569 
2024-11-21 18:39:27.071931: train_loss -0.9618 
2024-11-21 18:39:27.072077: val_loss -0.8898 
2024-11-21 18:39:27.072923: Pseudo dice [np.float32(0.9055)] 
2024-11-21 18:39:27.072982: Epoch time: 52.75 s 
2024-11-21 18:39:27.998843:  
2024-11-21 18:39:27.998972: Epoch 467 
2024-11-21 18:39:27.999039: Current learning rate: 0.00568 
2024-11-21 18:40:20.662390: train_loss -0.9632 
2024-11-21 18:40:20.662531: val_loss -0.8987 
2024-11-21 18:40:20.662599: Pseudo dice [np.float32(0.9121)] 
2024-11-21 18:40:20.662669: Epoch time: 52.66 s 
2024-11-21 18:40:21.617672:  
2024-11-21 18:40:21.617810: Epoch 468 
2024-11-21 18:40:21.617904: Current learning rate: 0.00567 
2024-11-21 18:41:14.106602: train_loss -0.9645 
2024-11-21 18:41:14.106730: val_loss -0.8966 
2024-11-21 18:41:14.106803: Pseudo dice [np.float32(0.9097)] 
2024-11-21 18:41:14.106891: Epoch time: 52.49 s 
2024-11-21 18:41:15.011503:  
2024-11-21 18:41:15.011741: Epoch 469 
2024-11-21 18:41:15.011833: Current learning rate: 0.00566 
2024-11-21 18:42:07.359529: train_loss -0.9652 
2024-11-21 18:42:07.359659: val_loss -0.9003 
2024-11-21 18:42:07.359734: Pseudo dice [np.float32(0.9132)] 
2024-11-21 18:42:07.359812: Epoch time: 52.35 s 
2024-11-21 18:42:08.575009:  
2024-11-21 18:42:08.575162: Epoch 470 
2024-11-21 18:42:08.575278: Current learning rate: 0.00565 
2024-11-21 18:43:01.018174: train_loss -0.9663 
2024-11-21 18:43:01.018294: val_loss -0.9001 
2024-11-21 18:43:01.018343: Pseudo dice [np.float32(0.9133)] 
2024-11-21 18:43:01.018395: Epoch time: 52.44 s 
2024-11-21 18:43:01.919960:  
2024-11-21 18:43:01.920103: Epoch 471 
2024-11-21 18:43:01.920170: Current learning rate: 0.00564 
2024-11-21 18:43:54.600662: train_loss -0.967 
2024-11-21 18:43:54.600778: val_loss -0.8948 
2024-11-21 18:43:54.600826: Pseudo dice [np.float32(0.9088)] 
2024-11-21 18:43:54.600879: Epoch time: 52.68 s 
2024-11-21 18:43:55.449114:  
2024-11-21 18:43:55.449263: Epoch 472 
2024-11-21 18:43:55.449330: Current learning rate: 0.00563 
2024-11-21 18:44:47.620308: train_loss -0.9668 
2024-11-21 18:44:47.620440: val_loss -0.895 
2024-11-21 18:44:47.620513: Pseudo dice [np.float32(0.9108)] 
2024-11-21 18:44:47.620585: Epoch time: 52.17 s 
2024-11-21 18:44:48.514673:  
2024-11-21 18:44:48.514826: Epoch 473 
2024-11-21 18:44:48.514960: Current learning rate: 0.00562 
2024-11-21 18:45:41.177179: train_loss -0.9665 
2024-11-21 18:45:41.177313: val_loss -0.8947 
2024-11-21 18:45:41.177359: Pseudo dice [np.float32(0.907)] 
2024-11-21 18:45:41.177418: Epoch time: 52.66 s 
2024-11-21 18:45:42.085562:  
2024-11-21 18:45:42.085896: Epoch 474 
2024-11-21 18:45:42.085962: Current learning rate: 0.00561 
2024-11-21 18:46:34.492276: train_loss -0.9649 
2024-11-21 18:46:34.492417: val_loss -0.8982 
2024-11-21 18:46:34.492526: Pseudo dice [np.float32(0.9128)] 
2024-11-21 18:46:34.492608: Epoch time: 52.41 s 
2024-11-21 18:46:35.424220:  
2024-11-21 18:46:35.424444: Epoch 475 
2024-11-21 18:46:35.424531: Current learning rate: 0.0056 
2024-11-21 18:47:27.992122: train_loss -0.9661 
2024-11-21 18:47:27.992244: val_loss -0.8982 
2024-11-21 18:47:27.992293: Pseudo dice [np.float32(0.9124)] 
2024-11-21 18:47:27.992347: Epoch time: 52.57 s 
2024-11-21 18:47:28.902074:  
2024-11-21 18:47:28.902276: Epoch 476 
2024-11-21 18:47:28.902360: Current learning rate: 0.00559 
2024-11-21 18:48:21.329170: train_loss -0.9676 
2024-11-21 18:48:21.329282: val_loss -0.9033 
2024-11-21 18:48:21.329329: Pseudo dice [np.float32(0.917)] 
2024-11-21 18:48:21.329380: Epoch time: 52.43 s 
2024-11-21 18:48:22.249150:  
2024-11-21 18:48:22.249295: Epoch 477 
2024-11-21 18:48:22.249363: Current learning rate: 0.00558 
2024-11-21 18:49:14.621695: train_loss -0.9696 
2024-11-21 18:49:14.621810: val_loss -0.9004 
2024-11-21 18:49:14.621862: Pseudo dice [np.float32(0.9145)] 
2024-11-21 18:49:14.621917: Epoch time: 52.37 s 
2024-11-21 18:49:15.560704:  
2024-11-21 18:49:15.560918: Epoch 478 
2024-11-21 18:49:15.561009: Current learning rate: 0.00557 
2024-11-21 18:50:07.857395: train_loss -0.9684 
2024-11-21 18:50:07.857573: val_loss -0.8948 
2024-11-21 18:50:07.857669: Pseudo dice [np.float32(0.9088)] 
2024-11-21 18:50:07.857722: Epoch time: 52.3 s 
2024-11-21 18:50:08.729777:  
2024-11-21 18:50:08.730014: Epoch 479 
2024-11-21 18:50:08.730096: Current learning rate: 0.00556 
2024-11-21 18:51:00.847650: train_loss -0.9689 
2024-11-21 18:51:00.847776: val_loss -0.8946 
2024-11-21 18:51:00.847826: Pseudo dice [np.float32(0.9089)] 
2024-11-21 18:51:00.847880: Epoch time: 52.12 s 
2024-11-21 18:51:01.770154:  
2024-11-21 18:51:01.770304: Epoch 480 
2024-11-21 18:51:01.770411: Current learning rate: 0.00555 
2024-11-21 18:51:53.805539: train_loss -0.9682 
2024-11-21 18:51:53.805658: val_loss -0.8978 
2024-11-21 18:51:53.805724: Pseudo dice [np.float32(0.9115)] 
2024-11-21 18:51:53.805799: Epoch time: 52.04 s 
2024-11-21 18:51:54.679891:  
2024-11-21 18:51:54.680021: Epoch 481 
2024-11-21 18:51:54.680109: Current learning rate: 0.00554 
2024-11-21 18:52:47.061855: train_loss -0.9685 
2024-11-21 18:52:47.061977: val_loss -0.8973 
2024-11-21 18:52:47.062028: Pseudo dice [np.float32(0.9125)] 
2024-11-21 18:52:47.062083: Epoch time: 52.38 s 
2024-11-21 18:52:48.049435:  
2024-11-21 18:52:48.049581: Epoch 482 
2024-11-21 18:52:48.049652: Current learning rate: 0.00553 
2024-11-21 18:53:40.479808: train_loss -0.97 
2024-11-21 18:53:40.479926: val_loss -0.8948 
2024-11-21 18:53:40.479976: Pseudo dice [np.float32(0.9096)] 
2024-11-21 18:53:40.480031: Epoch time: 52.43 s 
2024-11-21 18:53:41.697778:  
2024-11-21 18:53:41.697938: Epoch 483 
2024-11-21 18:53:41.698008: Current learning rate: 0.00552 
2024-11-21 18:54:34.112347: train_loss -0.9693 
2024-11-21 18:54:34.112492: val_loss -0.8967 
2024-11-21 18:54:34.112570: Pseudo dice [np.float32(0.9111)] 
2024-11-21 18:54:34.112626: Epoch time: 52.42 s 
2024-11-21 18:54:35.098013:  
2024-11-21 18:54:35.098162: Epoch 484 
2024-11-21 18:54:35.098230: Current learning rate: 0.00551 
2024-11-21 18:55:27.442992: train_loss -0.9696 
2024-11-21 18:55:27.443158: val_loss -0.8912 
2024-11-21 18:55:27.443209: Pseudo dice [np.float32(0.9056)] 
2024-11-21 18:55:27.443265: Epoch time: 52.35 s 
2024-11-21 18:55:28.362651:  
2024-11-21 18:55:28.362886: Epoch 485 
2024-11-21 18:55:28.362957: Current learning rate: 0.0055 
2024-11-21 18:56:20.829598: train_loss -0.9688 
2024-11-21 18:56:20.829717: val_loss -0.8917 
2024-11-21 18:56:20.829771: Pseudo dice [np.float32(0.9077)] 
2024-11-21 18:56:20.829824: Epoch time: 52.47 s 
2024-11-21 18:56:21.783039:  
2024-11-21 18:56:21.783277: Epoch 486 
2024-11-21 18:56:21.783349: Current learning rate: 0.00549 
2024-11-21 18:57:14.123669: train_loss -0.9673 
2024-11-21 18:57:14.123778: val_loss -0.8961 
2024-11-21 18:57:14.123823: Pseudo dice [np.float32(0.9104)] 
2024-11-21 18:57:14.123873: Epoch time: 52.34 s 
2024-11-21 18:57:15.063174:  
2024-11-21 18:57:15.063387: Epoch 487 
2024-11-21 18:57:15.063457: Current learning rate: 0.00548 
2024-11-21 18:58:07.424135: train_loss -0.9692 
2024-11-21 18:58:07.424311: val_loss -0.8977 
2024-11-21 18:58:07.424388: Pseudo dice [np.float32(0.9129)] 
2024-11-21 18:58:07.424455: Epoch time: 52.36 s 
2024-11-21 18:58:08.402989:  
2024-11-21 18:58:08.403140: Epoch 488 
2024-11-21 18:58:08.403232: Current learning rate: 0.00547 
2024-11-21 18:59:00.885923: train_loss -0.9697 
2024-11-21 18:59:00.886042: val_loss -0.8985 
2024-11-21 18:59:00.886089: Pseudo dice [np.float32(0.9119)] 
2024-11-21 18:59:00.886142: Epoch time: 52.48 s 
2024-11-21 18:59:01.795630:  
2024-11-21 18:59:01.795778: Epoch 489 
2024-11-21 18:59:01.795844: Current learning rate: 0.00546 
2024-11-21 18:59:54.710778: train_loss -0.969 
2024-11-21 18:59:54.710924: val_loss -0.8901 
2024-11-21 18:59:54.710975: Pseudo dice [np.float32(0.9061)] 
2024-11-21 18:59:54.711030: Epoch time: 52.92 s 
2024-11-21 18:59:55.666696:  
2024-11-21 18:59:55.666843: Epoch 490 
2024-11-21 18:59:55.666913: Current learning rate: 0.00546 
2024-11-21 19:00:48.253969: train_loss -0.9706 
2024-11-21 19:00:48.254089: val_loss -0.904 
2024-11-21 19:00:48.254144: Pseudo dice [np.float32(0.9181)] 
2024-11-21 19:00:48.254202: Epoch time: 52.59 s 
2024-11-21 19:00:49.269066:  
2024-11-21 19:00:49.269214: Epoch 491 
2024-11-21 19:00:49.269325: Current learning rate: 0.00545 
2024-11-21 19:01:41.833792: train_loss -0.9703 
2024-11-21 19:01:41.833910: val_loss -0.8977 
2024-11-21 19:01:41.833961: Pseudo dice [np.float32(0.9122)] 
2024-11-21 19:01:41.834018: Epoch time: 52.57 s 
2024-11-21 19:01:42.760108:  
2024-11-21 19:01:42.760354: Epoch 492 
2024-11-21 19:01:42.760454: Current learning rate: 0.00544 
2024-11-21 19:02:35.356990: train_loss -0.9696 
2024-11-21 19:02:35.357107: val_loss -0.8971 
2024-11-21 19:02:35.357156: Pseudo dice [np.float32(0.9135)] 
2024-11-21 19:02:35.357211: Epoch time: 52.6 s 
2024-11-21 19:02:36.309177:  
2024-11-21 19:02:36.309328: Epoch 493 
2024-11-21 19:02:36.309430: Current learning rate: 0.00543 
2024-11-21 19:03:29.162288: train_loss -0.9699 
2024-11-21 19:03:29.162453: val_loss -0.8958 
2024-11-21 19:03:29.162578: Pseudo dice [np.float32(0.912)] 
2024-11-21 19:03:29.162684: Epoch time: 52.85 s 
2024-11-21 19:03:30.154622:  
2024-11-21 19:03:30.154759: Epoch 494 
2024-11-21 19:03:30.154864: Current learning rate: 0.00542 
2024-11-21 19:04:22.983261: train_loss -0.9694 
2024-11-21 19:04:22.983401: val_loss -0.8978 
2024-11-21 19:04:22.984285: Pseudo dice [np.float32(0.9117)] 
2024-11-21 19:04:22.984341: Epoch time: 52.83 s 
2024-11-21 19:04:23.853373:  
2024-11-21 19:04:23.853579: Epoch 495 
2024-11-21 19:04:23.853687: Current learning rate: 0.00541 
2024-11-21 19:05:16.649600: train_loss -0.9698 
2024-11-21 19:05:16.649728: val_loss -0.8978 
2024-11-21 19:05:16.649806: Pseudo dice [np.float32(0.9112)] 
2024-11-21 19:05:16.649884: Epoch time: 52.8 s 
2024-11-21 19:05:17.575636:  
2024-11-21 19:05:17.575775: Epoch 496 
2024-11-21 19:05:17.575843: Current learning rate: 0.0054 
2024-11-21 19:06:10.064173: train_loss -0.9664 
2024-11-21 19:06:10.064306: val_loss -0.8984 
2024-11-21 19:06:10.064358: Pseudo dice [np.float32(0.9129)] 
2024-11-21 19:06:10.064430: Epoch time: 52.49 s 
2024-11-21 19:06:10.956810:  
2024-11-21 19:06:10.956964: Epoch 497 
2024-11-21 19:06:10.957030: Current learning rate: 0.00539 
2024-11-21 19:07:03.413860: train_loss -0.9674 
2024-11-21 19:07:03.413975: val_loss -0.9029 
2024-11-21 19:07:03.414043: Pseudo dice [np.float32(0.9165)] 
2024-11-21 19:07:03.414129: Epoch time: 52.46 s 
2024-11-21 19:07:04.329717:  
2024-11-21 19:07:04.329865: Epoch 498 
2024-11-21 19:07:04.329952: Current learning rate: 0.00538 
2024-11-21 19:07:57.088727: train_loss -0.9576 
2024-11-21 19:07:57.088883: val_loss -0.894 
2024-11-21 19:07:57.088974: Pseudo dice [np.float32(0.9089)] 
2024-11-21 19:07:57.089045: Epoch time: 52.76 s 
2024-11-21 19:07:58.037891:  
2024-11-21 19:07:58.038069: Epoch 499 
2024-11-21 19:07:58.038150: Current learning rate: 0.00537 
2024-11-21 19:08:50.657857: train_loss -0.9606 
2024-11-21 19:08:50.657968: val_loss -0.8907 
2024-11-21 19:08:50.658060: Pseudo dice [np.float32(0.9054)] 
2024-11-21 19:08:50.658112: Epoch time: 52.62 s 
2024-11-21 19:08:51.911921:  
2024-11-21 19:08:51.912104: Epoch 500 
2024-11-21 19:08:51.912182: Current learning rate: 0.00536 
2024-11-21 19:09:44.756777: train_loss -0.9653 
2024-11-21 19:09:44.756884: val_loss -0.8982 
2024-11-21 19:09:44.756974: Pseudo dice [np.float32(0.9122)] 
2024-11-21 19:09:44.757035: Epoch time: 52.85 s 
2024-11-21 19:09:45.665655:  
2024-11-21 19:09:45.665881: Epoch 501 
2024-11-21 19:09:45.665966: Current learning rate: 0.00535 
2024-11-21 19:10:38.077259: train_loss -0.9667 
2024-11-21 19:10:38.077392: val_loss -0.8908 
2024-11-21 19:10:38.077443: Pseudo dice [np.float32(0.9059)] 
2024-11-21 19:10:38.077530: Epoch time: 52.41 s 
2024-11-21 19:10:39.107680:  
2024-11-21 19:10:39.107819: Epoch 502 
2024-11-21 19:10:39.107888: Current learning rate: 0.00534 
2024-11-21 19:11:31.794580: train_loss -0.9665 
2024-11-21 19:11:31.794710: val_loss -0.9008 
2024-11-21 19:11:31.794775: Pseudo dice [np.float32(0.9127)] 
2024-11-21 19:11:31.794845: Epoch time: 52.69 s 
2024-11-21 19:11:32.721942:  
2024-11-21 19:11:32.722126: Epoch 503 
2024-11-21 19:11:32.722211: Current learning rate: 0.00533 
2024-11-21 19:12:25.120317: train_loss -0.9682 
2024-11-21 19:12:25.120423: val_loss -0.8983 
2024-11-21 19:12:25.120497: Pseudo dice [np.float32(0.9108)] 
2024-11-21 19:12:25.120572: Epoch time: 52.4 s 
2024-11-21 19:12:26.049814:  
2024-11-21 19:12:26.050055: Epoch 504 
2024-11-21 19:12:26.050143: Current learning rate: 0.00532 
2024-11-21 19:13:18.088800: train_loss -0.969 
2024-11-21 19:13:18.088955: val_loss -0.9045 
2024-11-21 19:13:18.089874: Pseudo dice [np.float32(0.9177)] 
2024-11-21 19:13:18.090024: Epoch time: 52.04 s 
2024-11-21 19:13:19.072275:  
2024-11-21 19:13:19.072451: Epoch 505 
2024-11-21 19:13:19.072558: Current learning rate: 0.00531 
2024-11-21 19:14:11.236706: train_loss -0.9709 
2024-11-21 19:14:11.236817: val_loss -0.8961 
2024-11-21 19:14:11.236865: Pseudo dice [np.float32(0.9094)] 
2024-11-21 19:14:11.236918: Epoch time: 52.17 s 
2024-11-21 19:14:12.453865:  
2024-11-21 19:14:12.454095: Epoch 506 
2024-11-21 19:14:12.454166: Current learning rate: 0.0053 
2024-11-21 19:15:04.498194: train_loss -0.9708 
2024-11-21 19:15:04.498334: val_loss -0.894 
2024-11-21 19:15:04.498388: Pseudo dice [np.float32(0.9089)] 
2024-11-21 19:15:04.498441: Epoch time: 52.05 s 
2024-11-21 19:15:05.489930:  
2024-11-21 19:15:05.490168: Epoch 507 
2024-11-21 19:15:05.490264: Current learning rate: 0.00529 
2024-11-21 19:15:57.892297: train_loss -0.9707 
2024-11-21 19:15:57.892452: val_loss -0.9027 
2024-11-21 19:15:57.892596: Pseudo dice [np.float32(0.9164)] 
2024-11-21 19:15:57.892696: Epoch time: 52.4 s 
2024-11-21 19:15:58.882806:  
2024-11-21 19:15:58.883000: Epoch 508 
2024-11-21 19:15:58.883071: Current learning rate: 0.00528 
2024-11-21 19:16:51.089748: train_loss -0.9703 
2024-11-21 19:16:51.089876: val_loss -0.9015 
2024-11-21 19:16:51.089942: Pseudo dice [np.float32(0.9157)] 
2024-11-21 19:16:51.090011: Epoch time: 52.21 s 
2024-11-21 19:16:52.098081:  
2024-11-21 19:16:52.098279: Epoch 509 
2024-11-21 19:16:52.098399: Current learning rate: 0.00527 
2024-11-21 19:17:44.284544: train_loss -0.9704 
2024-11-21 19:17:44.284706: val_loss -0.9007 
2024-11-21 19:17:44.284759: Pseudo dice [np.float32(0.9155)] 
2024-11-21 19:17:44.284815: Epoch time: 52.19 s 
2024-11-21 19:17:45.321317:  
2024-11-21 19:17:45.321500: Epoch 510 
2024-11-21 19:17:45.321584: Current learning rate: 0.00526 
2024-11-21 19:18:37.573060: train_loss -0.9697 
2024-11-21 19:18:37.573206: val_loss -0.8964 
2024-11-21 19:18:37.573278: Pseudo dice [np.float32(0.9099)] 
2024-11-21 19:18:37.573346: Epoch time: 52.25 s 
2024-11-21 19:18:38.587696:  
2024-11-21 19:18:38.587867: Epoch 511 
2024-11-21 19:18:38.587984: Current learning rate: 0.00525 
2024-11-21 19:19:30.825985: train_loss -0.9703 
2024-11-21 19:19:30.826114: val_loss -0.8962 
2024-11-21 19:19:30.826179: Pseudo dice [np.float32(0.9104)] 
2024-11-21 19:19:30.826262: Epoch time: 52.24 s 
2024-11-21 19:19:31.769548:  
2024-11-21 19:19:31.769750: Epoch 512 
2024-11-21 19:19:31.769824: Current learning rate: 0.00524 
2024-11-21 19:20:24.445183: train_loss -0.9715 
2024-11-21 19:20:24.445288: val_loss -0.9013 
2024-11-21 19:20:24.445336: Pseudo dice [np.float32(0.9147)] 
2024-11-21 19:20:24.445423: Epoch time: 52.68 s 
2024-11-21 19:20:25.415931:  
2024-11-21 19:20:25.416171: Epoch 513 
2024-11-21 19:20:25.416251: Current learning rate: 0.00523 
2024-11-21 19:21:17.632038: train_loss -0.9699 
2024-11-21 19:21:17.632191: val_loss -0.9023 
2024-11-21 19:21:17.632238: Pseudo dice [np.float32(0.9157)] 
2024-11-21 19:21:17.632290: Epoch time: 52.22 s 
2024-11-21 19:21:18.519575:  
2024-11-21 19:21:18.519712: Epoch 514 
2024-11-21 19:21:18.519779: Current learning rate: 0.00522 
2024-11-21 19:22:10.987846: train_loss -0.9699 
2024-11-21 19:22:10.987958: val_loss -0.8974 
2024-11-21 19:22:10.988008: Pseudo dice [np.float32(0.9125)] 
2024-11-21 19:22:10.988061: Epoch time: 52.47 s 
2024-11-21 19:22:11.947800:  
2024-11-21 19:22:11.947941: Epoch 515 
2024-11-21 19:22:11.948006: Current learning rate: 0.00521 
2024-11-21 19:23:04.394073: train_loss -0.9714 
2024-11-21 19:23:04.394196: val_loss -0.9028 
2024-11-21 19:23:04.394293: Pseudo dice [np.float32(0.9163)] 
2024-11-21 19:23:04.394347: Epoch time: 52.45 s 
2024-11-21 19:23:04.394391: Yayy! New best EMA pseudo Dice: 0.9128999710083008 
2024-11-21 19:23:05.776056:  
2024-11-21 19:23:05.776197: Epoch 516 
2024-11-21 19:23:05.776263: Current learning rate: 0.0052 
2024-11-21 19:23:57.972803: train_loss -0.9708 
2024-11-21 19:23:57.972971: val_loss -0.8988 
2024-11-21 19:23:57.973052: Pseudo dice [np.float32(0.9142)] 
2024-11-21 19:23:57.973134: Epoch time: 52.2 s 
2024-11-21 19:23:57.973194: Yayy! New best EMA pseudo Dice: 0.9129999876022339 
2024-11-21 19:23:59.327835:  
2024-11-21 19:23:59.328049: Epoch 517 
2024-11-21 19:23:59.328126: Current learning rate: 0.00519 
2024-11-21 19:24:51.678121: train_loss -0.9692 
2024-11-21 19:24:51.678233: val_loss -0.8998 
2024-11-21 19:24:51.678301: Pseudo dice [np.float32(0.9128)] 
2024-11-21 19:24:51.678382: Epoch time: 52.35 s 
2024-11-21 19:24:52.663103:  
2024-11-21 19:24:52.663238: Epoch 518 
2024-11-21 19:24:52.663307: Current learning rate: 0.00518 
2024-11-21 19:25:44.588583: train_loss -0.971 
2024-11-21 19:25:44.588706: val_loss -0.8956 
2024-11-21 19:25:44.588774: Pseudo dice [np.float32(0.9131)] 
2024-11-21 19:25:44.588828: Epoch time: 51.93 s 
2024-11-21 19:25:45.811083:  
2024-11-21 19:25:45.811223: Epoch 519 
2024-11-21 19:25:45.811290: Current learning rate: 0.00518 
2024-11-21 19:26:38.452885: train_loss -0.9714 
2024-11-21 19:26:38.453021: val_loss -0.8962 
2024-11-21 19:26:38.453072: Pseudo dice [np.float32(0.9088)] 
2024-11-21 19:26:38.453126: Epoch time: 52.64 s 
2024-11-21 19:26:39.321342:  
2024-11-21 19:26:39.321486: Epoch 520 
2024-11-21 19:26:39.321555: Current learning rate: 0.00517 
2024-11-21 19:27:31.948390: train_loss -0.9707 
2024-11-21 19:27:31.948521: val_loss -0.8962 
2024-11-21 19:27:31.949439: Pseudo dice [np.float32(0.9114)] 
2024-11-21 19:27:31.949549: Epoch time: 52.63 s 
2024-11-21 19:27:32.836304:  
2024-11-21 19:27:32.836461: Epoch 521 
2024-11-21 19:27:32.836598: Current learning rate: 0.00516 
2024-11-21 19:28:25.293280: train_loss -0.971 
2024-11-21 19:28:25.293395: val_loss -0.8963 
2024-11-21 19:28:25.293444: Pseudo dice [np.float32(0.9091)] 
2024-11-21 19:28:25.293504: Epoch time: 52.46 s 
2024-11-21 19:28:26.298284:  
2024-11-21 19:28:26.298464: Epoch 522 
2024-11-21 19:28:26.298552: Current learning rate: 0.00515 
2024-11-21 19:29:18.601534: train_loss -0.9724 
2024-11-21 19:29:18.601680: val_loss -0.9014 
2024-11-21 19:29:18.601777: Pseudo dice [np.float32(0.9153)] 
2024-11-21 19:29:18.601846: Epoch time: 52.3 s 
2024-11-21 19:29:19.607206:  
2024-11-21 19:29:19.607487: Epoch 523 
2024-11-21 19:29:19.607607: Current learning rate: 0.00514 
2024-11-21 19:30:11.949939: train_loss -0.9713 
2024-11-21 19:30:11.950137: val_loss -0.8962 
2024-11-21 19:30:11.950207: Pseudo dice [np.float32(0.9105)] 
2024-11-21 19:30:11.950263: Epoch time: 52.34 s 
2024-11-21 19:30:12.908142:  
2024-11-21 19:30:12.908289: Epoch 524 
2024-11-21 19:30:12.908360: Current learning rate: 0.00513 
2024-11-21 19:31:05.284922: train_loss -0.9716 
2024-11-21 19:31:05.285045: val_loss -0.9002 
2024-11-21 19:31:05.285111: Pseudo dice [np.float32(0.9147)] 
2024-11-21 19:31:05.285176: Epoch time: 52.38 s 
2024-11-21 19:31:06.302325:  
2024-11-21 19:31:06.302464: Epoch 525 
2024-11-21 19:31:06.302611: Current learning rate: 0.00512 
2024-11-21 19:31:58.515144: train_loss -0.9721 
2024-11-21 19:31:58.515283: val_loss -0.8919 
2024-11-21 19:31:58.515347: Pseudo dice [np.float32(0.9075)] 
2024-11-21 19:31:58.515414: Epoch time: 52.21 s 
2024-11-21 19:31:59.540587:  
2024-11-21 19:31:59.540816: Epoch 526 
2024-11-21 19:31:59.540901: Current learning rate: 0.00511 
2024-11-21 19:32:52.135582: train_loss -0.9708 
2024-11-21 19:32:52.135695: val_loss -0.9008 
2024-11-21 19:32:52.135743: Pseudo dice [np.float32(0.9144)] 
2024-11-21 19:32:52.135796: Epoch time: 52.6 s 
2024-11-21 19:32:53.077108:  
2024-11-21 19:32:53.077249: Epoch 527 
2024-11-21 19:32:53.077315: Current learning rate: 0.0051 
2024-11-21 19:33:45.570870: train_loss -0.9714 
2024-11-21 19:33:45.570980: val_loss -0.8982 
2024-11-21 19:33:45.571028: Pseudo dice [np.float32(0.9114)] 
2024-11-21 19:33:45.571079: Epoch time: 52.49 s 
2024-11-21 19:33:46.508375:  
2024-11-21 19:33:46.508556: Epoch 528 
2024-11-21 19:33:46.508642: Current learning rate: 0.00509 
2024-11-21 19:34:39.130953: train_loss -0.9708 
2024-11-21 19:34:39.131068: val_loss -0.9032 
2024-11-21 19:34:39.131117: Pseudo dice [np.float32(0.9155)] 
2024-11-21 19:34:39.131170: Epoch time: 52.62 s 
2024-11-21 19:34:40.047420:  
2024-11-21 19:34:40.047609: Epoch 529 
2024-11-21 19:34:40.047678: Current learning rate: 0.00508 
2024-11-21 19:35:32.777780: train_loss -0.9711 
2024-11-21 19:35:32.777915: val_loss -0.896 
2024-11-21 19:35:32.777977: Pseudo dice [np.float32(0.9097)] 
2024-11-21 19:35:32.778044: Epoch time: 52.73 s 
2024-11-21 19:35:33.743432:  
2024-11-21 19:35:33.743624: Epoch 530 
2024-11-21 19:35:33.743712: Current learning rate: 0.00507 
2024-11-21 19:36:26.131375: train_loss -0.9723 
2024-11-21 19:36:26.131577: val_loss -0.8991 
2024-11-21 19:36:26.131650: Pseudo dice [np.float32(0.9137)] 
2024-11-21 19:36:26.131706: Epoch time: 52.39 s 
2024-11-21 19:36:27.400979:  
2024-11-21 19:36:27.401169: Epoch 531 
2024-11-21 19:36:27.401260: Current learning rate: 0.00506 
2024-11-21 19:37:19.808907: train_loss -0.972 
2024-11-21 19:37:19.809040: val_loss -0.8969 
2024-11-21 19:37:19.809106: Pseudo dice [np.float32(0.9117)] 
2024-11-21 19:37:19.809177: Epoch time: 52.41 s 
2024-11-21 19:37:20.761686:  
2024-11-21 19:37:20.761853: Epoch 532 
2024-11-21 19:37:20.761945: Current learning rate: 0.00505 
2024-11-21 19:38:13.192834: train_loss -0.9725 
2024-11-21 19:38:13.193056: val_loss -0.8977 
2024-11-21 19:38:13.193120: Pseudo dice [np.float32(0.9126)] 
2024-11-21 19:38:13.193188: Epoch time: 52.43 s 
2024-11-21 19:38:14.138033:  
2024-11-21 19:38:14.138172: Epoch 533 
2024-11-21 19:38:14.138312: Current learning rate: 0.00504 
2024-11-21 19:39:06.407575: train_loss -0.973 
2024-11-21 19:39:06.407692: val_loss -0.8942 
2024-11-21 19:39:06.407738: Pseudo dice [np.float32(0.909)] 
2024-11-21 19:39:06.407789: Epoch time: 52.27 s 
2024-11-21 19:39:07.315330:  
2024-11-21 19:39:07.315480: Epoch 534 
2024-11-21 19:39:07.315600: Current learning rate: 0.00503 
2024-11-21 19:39:59.850150: train_loss -0.9718 
2024-11-21 19:39:59.850267: val_loss -0.8963 
2024-11-21 19:39:59.850320: Pseudo dice [np.float32(0.9113)] 
2024-11-21 19:39:59.850384: Epoch time: 52.54 s 
2024-11-21 19:40:00.798258:  
2024-11-21 19:40:00.798445: Epoch 535 
2024-11-21 19:40:00.798552: Current learning rate: 0.00502 
2024-11-21 19:40:53.211738: train_loss -0.9724 
2024-11-21 19:40:53.211875: val_loss -0.8974 
2024-11-21 19:40:53.211924: Pseudo dice [np.float32(0.9132)] 
2024-11-21 19:40:53.211975: Epoch time: 52.41 s 
2024-11-21 19:40:54.162594:  
2024-11-21 19:40:54.162772: Epoch 536 
2024-11-21 19:40:54.162852: Current learning rate: 0.00501 
2024-11-21 19:41:46.860367: train_loss -0.9715 
2024-11-21 19:41:46.860529: val_loss -0.9011 
2024-11-21 19:41:46.860611: Pseudo dice [np.float32(0.9142)] 
2024-11-21 19:41:46.860740: Epoch time: 52.7 s 
2024-11-21 19:41:47.811465:  
2024-11-21 19:41:47.811798: Epoch 537 
2024-11-21 19:41:47.811899: Current learning rate: 0.005 
2024-11-21 19:42:39.945945: train_loss -0.9726 
2024-11-21 19:42:39.946069: val_loss -0.8974 
2024-11-21 19:42:39.946116: Pseudo dice [np.float32(0.914)] 
2024-11-21 19:42:39.946195: Epoch time: 52.14 s 
2024-11-21 19:42:40.927515:  
2024-11-21 19:42:40.927690: Epoch 538 
2024-11-21 19:42:40.927759: Current learning rate: 0.00499 
2024-11-21 19:43:33.259025: train_loss -0.9719 
2024-11-21 19:43:33.259142: val_loss -0.9044 
2024-11-21 19:43:33.259189: Pseudo dice [np.float32(0.9178)] 
2024-11-21 19:43:33.259241: Epoch time: 52.33 s 
2024-11-21 19:43:34.216155:  
2024-11-21 19:43:34.216323: Epoch 539 
2024-11-21 19:43:34.216403: Current learning rate: 0.00498 
2024-11-21 19:44:26.206812: train_loss -0.9735 
2024-11-21 19:44:26.206938: val_loss -0.8971 
2024-11-21 19:44:26.207002: Pseudo dice [np.float32(0.9123)] 
2024-11-21 19:44:26.207071: Epoch time: 51.99 s 
2024-11-21 19:44:27.229442:  
2024-11-21 19:44:27.229786: Epoch 540 
2024-11-21 19:44:27.229877: Current learning rate: 0.00497 
2024-11-21 19:45:19.498116: train_loss -0.9724 
2024-11-21 19:45:19.498253: val_loss -0.9009 
2024-11-21 19:45:19.498314: Pseudo dice [np.float32(0.9153)] 
2024-11-21 19:45:19.498383: Epoch time: 52.27 s 
2024-11-21 19:45:19.498441: Yayy! New best EMA pseudo Dice: 0.9132000207901001 
2024-11-21 19:45:20.800556:  
2024-11-21 19:45:20.800791: Epoch 541 
2024-11-21 19:45:20.800861: Current learning rate: 0.00496 
2024-11-21 19:46:13.134141: train_loss -0.9721 
2024-11-21 19:46:13.134303: val_loss -0.9017 
2024-11-21 19:46:13.134368: Pseudo dice [np.float32(0.9157)] 
2024-11-21 19:46:13.134436: Epoch time: 52.33 s 
2024-11-21 19:46:13.134499: Yayy! New best EMA pseudo Dice: 0.9133999943733215 
2024-11-21 19:46:14.448971:  
2024-11-21 19:46:14.449104: Epoch 542 
2024-11-21 19:46:14.449172: Current learning rate: 0.00495 
2024-11-21 19:47:07.148526: train_loss -0.9699 
2024-11-21 19:47:07.148671: val_loss -0.8921 
2024-11-21 19:47:07.148738: Pseudo dice [np.float32(0.9084)] 
2024-11-21 19:47:07.148810: Epoch time: 52.7 s 
2024-11-21 19:47:08.475754:  
2024-11-21 19:47:08.475911: Epoch 543 
2024-11-21 19:47:08.475995: Current learning rate: 0.00494 
2024-11-21 19:48:01.123293: train_loss -0.9713 
2024-11-21 19:48:01.123439: val_loss -0.902 
2024-11-21 19:48:01.123564: Pseudo dice [np.float32(0.917)] 
2024-11-21 19:48:01.123630: Epoch time: 52.65 s 
2024-11-21 19:48:02.061586:  
2024-11-21 19:48:02.061877: Epoch 544 
2024-11-21 19:48:02.061962: Current learning rate: 0.00493 
2024-11-21 19:48:54.595423: train_loss -0.9722 
2024-11-21 19:48:54.595626: val_loss -0.8928 
2024-11-21 19:48:54.595675: Pseudo dice [np.float32(0.9065)] 
2024-11-21 19:48:54.595727: Epoch time: 52.53 s 
2024-11-21 19:48:55.573545:  
2024-11-21 19:48:55.573711: Epoch 545 
2024-11-21 19:48:55.573779: Current learning rate: 0.00492 
2024-11-21 19:49:48.075302: train_loss -0.9713 
2024-11-21 19:49:48.075459: val_loss -0.9 
2024-11-21 19:49:48.075554: Pseudo dice [np.float32(0.9137)] 
2024-11-21 19:49:48.075636: Epoch time: 52.5 s 
2024-11-21 19:49:49.040379:  
2024-11-21 19:49:49.040613: Epoch 546 
2024-11-21 19:49:49.040680: Current learning rate: 0.00491 
2024-11-21 19:50:41.301051: train_loss -0.9718 
2024-11-21 19:50:41.301212: val_loss -0.9015 
2024-11-21 19:50:41.301344: Pseudo dice [np.float32(0.9145)] 
2024-11-21 19:50:41.301411: Epoch time: 52.26 s 
2024-11-21 19:50:42.291134:  
2024-11-21 19:50:42.291276: Epoch 547 
2024-11-21 19:50:42.291342: Current learning rate: 0.0049 
2024-11-21 19:51:34.902459: train_loss -0.9712 
2024-11-21 19:51:34.902647: val_loss -0.8985 
2024-11-21 19:51:34.902728: Pseudo dice [np.float32(0.914)] 
2024-11-21 19:51:34.902816: Epoch time: 52.61 s 
2024-11-21 19:51:35.806186:  
2024-11-21 19:51:35.806340: Epoch 548 
2024-11-21 19:51:35.806436: Current learning rate: 0.00489 
2024-11-21 19:52:28.413193: train_loss -0.9715 
2024-11-21 19:52:28.413309: val_loss -0.8986 
2024-11-21 19:52:28.413358: Pseudo dice [np.float32(0.9132)] 
2024-11-21 19:52:28.413439: Epoch time: 52.61 s 
2024-11-21 19:52:29.328359:  
2024-11-21 19:52:29.328519: Epoch 549 
2024-11-21 19:52:29.328588: Current learning rate: 0.00488 
2024-11-21 19:53:21.894283: train_loss -0.9712 
2024-11-21 19:53:21.894431: val_loss -0.9043 
2024-11-21 19:53:21.894486: Pseudo dice [np.float32(0.9171)] 
2024-11-21 19:53:21.894542: Epoch time: 52.57 s 
2024-11-21 19:53:22.258018: Yayy! New best EMA pseudo Dice: 0.9133999943733215 
2024-11-21 19:53:23.650248:  
2024-11-21 19:53:23.650427: Epoch 550 
2024-11-21 19:53:23.650517: Current learning rate: 0.00487 
2024-11-21 19:54:16.304332: train_loss -0.9714 
2024-11-21 19:54:16.304460: val_loss -0.8929 
2024-11-21 19:54:16.304527: Pseudo dice [np.float32(0.9082)] 
2024-11-21 19:54:16.304625: Epoch time: 52.66 s 
2024-11-21 19:54:17.204675:  
2024-11-21 19:54:17.204816: Epoch 551 
2024-11-21 19:54:17.204883: Current learning rate: 0.00486 
2024-11-21 19:55:09.378366: train_loss -0.9709 
2024-11-21 19:55:09.378522: val_loss -0.9031 
2024-11-21 19:55:09.378609: Pseudo dice [np.float32(0.9172)] 
2024-11-21 19:55:09.378678: Epoch time: 52.17 s 
2024-11-21 19:55:10.330725:  
2024-11-21 19:55:10.331002: Epoch 552 
2024-11-21 19:55:10.331121: Current learning rate: 0.00485 
2024-11-21 19:56:02.616790: train_loss -0.9718 
2024-11-21 19:56:02.616921: val_loss -0.8975 
2024-11-21 19:56:02.616971: Pseudo dice [np.float32(0.9108)] 
2024-11-21 19:56:02.617023: Epoch time: 52.29 s 
2024-11-21 19:56:03.550755:  
2024-11-21 19:56:03.550891: Epoch 553 
2024-11-21 19:56:03.550958: Current learning rate: 0.00484 
2024-11-21 19:56:56.143985: train_loss -0.9712 
2024-11-21 19:56:56.144122: val_loss -0.8878 
2024-11-21 19:56:56.144187: Pseudo dice [np.float32(0.9034)] 
2024-11-21 19:56:56.144258: Epoch time: 52.59 s 
2024-11-21 19:56:57.471117:  
2024-11-21 19:56:57.471304: Epoch 554 
2024-11-21 19:56:57.471394: Current learning rate: 0.00484 
2024-11-21 19:57:49.672225: train_loss -0.9714 
2024-11-21 19:57:49.672328: val_loss -0.8966 
2024-11-21 19:57:49.672375: Pseudo dice [np.float32(0.9105)] 
2024-11-21 19:57:49.672426: Epoch time: 52.2 s 
2024-11-21 19:57:50.666784:  
2024-11-21 19:57:50.666919: Epoch 555 
2024-11-21 19:57:50.667013: Current learning rate: 0.00483 
2024-11-21 19:58:43.197176: train_loss -0.9707 
2024-11-21 19:58:43.197306: val_loss -0.8948 
2024-11-21 19:58:43.197367: Pseudo dice [np.float32(0.9096)] 
2024-11-21 19:58:43.197435: Epoch time: 52.53 s 
2024-11-21 19:58:44.117830:  
2024-11-21 19:58:44.117979: Epoch 556 
2024-11-21 19:58:44.118047: Current learning rate: 0.00482 
2024-11-21 19:59:36.685750: train_loss -0.9713 
2024-11-21 19:59:36.685865: val_loss -0.9005 
2024-11-21 19:59:36.685915: Pseudo dice [np.float32(0.9142)] 
2024-11-21 19:59:36.685967: Epoch time: 52.57 s 
2024-11-21 19:59:37.674113:  
2024-11-21 19:59:37.674366: Epoch 557 
2024-11-21 19:59:37.674433: Current learning rate: 0.00481 
2024-11-21 20:00:30.535135: train_loss -0.9725 
2024-11-21 20:00:30.535294: val_loss -0.8942 
2024-11-21 20:00:30.535362: Pseudo dice [np.float32(0.9083)] 
2024-11-21 20:00:30.535414: Epoch time: 52.86 s 
2024-11-21 20:00:31.510298:  
2024-11-21 20:00:31.510571: Epoch 558 
2024-11-21 20:00:31.510656: Current learning rate: 0.0048 
2024-11-21 20:01:23.896100: train_loss -0.9702 
2024-11-21 20:01:23.896216: val_loss -0.8929 
2024-11-21 20:01:23.896274: Pseudo dice [np.float32(0.9059)] 
2024-11-21 20:01:23.896328: Epoch time: 52.39 s 
2024-11-21 20:01:24.830852:  
2024-11-21 20:01:24.831024: Epoch 559 
2024-11-21 20:01:24.831107: Current learning rate: 0.00479 
2024-11-21 20:02:17.139187: train_loss -0.9696 
2024-11-21 20:02:17.139294: val_loss -0.8992 
2024-11-21 20:02:17.139342: Pseudo dice [np.float32(0.9125)] 
2024-11-21 20:02:17.139396: Epoch time: 52.31 s 
2024-11-21 20:02:18.018286:  
2024-11-21 20:02:18.018424: Epoch 560 
2024-11-21 20:02:18.018499: Current learning rate: 0.00478 
2024-11-21 20:03:10.544829: train_loss -0.9701 
2024-11-21 20:03:10.544949: val_loss -0.8964 
2024-11-21 20:03:10.545022: Pseudo dice [np.float32(0.9109)] 
2024-11-21 20:03:10.545093: Epoch time: 52.53 s 
2024-11-21 20:03:11.462122:  
2024-11-21 20:03:11.462309: Epoch 561 
2024-11-21 20:03:11.462416: Current learning rate: 0.00477 
2024-11-21 20:04:04.043984: train_loss -0.9688 
2024-11-21 20:04:04.044099: val_loss -0.8926 
2024-11-21 20:04:04.044147: Pseudo dice [np.float32(0.9068)] 
2024-11-21 20:04:04.044198: Epoch time: 52.58 s 
2024-11-21 20:04:04.936790:  
2024-11-21 20:04:04.936922: Epoch 562 
2024-11-21 20:04:04.936999: Current learning rate: 0.00476 
2024-11-21 20:04:57.523226: train_loss -0.9687 
2024-11-21 20:04:57.523360: val_loss -0.9031 
2024-11-21 20:04:57.523409: Pseudo dice [np.float32(0.9163)] 
2024-11-21 20:04:57.523461: Epoch time: 52.59 s 
2024-11-21 20:04:58.459237:  
2024-11-21 20:04:58.459425: Epoch 563 
2024-11-21 20:04:58.459522: Current learning rate: 0.00475 
2024-11-21 20:05:50.489657: train_loss -0.967 
2024-11-21 20:05:50.489828: val_loss -0.8952 
2024-11-21 20:05:50.490732: Pseudo dice [np.float32(0.9111)] 
2024-11-21 20:05:50.490805: Epoch time: 52.03 s 
2024-11-21 20:05:51.425358:  
2024-11-21 20:05:51.425587: Epoch 564 
2024-11-21 20:05:51.425656: Current learning rate: 0.00474 
2024-11-21 20:06:43.911521: train_loss -0.9667 
2024-11-21 20:06:43.911665: val_loss -0.8959 
2024-11-21 20:06:43.911715: Pseudo dice [np.float32(0.91)] 
2024-11-21 20:06:43.911770: Epoch time: 52.49 s 
2024-11-21 20:06:44.810363:  
2024-11-21 20:06:44.810549: Epoch 565 
2024-11-21 20:06:44.810658: Current learning rate: 0.00473 
2024-11-21 20:07:37.462219: train_loss -0.9676 
2024-11-21 20:07:37.462355: val_loss -0.8917 
2024-11-21 20:07:37.462404: Pseudo dice [np.float32(0.9072)] 
2024-11-21 20:07:37.462458: Epoch time: 52.65 s 
2024-11-21 20:07:38.396571:  
2024-11-21 20:07:38.396815: Epoch 566 
2024-11-21 20:07:38.396911: Current learning rate: 0.00472 
2024-11-21 20:08:30.794144: train_loss -0.967 
2024-11-21 20:08:30.794262: val_loss -0.8879 
2024-11-21 20:08:30.794310: Pseudo dice [np.float32(0.9043)] 
2024-11-21 20:08:30.794363: Epoch time: 52.4 s 
2024-11-21 20:08:32.091872:  
2024-11-21 20:08:32.092073: Epoch 567 
2024-11-21 20:08:32.092166: Current learning rate: 0.00471 
2024-11-21 20:09:24.346004: train_loss -0.966 
2024-11-21 20:09:24.346148: val_loss -0.9048 
2024-11-21 20:09:24.346202: Pseudo dice [np.float32(0.9176)] 
2024-11-21 20:09:24.346279: Epoch time: 52.26 s 
2024-11-21 20:09:25.265893:  
2024-11-21 20:09:25.266052: Epoch 568 
2024-11-21 20:09:25.266161: Current learning rate: 0.0047 
2024-11-21 20:10:17.989412: train_loss -0.9536 
2024-11-21 20:10:17.989574: val_loss -0.8826 
2024-11-21 20:10:17.989637: Pseudo dice [np.float32(0.9005)] 
2024-11-21 20:10:17.989702: Epoch time: 52.72 s 
2024-11-21 20:10:18.959424:  
2024-11-21 20:10:18.959633: Epoch 569 
2024-11-21 20:10:18.959702: Current learning rate: 0.00469 
2024-11-21 20:11:11.461194: train_loss -0.9501 
2024-11-21 20:11:11.461317: val_loss -0.8914 
2024-11-21 20:11:11.461370: Pseudo dice [np.float32(0.9058)] 
2024-11-21 20:11:11.461423: Epoch time: 52.5 s 
2024-11-21 20:11:12.425819:  
2024-11-21 20:11:12.426003: Epoch 570 
2024-11-21 20:11:12.426094: Current learning rate: 0.00468 
2024-11-21 20:12:05.204218: train_loss -0.9519 
2024-11-21 20:12:05.204382: val_loss -0.8852 
2024-11-21 20:12:05.204431: Pseudo dice [np.float32(0.9006)] 
2024-11-21 20:12:05.204489: Epoch time: 52.78 s 
2024-11-21 20:12:06.108264:  
2024-11-21 20:12:06.108467: Epoch 571 
2024-11-21 20:12:06.108558: Current learning rate: 0.00467 
2024-11-21 20:12:58.801258: train_loss -0.9521 
2024-11-21 20:12:58.801381: val_loss -0.8902 
2024-11-21 20:12:58.801446: Pseudo dice [np.float32(0.9058)] 
2024-11-21 20:12:58.801560: Epoch time: 52.69 s 
2024-11-21 20:12:59.736655:  
2024-11-21 20:12:59.736861: Epoch 572 
2024-11-21 20:12:59.736948: Current learning rate: 0.00466 
2024-11-21 20:13:52.346642: train_loss -0.9567 
2024-11-21 20:13:52.346782: val_loss -0.8932 
2024-11-21 20:13:52.346846: Pseudo dice [np.float32(0.9075)] 
2024-11-21 20:13:52.346923: Epoch time: 52.61 s 
2024-11-21 20:13:53.306653:  
2024-11-21 20:13:53.306797: Epoch 573 
2024-11-21 20:13:53.306863: Current learning rate: 0.00465 
2024-11-21 20:14:45.690940: train_loss -0.9618 
2024-11-21 20:14:45.691059: val_loss -0.895 
2024-11-21 20:14:45.691137: Pseudo dice [np.float32(0.9107)] 
2024-11-21 20:14:45.691214: Epoch time: 52.39 s 
2024-11-21 20:14:46.624844:  
2024-11-21 20:14:46.624993: Epoch 574 
2024-11-21 20:14:46.625095: Current learning rate: 0.00464 
2024-11-21 20:15:39.133364: train_loss -0.9646 
2024-11-21 20:15:39.133502: val_loss -0.901 
2024-11-21 20:15:39.133572: Pseudo dice [np.float32(0.9131)] 
2024-11-21 20:15:39.133659: Epoch time: 52.51 s 
2024-11-21 20:15:40.063534:  
2024-11-21 20:15:40.063717: Epoch 575 
2024-11-21 20:15:40.063800: Current learning rate: 0.00463 
2024-11-21 20:16:32.552914: train_loss -0.9664 
2024-11-21 20:16:32.553045: val_loss -0.8991 
2024-11-21 20:16:32.553095: Pseudo dice [np.float32(0.9131)] 
2024-11-21 20:16:32.553150: Epoch time: 52.49 s 
2024-11-21 20:16:33.554981:  
2024-11-21 20:16:33.555151: Epoch 576 
2024-11-21 20:16:33.555263: Current learning rate: 0.00462 
2024-11-21 20:17:25.735778: train_loss -0.9681 
2024-11-21 20:17:25.735916: val_loss -0.8935 
2024-11-21 20:17:25.735980: Pseudo dice [np.float32(0.9076)] 
2024-11-21 20:17:25.736050: Epoch time: 52.18 s 
2024-11-21 20:17:26.802291:  
2024-11-21 20:17:26.802425: Epoch 577 
2024-11-21 20:17:26.802521: Current learning rate: 0.00461 
2024-11-21 20:18:18.905664: train_loss -0.9684 
2024-11-21 20:18:18.905781: val_loss -0.8986 
2024-11-21 20:18:18.905830: Pseudo dice [np.float32(0.9134)] 
2024-11-21 20:18:18.905884: Epoch time: 52.1 s 
2024-11-21 20:18:20.154755:  
2024-11-21 20:18:20.154944: Epoch 578 
2024-11-21 20:18:20.155033: Current learning rate: 0.0046 
2024-11-21 20:19:12.257189: train_loss -0.9684 
2024-11-21 20:19:12.257351: val_loss -0.8951 
2024-11-21 20:19:12.257416: Pseudo dice [np.float32(0.9091)] 
2024-11-21 20:19:12.257491: Epoch time: 52.1 s 
2024-11-21 20:19:13.184627:  
2024-11-21 20:19:13.184786: Epoch 579 
2024-11-21 20:19:13.184856: Current learning rate: 0.00459 
2024-11-21 20:20:05.418435: train_loss -0.9696 
2024-11-21 20:20:05.418636: val_loss -0.9 
2024-11-21 20:20:05.418699: Pseudo dice [np.float32(0.9138)] 
2024-11-21 20:20:05.418766: Epoch time: 52.23 s 
2024-11-21 20:20:06.359852:  
2024-11-21 20:20:06.360032: Epoch 580 
2024-11-21 20:20:06.360151: Current learning rate: 0.00458 
2024-11-21 20:20:58.682226: train_loss -0.9708 
2024-11-21 20:20:58.682353: val_loss -0.9015 
2024-11-21 20:20:58.682417: Pseudo dice [np.float32(0.9152)] 
2024-11-21 20:20:58.682518: Epoch time: 52.32 s 
2024-11-21 20:20:59.639159:  
2024-11-21 20:20:59.639378: Epoch 581 
2024-11-21 20:20:59.639576: Current learning rate: 0.00457 
2024-11-21 20:21:51.894612: train_loss -0.9702 
2024-11-21 20:21:51.894749: val_loss -0.899 
2024-11-21 20:21:51.894829: Pseudo dice [np.float32(0.9134)] 
2024-11-21 20:21:51.894894: Epoch time: 52.26 s 
2024-11-21 20:21:52.863362:  
2024-11-21 20:21:52.863568: Epoch 582 
2024-11-21 20:21:52.863647: Current learning rate: 0.00456 
2024-11-21 20:22:45.065992: train_loss -0.9706 
2024-11-21 20:22:45.066156: val_loss -0.8915 
2024-11-21 20:22:45.066220: Pseudo dice [np.float32(0.9072)] 
2024-11-21 20:22:45.066288: Epoch time: 52.2 s 
2024-11-21 20:22:46.033861:  
2024-11-21 20:22:46.033995: Epoch 583 
2024-11-21 20:22:46.034065: Current learning rate: 0.00455 
2024-11-21 20:23:38.293094: train_loss -0.9706 
2024-11-21 20:23:38.293213: val_loss -0.8975 
2024-11-21 20:23:38.293317: Pseudo dice [np.float32(0.9114)] 
2024-11-21 20:23:38.293371: Epoch time: 52.26 s 
2024-11-21 20:23:39.293535:  
2024-11-21 20:23:39.293777: Epoch 584 
2024-11-21 20:23:39.293863: Current learning rate: 0.00454 
2024-11-21 20:24:31.603625: train_loss -0.9714 
2024-11-21 20:24:31.603798: val_loss -0.8998 
2024-11-21 20:24:31.603861: Pseudo dice [np.float32(0.9137)] 
2024-11-21 20:24:31.603925: Epoch time: 52.31 s 
2024-11-21 20:24:32.612865:  
2024-11-21 20:24:32.613064: Epoch 585 
2024-11-21 20:24:32.613147: Current learning rate: 0.00453 
2024-11-21 20:25:24.956921: train_loss -0.9715 
2024-11-21 20:25:24.957047: val_loss -0.9041 
2024-11-21 20:25:24.957111: Pseudo dice [np.float32(0.9175)] 
2024-11-21 20:25:24.957164: Epoch time: 52.35 s 
2024-11-21 20:25:25.922069:  
2024-11-21 20:25:25.922202: Epoch 586 
2024-11-21 20:25:25.922269: Current learning rate: 0.00452 
2024-11-21 20:26:18.429137: train_loss -0.9724 
2024-11-21 20:26:18.429274: val_loss -0.8966 
2024-11-21 20:26:18.429361: Pseudo dice [np.float32(0.9124)] 
2024-11-21 20:26:18.429431: Epoch time: 52.51 s 
2024-11-21 20:26:19.484672:  
2024-11-21 20:26:19.484837: Epoch 587 
2024-11-21 20:26:19.484955: Current learning rate: 0.00451 
2024-11-21 20:27:11.885718: train_loss -0.9714 
2024-11-21 20:27:11.885872: val_loss -0.9008 
2024-11-21 20:27:11.885960: Pseudo dice [np.float32(0.9135)] 
2024-11-21 20:27:11.886053: Epoch time: 52.4 s 
2024-11-21 20:27:12.893639:  
2024-11-21 20:27:12.893860: Epoch 588 
2024-11-21 20:27:12.893946: Current learning rate: 0.0045 
2024-11-21 20:28:05.065645: train_loss -0.9719 
2024-11-21 20:28:05.065780: val_loss -0.8951 
2024-11-21 20:28:05.065864: Pseudo dice [np.float32(0.9089)] 
2024-11-21 20:28:05.065948: Epoch time: 52.17 s 
2024-11-21 20:28:06.045942:  
2024-11-21 20:28:06.046113: Epoch 589 
2024-11-21 20:28:06.046212: Current learning rate: 0.00449 
2024-11-21 20:28:58.200237: train_loss -0.9721 
2024-11-21 20:28:58.200372: val_loss -0.8995 
2024-11-21 20:28:58.200422: Pseudo dice [np.float32(0.9123)] 
2024-11-21 20:28:58.200577: Epoch time: 52.16 s 
2024-11-21 20:28:59.499400:  
2024-11-21 20:28:59.499617: Epoch 590 
2024-11-21 20:28:59.499694: Current learning rate: 0.00448 
2024-11-21 20:29:52.014907: train_loss -0.9721 
2024-11-21 20:29:52.015055: val_loss -0.9003 
2024-11-21 20:29:52.015182: Pseudo dice [np.float32(0.9133)] 
2024-11-21 20:29:52.015238: Epoch time: 52.52 s 
2024-11-21 20:29:52.994466:  
2024-11-21 20:29:52.994662: Epoch 591 
2024-11-21 20:29:52.994730: Current learning rate: 0.00447 
2024-11-21 20:30:45.319279: train_loss -0.9717 
2024-11-21 20:30:45.319386: val_loss -0.8903 
2024-11-21 20:30:45.319437: Pseudo dice [np.float32(0.9039)] 
2024-11-21 20:30:45.319583: Epoch time: 52.33 s 
2024-11-21 20:30:46.224700:  
2024-11-21 20:30:46.224840: Epoch 592 
2024-11-21 20:30:46.224908: Current learning rate: 0.00446 
2024-11-21 20:31:38.869249: train_loss -0.9715 
2024-11-21 20:31:38.869517: val_loss -0.8913 
2024-11-21 20:31:38.869624: Pseudo dice [np.float32(0.9085)] 
2024-11-21 20:31:38.869684: Epoch time: 52.65 s 
2024-11-21 20:31:39.789689:  
2024-11-21 20:31:39.789874: Epoch 593 
2024-11-21 20:31:39.789956: Current learning rate: 0.00445 
2024-11-21 20:32:32.130871: train_loss -0.9723 
2024-11-21 20:32:32.131010: val_loss -0.8967 
2024-11-21 20:32:32.131076: Pseudo dice [np.float32(0.9106)] 
2024-11-21 20:32:32.131146: Epoch time: 52.34 s 
2024-11-21 20:32:33.225584:  
2024-11-21 20:32:33.225770: Epoch 594 
2024-11-21 20:32:33.225857: Current learning rate: 0.00444 
2024-11-21 20:33:25.430158: train_loss -0.9726 
2024-11-21 20:33:25.430274: val_loss -0.9024 
2024-11-21 20:33:25.430323: Pseudo dice [np.float32(0.9154)] 
2024-11-21 20:33:25.430408: Epoch time: 52.21 s 
2024-11-21 20:33:26.439764:  
2024-11-21 20:33:26.439938: Epoch 595 
2024-11-21 20:33:26.440022: Current learning rate: 0.00443 
2024-11-21 20:34:18.618646: train_loss -0.9726 
2024-11-21 20:34:18.618763: val_loss -0.8938 
2024-11-21 20:34:18.618810: Pseudo dice [np.float32(0.9102)] 
2024-11-21 20:34:18.618861: Epoch time: 52.18 s 
2024-11-21 20:34:19.599763:  
2024-11-21 20:34:19.599985: Epoch 596 
2024-11-21 20:34:19.600080: Current learning rate: 0.00442 
2024-11-21 20:35:12.295721: train_loss -0.9729 
2024-11-21 20:35:12.295851: val_loss -0.9018 
2024-11-21 20:35:12.295936: Pseudo dice [np.float32(0.9166)] 
2024-11-21 20:35:12.296005: Epoch time: 52.7 s 
2024-11-21 20:35:13.198986:  
2024-11-21 20:35:13.199134: Epoch 597 
2024-11-21 20:35:13.199199: Current learning rate: 0.00441 
2024-11-21 20:36:05.563696: train_loss -0.973 
2024-11-21 20:36:05.563874: val_loss -0.898 
2024-11-21 20:36:05.563967: Pseudo dice [np.float32(0.9117)] 
2024-11-21 20:36:05.564035: Epoch time: 52.37 s 
2024-11-21 20:36:06.599024:  
2024-11-21 20:36:06.599248: Epoch 598 
2024-11-21 20:36:06.599333: Current learning rate: 0.0044 
2024-11-21 20:36:59.199846: train_loss -0.9728 
2024-11-21 20:36:59.199955: val_loss -0.8992 
2024-11-21 20:36:59.200004: Pseudo dice [np.float32(0.9137)] 
2024-11-21 20:36:59.200057: Epoch time: 52.6 s 
2024-11-21 20:37:00.135460:  
2024-11-21 20:37:00.135779: Epoch 599 
2024-11-21 20:37:00.135934: Current learning rate: 0.00439 
2024-11-21 20:37:52.597800: train_loss -0.9733 
2024-11-21 20:37:52.597912: val_loss -0.8973 
2024-11-21 20:37:52.597960: Pseudo dice [np.float32(0.9115)] 
2024-11-21 20:37:52.598013: Epoch time: 52.46 s 
2024-11-21 20:37:53.918904:  
2024-11-21 20:37:53.919026: Epoch 600 
2024-11-21 20:37:53.919101: Current learning rate: 0.00438 
2024-11-21 20:38:46.348506: train_loss -0.9733 
2024-11-21 20:38:46.348669: val_loss -0.8966 
2024-11-21 20:38:46.348720: Pseudo dice [np.float32(0.9107)] 
2024-11-21 20:38:46.348775: Epoch time: 52.43 s 
2024-11-21 20:38:47.318360:  
2024-11-21 20:38:47.318551: Epoch 601 
2024-11-21 20:38:47.318635: Current learning rate: 0.00437 
2024-11-21 20:39:39.767742: train_loss -0.9728 
2024-11-21 20:39:39.767872: val_loss -0.8909 
2024-11-21 20:39:39.767936: Pseudo dice [np.float32(0.9068)] 
2024-11-21 20:39:39.768002: Epoch time: 52.45 s 
2024-11-21 20:39:41.141811:  
2024-11-21 20:39:41.142061: Epoch 602 
2024-11-21 20:39:41.142174: Current learning rate: 0.00436 
2024-11-21 20:40:33.217827: train_loss -0.9737 
2024-11-21 20:40:33.217956: val_loss -0.8962 
2024-11-21 20:40:33.218006: Pseudo dice [np.float32(0.9115)] 
2024-11-21 20:40:33.218057: Epoch time: 52.08 s 
2024-11-21 20:40:34.281972:  
2024-11-21 20:40:34.282168: Epoch 603 
2024-11-21 20:40:34.282253: Current learning rate: 0.00435 
2024-11-21 20:41:26.673639: train_loss -0.9738 
2024-11-21 20:41:26.673771: val_loss -0.9015 
2024-11-21 20:41:26.673820: Pseudo dice [np.float32(0.9158)] 
2024-11-21 20:41:26.673875: Epoch time: 52.39 s 
2024-11-21 20:41:27.696349:  
2024-11-21 20:41:27.696515: Epoch 604 
2024-11-21 20:41:27.696617: Current learning rate: 0.00434 
2024-11-21 20:42:20.226350: train_loss -0.9723 
2024-11-21 20:42:20.226497: val_loss -0.9007 
2024-11-21 20:42:20.226568: Pseudo dice [np.float32(0.9146)] 
2024-11-21 20:42:20.226637: Epoch time: 52.53 s 
2024-11-21 20:42:21.221981:  
2024-11-21 20:42:21.222116: Epoch 605 
2024-11-21 20:42:21.222244: Current learning rate: 0.00433 
2024-11-21 20:43:13.620350: train_loss -0.9732 
2024-11-21 20:43:13.620502: val_loss -0.8975 
2024-11-21 20:43:13.620620: Pseudo dice [np.float32(0.9119)] 
2024-11-21 20:43:13.620707: Epoch time: 52.4 s 
2024-11-21 20:43:14.528935:  
2024-11-21 20:43:14.529111: Epoch 606 
2024-11-21 20:43:14.529183: Current learning rate: 0.00432 
2024-11-21 20:44:07.161230: train_loss -0.9729 
2024-11-21 20:44:07.161348: val_loss -0.8969 
2024-11-21 20:44:07.161399: Pseudo dice [np.float32(0.9115)] 
2024-11-21 20:44:07.161453: Epoch time: 52.63 s 
2024-11-21 20:44:08.144559:  
2024-11-21 20:44:08.144735: Epoch 607 
2024-11-21 20:44:08.144821: Current learning rate: 0.00431 
2024-11-21 20:45:00.675718: train_loss -0.9719 
2024-11-21 20:45:00.675940: val_loss -0.897 
2024-11-21 20:45:00.676051: Pseudo dice [np.float32(0.9114)] 
2024-11-21 20:45:00.676179: Epoch time: 52.53 s 
2024-11-21 20:45:01.645256:  
2024-11-21 20:45:01.645405: Epoch 608 
2024-11-21 20:45:01.645535: Current learning rate: 0.0043 
2024-11-21 20:45:53.836233: train_loss -0.973 
2024-11-21 20:45:53.836341: val_loss -0.8905 
2024-11-21 20:45:53.836388: Pseudo dice [np.float32(0.9064)] 
2024-11-21 20:45:53.836459: Epoch time: 52.19 s 
2024-11-21 20:45:54.847126:  
2024-11-21 20:45:54.847263: Epoch 609 
2024-11-21 20:45:54.847331: Current learning rate: 0.00429 
2024-11-21 20:46:47.183126: train_loss -0.9733 
2024-11-21 20:46:47.183273: val_loss -0.8979 
2024-11-21 20:46:47.183352: Pseudo dice [np.float32(0.9122)] 
2024-11-21 20:46:47.183438: Epoch time: 52.34 s 
2024-11-21 20:46:48.131322:  
2024-11-21 20:46:48.131451: Epoch 610 
2024-11-21 20:46:48.131590: Current learning rate: 0.00429 
2024-11-21 20:47:40.606976: train_loss -0.9724 
2024-11-21 20:47:40.607102: val_loss -0.8941 
2024-11-21 20:47:40.607154: Pseudo dice [np.float32(0.9089)] 
2024-11-21 20:47:40.607208: Epoch time: 52.48 s 
2024-11-21 20:47:41.538058:  
2024-11-21 20:47:41.538197: Epoch 611 
2024-11-21 20:47:41.538261: Current learning rate: 0.00428 
2024-11-21 20:48:34.334818: train_loss -0.9723 
2024-11-21 20:48:34.334933: val_loss -0.8947 
2024-11-21 20:48:34.334981: Pseudo dice [np.float32(0.9117)] 
2024-11-21 20:48:34.335034: Epoch time: 52.8 s 
2024-11-21 20:48:35.310709:  
2024-11-21 20:48:35.310987: Epoch 612 
2024-11-21 20:48:35.311107: Current learning rate: 0.00427 
2024-11-21 20:49:27.701880: train_loss -0.9736 
2024-11-21 20:49:27.702003: val_loss -0.8946 
2024-11-21 20:49:27.702069: Pseudo dice [np.float32(0.9091)] 
2024-11-21 20:49:27.702141: Epoch time: 52.39 s 
2024-11-21 20:49:28.698665:  
2024-11-21 20:49:28.698917: Epoch 613 
2024-11-21 20:49:28.698986: Current learning rate: 0.00426 
2024-11-21 20:50:21.292358: train_loss -0.9733 
2024-11-21 20:50:21.292524: val_loss -0.8953 
2024-11-21 20:50:21.292597: Pseudo dice [np.float32(0.9116)] 
2024-11-21 20:50:21.292671: Epoch time: 52.59 s 
2024-11-21 20:50:22.715898:  
2024-11-21 20:50:22.716084: Epoch 614 
2024-11-21 20:50:22.716168: Current learning rate: 0.00425 
2024-11-21 20:51:15.380369: train_loss -0.9741 
2024-11-21 20:51:15.380530: val_loss -0.8978 
2024-11-21 20:51:15.380611: Pseudo dice [np.float32(0.9132)] 
2024-11-21 20:51:15.380665: Epoch time: 52.67 s 
2024-11-21 20:51:16.365221:  
2024-11-21 20:51:16.365386: Epoch 615 
2024-11-21 20:51:16.365456: Current learning rate: 0.00424 
2024-11-21 20:52:08.912686: train_loss -0.9731 
2024-11-21 20:52:08.912814: val_loss -0.8928 
2024-11-21 20:52:08.912880: Pseudo dice [np.float32(0.9086)] 
2024-11-21 20:52:08.912982: Epoch time: 52.55 s 
2024-11-21 20:52:09.976902:  
2024-11-21 20:52:09.977158: Epoch 616 
2024-11-21 20:52:09.977235: Current learning rate: 0.00423 
2024-11-21 20:53:02.286148: train_loss -0.9741 
2024-11-21 20:53:02.286342: val_loss -0.8988 
2024-11-21 20:53:02.286408: Pseudo dice [np.float32(0.9131)] 
2024-11-21 20:53:02.286486: Epoch time: 52.31 s 
2024-11-21 20:53:03.249918:  
2024-11-21 20:53:03.250167: Epoch 617 
2024-11-21 20:53:03.250249: Current learning rate: 0.00422 
2024-11-21 20:53:55.583751: train_loss -0.9742 
2024-11-21 20:53:55.583897: val_loss -0.8984 
2024-11-21 20:53:55.583946: Pseudo dice [np.float32(0.9122)] 
2024-11-21 20:53:55.583998: Epoch time: 52.33 s 
2024-11-21 20:53:56.553655:  
2024-11-21 20:53:56.553949: Epoch 618 
2024-11-21 20:53:56.554075: Current learning rate: 0.00421 
2024-11-21 20:54:48.722011: train_loss -0.9741 
2024-11-21 20:54:48.722124: val_loss -0.8935 
2024-11-21 20:54:48.722171: Pseudo dice [np.float32(0.9107)] 
2024-11-21 20:54:48.722223: Epoch time: 52.17 s 
2024-11-21 20:54:49.641099:  
2024-11-21 20:54:49.641237: Epoch 619 
2024-11-21 20:54:49.641324: Current learning rate: 0.0042 
2024-11-21 20:55:42.183360: train_loss -0.9734 
2024-11-21 20:55:42.183486: val_loss -0.8971 
2024-11-21 20:55:42.183624: Pseudo dice [np.float32(0.9116)] 
2024-11-21 20:55:42.183681: Epoch time: 52.54 s 
2024-11-21 20:55:43.170982:  
2024-11-21 20:55:43.171196: Epoch 620 
2024-11-21 20:55:43.171283: Current learning rate: 0.00419 
2024-11-21 20:56:35.636590: train_loss -0.9742 
2024-11-21 20:56:35.636709: val_loss -0.8904 
2024-11-21 20:56:35.636760: Pseudo dice [np.float32(0.9062)] 
2024-11-21 20:56:35.636816: Epoch time: 52.47 s 
2024-11-21 20:56:36.616974:  
2024-11-21 20:56:36.617256: Epoch 621 
2024-11-21 20:56:36.617340: Current learning rate: 0.00418 
2024-11-21 20:57:28.973943: train_loss -0.9736 
2024-11-21 20:57:28.974074: val_loss -0.8994 
2024-11-21 20:57:28.974140: Pseudo dice [np.float32(0.9152)] 
2024-11-21 20:57:28.974210: Epoch time: 52.36 s 
2024-11-21 20:57:29.987963:  
2024-11-21 20:57:29.988115: Epoch 622 
2024-11-21 20:57:29.988185: Current learning rate: 0.00417 
2024-11-21 20:58:22.386205: train_loss -0.9744 
2024-11-21 20:58:22.386333: val_loss -0.8948 
2024-11-21 20:58:22.386403: Pseudo dice [np.float32(0.9099)] 
2024-11-21 20:58:22.386456: Epoch time: 52.4 s 
2024-11-21 20:58:23.357600:  
2024-11-21 20:58:23.357824: Epoch 623 
2024-11-21 20:58:23.357911: Current learning rate: 0.00416 
2024-11-21 20:59:15.393328: train_loss -0.9746 
2024-11-21 20:59:15.393468: val_loss -0.8926 
2024-11-21 20:59:15.393584: Pseudo dice [np.float32(0.9082)] 
2024-11-21 20:59:15.393636: Epoch time: 52.04 s 
2024-11-21 20:59:16.321807:  
2024-11-21 20:59:16.321992: Epoch 624 
2024-11-21 20:59:16.322078: Current learning rate: 0.00415 
2024-11-21 21:00:08.797531: train_loss -0.974 
2024-11-21 21:00:08.797669: val_loss -0.8972 
2024-11-21 21:00:08.797721: Pseudo dice [np.float32(0.9116)] 
2024-11-21 21:00:08.797775: Epoch time: 52.48 s 
2024-11-21 21:00:10.074108:  
2024-11-21 21:00:10.074266: Epoch 625 
2024-11-21 21:00:10.074337: Current learning rate: 0.00414 
2024-11-21 21:01:02.401590: train_loss -0.9738 
2024-11-21 21:01:02.401752: val_loss -0.8942 
2024-11-21 21:01:02.401803: Pseudo dice [np.float32(0.9077)] 
2024-11-21 21:01:02.401858: Epoch time: 52.33 s 
2024-11-21 21:01:03.424153:  
2024-11-21 21:01:03.424340: Epoch 626 
2024-11-21 21:01:03.424424: Current learning rate: 0.00413 
2024-11-21 21:01:55.525076: train_loss -0.9736 
2024-11-21 21:01:55.525290: val_loss -0.8928 
2024-11-21 21:01:55.525385: Pseudo dice [np.float32(0.9091)] 
2024-11-21 21:01:55.525455: Epoch time: 52.1 s 
2024-11-21 21:01:56.554652:  
2024-11-21 21:01:56.554829: Epoch 627 
2024-11-21 21:01:56.554917: Current learning rate: 0.00412 
2024-11-21 21:02:49.204941: train_loss -0.9735 
2024-11-21 21:02:49.205059: val_loss -0.8938 
2024-11-21 21:02:49.205126: Pseudo dice [np.float32(0.9097)] 
2024-11-21 21:02:49.205179: Epoch time: 52.65 s 
2024-11-21 21:02:50.135447:  
2024-11-21 21:02:50.135687: Epoch 628 
2024-11-21 21:02:50.135755: Current learning rate: 0.00411 
2024-11-21 21:03:43.002071: train_loss -0.974 
2024-11-21 21:03:43.002322: val_loss -0.9009 
2024-11-21 21:03:43.002387: Pseudo dice [np.float32(0.9149)] 
2024-11-21 21:03:43.002455: Epoch time: 52.87 s 
2024-11-21 21:03:43.994040:  
2024-11-21 21:03:43.994266: Epoch 629 
2024-11-21 21:03:43.994353: Current learning rate: 0.0041 
2024-11-21 21:04:36.285422: train_loss -0.974 
2024-11-21 21:04:36.285635: val_loss -0.8966 
2024-11-21 21:04:36.285729: Pseudo dice [np.float32(0.9118)] 
2024-11-21 21:04:36.285796: Epoch time: 52.29 s 
2024-11-21 21:04:37.181846:  
2024-11-21 21:04:37.182070: Epoch 630 
2024-11-21 21:04:37.182157: Current learning rate: 0.00409 
2024-11-21 21:05:29.550280: train_loss -0.9744 
2024-11-21 21:05:29.550413: val_loss -0.899 
2024-11-21 21:05:29.550461: Pseudo dice [np.float32(0.9122)] 
2024-11-21 21:05:29.550556: Epoch time: 52.37 s 
2024-11-21 21:05:30.549048:  
2024-11-21 21:05:30.549230: Epoch 631 
2024-11-21 21:05:30.549313: Current learning rate: 0.00408 
2024-11-21 21:06:22.844043: train_loss -0.9744 
2024-11-21 21:06:22.844195: val_loss -0.8991 
2024-11-21 21:06:22.844257: Pseudo dice [np.float32(0.9133)] 
2024-11-21 21:06:22.844323: Epoch time: 52.3 s 
2024-11-21 21:06:23.819055:  
2024-11-21 21:06:23.819272: Epoch 632 
2024-11-21 21:06:23.819399: Current learning rate: 0.00407 
2024-11-21 21:07:16.425431: train_loss -0.9744 
2024-11-21 21:07:16.425608: val_loss -0.8972 
2024-11-21 21:07:16.425660: Pseudo dice [np.float32(0.9123)] 
2024-11-21 21:07:16.425751: Epoch time: 52.61 s 
2024-11-21 21:07:17.396395:  
2024-11-21 21:07:17.396528: Epoch 633 
2024-11-21 21:07:17.396750: Current learning rate: 0.00406 
2024-11-21 21:08:09.867963: train_loss -0.9741 
2024-11-21 21:08:09.868098: val_loss -0.9035 
2024-11-21 21:08:09.868152: Pseudo dice [np.float32(0.9176)] 
2024-11-21 21:08:09.868227: Epoch time: 52.47 s 
2024-11-21 21:08:10.886463:  
2024-11-21 21:08:10.886645: Epoch 634 
2024-11-21 21:08:10.886731: Current learning rate: 0.00405 
2024-11-21 21:09:03.239727: train_loss -0.9738 
2024-11-21 21:09:03.239859: val_loss -0.9035 
2024-11-21 21:09:03.240752: Pseudo dice [np.float32(0.9178)] 
2024-11-21 21:09:03.240810: Epoch time: 52.35 s 
2024-11-21 21:09:04.279973:  
2024-11-21 21:09:04.280146: Epoch 635 
2024-11-21 21:09:04.280231: Current learning rate: 0.00404 
2024-11-21 21:09:56.624822: train_loss -0.9743 
2024-11-21 21:09:56.624969: val_loss -0.8965 
2024-11-21 21:09:56.625018: Pseudo dice [np.float32(0.9113)] 
2024-11-21 21:09:56.625070: Epoch time: 52.35 s 
2024-11-21 21:09:57.568866:  
2024-11-21 21:09:57.569006: Epoch 636 
2024-11-21 21:09:57.569073: Current learning rate: 0.00403 
2024-11-21 21:10:49.817704: train_loss -0.9748 
2024-11-21 21:10:49.817820: val_loss -0.899 
2024-11-21 21:10:49.817868: Pseudo dice [np.float32(0.9143)] 
2024-11-21 21:10:49.817922: Epoch time: 52.25 s 
2024-11-21 21:10:51.161592:  
2024-11-21 21:10:51.161764: Epoch 637 
2024-11-21 21:10:51.161887: Current learning rate: 0.00402 
2024-11-21 21:11:43.607630: train_loss -0.974 
2024-11-21 21:11:43.607764: val_loss -0.8981 
2024-11-21 21:11:43.607830: Pseudo dice [np.float32(0.9135)] 
2024-11-21 21:11:43.607900: Epoch time: 52.45 s 
2024-11-21 21:11:44.595316:  
2024-11-21 21:11:44.595520: Epoch 638 
2024-11-21 21:11:44.595620: Current learning rate: 0.00401 
2024-11-21 21:12:37.235848: train_loss -0.9734 
2024-11-21 21:12:37.235976: val_loss -0.8945 
2024-11-21 21:12:37.236063: Pseudo dice [np.float32(0.9094)] 
2024-11-21 21:12:37.236151: Epoch time: 52.64 s 
2024-11-21 21:12:38.173128:  
2024-11-21 21:12:38.173266: Epoch 639 
2024-11-21 21:12:38.173338: Current learning rate: 0.004 
2024-11-21 21:13:30.640769: train_loss -0.9735 
2024-11-21 21:13:30.640895: val_loss -0.8966 
2024-11-21 21:13:30.640947: Pseudo dice [np.float32(0.912)] 
2024-11-21 21:13:30.641002: Epoch time: 52.47 s 
2024-11-21 21:13:31.568920:  
2024-11-21 21:13:31.569061: Epoch 640 
2024-11-21 21:13:31.569134: Current learning rate: 0.00399 
2024-11-21 21:14:24.219361: train_loss -0.9744 
2024-11-21 21:14:24.219542: val_loss -0.8952 
2024-11-21 21:14:24.219676: Pseudo dice [np.float32(0.9105)] 
2024-11-21 21:14:24.219812: Epoch time: 52.65 s 
2024-11-21 21:14:25.228630:  
2024-11-21 21:14:25.228818: Epoch 641 
2024-11-21 21:14:25.228899: Current learning rate: 0.00398 
2024-11-21 21:15:17.384960: train_loss -0.9744 
2024-11-21 21:15:17.385085: val_loss -0.8999 
2024-11-21 21:15:17.385146: Pseudo dice [np.float32(0.9136)] 
2024-11-21 21:15:17.385213: Epoch time: 52.16 s 
2024-11-21 21:15:18.447271:  
2024-11-21 21:15:18.447463: Epoch 642 
2024-11-21 21:15:18.447562: Current learning rate: 0.00397 
2024-11-21 21:16:11.147664: train_loss -0.9749 
2024-11-21 21:16:11.147806: val_loss -0.896 
2024-11-21 21:16:11.147857: Pseudo dice [np.float32(0.9106)] 
2024-11-21 21:16:11.147914: Epoch time: 52.7 s 
2024-11-21 21:16:12.147590:  
2024-11-21 21:16:12.147768: Epoch 643 
2024-11-21 21:16:12.147855: Current learning rate: 0.00396 
2024-11-21 21:17:04.403734: train_loss -0.9746 
2024-11-21 21:17:04.403861: val_loss -0.8988 
2024-11-21 21:17:04.403909: Pseudo dice [np.float32(0.9137)] 
2024-11-21 21:17:04.403960: Epoch time: 52.26 s 
2024-11-21 21:17:05.312682:  
2024-11-21 21:17:05.312816: Epoch 644 
2024-11-21 21:17:05.312882: Current learning rate: 0.00395 
2024-11-21 21:17:57.715448: train_loss -0.9752 
2024-11-21 21:17:57.715567: val_loss -0.9011 
2024-11-21 21:17:57.715621: Pseudo dice [np.float32(0.9166)] 
2024-11-21 21:17:57.715672: Epoch time: 52.4 s 
2024-11-21 21:17:58.694164:  
2024-11-21 21:17:58.694347: Epoch 645 
2024-11-21 21:17:58.694433: Current learning rate: 0.00394 
2024-11-21 21:18:50.933550: train_loss -0.9745 
2024-11-21 21:18:50.933700: val_loss -0.8966 
2024-11-21 21:18:50.933749: Pseudo dice [np.float32(0.912)] 
2024-11-21 21:18:50.933804: Epoch time: 52.24 s 
2024-11-21 21:18:51.967900:  
2024-11-21 21:18:51.968080: Epoch 646 
2024-11-21 21:18:51.968166: Current learning rate: 0.00393 
2024-11-21 21:19:44.327814: train_loss -0.9753 
2024-11-21 21:19:44.327939: val_loss -0.8951 
2024-11-21 21:19:44.327989: Pseudo dice [np.float32(0.9107)] 
2024-11-21 21:19:44.328041: Epoch time: 52.36 s 
2024-11-21 21:19:45.335516:  
2024-11-21 21:19:45.335683: Epoch 647 
2024-11-21 21:19:45.335763: Current learning rate: 0.00392 
2024-11-21 21:20:37.800163: train_loss -0.9754 
2024-11-21 21:20:37.800276: val_loss -0.8963 
2024-11-21 21:20:37.800322: Pseudo dice [np.float32(0.9125)] 
2024-11-21 21:20:37.800375: Epoch time: 52.47 s 
2024-11-21 21:20:38.712911:  
2024-11-21 21:20:38.713065: Epoch 648 
2024-11-21 21:20:38.713139: Current learning rate: 0.00391 
2024-11-21 21:21:31.022055: train_loss -0.9742 
2024-11-21 21:21:31.022169: val_loss -0.902 
2024-11-21 21:21:31.022218: Pseudo dice [np.float32(0.9142)] 
2024-11-21 21:21:31.022270: Epoch time: 52.31 s 
2024-11-21 21:21:32.330209:  
2024-11-21 21:21:32.330365: Epoch 649 
2024-11-21 21:21:32.330432: Current learning rate: 0.0039 
2024-11-21 21:22:24.832073: train_loss -0.9737 
2024-11-21 21:22:24.832219: val_loss -0.9053 
2024-11-21 21:22:24.832275: Pseudo dice [np.float32(0.9181)] 
2024-11-21 21:22:24.832331: Epoch time: 52.5 s 
2024-11-21 21:22:26.231339:  
2024-11-21 21:22:26.231605: Epoch 650 
2024-11-21 21:22:26.231675: Current learning rate: 0.00389 
2024-11-21 21:23:18.580842: train_loss -0.974 
2024-11-21 21:23:18.580990: val_loss -0.8983 
2024-11-21 21:23:18.581106: Pseudo dice [np.float32(0.9134)] 
2024-11-21 21:23:18.581363: Epoch time: 52.35 s 
2024-11-21 21:23:19.589242:  
2024-11-21 21:23:19.589429: Epoch 651 
2024-11-21 21:23:19.589522: Current learning rate: 0.00388 
2024-11-21 21:24:12.242430: train_loss -0.9752 
2024-11-21 21:24:12.242625: val_loss -0.9004 
2024-11-21 21:24:12.242672: Pseudo dice [np.float32(0.9151)] 
2024-11-21 21:24:12.242723: Epoch time: 52.65 s 
2024-11-21 21:24:13.289951:  
2024-11-21 21:24:13.290383: Epoch 652 
2024-11-21 21:24:13.290483: Current learning rate: 0.00387 
2024-11-21 21:25:05.703186: train_loss -0.9751 
2024-11-21 21:25:05.703305: val_loss -0.901 
2024-11-21 21:25:05.703356: Pseudo dice [np.float32(0.9167)] 
2024-11-21 21:25:05.703410: Epoch time: 52.41 s 
2024-11-21 21:25:05.703454: Yayy! New best EMA pseudo Dice: 0.9136999845504761 
2024-11-21 21:25:07.150449:  
2024-11-21 21:25:07.150637: Epoch 653 
2024-11-21 21:25:07.150724: Current learning rate: 0.00386 
2024-11-21 21:25:59.491537: train_loss -0.9752 
2024-11-21 21:25:59.491657: val_loss -0.9002 
2024-11-21 21:25:59.491703: Pseudo dice [np.float32(0.9157)] 
2024-11-21 21:25:59.491753: Epoch time: 52.34 s 
2024-11-21 21:25:59.491794: Yayy! New best EMA pseudo Dice: 0.9139000177383423 
2024-11-21 21:26:00.721388:  
2024-11-21 21:26:00.721560: Epoch 654 
2024-11-21 21:26:00.721627: Current learning rate: 0.00385 
2024-11-21 21:26:53.265090: train_loss -0.9746 
2024-11-21 21:26:53.265203: val_loss -0.8973 
2024-11-21 21:26:53.265272: Pseudo dice [np.float32(0.9125)] 
2024-11-21 21:26:53.265352: Epoch time: 52.54 s 
2024-11-21 21:26:54.150333:  
2024-11-21 21:26:54.150472: Epoch 655 
2024-11-21 21:26:54.150541: Current learning rate: 0.00384 
2024-11-21 21:27:46.716691: train_loss -0.9758 
2024-11-21 21:27:46.716837: val_loss -0.9039 
2024-11-21 21:27:46.716888: Pseudo dice [np.float32(0.9183)] 
2024-11-21 21:27:46.716943: Epoch time: 52.57 s 
2024-11-21 21:27:46.716990: Yayy! New best EMA pseudo Dice: 0.9142000079154968 
2024-11-21 21:27:48.035269:  
2024-11-21 21:27:48.035408: Epoch 656 
2024-11-21 21:27:48.035518: Current learning rate: 0.00383 
2024-11-21 21:28:40.151946: train_loss -0.9752 
2024-11-21 21:28:40.152154: val_loss -0.8983 
2024-11-21 21:28:40.152208: Pseudo dice [np.float32(0.9121)] 
2024-11-21 21:28:40.152261: Epoch time: 52.12 s 
2024-11-21 21:28:41.176311:  
2024-11-21 21:28:41.176456: Epoch 657 
2024-11-21 21:28:41.176585: Current learning rate: 0.00382 
2024-11-21 21:29:33.110013: train_loss -0.9749 
2024-11-21 21:29:33.110147: val_loss -0.8935 
2024-11-21 21:29:33.110227: Pseudo dice [np.float32(0.9088)] 
2024-11-21 21:29:33.110281: Epoch time: 51.93 s 
2024-11-21 21:29:34.241047:  
2024-11-21 21:29:34.241223: Epoch 658 
2024-11-21 21:29:34.241337: Current learning rate: 0.00381 
2024-11-21 21:30:26.196169: train_loss -0.9761 
2024-11-21 21:30:26.196361: val_loss -0.8988 
2024-11-21 21:30:26.196412: Pseudo dice [np.float32(0.9133)] 
2024-11-21 21:30:26.196468: Epoch time: 51.96 s 
2024-11-21 21:30:27.225157:  
2024-11-21 21:30:27.225295: Epoch 659 
2024-11-21 21:30:27.225363: Current learning rate: 0.0038 
2024-11-21 21:31:19.462633: train_loss -0.976 
2024-11-21 21:31:19.462770: val_loss -0.8991 
2024-11-21 21:31:19.462822: Pseudo dice [np.float32(0.9141)] 
2024-11-21 21:31:19.462878: Epoch time: 52.24 s 
2024-11-21 21:31:20.735368:  
2024-11-21 21:31:20.735540: Epoch 660 
2024-11-21 21:31:20.735666: Current learning rate: 0.00379 
2024-11-21 21:32:12.894261: train_loss -0.9761 
2024-11-21 21:32:12.894401: val_loss -0.9021 
2024-11-21 21:32:12.894457: Pseudo dice [np.float32(0.9169)] 
2024-11-21 21:32:12.894559: Epoch time: 52.16 s 
2024-11-21 21:32:13.911478:  
2024-11-21 21:32:13.911642: Epoch 661 
2024-11-21 21:32:13.911713: Current learning rate: 0.00378 
2024-11-21 21:33:06.128456: train_loss -0.9758 
2024-11-21 21:33:06.128594: val_loss -0.8964 
2024-11-21 21:33:06.128656: Pseudo dice [np.float32(0.9115)] 
2024-11-21 21:33:06.128724: Epoch time: 52.22 s 
2024-11-21 21:33:07.164648:  
2024-11-21 21:33:07.164835: Epoch 662 
2024-11-21 21:33:07.164918: Current learning rate: 0.00377 
2024-11-21 21:33:59.265338: train_loss -0.975 
2024-11-21 21:33:59.265495: val_loss -0.8975 
2024-11-21 21:33:59.265562: Pseudo dice [np.float32(0.9116)] 
2024-11-21 21:33:59.265632: Epoch time: 52.1 s 
2024-11-21 21:34:00.287253:  
2024-11-21 21:34:00.287422: Epoch 663 
2024-11-21 21:34:00.287518: Current learning rate: 0.00376 
2024-11-21 21:34:52.460740: train_loss -0.9758 
2024-11-21 21:34:52.460856: val_loss -0.8995 
2024-11-21 21:34:52.460908: Pseudo dice [np.float32(0.9135)] 
2024-11-21 21:34:52.460964: Epoch time: 52.17 s 
2024-11-21 21:34:53.598508:  
2024-11-21 21:34:53.598700: Epoch 664 
2024-11-21 21:34:53.598787: Current learning rate: 0.00375 
2024-11-21 21:35:46.044683: train_loss -0.9755 
2024-11-21 21:35:46.044803: val_loss -0.8948 
2024-11-21 21:35:46.044855: Pseudo dice [np.float32(0.9108)] 
2024-11-21 21:35:46.044909: Epoch time: 52.45 s 
2024-11-21 21:35:47.050163:  
2024-11-21 21:35:47.050333: Epoch 665 
2024-11-21 21:35:47.050402: Current learning rate: 0.00374 
2024-11-21 21:36:39.595014: train_loss -0.9744 
2024-11-21 21:36:39.595139: val_loss -0.8956 
2024-11-21 21:36:39.595188: Pseudo dice [np.float32(0.9095)] 
2024-11-21 21:36:39.595240: Epoch time: 52.55 s 
2024-11-21 21:36:40.559731:  
2024-11-21 21:36:40.559879: Epoch 666 
2024-11-21 21:36:40.559971: Current learning rate: 0.00373 
2024-11-21 21:37:32.662552: train_loss -0.9749 
2024-11-21 21:37:32.662682: val_loss -0.8967 
2024-11-21 21:37:32.662744: Pseudo dice [np.float32(0.912)] 
2024-11-21 21:37:32.662811: Epoch time: 52.1 s 
2024-11-21 21:37:33.594002:  
2024-11-21 21:37:33.594146: Epoch 667 
2024-11-21 21:37:33.594213: Current learning rate: 0.00372 
2024-11-21 21:38:25.683633: train_loss -0.9758 
2024-11-21 21:38:25.683776: val_loss -0.8949 
2024-11-21 21:38:25.683849: Pseudo dice [np.float32(0.9108)] 
2024-11-21 21:38:25.683902: Epoch time: 52.09 s 
2024-11-21 21:38:26.815553:  
2024-11-21 21:38:26.815731: Epoch 668 
2024-11-21 21:38:26.815814: Current learning rate: 0.00371 
2024-11-21 21:39:19.094356: train_loss -0.9759 
2024-11-21 21:39:19.094491: val_loss -0.9025 
2024-11-21 21:39:19.094540: Pseudo dice [np.float32(0.9166)] 
2024-11-21 21:39:19.094590: Epoch time: 52.28 s 
2024-11-21 21:39:20.002215:  
2024-11-21 21:39:20.002352: Epoch 669 
2024-11-21 21:39:20.002429: Current learning rate: 0.0037 
2024-11-21 21:40:11.844916: train_loss -0.9753 
2024-11-21 21:40:11.845056: val_loss -0.8974 
2024-11-21 21:40:11.845162: Pseudo dice [np.float32(0.9134)] 
2024-11-21 21:40:11.845216: Epoch time: 51.84 s 
2024-11-21 21:40:12.844347:  
2024-11-21 21:40:12.844574: Epoch 670 
2024-11-21 21:40:12.844645: Current learning rate: 0.00369 
2024-11-21 21:41:05.070768: train_loss -0.9757 
2024-11-21 21:41:05.070889: val_loss -0.8944 
2024-11-21 21:41:05.070941: Pseudo dice [np.float32(0.9093)] 
2024-11-21 21:41:05.070996: Epoch time: 52.23 s 
2024-11-21 21:41:06.052405:  
2024-11-21 21:41:06.052619: Epoch 671 
2024-11-21 21:41:06.052689: Current learning rate: 0.00368 
2024-11-21 21:41:58.624021: train_loss -0.9746 
2024-11-21 21:41:58.624179: val_loss -0.9008 
2024-11-21 21:41:58.624242: Pseudo dice [np.float32(0.9157)] 
2024-11-21 21:41:58.624308: Epoch time: 52.57 s 
2024-11-21 21:41:59.592245:  
2024-11-21 21:41:59.592441: Epoch 672 
2024-11-21 21:41:59.592554: Current learning rate: 0.00367 
2024-11-21 21:42:52.134841: train_loss -0.9753 
2024-11-21 21:42:52.135027: val_loss -0.8982 
2024-11-21 21:42:52.135094: Pseudo dice [np.float32(0.9119)] 
2024-11-21 21:42:52.135189: Epoch time: 52.54 s 
2024-11-21 21:42:53.186631:  
2024-11-21 21:42:53.186827: Epoch 673 
2024-11-21 21:42:53.186913: Current learning rate: 0.00366 
2024-11-21 21:43:45.722157: train_loss -0.9759 
2024-11-21 21:43:45.722299: val_loss -0.8993 
2024-11-21 21:43:45.722353: Pseudo dice [np.float32(0.9143)] 
2024-11-21 21:43:45.722408: Epoch time: 52.54 s 
2024-11-21 21:43:46.724354:  
2024-11-21 21:43:46.724538: Epoch 674 
2024-11-21 21:43:46.724627: Current learning rate: 0.00365 
2024-11-21 21:44:39.351357: train_loss -0.9756 
2024-11-21 21:44:39.351494: val_loss -0.8996 
2024-11-21 21:44:39.351549: Pseudo dice [np.float32(0.9125)] 
2024-11-21 21:44:39.351605: Epoch time: 52.63 s 
2024-11-21 21:44:40.309678:  
2024-11-21 21:44:40.309866: Epoch 675 
2024-11-21 21:44:40.309938: Current learning rate: 0.00364 
2024-11-21 21:45:32.518730: train_loss -0.9757 
2024-11-21 21:45:32.518862: val_loss -0.899 
2024-11-21 21:45:32.518965: Pseudo dice [np.float32(0.9132)] 
2024-11-21 21:45:32.519055: Epoch time: 52.21 s 
2024-11-21 21:45:33.561033:  
2024-11-21 21:45:33.561202: Epoch 676 
2024-11-21 21:45:33.561300: Current learning rate: 0.00363 
2024-11-21 21:46:25.648914: train_loss -0.9749 
2024-11-21 21:46:25.649029: val_loss -0.9023 
2024-11-21 21:46:25.649086: Pseudo dice [np.float32(0.916)] 
2024-11-21 21:46:25.649157: Epoch time: 52.09 s 
2024-11-21 21:46:26.692265:  
2024-11-21 21:46:26.692439: Epoch 677 
2024-11-21 21:46:26.692554: Current learning rate: 0.00362 
2024-11-21 21:47:19.265388: train_loss -0.9758 
2024-11-21 21:47:19.265527: val_loss -0.8983 
2024-11-21 21:47:19.265593: Pseudo dice [np.float32(0.9125)] 
2024-11-21 21:47:19.265664: Epoch time: 52.57 s 
2024-11-21 21:47:20.359347:  
2024-11-21 21:47:20.359588: Epoch 678 
2024-11-21 21:47:20.359674: Current learning rate: 0.00361 
2024-11-21 21:48:12.701169: train_loss -0.9755 
2024-11-21 21:48:12.701301: val_loss -0.9017 
2024-11-21 21:48:12.701355: Pseudo dice [np.float32(0.915)] 
2024-11-21 21:48:12.701410: Epoch time: 52.34 s 
2024-11-21 21:48:13.733436:  
2024-11-21 21:48:13.733632: Epoch 679 
2024-11-21 21:48:13.733765: Current learning rate: 0.0036 
2024-11-21 21:49:06.097421: train_loss -0.9756 
2024-11-21 21:49:06.097619: val_loss -0.8948 
2024-11-21 21:49:06.097669: Pseudo dice [np.float32(0.9096)] 
2024-11-21 21:49:06.097731: Epoch time: 52.37 s 
2024-11-21 21:49:07.104668:  
2024-11-21 21:49:07.104810: Epoch 680 
2024-11-21 21:49:07.104938: Current learning rate: 0.00359 
2024-11-21 21:49:59.521290: train_loss -0.9759 
2024-11-21 21:49:59.521396: val_loss -0.8959 
2024-11-21 21:49:59.521445: Pseudo dice [np.float32(0.9124)] 
2024-11-21 21:49:59.521544: Epoch time: 52.42 s 
2024-11-21 21:50:00.609427:  
2024-11-21 21:50:00.609632: Epoch 681 
2024-11-21 21:50:00.609736: Current learning rate: 0.00358 
2024-11-21 21:50:53.089951: train_loss -0.9763 
2024-11-21 21:50:53.090063: val_loss -0.8917 
2024-11-21 21:50:53.090163: Pseudo dice [np.float32(0.9067)] 
2024-11-21 21:50:53.090229: Epoch time: 52.48 s 
2024-11-21 21:50:54.101322:  
2024-11-21 21:50:54.101507: Epoch 682 
2024-11-21 21:50:54.101593: Current learning rate: 0.00357 
2024-11-21 21:51:46.541763: train_loss -0.9759 
2024-11-21 21:51:46.541888: val_loss -0.8966 
2024-11-21 21:51:46.541942: Pseudo dice [np.float32(0.9105)] 
2024-11-21 21:51:46.541999: Epoch time: 52.44 s 
2024-11-21 21:51:47.818281:  
2024-11-21 21:51:47.818463: Epoch 683 
2024-11-21 21:51:47.818565: Current learning rate: 0.00356 
2024-11-21 21:52:40.072279: train_loss -0.9755 
2024-11-21 21:52:40.072423: val_loss -0.896 
2024-11-21 21:52:40.072494: Pseudo dice [np.float32(0.9119)] 
2024-11-21 21:52:40.072565: Epoch time: 52.26 s 
2024-11-21 21:52:41.033525:  
2024-11-21 21:52:41.033708: Epoch 684 
2024-11-21 21:52:41.033774: Current learning rate: 0.00355 
2024-11-21 21:53:33.754307: train_loss -0.9761 
2024-11-21 21:53:33.754422: val_loss -0.8936 
2024-11-21 21:53:33.754501: Pseudo dice [np.float32(0.9096)] 
2024-11-21 21:53:33.754603: Epoch time: 52.72 s 
2024-11-21 21:53:34.766302:  
2024-11-21 21:53:34.766476: Epoch 685 
2024-11-21 21:53:34.766575: Current learning rate: 0.00354 
2024-11-21 21:54:27.310517: train_loss -0.9756 
2024-11-21 21:54:27.310648: val_loss -0.9001 
2024-11-21 21:54:27.310712: Pseudo dice [np.float32(0.9134)] 
2024-11-21 21:54:27.310781: Epoch time: 52.55 s 
2024-11-21 21:54:28.257693:  
2024-11-21 21:54:28.258127: Epoch 686 
2024-11-21 21:54:28.258213: Current learning rate: 0.00353 
2024-11-21 21:55:20.936311: train_loss -0.9746 
2024-11-21 21:55:20.936428: val_loss -0.9057 
2024-11-21 21:55:20.936506: Pseudo dice [np.float32(0.9199)] 
2024-11-21 21:55:20.936583: Epoch time: 52.68 s 
2024-11-21 21:55:21.918154:  
2024-11-21 21:55:21.918374: Epoch 687 
2024-11-21 21:55:21.918472: Current learning rate: 0.00352 
2024-11-21 21:56:14.620234: train_loss -0.9754 
2024-11-21 21:56:14.620348: val_loss -0.8982 
2024-11-21 21:56:14.620396: Pseudo dice [np.float32(0.9128)] 
2024-11-21 21:56:14.620447: Epoch time: 52.7 s 
2024-11-21 21:56:15.550912:  
2024-11-21 21:56:15.551061: Epoch 688 
2024-11-21 21:56:15.551128: Current learning rate: 0.00351 
2024-11-21 21:57:08.132697: train_loss -0.9756 
2024-11-21 21:57:08.132854: val_loss -0.895 
2024-11-21 21:57:08.132905: Pseudo dice [np.float32(0.9089)] 
2024-11-21 21:57:08.132960: Epoch time: 52.58 s 
2024-11-21 21:57:09.177803:  
2024-11-21 21:57:09.177935: Epoch 689 
2024-11-21 21:57:09.178009: Current learning rate: 0.0035 
2024-11-21 21:58:01.503081: train_loss -0.9759 
2024-11-21 21:58:01.503214: val_loss -0.8928 
2024-11-21 21:58:01.503276: Pseudo dice [np.float32(0.9075)] 
2024-11-21 21:58:01.503342: Epoch time: 52.33 s 
2024-11-21 21:58:02.458168:  
2024-11-21 21:58:02.458316: Epoch 690 
2024-11-21 21:58:02.458423: Current learning rate: 0.00349 
2024-11-21 21:58:55.106417: train_loss -0.9748 
2024-11-21 21:58:55.106590: val_loss -0.8984 
2024-11-21 21:58:55.106655: Pseudo dice [np.float32(0.9117)] 
2024-11-21 21:58:55.106723: Epoch time: 52.65 s 
2024-11-21 21:58:56.094361:  
2024-11-21 21:58:56.094526: Epoch 691 
2024-11-21 21:58:56.094608: Current learning rate: 0.00348 
2024-11-21 21:59:48.582908: train_loss -0.9751 
2024-11-21 21:59:48.583066: val_loss -0.8972 
2024-11-21 21:59:48.583130: Pseudo dice [np.float32(0.9129)] 
2024-11-21 21:59:48.583198: Epoch time: 52.49 s 
2024-11-21 21:59:49.587764:  
2024-11-21 21:59:49.587899: Epoch 692 
2024-11-21 21:59:49.587964: Current learning rate: 0.00346 
2024-11-21 22:00:41.777730: train_loss -0.975 
2024-11-21 22:00:41.777866: val_loss -0.9003 
2024-11-21 22:00:41.777955: Pseudo dice [np.float32(0.915)] 
2024-11-21 22:00:41.778045: Epoch time: 52.19 s 
2024-11-21 22:00:42.791108:  
2024-11-21 22:00:42.791311: Epoch 693 
2024-11-21 22:00:42.791422: Current learning rate: 0.00345 
2024-11-21 22:01:34.572016: train_loss -0.9752 
2024-11-21 22:01:34.572152: val_loss -0.8975 
2024-11-21 22:01:34.572239: Pseudo dice [np.float32(0.9111)] 
2024-11-21 22:01:34.572306: Epoch time: 51.78 s 
2024-11-21 22:01:35.949370:  
2024-11-21 22:01:35.949619: Epoch 694 
2024-11-21 22:01:35.949704: Current learning rate: 0.00344 
2024-11-21 22:02:28.222026: train_loss -0.9759 
2024-11-21 22:02:28.222144: val_loss -0.8983 
2024-11-21 22:02:28.222195: Pseudo dice [np.float32(0.9125)] 
2024-11-21 22:02:28.222271: Epoch time: 52.27 s 
2024-11-21 22:02:29.267637:  
2024-11-21 22:02:29.267852: Epoch 695 
2024-11-21 22:02:29.267937: Current learning rate: 0.00343 
2024-11-21 22:03:21.544522: train_loss -0.9748 
2024-11-21 22:03:21.544657: val_loss -0.9032 
2024-11-21 22:03:21.544722: Pseudo dice [np.float32(0.9167)] 
2024-11-21 22:03:21.544834: Epoch time: 52.28 s 
2024-11-21 22:03:22.545953:  
2024-11-21 22:03:22.546141: Epoch 696 
2024-11-21 22:03:22.546227: Current learning rate: 0.00342 
2024-11-21 22:04:14.884267: train_loss -0.9764 
2024-11-21 22:04:14.884402: val_loss -0.9007 
2024-11-21 22:04:14.884450: Pseudo dice [np.float32(0.9144)] 
2024-11-21 22:04:14.884592: Epoch time: 52.34 s 
2024-11-21 22:04:15.873966:  
2024-11-21 22:04:15.874133: Epoch 697 
2024-11-21 22:04:15.874200: Current learning rate: 0.00341 
2024-11-21 22:05:08.074854: train_loss -0.9752 
2024-11-21 22:05:08.074985: val_loss -0.8969 
2024-11-21 22:05:08.075047: Pseudo dice [np.float32(0.9128)] 
2024-11-21 22:05:08.075116: Epoch time: 52.2 s 
2024-11-21 22:05:09.139289:  
2024-11-21 22:05:09.139476: Epoch 698 
2024-11-21 22:05:09.139563: Current learning rate: 0.0034 
2024-11-21 22:06:01.318566: train_loss -0.976 
2024-11-21 22:06:01.318767: val_loss -0.8948 
2024-11-21 22:06:01.318835: Pseudo dice [np.float32(0.9097)] 
2024-11-21 22:06:01.318970: Epoch time: 52.18 s 
2024-11-21 22:06:02.260487:  
2024-11-21 22:06:02.260677: Epoch 699 
2024-11-21 22:06:02.260786: Current learning rate: 0.00339 
2024-11-21 22:06:54.513283: train_loss -0.9762 
2024-11-21 22:06:54.513428: val_loss -0.9007 
2024-11-21 22:06:54.513481: Pseudo dice [np.float32(0.915)] 
2024-11-21 22:06:54.513551: Epoch time: 52.25 s 
2024-11-21 22:06:55.964952:  
2024-11-21 22:06:55.965146: Epoch 700 
2024-11-21 22:06:55.965228: Current learning rate: 0.00338 
2024-11-21 22:07:48.276867: train_loss -0.9752 
2024-11-21 22:07:48.277012: val_loss -0.8918 
2024-11-21 22:07:48.277077: Pseudo dice [np.float32(0.9065)] 
2024-11-21 22:07:48.277145: Epoch time: 52.31 s 
2024-11-21 22:07:49.359649:  
2024-11-21 22:07:49.359785: Epoch 701 
2024-11-21 22:07:49.359853: Current learning rate: 0.00337 
2024-11-21 22:08:41.803807: train_loss -0.9761 
2024-11-21 22:08:41.803936: val_loss -0.9026 
2024-11-21 22:08:41.803986: Pseudo dice [np.float32(0.916)] 
2024-11-21 22:08:41.804040: Epoch time: 52.44 s 
2024-11-21 22:08:42.789373:  
2024-11-21 22:08:42.789550: Epoch 702 
2024-11-21 22:08:42.789637: Current learning rate: 0.00336 
2024-11-21 22:09:35.002280: train_loss -0.9762 
2024-11-21 22:09:35.002405: val_loss -0.9018 
2024-11-21 22:09:35.002454: Pseudo dice [np.float32(0.9148)] 
2024-11-21 22:09:35.002551: Epoch time: 52.21 s 
2024-11-21 22:09:36.005245:  
2024-11-21 22:09:36.005390: Epoch 703 
2024-11-21 22:09:36.005459: Current learning rate: 0.00335 
2024-11-21 22:10:28.589958: train_loss -0.9756 
2024-11-21 22:10:28.590073: val_loss -0.8962 
2024-11-21 22:10:28.590156: Pseudo dice [np.float32(0.9116)] 
2024-11-21 22:10:28.590211: Epoch time: 52.59 s 
2024-11-21 22:10:29.521159:  
2024-11-21 22:10:29.521332: Epoch 704 
2024-11-21 22:10:29.521414: Current learning rate: 0.00334 
2024-11-21 22:11:21.824688: train_loss -0.9761 
2024-11-21 22:11:21.824846: val_loss -0.9018 
2024-11-21 22:11:21.824911: Pseudo dice [np.float32(0.9165)] 
2024-11-21 22:11:21.824980: Epoch time: 52.3 s 
2024-11-21 22:11:23.140782:  
2024-11-21 22:11:23.141002: Epoch 705 
2024-11-21 22:11:23.141107: Current learning rate: 0.00333 
2024-11-21 22:12:15.436865: train_loss -0.9758 
2024-11-21 22:12:15.436981: val_loss -0.8839 
2024-11-21 22:12:15.437029: Pseudo dice [np.float32(0.9001)] 
2024-11-21 22:12:15.437081: Epoch time: 52.3 s 
2024-11-21 22:12:16.504277:  
2024-11-21 22:12:16.504441: Epoch 706 
2024-11-21 22:12:16.504528: Current learning rate: 0.00332 
2024-11-21 22:13:08.924779: train_loss -0.9738 
2024-11-21 22:13:08.924960: val_loss -0.898 
2024-11-21 22:13:08.925010: Pseudo dice [np.float32(0.9129)] 
2024-11-21 22:13:08.925064: Epoch time: 52.42 s 
2024-11-21 22:13:09.958517:  
2024-11-21 22:13:09.958697: Epoch 707 
2024-11-21 22:13:09.958765: Current learning rate: 0.00331 
2024-11-21 22:14:02.189357: train_loss -0.9721 
2024-11-21 22:14:02.189479: val_loss -0.8977 
2024-11-21 22:14:02.189532: Pseudo dice [np.float32(0.9136)] 
2024-11-21 22:14:02.189584: Epoch time: 52.23 s 
2024-11-21 22:14:03.209694:  
2024-11-21 22:14:03.209907: Epoch 708 
2024-11-21 22:14:03.209975: Current learning rate: 0.0033 
2024-11-21 22:14:55.683800: train_loss -0.9742 
2024-11-21 22:14:55.683932: val_loss -0.8958 
2024-11-21 22:14:55.683985: Pseudo dice [np.float32(0.9105)] 
2024-11-21 22:14:55.684045: Epoch time: 52.47 s 
2024-11-21 22:14:56.697834:  
2024-11-21 22:14:56.698069: Epoch 709 
2024-11-21 22:14:56.698278: Current learning rate: 0.00329 
2024-11-21 22:15:49.104617: train_loss -0.9745 
2024-11-21 22:15:49.104729: val_loss -0.9001 
2024-11-21 22:15:49.104779: Pseudo dice [np.float32(0.914)] 
2024-11-21 22:15:49.104832: Epoch time: 52.41 s 
2024-11-21 22:15:50.102238:  
2024-11-21 22:15:50.102496: Epoch 710 
2024-11-21 22:15:50.102594: Current learning rate: 0.00328 
2024-11-21 22:16:42.531822: train_loss -0.9753 
2024-11-21 22:16:42.531947: val_loss -0.8954 
2024-11-21 22:16:42.531997: Pseudo dice [np.float32(0.9105)] 
2024-11-21 22:16:42.532054: Epoch time: 52.43 s 
2024-11-21 22:16:43.609587:  
2024-11-21 22:16:43.609769: Epoch 711 
2024-11-21 22:16:43.609855: Current learning rate: 0.00327 
2024-11-21 22:17:36.009591: train_loss -0.9758 
2024-11-21 22:17:36.009707: val_loss -0.8938 
2024-11-21 22:17:36.009779: Pseudo dice [np.float32(0.9088)] 
2024-11-21 22:17:36.009832: Epoch time: 52.4 s 
2024-11-21 22:17:37.064282:  
2024-11-21 22:17:37.064467: Epoch 712 
2024-11-21 22:17:37.064554: Current learning rate: 0.00326 
2024-11-21 22:18:29.452818: train_loss -0.9747 
2024-11-21 22:18:29.452937: val_loss -0.9008 
2024-11-21 22:18:29.452990: Pseudo dice [np.float32(0.9142)] 
2024-11-21 22:18:29.453046: Epoch time: 52.39 s 
2024-11-21 22:18:30.476383:  
2024-11-21 22:18:30.476553: Epoch 713 
2024-11-21 22:18:30.476636: Current learning rate: 0.00325 
2024-11-21 22:19:22.940553: train_loss -0.9753 
2024-11-21 22:19:22.940659: val_loss -0.9031 
2024-11-21 22:19:22.940729: Pseudo dice [np.float32(0.9177)] 
2024-11-21 22:19:22.940781: Epoch time: 52.47 s 
2024-11-21 22:19:23.897822:  
2024-11-21 22:19:23.897957: Epoch 714 
2024-11-21 22:19:23.898025: Current learning rate: 0.00324 
2024-11-21 22:20:16.765085: train_loss -0.9751 
2024-11-21 22:20:16.765214: val_loss -0.8997 
2024-11-21 22:20:16.765263: Pseudo dice [np.float32(0.9163)] 
2024-11-21 22:20:16.765316: Epoch time: 52.87 s 
2024-11-21 22:20:17.716098:  
2024-11-21 22:20:17.716238: Epoch 715 
2024-11-21 22:20:17.716311: Current learning rate: 0.00323 
2024-11-21 22:21:10.245512: train_loss -0.9744 
2024-11-21 22:21:10.245648: val_loss -0.8963 
2024-11-21 22:21:10.245697: Pseudo dice [np.float32(0.9124)] 
2024-11-21 22:21:10.245749: Epoch time: 52.53 s 
2024-11-21 22:21:11.343276:  
2024-11-21 22:21:11.343410: Epoch 716 
2024-11-21 22:21:11.343518: Current learning rate: 0.00322 
2024-11-21 22:22:03.667957: train_loss -0.9749 
2024-11-21 22:22:03.668086: val_loss -0.8956 
2024-11-21 22:22:03.668176: Pseudo dice [np.float32(0.9101)] 
2024-11-21 22:22:03.668256: Epoch time: 52.33 s 
2024-11-21 22:22:04.890046:  
2024-11-21 22:22:04.890279: Epoch 717 
2024-11-21 22:22:04.890347: Current learning rate: 0.00321 
2024-11-21 22:22:57.139585: train_loss -0.9757 
2024-11-21 22:22:57.139776: val_loss -0.8983 
2024-11-21 22:22:57.139851: Pseudo dice [np.float32(0.9126)] 
2024-11-21 22:22:57.139919: Epoch time: 52.25 s 
2024-11-21 22:22:58.125298:  
2024-11-21 22:22:58.125414: Epoch 718 
2024-11-21 22:22:58.125516: Current learning rate: 0.0032 
2024-11-21 22:23:50.299103: train_loss -0.9759 
2024-11-21 22:23:50.299263: val_loss -0.8947 
2024-11-21 22:23:50.299465: Pseudo dice [np.float32(0.9079)] 
2024-11-21 22:23:50.299546: Epoch time: 52.17 s 
2024-11-21 22:23:51.372988:  
2024-11-21 22:23:51.373193: Epoch 719 
2024-11-21 22:23:51.373281: Current learning rate: 0.00319 
2024-11-21 22:24:43.650774: train_loss -0.9754 
2024-11-21 22:24:43.650909: val_loss -0.896 
2024-11-21 22:24:43.650957: Pseudo dice [np.float32(0.9118)] 
2024-11-21 22:24:43.651009: Epoch time: 52.28 s 
2024-11-21 22:24:44.635676:  
2024-11-21 22:24:44.635834: Epoch 720 
2024-11-21 22:24:44.635955: Current learning rate: 0.00318 
2024-11-21 22:25:36.878918: train_loss -0.9749 
2024-11-21 22:25:36.879050: val_loss -0.8932 
2024-11-21 22:25:36.879117: Pseudo dice [np.float32(0.9089)] 
2024-11-21 22:25:36.879172: Epoch time: 52.24 s 
2024-11-21 22:25:37.935668:  
2024-11-21 22:25:37.935850: Epoch 721 
2024-11-21 22:25:37.935934: Current learning rate: 0.00317 
2024-11-21 22:26:29.788859: train_loss -0.9756 
2024-11-21 22:26:29.788992: val_loss -0.893 
2024-11-21 22:26:29.789044: Pseudo dice [np.float32(0.9082)] 
2024-11-21 22:26:29.789099: Epoch time: 51.85 s 
2024-11-21 22:26:30.886566:  
2024-11-21 22:26:30.886881: Epoch 722 
2024-11-21 22:26:30.886969: Current learning rate: 0.00316 
2024-11-21 22:27:23.377313: train_loss -0.976 
2024-11-21 22:27:23.377464: val_loss -0.8969 
2024-11-21 22:27:23.377519: Pseudo dice [np.float32(0.9123)] 
2024-11-21 22:27:23.377573: Epoch time: 52.49 s 
2024-11-21 22:27:24.379927:  
2024-11-21 22:27:24.380068: Epoch 723 
2024-11-21 22:27:24.380135: Current learning rate: 0.00315 
2024-11-21 22:28:16.963341: train_loss -0.9766 
2024-11-21 22:28:16.963500: val_loss -0.8988 
2024-11-21 22:28:16.963569: Pseudo dice [np.float32(0.9158)] 
2024-11-21 22:28:16.963639: Epoch time: 52.58 s 
2024-11-21 22:28:18.034303:  
2024-11-21 22:28:18.034495: Epoch 724 
2024-11-21 22:28:18.034601: Current learning rate: 0.00314 
2024-11-21 22:29:10.455343: train_loss -0.9762 
2024-11-21 22:29:10.455463: val_loss -0.8979 
2024-11-21 22:29:10.455521: Pseudo dice [np.float32(0.9139)] 
2024-11-21 22:29:10.455575: Epoch time: 52.42 s 
2024-11-21 22:29:11.428221:  
2024-11-21 22:29:11.428396: Epoch 725 
2024-11-21 22:29:11.428543: Current learning rate: 0.00313 
2024-11-21 22:30:03.686513: train_loss -0.9772 
2024-11-21 22:30:03.686653: val_loss -0.894 
2024-11-21 22:30:03.686702: Pseudo dice [np.float32(0.9081)] 
2024-11-21 22:30:03.686754: Epoch time: 52.26 s 
2024-11-21 22:30:04.669181:  
2024-11-21 22:30:04.669323: Epoch 726 
2024-11-21 22:30:04.669388: Current learning rate: 0.00312 
2024-11-21 22:30:57.194793: train_loss -0.9764 
2024-11-21 22:30:57.194910: val_loss -0.8953 
2024-11-21 22:30:57.194958: Pseudo dice [np.float32(0.9099)] 
2024-11-21 22:30:57.195011: Epoch time: 52.53 s 
2024-11-21 22:30:58.151794:  
2024-11-21 22:30:58.151933: Epoch 727 
2024-11-21 22:30:58.152002: Current learning rate: 0.00311 
2024-11-21 22:31:50.263719: train_loss -0.9761 
2024-11-21 22:31:50.263848: val_loss -0.898 
2024-11-21 22:31:50.264739: Pseudo dice [np.float32(0.9127)] 
2024-11-21 22:31:50.264808: Epoch time: 52.11 s 
2024-11-21 22:31:51.571653:  
2024-11-21 22:31:51.571805: Epoch 728 
2024-11-21 22:31:51.571888: Current learning rate: 0.0031 
2024-11-21 22:32:44.236891: train_loss -0.9763 
2024-11-21 22:32:44.237061: val_loss -0.8918 
2024-11-21 22:32:44.237128: Pseudo dice [np.float32(0.9075)] 
2024-11-21 22:32:44.237198: Epoch time: 52.67 s 
2024-11-21 22:32:45.218223:  
2024-11-21 22:32:45.218381: Epoch 729 
2024-11-21 22:32:45.218449: Current learning rate: 0.00309 
2024-11-21 22:33:37.875007: train_loss -0.9763 
2024-11-21 22:33:37.875127: val_loss -0.8989 
2024-11-21 22:33:37.875179: Pseudo dice [np.float32(0.9131)] 
2024-11-21 22:33:37.875278: Epoch time: 52.66 s 
2024-11-21 22:33:38.910097:  
2024-11-21 22:33:38.910252: Epoch 730 
2024-11-21 22:33:38.910341: Current learning rate: 0.00308 
2024-11-21 22:34:31.659870: train_loss -0.976 
2024-11-21 22:34:31.660072: val_loss -0.8954 
2024-11-21 22:34:31.660123: Pseudo dice [np.float32(0.9106)] 
2024-11-21 22:34:31.660176: Epoch time: 52.75 s 
2024-11-21 22:34:32.759709:  
2024-11-21 22:34:32.759863: Epoch 731 
2024-11-21 22:34:32.759930: Current learning rate: 0.00307 
2024-11-21 22:35:25.112066: train_loss -0.9768 
2024-11-21 22:35:25.112210: val_loss -0.8971 
2024-11-21 22:35:25.112271: Pseudo dice [np.float32(0.9126)] 
2024-11-21 22:35:25.112337: Epoch time: 52.35 s 
2024-11-21 22:35:26.192506:  
2024-11-21 22:35:26.192695: Epoch 732 
2024-11-21 22:35:26.192777: Current learning rate: 0.00306 
2024-11-21 22:36:18.495914: train_loss -0.9763 
2024-11-21 22:36:18.496076: val_loss -0.8979 
2024-11-21 22:36:18.496161: Pseudo dice [np.float32(0.9127)] 
2024-11-21 22:36:18.496248: Epoch time: 52.3 s 
2024-11-21 22:36:19.478071:  
2024-11-21 22:36:19.478213: Epoch 733 
2024-11-21 22:36:19.478311: Current learning rate: 0.00305 
2024-11-21 22:37:11.946935: train_loss -0.9755 
2024-11-21 22:37:11.947056: val_loss -0.8971 
2024-11-21 22:37:11.947141: Pseudo dice [np.float32(0.9113)] 
2024-11-21 22:37:11.947196: Epoch time: 52.47 s 
2024-11-21 22:37:12.926412:  
2024-11-21 22:37:12.926703: Epoch 734 
2024-11-21 22:37:12.926806: Current learning rate: 0.00304 
2024-11-21 22:38:05.531845: train_loss -0.9763 
2024-11-21 22:38:05.531962: val_loss -0.8944 
2024-11-21 22:38:05.532010: Pseudo dice [np.float32(0.9089)] 
2024-11-21 22:38:05.532062: Epoch time: 52.61 s 
2024-11-21 22:38:06.528844:  
2024-11-21 22:38:06.528990: Epoch 735 
2024-11-21 22:38:06.529055: Current learning rate: 0.00303 
2024-11-21 22:38:58.782599: train_loss -0.9755 
2024-11-21 22:38:58.782704: val_loss -0.8968 
2024-11-21 22:38:58.782751: Pseudo dice [np.float32(0.9111)] 
2024-11-21 22:38:58.782802: Epoch time: 52.25 s 
2024-11-21 22:38:59.753924:  
2024-11-21 22:38:59.754167: Epoch 736 
2024-11-21 22:38:59.754272: Current learning rate: 0.00302 
2024-11-21 22:39:52.182861: train_loss -0.9753 
2024-11-21 22:39:52.182997: val_loss -0.889 
2024-11-21 22:39:52.183048: Pseudo dice [np.float32(0.9076)] 
2024-11-21 22:39:52.183103: Epoch time: 52.43 s 
2024-11-21 22:39:53.276326:  
2024-11-21 22:39:53.276493: Epoch 737 
2024-11-21 22:39:53.276580: Current learning rate: 0.00301 
2024-11-21 22:40:45.778699: train_loss -0.9736 
2024-11-21 22:40:45.778829: val_loss -0.8934 
2024-11-21 22:40:45.778878: Pseudo dice [np.float32(0.9113)] 
2024-11-21 22:40:45.778934: Epoch time: 52.5 s 
2024-11-21 22:40:46.711360:  
2024-11-21 22:40:46.711497: Epoch 738 
2024-11-21 22:40:46.711566: Current learning rate: 0.003 
2024-11-21 22:41:38.810951: train_loss -0.9749 
2024-11-21 22:41:38.811069: val_loss -0.9004 
2024-11-21 22:41:38.811131: Pseudo dice [np.float32(0.9149)] 
2024-11-21 22:41:38.811198: Epoch time: 52.1 s 
2024-11-21 22:41:40.156993:  
2024-11-21 22:41:40.157162: Epoch 739 
2024-11-21 22:41:40.157231: Current learning rate: 0.00299 
2024-11-21 22:42:32.541234: train_loss -0.9754 
2024-11-21 22:42:32.541368: val_loss -0.8994 
2024-11-21 22:42:32.541417: Pseudo dice [np.float32(0.9125)] 
2024-11-21 22:42:32.541468: Epoch time: 52.39 s 
2024-11-21 22:42:33.566712:  
2024-11-21 22:42:33.566866: Epoch 740 
2024-11-21 22:42:33.566973: Current learning rate: 0.00297 
2024-11-21 22:43:25.630010: train_loss -0.9762 
2024-11-21 22:43:25.630163: val_loss -0.9015 
2024-11-21 22:43:25.630229: Pseudo dice [np.float32(0.9153)] 
2024-11-21 22:43:25.630299: Epoch time: 52.06 s 
2024-11-21 22:43:26.615992:  
2024-11-21 22:43:26.616167: Epoch 741 
2024-11-21 22:43:26.616235: Current learning rate: 0.00296 
2024-11-21 22:44:19.291312: train_loss -0.9762 
2024-11-21 22:44:19.291426: val_loss -0.8991 
2024-11-21 22:44:19.291504: Pseudo dice [np.float32(0.9133)] 
2024-11-21 22:44:19.291603: Epoch time: 52.68 s 
2024-11-21 22:44:20.314022:  
2024-11-21 22:44:20.314174: Epoch 742 
2024-11-21 22:44:20.314248: Current learning rate: 0.00295 
2024-11-21 22:45:12.809050: train_loss -0.9767 
2024-11-21 22:45:12.809169: val_loss -0.9016 
2024-11-21 22:45:12.809221: Pseudo dice [np.float32(0.9163)] 
2024-11-21 22:45:12.809276: Epoch time: 52.5 s 
2024-11-21 22:45:13.851967:  
2024-11-21 22:45:13.852202: Epoch 743 
2024-11-21 22:45:13.852305: Current learning rate: 0.00294 
2024-11-21 22:46:06.393635: train_loss -0.977 
2024-11-21 22:46:06.393764: val_loss -0.8996 
2024-11-21 22:46:06.393826: Pseudo dice [np.float32(0.913)] 
2024-11-21 22:46:06.393894: Epoch time: 52.54 s 
2024-11-21 22:46:07.389461:  
2024-11-21 22:46:07.389600: Epoch 744 
2024-11-21 22:46:07.389670: Current learning rate: 0.00293 
2024-11-21 22:46:59.767191: train_loss -0.9765 
2024-11-21 22:46:59.767371: val_loss -0.899 
2024-11-21 22:46:59.768291: Pseudo dice [np.float32(0.9142)] 
2024-11-21 22:46:59.768344: Epoch time: 52.38 s 
2024-11-21 22:47:00.727010:  
2024-11-21 22:47:00.727146: Epoch 745 
2024-11-21 22:47:00.727212: Current learning rate: 0.00292 
2024-11-21 22:47:53.023465: train_loss -0.977 
2024-11-21 22:47:53.023628: val_loss -0.9044 
2024-11-21 22:47:53.023675: Pseudo dice [np.float32(0.9183)] 
2024-11-21 22:47:53.023741: Epoch time: 52.3 s 
2024-11-21 22:47:54.083272:  
2024-11-21 22:47:54.083447: Epoch 746 
2024-11-21 22:47:54.083537: Current learning rate: 0.00291 
2024-11-21 22:48:46.533136: train_loss -0.9767 
2024-11-21 22:48:46.533248: val_loss -0.8956 
2024-11-21 22:48:46.533297: Pseudo dice [np.float32(0.9107)] 
2024-11-21 22:48:46.533349: Epoch time: 52.45 s 
2024-11-21 22:48:47.508282:  
2024-11-21 22:48:47.508425: Epoch 747 
2024-11-21 22:48:47.508536: Current learning rate: 0.0029 
2024-11-21 22:49:39.844915: train_loss -0.976 
2024-11-21 22:49:39.845037: val_loss -0.9004 
2024-11-21 22:49:39.845089: Pseudo dice [np.float32(0.9158)] 
2024-11-21 22:49:39.845142: Epoch time: 52.34 s 
2024-11-21 22:49:40.852375:  
2024-11-21 22:49:40.852558: Epoch 748 
2024-11-21 22:49:40.852635: Current learning rate: 0.00289 
2024-11-21 22:50:33.290316: train_loss -0.9765 
2024-11-21 22:50:33.290455: val_loss -0.9013 
2024-11-21 22:50:33.290554: Pseudo dice [np.float32(0.9141)] 
2024-11-21 22:50:33.290610: Epoch time: 52.44 s 
2024-11-21 22:50:34.380796:  
2024-11-21 22:50:34.380974: Epoch 749 
2024-11-21 22:50:34.381062: Current learning rate: 0.00288 
2024-11-21 22:51:26.653421: train_loss -0.9761 
2024-11-21 22:51:26.653603: val_loss -0.896 
2024-11-21 22:51:26.653651: Pseudo dice [np.float32(0.9121)] 
2024-11-21 22:51:26.653704: Epoch time: 52.27 s 
2024-11-21 22:51:28.391867:  
2024-11-21 22:51:28.392026: Epoch 750 
2024-11-21 22:51:28.392097: Current learning rate: 0.00287 
2024-11-21 22:52:20.974997: train_loss -0.975 
2024-11-21 22:52:20.975112: val_loss -0.8987 
2024-11-21 22:52:20.975161: Pseudo dice [np.float32(0.9141)] 
2024-11-21 22:52:20.975212: Epoch time: 52.58 s 
2024-11-21 22:52:21.967205:  
2024-11-21 22:52:21.967365: Epoch 751 
2024-11-21 22:52:21.967431: Current learning rate: 0.00286 
2024-11-21 22:53:14.444988: train_loss -0.9748 
2024-11-21 22:53:14.445120: val_loss -0.8982 
2024-11-21 22:53:14.445264: Pseudo dice [np.float32(0.9132)] 
2024-11-21 22:53:14.445316: Epoch time: 52.48 s 
2024-11-21 22:53:15.424046:  
2024-11-21 22:53:15.424192: Epoch 752 
2024-11-21 22:53:15.424299: Current learning rate: 0.00285 
2024-11-21 22:54:07.820251: train_loss -0.9762 
2024-11-21 22:54:07.820364: val_loss -0.904 
2024-11-21 22:54:07.820413: Pseudo dice [np.float32(0.918)] 
2024-11-21 22:54:07.820464: Epoch time: 52.4 s 
2024-11-21 22:54:08.829521:  
2024-11-21 22:54:08.829716: Epoch 753 
2024-11-21 22:54:08.829800: Current learning rate: 0.00284 
2024-11-21 22:55:00.958118: train_loss -0.9758 
2024-11-21 22:55:00.958269: val_loss -0.8999 
2024-11-21 22:55:00.958341: Pseudo dice [np.float32(0.913)] 
2024-11-21 22:55:00.958415: Epoch time: 52.13 s 
2024-11-21 22:55:01.981860:  
2024-11-21 22:55:01.982003: Epoch 754 
2024-11-21 22:55:01.982118: Current learning rate: 0.00283 
2024-11-21 22:55:54.187364: train_loss -0.9754 
2024-11-21 22:55:54.187552: val_loss -0.8987 
2024-11-21 22:55:54.187619: Pseudo dice [np.float32(0.9142)] 
2024-11-21 22:55:54.187696: Epoch time: 52.21 s 
2024-11-21 22:55:55.236290:  
2024-11-21 22:55:55.236436: Epoch 755 
2024-11-21 22:55:55.236544: Current learning rate: 0.00282 
2024-11-21 22:56:47.841675: train_loss -0.9765 
2024-11-21 22:56:47.841803: val_loss -0.8972 
2024-11-21 22:56:47.841865: Pseudo dice [np.float32(0.911)] 
2024-11-21 22:56:47.841933: Epoch time: 52.61 s 
2024-11-21 22:56:48.842343:  
2024-11-21 22:56:48.842537: Epoch 756 
2024-11-21 22:56:48.842606: Current learning rate: 0.00281 
2024-11-21 22:57:40.934285: train_loss -0.9765 
2024-11-21 22:57:40.934417: val_loss -0.9007 
2024-11-21 22:57:40.934489: Pseudo dice [np.float32(0.9168)] 
2024-11-21 22:57:40.934561: Epoch time: 52.09 s 
2024-11-21 22:57:41.954174:  
2024-11-21 22:57:41.954309: Epoch 757 
2024-11-21 22:57:41.954379: Current learning rate: 0.0028 
2024-11-21 22:58:34.660581: train_loss -0.9766 
2024-11-21 22:58:34.660720: val_loss -0.8902 
2024-11-21 22:58:34.660772: Pseudo dice [np.float32(0.9054)] 
2024-11-21 22:58:34.660828: Epoch time: 52.71 s 
2024-11-21 22:58:35.661304:  
2024-11-21 22:58:35.661441: Epoch 758 
2024-11-21 22:58:35.661518: Current learning rate: 0.00279 
2024-11-21 22:59:27.939599: train_loss -0.9764 
2024-11-21 22:59:27.939740: val_loss -0.9002 
2024-11-21 22:59:27.939838: Pseudo dice [np.float32(0.9159)] 
2024-11-21 22:59:27.939953: Epoch time: 52.28 s 
2024-11-21 22:59:28.927649:  
2024-11-21 22:59:28.927838: Epoch 759 
2024-11-21 22:59:28.927907: Current learning rate: 0.00278 
2024-11-21 23:00:21.457943: train_loss -0.977 
2024-11-21 23:00:21.458059: val_loss -0.9046 
2024-11-21 23:00:21.458110: Pseudo dice [np.float32(0.9178)] 
2024-11-21 23:00:21.458163: Epoch time: 52.53 s 
2024-11-21 23:00:22.484126:  
2024-11-21 23:00:22.484285: Epoch 760 
2024-11-21 23:00:22.484357: Current learning rate: 0.00277 
2024-11-21 23:01:15.023412: train_loss -0.9769 
2024-11-21 23:01:15.023573: val_loss -0.9017 
2024-11-21 23:01:15.023641: Pseudo dice [np.float32(0.9155)] 
2024-11-21 23:01:15.023710: Epoch time: 52.54 s 
2024-11-21 23:01:16.017661:  
2024-11-21 23:01:16.017884: Epoch 761 
2024-11-21 23:01:16.017972: Current learning rate: 0.00276 
2024-11-21 23:02:08.458024: train_loss -0.9776 
2024-11-21 23:02:08.458216: val_loss -0.8997 
2024-11-21 23:02:08.458266: Pseudo dice [np.float32(0.9152)] 
2024-11-21 23:02:08.458319: Epoch time: 52.44 s 
2024-11-21 23:02:09.702298:  
2024-11-21 23:02:09.702466: Epoch 762 
2024-11-21 23:02:09.702654: Current learning rate: 0.00275 
2024-11-21 23:03:02.224535: train_loss -0.9775 
2024-11-21 23:03:02.224670: val_loss -0.8981 
2024-11-21 23:03:02.224809: Pseudo dice [np.float32(0.9118)] 
2024-11-21 23:03:02.224895: Epoch time: 52.52 s 
2024-11-21 23:03:03.166343:  
2024-11-21 23:03:03.166563: Epoch 763 
2024-11-21 23:03:03.166631: Current learning rate: 0.00274 
2024-11-21 23:03:55.838786: train_loss -0.977 
2024-11-21 23:03:55.838930: val_loss -0.8974 
2024-11-21 23:03:55.838980: Pseudo dice [np.float32(0.913)] 
2024-11-21 23:03:55.839034: Epoch time: 52.67 s 
2024-11-21 23:03:56.903373:  
2024-11-21 23:03:56.903564: Epoch 764 
2024-11-21 23:03:56.903714: Current learning rate: 0.00273 
2024-11-21 23:04:49.608165: train_loss -0.9772 
2024-11-21 23:04:49.608285: val_loss -0.897 
2024-11-21 23:04:49.608333: Pseudo dice [np.float32(0.9116)] 
2024-11-21 23:04:49.608387: Epoch time: 52.71 s 
2024-11-21 23:04:50.639643:  
2024-11-21 23:04:50.639805: Epoch 765 
2024-11-21 23:04:50.639874: Current learning rate: 0.00272 
2024-11-21 23:05:43.251446: train_loss -0.978 
2024-11-21 23:05:43.251640: val_loss -0.8995 
2024-11-21 23:05:43.251689: Pseudo dice [np.float32(0.9141)] 
2024-11-21 23:05:43.251742: Epoch time: 52.61 s 
2024-11-21 23:05:44.181901:  
2024-11-21 23:05:44.182028: Epoch 766 
2024-11-21 23:05:44.182127: Current learning rate: 0.00271 
2024-11-21 23:06:37.022388: train_loss -0.977 
2024-11-21 23:06:37.022527: val_loss -0.8985 
2024-11-21 23:06:37.022609: Pseudo dice [np.float32(0.9141)] 
2024-11-21 23:06:37.022671: Epoch time: 52.84 s 
2024-11-21 23:06:37.967742:  
2024-11-21 23:06:37.967898: Epoch 767 
2024-11-21 23:06:37.967994: Current learning rate: 0.0027 
2024-11-21 23:07:30.663561: train_loss -0.976 
2024-11-21 23:07:30.663674: val_loss -0.8998 
2024-11-21 23:07:30.663722: Pseudo dice [np.float32(0.9142)] 
2024-11-21 23:07:30.663802: Epoch time: 52.7 s 
2024-11-21 23:07:31.678844:  
2024-11-21 23:07:31.679096: Epoch 768 
2024-11-21 23:07:31.679224: Current learning rate: 0.00268 
2024-11-21 23:08:24.385480: train_loss -0.9775 
2024-11-21 23:08:24.385602: val_loss -0.8965 
2024-11-21 23:08:24.385651: Pseudo dice [np.float32(0.9132)] 
2024-11-21 23:08:24.385705: Epoch time: 52.71 s 
2024-11-21 23:08:25.368746:  
2024-11-21 23:08:25.368880: Epoch 769 
2024-11-21 23:08:25.368948: Current learning rate: 0.00267 
2024-11-21 23:09:17.936768: train_loss -0.9769 
2024-11-21 23:09:17.936916: val_loss -0.8973 
2024-11-21 23:09:17.937016: Pseudo dice [np.float32(0.9128)] 
2024-11-21 23:09:17.937132: Epoch time: 52.57 s 
2024-11-21 23:09:18.920949:  
2024-11-21 23:09:18.921081: Epoch 770 
2024-11-21 23:09:18.921147: Current learning rate: 0.00266 
2024-11-21 23:10:11.502620: train_loss -0.9771 
2024-11-21 23:10:11.502745: val_loss -0.8963 
2024-11-21 23:10:11.502794: Pseudo dice [np.float32(0.9099)] 
2024-11-21 23:10:11.502846: Epoch time: 52.58 s 
2024-11-21 23:10:12.514281:  
2024-11-21 23:10:12.514453: Epoch 771 
2024-11-21 23:10:12.514544: Current learning rate: 0.00265 
2024-11-21 23:11:05.158411: train_loss -0.9775 
2024-11-21 23:11:05.158585: val_loss -0.897 
2024-11-21 23:11:05.158631: Pseudo dice [np.float32(0.9124)] 
2024-11-21 23:11:05.158684: Epoch time: 52.65 s 
2024-11-21 23:11:06.121285:  
2024-11-21 23:11:06.121476: Epoch 772 
2024-11-21 23:11:06.121753: Current learning rate: 0.00264 
2024-11-21 23:11:58.450613: train_loss -0.9779 
2024-11-21 23:11:58.450737: val_loss -0.9009 
2024-11-21 23:11:58.450785: Pseudo dice [np.float32(0.9151)] 
2024-11-21 23:11:58.450837: Epoch time: 52.33 s 
2024-11-21 23:11:59.738249:  
2024-11-21 23:11:59.738421: Epoch 773 
2024-11-21 23:11:59.738533: Current learning rate: 0.00263 
2024-11-21 23:12:52.439127: train_loss -0.978 
2024-11-21 23:12:52.439283: val_loss -0.9 
2024-11-21 23:12:52.439348: Pseudo dice [np.float32(0.9155)] 
2024-11-21 23:12:52.439417: Epoch time: 52.7 s 
2024-11-21 23:12:53.469007:  
2024-11-21 23:12:53.469208: Epoch 774 
2024-11-21 23:12:53.469293: Current learning rate: 0.00262 
2024-11-21 23:13:46.258711: train_loss -0.9779 
2024-11-21 23:13:46.258826: val_loss -0.8965 
2024-11-21 23:13:46.258878: Pseudo dice [np.float32(0.912)] 
2024-11-21 23:13:46.258928: Epoch time: 52.79 s 
2024-11-21 23:13:47.397369:  
2024-11-21 23:13:47.397556: Epoch 775 
2024-11-21 23:13:47.397625: Current learning rate: 0.00261 
2024-11-21 23:14:40.108266: train_loss -0.9783 
2024-11-21 23:14:40.108389: val_loss -0.8988 
2024-11-21 23:14:40.108450: Pseudo dice [np.float32(0.913)] 
2024-11-21 23:14:40.108522: Epoch time: 52.71 s 
2024-11-21 23:14:41.107925:  
2024-11-21 23:14:41.108073: Epoch 776 
2024-11-21 23:14:41.108139: Current learning rate: 0.0026 
2024-11-21 23:15:33.832184: train_loss -0.9777 
2024-11-21 23:15:33.832313: val_loss -0.8984 
2024-11-21 23:15:33.832375: Pseudo dice [np.float32(0.9131)] 
2024-11-21 23:15:33.832440: Epoch time: 52.73 s 
2024-11-21 23:15:34.838820:  
2024-11-21 23:15:34.838954: Epoch 777 
2024-11-21 23:15:34.839022: Current learning rate: 0.00259 
2024-11-21 23:16:27.593339: train_loss -0.9779 
2024-11-21 23:16:27.593546: val_loss -0.8979 
2024-11-21 23:16:27.594382: Pseudo dice [np.float32(0.9127)] 
2024-11-21 23:16:27.594439: Epoch time: 52.76 s 
2024-11-21 23:16:28.574833:  
2024-11-21 23:16:28.574987: Epoch 778 
2024-11-21 23:16:28.575055: Current learning rate: 0.00258 
2024-11-21 23:17:21.226861: train_loss -0.9775 
2024-11-21 23:17:21.227036: val_loss -0.9016 
2024-11-21 23:17:21.227101: Pseudo dice [np.float32(0.915)] 
2024-11-21 23:17:21.227157: Epoch time: 52.65 s 
2024-11-21 23:17:22.210635:  
2024-11-21 23:17:22.210772: Epoch 779 
2024-11-21 23:17:22.210839: Current learning rate: 0.00257 
2024-11-21 23:18:14.754175: train_loss -0.9773 
2024-11-21 23:18:14.754282: val_loss -0.8988 
2024-11-21 23:18:14.754328: Pseudo dice [np.float32(0.9129)] 
2024-11-21 23:18:14.754380: Epoch time: 52.54 s 
2024-11-21 23:18:15.763011:  
2024-11-21 23:18:15.763210: Epoch 780 
2024-11-21 23:18:15.763298: Current learning rate: 0.00256 
2024-11-21 23:19:08.417767: train_loss -0.9779 
2024-11-21 23:19:08.417899: val_loss -0.9017 
2024-11-21 23:19:08.417953: Pseudo dice [np.float32(0.916)] 
2024-11-21 23:19:08.418006: Epoch time: 52.66 s 
2024-11-21 23:19:09.403523:  
2024-11-21 23:19:09.403719: Epoch 781 
2024-11-21 23:19:09.403842: Current learning rate: 0.00255 
2024-11-21 23:20:02.127352: train_loss -0.9782 
2024-11-21 23:20:02.127531: val_loss -0.8991 
2024-11-21 23:20:02.127614: Pseudo dice [np.float32(0.9144)] 
2024-11-21 23:20:02.127668: Epoch time: 52.72 s 
2024-11-21 23:20:03.093311:  
2024-11-21 23:20:03.093519: Epoch 782 
2024-11-21 23:20:03.093621: Current learning rate: 0.00254 
2024-11-21 23:20:55.631093: train_loss -0.9779 
2024-11-21 23:20:55.631247: val_loss -0.8926 
2024-11-21 23:20:55.631310: Pseudo dice [np.float32(0.9113)] 
2024-11-21 23:20:55.631377: Epoch time: 52.54 s 
2024-11-21 23:20:56.660271:  
2024-11-21 23:20:56.660548: Epoch 783 
2024-11-21 23:20:56.660638: Current learning rate: 0.00253 
2024-11-21 23:21:49.161777: train_loss -0.9772 
2024-11-21 23:21:49.161886: val_loss -0.8955 
2024-11-21 23:21:49.161932: Pseudo dice [np.float32(0.9103)] 
2024-11-21 23:21:49.162009: Epoch time: 52.5 s 
2024-11-21 23:21:50.452742:  
2024-11-21 23:21:50.452919: Epoch 784 
2024-11-21 23:21:50.453013: Current learning rate: 0.00252 
2024-11-21 23:22:42.886629: train_loss -0.9773 
2024-11-21 23:22:42.886759: val_loss -0.8931 
2024-11-21 23:22:42.886806: Pseudo dice [np.float32(0.9095)] 
2024-11-21 23:22:42.886858: Epoch time: 52.43 s 
2024-11-21 23:22:43.900173:  
2024-11-21 23:22:43.900393: Epoch 785 
2024-11-21 23:22:43.900483: Current learning rate: 0.00251 
2024-11-21 23:23:36.441944: train_loss -0.9777 
2024-11-21 23:23:36.442080: val_loss -0.898 
2024-11-21 23:23:36.442128: Pseudo dice [np.float32(0.9138)] 
2024-11-21 23:23:36.442179: Epoch time: 52.54 s 
2024-11-21 23:23:37.446957:  
2024-11-21 23:23:37.447138: Epoch 786 
2024-11-21 23:23:37.447212: Current learning rate: 0.0025 
2024-11-21 23:24:29.746869: train_loss -0.9776 
2024-11-21 23:24:29.746992: val_loss -0.8962 
2024-11-21 23:24:29.747045: Pseudo dice [np.float32(0.9119)] 
2024-11-21 23:24:29.747100: Epoch time: 52.3 s 
2024-11-21 23:24:30.712336:  
2024-11-21 23:24:30.712489: Epoch 787 
2024-11-21 23:24:30.712612: Current learning rate: 0.00249 
2024-11-21 23:25:23.371365: train_loss -0.9782 
2024-11-21 23:25:23.371543: val_loss -0.8986 
2024-11-21 23:25:23.371641: Pseudo dice [np.float32(0.9135)] 
2024-11-21 23:25:23.371696: Epoch time: 52.66 s 
2024-11-21 23:25:24.301098:  
2024-11-21 23:25:24.301245: Epoch 788 
2024-11-21 23:25:24.301312: Current learning rate: 0.00248 
2024-11-21 23:26:17.038365: train_loss -0.9775 
2024-11-21 23:26:17.038513: val_loss -0.9028 
2024-11-21 23:26:17.038612: Pseudo dice [np.float32(0.9177)] 
2024-11-21 23:26:17.038666: Epoch time: 52.74 s 
2024-11-21 23:26:18.095556:  
2024-11-21 23:26:18.095737: Epoch 789 
2024-11-21 23:26:18.095865: Current learning rate: 0.00247 
2024-11-21 23:27:10.456196: train_loss -0.9787 
2024-11-21 23:27:10.456356: val_loss -0.8972 
2024-11-21 23:27:10.456460: Pseudo dice [np.float32(0.9129)] 
2024-11-21 23:27:10.456561: Epoch time: 52.36 s 
2024-11-21 23:27:11.416683:  
2024-11-21 23:27:11.416881: Epoch 790 
2024-11-21 23:27:11.417032: Current learning rate: 0.00245 
2024-11-21 23:28:03.797190: train_loss -0.9787 
2024-11-21 23:28:03.797327: val_loss -0.892 
2024-11-21 23:28:03.797376: Pseudo dice [np.float32(0.9071)] 
2024-11-21 23:28:03.797435: Epoch time: 52.38 s 
2024-11-21 23:28:04.798055:  
2024-11-21 23:28:04.798198: Epoch 791 
2024-11-21 23:28:04.798302: Current learning rate: 0.00244 
2024-11-21 23:28:57.295464: train_loss -0.9789 
2024-11-21 23:28:57.295625: val_loss -0.8969 
2024-11-21 23:28:57.295672: Pseudo dice [np.float32(0.9124)] 
2024-11-21 23:28:57.295723: Epoch time: 52.5 s 
2024-11-21 23:28:58.293286:  
2024-11-21 23:28:58.293491: Epoch 792 
2024-11-21 23:28:58.293578: Current learning rate: 0.00243 
2024-11-21 23:29:50.634536: train_loss -0.9781 
2024-11-21 23:29:50.634683: val_loss -0.9021 
2024-11-21 23:29:50.635592: Pseudo dice [np.float32(0.9151)] 
2024-11-21 23:29:50.635664: Epoch time: 52.34 s 
2024-11-21 23:29:51.648738:  
2024-11-21 23:29:51.648971: Epoch 793 
2024-11-21 23:29:51.649057: Current learning rate: 0.00242 
2024-11-21 23:30:43.978233: train_loss -0.9777 
2024-11-21 23:30:43.978354: val_loss -0.8927 
2024-11-21 23:30:43.978408: Pseudo dice [np.float32(0.909)] 
2024-11-21 23:30:43.978465: Epoch time: 52.33 s 
2024-11-21 23:30:45.022227:  
2024-11-21 23:30:45.022404: Epoch 794 
2024-11-21 23:30:45.022502: Current learning rate: 0.00241 
2024-11-21 23:31:37.134123: train_loss -0.9793 
2024-11-21 23:31:37.134276: val_loss -0.8985 
2024-11-21 23:31:37.134343: Pseudo dice [np.float32(0.914)] 
2024-11-21 23:31:37.134420: Epoch time: 52.11 s 
2024-11-21 23:31:38.423602:  
2024-11-21 23:31:38.423778: Epoch 795 
2024-11-21 23:31:38.423868: Current learning rate: 0.0024 
2024-11-21 23:32:30.948114: train_loss -0.9787 
2024-11-21 23:32:30.948249: val_loss -0.8998 
2024-11-21 23:32:30.948298: Pseudo dice [np.float32(0.9136)] 
2024-11-21 23:32:30.948351: Epoch time: 52.53 s 
2024-11-21 23:32:31.953573:  
2024-11-21 23:32:31.953761: Epoch 796 
2024-11-21 23:32:31.953862: Current learning rate: 0.00239 
2024-11-21 23:33:24.410856: train_loss -0.9792 
2024-11-21 23:33:24.411037: val_loss -0.8993 
2024-11-21 23:33:24.411086: Pseudo dice [np.float32(0.9151)] 
2024-11-21 23:33:24.411139: Epoch time: 52.46 s 
2024-11-21 23:33:25.412538:  
2024-11-21 23:33:25.412730: Epoch 797 
2024-11-21 23:33:25.412854: Current learning rate: 0.00238 
2024-11-21 23:34:17.962042: train_loss -0.9784 
2024-11-21 23:34:17.962157: val_loss -0.8993 
2024-11-21 23:34:17.962204: Pseudo dice [np.float32(0.9142)] 
2024-11-21 23:34:17.962256: Epoch time: 52.55 s 
2024-11-21 23:34:18.931128:  
2024-11-21 23:34:18.931257: Epoch 798 
2024-11-21 23:34:18.931325: Current learning rate: 0.00237 
2024-11-21 23:35:11.147669: train_loss -0.9787 
2024-11-21 23:35:11.147792: val_loss -0.9025 
2024-11-21 23:35:11.147841: Pseudo dice [np.float32(0.916)] 
2024-11-21 23:35:11.147894: Epoch time: 52.22 s 
2024-11-21 23:35:12.128356:  
2024-11-21 23:35:12.128580: Epoch 799 
2024-11-21 23:35:12.128665: Current learning rate: 0.00236 
2024-11-21 23:36:04.690794: train_loss -0.9786 
2024-11-21 23:36:04.690968: val_loss -0.9028 
2024-11-21 23:36:04.691015: Pseudo dice [np.float32(0.9189)] 
2024-11-21 23:36:04.691067: Epoch time: 52.56 s 
2024-11-21 23:36:06.130611:  
2024-11-21 23:36:06.130791: Epoch 800 
2024-11-21 23:36:06.130877: Current learning rate: 0.00235 
2024-11-21 23:36:58.430456: train_loss -0.9781 
2024-11-21 23:36:58.430620: val_loss -0.9023 
2024-11-21 23:36:58.430712: Pseudo dice [np.float32(0.9164)] 
2024-11-21 23:36:58.430784: Epoch time: 52.3 s 
2024-11-21 23:36:59.490411:  
2024-11-21 23:36:59.490577: Epoch 801 
2024-11-21 23:36:59.490664: Current learning rate: 0.00234 
2024-11-21 23:37:51.932881: train_loss -0.9775 
2024-11-21 23:37:51.932995: val_loss -0.8925 
2024-11-21 23:37:51.933044: Pseudo dice [np.float32(0.9109)] 
2024-11-21 23:37:51.933098: Epoch time: 52.44 s 
2024-11-21 23:37:52.883072:  
2024-11-21 23:37:52.883208: Epoch 802 
2024-11-21 23:37:52.883277: Current learning rate: 0.00233 
2024-11-21 23:38:45.074573: train_loss -0.9778 
2024-11-21 23:38:45.074731: val_loss -0.9007 
2024-11-21 23:38:45.074781: Pseudo dice [np.float32(0.9162)] 
2024-11-21 23:38:45.074836: Epoch time: 52.19 s 
2024-11-21 23:38:46.084640:  
2024-11-21 23:38:46.084841: Epoch 803 
2024-11-21 23:38:46.084913: Current learning rate: 0.00232 
2024-11-21 23:39:38.586412: train_loss -0.9783 
2024-11-21 23:39:38.586604: val_loss -0.9027 
2024-11-21 23:39:38.586748: Pseudo dice [np.float32(0.9171)] 
2024-11-21 23:39:38.586849: Epoch time: 52.5 s 
2024-11-21 23:39:38.586949: Yayy! New best EMA pseudo Dice: 0.9143999814987183 
2024-11-21 23:39:40.030463:  
2024-11-21 23:39:40.030628: Epoch 804 
2024-11-21 23:39:40.030729: Current learning rate: 0.00231 
2024-11-21 23:40:32.749495: train_loss -0.9785 
2024-11-21 23:40:32.749620: val_loss -0.9003 
2024-11-21 23:40:32.749683: Pseudo dice [np.float32(0.9151)] 
2024-11-21 23:40:32.749801: Epoch time: 52.72 s 
2024-11-21 23:40:32.749860: Yayy! New best EMA pseudo Dice: 0.9144999980926514 
2024-11-21 23:40:34.147211:  
2024-11-21 23:40:34.147362: Epoch 805 
2024-11-21 23:40:34.147511: Current learning rate: 0.0023 
2024-11-21 23:41:26.816625: train_loss -0.9785 
2024-11-21 23:41:26.816953: val_loss -0.8974 
2024-11-21 23:41:26.817028: Pseudo dice [np.float32(0.9134)] 
2024-11-21 23:41:26.817084: Epoch time: 52.67 s 
2024-11-21 23:41:28.089841:  
2024-11-21 23:41:28.090041: Epoch 806 
2024-11-21 23:41:28.090129: Current learning rate: 0.00229 
2024-11-21 23:42:20.610219: train_loss -0.9788 
2024-11-21 23:42:20.610339: val_loss -0.8953 
2024-11-21 23:42:20.610386: Pseudo dice [np.float32(0.9114)] 
2024-11-21 23:42:20.610437: Epoch time: 52.52 s 
2024-11-21 23:42:21.644535:  
2024-11-21 23:42:21.644685: Epoch 807 
2024-11-21 23:42:21.644751: Current learning rate: 0.00228 
2024-11-21 23:43:13.909205: train_loss -0.9786 
2024-11-21 23:43:13.909323: val_loss -0.9025 
2024-11-21 23:43:13.909376: Pseudo dice [np.float32(0.9174)] 
2024-11-21 23:43:13.909433: Epoch time: 52.27 s 
2024-11-21 23:43:14.876108:  
2024-11-21 23:43:14.876301: Epoch 808 
2024-11-21 23:43:14.876369: Current learning rate: 0.00226 
2024-11-21 23:44:07.148458: train_loss -0.9786 
2024-11-21 23:44:07.148594: val_loss -0.9004 
2024-11-21 23:44:07.148643: Pseudo dice [np.float32(0.9152)] 
2024-11-21 23:44:07.148696: Epoch time: 52.27 s 
2024-11-21 23:44:07.148740: Yayy! New best EMA pseudo Dice: 0.9144999980926514 
2024-11-21 23:44:08.551737:  
2024-11-21 23:44:08.552075: Epoch 809 
2024-11-21 23:44:08.552167: Current learning rate: 0.00225 
2024-11-21 23:45:01.034565: train_loss -0.9789 
2024-11-21 23:45:01.034691: val_loss -0.897 
2024-11-21 23:45:01.035560: Pseudo dice [np.float32(0.9126)] 
2024-11-21 23:45:01.035616: Epoch time: 52.48 s 
2024-11-21 23:45:02.048121:  
2024-11-21 23:45:02.048315: Epoch 810 
2024-11-21 23:45:02.048400: Current learning rate: 0.00224 
2024-11-21 23:45:54.326442: train_loss -0.9784 
2024-11-21 23:45:54.326622: val_loss -0.8989 
2024-11-21 23:45:54.326672: Pseudo dice [np.float32(0.9139)] 
2024-11-21 23:45:54.326726: Epoch time: 52.28 s 
2024-11-21 23:45:55.252508:  
2024-11-21 23:45:55.252770: Epoch 811 
2024-11-21 23:45:55.252844: Current learning rate: 0.00223 
2024-11-21 23:46:47.686365: train_loss -0.9791 
2024-11-21 23:46:47.686527: val_loss -0.9016 
2024-11-21 23:46:47.686607: Pseudo dice [np.float32(0.9167)] 
2024-11-21 23:46:47.686698: Epoch time: 52.43 s 
2024-11-21 23:46:47.686754: Yayy! New best EMA pseudo Dice: 0.9144999980926514 
2024-11-21 23:46:49.042735:  
2024-11-21 23:46:49.042888: Epoch 812 
2024-11-21 23:46:49.042953: Current learning rate: 0.00222 
2024-11-21 23:47:41.311192: train_loss -0.9795 
2024-11-21 23:47:41.311311: val_loss -0.9006 
2024-11-21 23:47:41.311361: Pseudo dice [np.float32(0.9147)] 
2024-11-21 23:47:41.311413: Epoch time: 52.27 s 
2024-11-21 23:47:41.311529: Yayy! New best EMA pseudo Dice: 0.9144999980926514 
2024-11-21 23:47:42.757416:  
2024-11-21 23:47:42.757693: Epoch 813 
2024-11-21 23:47:42.757763: Current learning rate: 0.00221 
2024-11-21 23:48:35.172893: train_loss -0.9789 
2024-11-21 23:48:35.173002: val_loss -0.8981 
2024-11-21 23:48:35.173052: Pseudo dice [np.float32(0.9121)] 
2024-11-21 23:48:35.173107: Epoch time: 52.42 s 
2024-11-21 23:48:36.190666:  
2024-11-21 23:48:36.190812: Epoch 814 
2024-11-21 23:48:36.190880: Current learning rate: 0.0022 
2024-11-21 23:49:28.284753: train_loss -0.9791 
2024-11-21 23:49:28.284895: val_loss -0.9026 
2024-11-21 23:49:28.284966: Pseudo dice [np.float32(0.9155)] 
2024-11-21 23:49:28.285031: Epoch time: 52.09 s 
2024-11-21 23:49:29.247452:  
2024-11-21 23:49:29.247635: Epoch 815 
2024-11-21 23:49:29.247700: Current learning rate: 0.00219 
2024-11-21 23:50:21.856066: train_loss -0.9786 
2024-11-21 23:50:21.856193: val_loss -0.898 
2024-11-21 23:50:21.856242: Pseudo dice [np.float32(0.9143)] 
2024-11-21 23:50:21.856293: Epoch time: 52.61 s 
2024-11-21 23:50:23.130498:  
2024-11-21 23:50:23.130764: Epoch 816 
2024-11-21 23:50:23.130855: Current learning rate: 0.00218 
2024-11-21 23:51:15.600159: train_loss -0.9787 
2024-11-21 23:51:15.600277: val_loss -0.8986 
2024-11-21 23:51:15.601153: Pseudo dice [np.float32(0.9143)] 
2024-11-21 23:51:15.601207: Epoch time: 52.47 s 
2024-11-21 23:51:16.540746:  
2024-11-21 23:51:16.540892: Epoch 817 
2024-11-21 23:51:16.540957: Current learning rate: 0.00217 
2024-11-21 23:52:09.255179: train_loss -0.9789 
2024-11-21 23:52:09.255362: val_loss -0.8993 
2024-11-21 23:52:09.255457: Pseudo dice [np.float32(0.9129)] 
2024-11-21 23:52:09.255544: Epoch time: 52.72 s 
2024-11-21 23:52:10.237804:  
2024-11-21 23:52:10.237946: Epoch 818 
2024-11-21 23:52:10.238030: Current learning rate: 0.00216 
2024-11-21 23:53:03.079112: train_loss -0.9788 
2024-11-21 23:53:03.079321: val_loss -0.8997 
2024-11-21 23:53:03.079473: Pseudo dice [np.float32(0.9152)] 
2024-11-21 23:53:03.079628: Epoch time: 52.84 s 
2024-11-21 23:53:04.082468:  
2024-11-21 23:53:04.082663: Epoch 819 
2024-11-21 23:53:04.082773: Current learning rate: 0.00215 
2024-11-21 23:53:56.663435: train_loss -0.9787 
2024-11-21 23:53:56.663573: val_loss -0.9033 
2024-11-21 23:53:56.663637: Pseudo dice [np.float32(0.9173)] 
2024-11-21 23:53:56.663765: Epoch time: 52.58 s 
2024-11-21 23:53:56.663827: Yayy! New best EMA pseudo Dice: 0.9146000146865845 
2024-11-21 23:53:57.972819:  
2024-11-21 23:53:57.972960: Epoch 820 
2024-11-21 23:53:57.973027: Current learning rate: 0.00214 
2024-11-21 23:54:50.617943: train_loss -0.9789 
2024-11-21 23:54:50.618062: val_loss -0.8954 
2024-11-21 23:54:50.618127: Pseudo dice [np.float32(0.9106)] 
2024-11-21 23:54:50.618194: Epoch time: 52.65 s 
2024-11-21 23:54:51.528012:  
2024-11-21 23:54:51.528155: Epoch 821 
2024-11-21 23:54:51.528236: Current learning rate: 0.00213 
2024-11-21 23:55:44.087151: train_loss -0.9783 
2024-11-21 23:55:44.087275: val_loss -0.8955 
2024-11-21 23:55:44.087325: Pseudo dice [np.float32(0.9112)] 
2024-11-21 23:55:44.087380: Epoch time: 52.56 s 
2024-11-21 23:55:44.976442:  
2024-11-21 23:55:44.976655: Epoch 822 
2024-11-21 23:55:44.976725: Current learning rate: 0.00212 
2024-11-21 23:56:37.249861: train_loss -0.9776 
2024-11-21 23:56:37.249976: val_loss -0.9022 
2024-11-21 23:56:37.250044: Pseudo dice [np.float32(0.9168)] 
2024-11-21 23:56:37.250098: Epoch time: 52.27 s 
2024-11-21 23:56:38.215611:  
2024-11-21 23:56:38.215747: Epoch 823 
2024-11-21 23:56:38.216185: Current learning rate: 0.0021 
2024-11-21 23:57:30.712195: train_loss -0.9793 
2024-11-21 23:57:30.712356: val_loss -0.8976 
2024-11-21 23:57:30.712406: Pseudo dice [np.float32(0.9127)] 
2024-11-21 23:57:30.712461: Epoch time: 52.5 s 
2024-11-21 23:57:31.599588:  
2024-11-21 23:57:31.599721: Epoch 824 
2024-11-21 23:57:31.599789: Current learning rate: 0.00209 
2024-11-21 23:58:24.151860: train_loss -0.9765 
2024-11-21 23:58:24.151999: val_loss -0.8914 
2024-11-21 23:58:24.152065: Pseudo dice [np.float32(0.9068)] 
2024-11-21 23:58:24.152140: Epoch time: 52.55 s 
2024-11-21 23:58:25.104580:  
2024-11-21 23:58:25.104752: Epoch 825 
2024-11-21 23:58:25.104834: Current learning rate: 0.00208 
2024-11-21 23:59:17.296237: train_loss -0.9767 
2024-11-21 23:59:17.296368: val_loss -0.8984 
2024-11-21 23:59:17.296429: Pseudo dice [np.float32(0.9127)] 
2024-11-21 23:59:17.296501: Epoch time: 52.19 s 
2024-11-21 23:59:18.251026:  
2024-11-21 23:59:18.251254: Epoch 826 
2024-11-21 23:59:18.251352: Current learning rate: 0.00207 
2024-11-22 00:00:10.467609: train_loss -0.9779 
2024-11-22 00:00:10.467744: val_loss -0.8959 
2024-11-22 00:00:10.467794: Pseudo dice [np.float32(0.9102)] 
2024-11-22 00:00:10.467852: Epoch time: 52.22 s 
2024-11-22 00:00:11.466976:  
2024-11-22 00:00:11.467115: Epoch 827 
2024-11-22 00:00:11.467196: Current learning rate: 0.00206 
2024-11-22 00:01:03.779114: train_loss -0.9761 
2024-11-22 00:01:03.779226: val_loss -0.8973 
2024-11-22 00:01:03.779275: Pseudo dice [np.float32(0.9126)] 
2024-11-22 00:01:03.779328: Epoch time: 52.31 s 
2024-11-22 00:01:05.007449:  
2024-11-22 00:01:05.007650: Epoch 828 
2024-11-22 00:01:05.007732: Current learning rate: 0.00205 
2024-11-22 00:01:57.379283: train_loss -0.9767 
2024-11-22 00:01:57.379483: val_loss -0.8964 
2024-11-22 00:01:57.379569: Pseudo dice [np.float32(0.9119)] 
2024-11-22 00:01:57.379628: Epoch time: 52.37 s 
2024-11-22 00:01:58.316247:  
2024-11-22 00:01:58.316402: Epoch 829 
2024-11-22 00:01:58.316503: Current learning rate: 0.00204 
2024-11-22 00:02:51.018238: train_loss -0.9778 
2024-11-22 00:02:51.018348: val_loss -0.9044 
2024-11-22 00:02:51.019275: Pseudo dice [np.float32(0.9181)] 
2024-11-22 00:02:51.019332: Epoch time: 52.7 s 
2024-11-22 00:02:51.894076:  
2024-11-22 00:02:51.894319: Epoch 830 
2024-11-22 00:02:51.894387: Current learning rate: 0.00203 
2024-11-22 00:03:44.287088: train_loss -0.9776 
2024-11-22 00:03:44.287206: val_loss -0.899 
2024-11-22 00:03:44.287257: Pseudo dice [np.float32(0.9145)] 
2024-11-22 00:03:44.287310: Epoch time: 52.39 s 
2024-11-22 00:03:45.260756:  
2024-11-22 00:03:45.261179: Epoch 831 
2024-11-22 00:03:45.261263: Current learning rate: 0.00202 
2024-11-22 00:04:37.575912: train_loss -0.9777 
2024-11-22 00:04:37.576041: val_loss -0.9019 
2024-11-22 00:04:37.576104: Pseudo dice [np.float32(0.9176)] 
2024-11-22 00:04:37.576173: Epoch time: 52.32 s 
2024-11-22 00:04:38.572593:  
2024-11-22 00:04:38.572749: Epoch 832 
2024-11-22 00:04:38.572814: Current learning rate: 0.00201 
2024-11-22 00:05:30.874781: train_loss -0.9788 
2024-11-22 00:05:30.874894: val_loss -0.902 
2024-11-22 00:05:30.874950: Pseudo dice [np.float32(0.9177)] 
2024-11-22 00:05:30.875021: Epoch time: 52.3 s 
2024-11-22 00:05:31.803383:  
2024-11-22 00:05:31.803760: Epoch 833 
2024-11-22 00:05:31.803916: Current learning rate: 0.002 
2024-11-22 00:06:24.156813: train_loss -0.9785 
2024-11-22 00:06:24.156964: val_loss -0.8975 
2024-11-22 00:06:24.157041: Pseudo dice [np.float32(0.9108)] 
2024-11-22 00:06:24.157134: Epoch time: 52.35 s 
2024-11-22 00:06:25.078270:  
2024-11-22 00:06:25.078433: Epoch 834 
2024-11-22 00:06:25.078564: Current learning rate: 0.00199 
2024-11-22 00:07:17.414873: train_loss -0.9775 
2024-11-22 00:07:17.414988: val_loss -0.8981 
2024-11-22 00:07:17.415036: Pseudo dice [np.float32(0.9125)] 
2024-11-22 00:07:17.415089: Epoch time: 52.34 s 
2024-11-22 00:07:18.409945:  
2024-11-22 00:07:18.410125: Epoch 835 
2024-11-22 00:07:18.410199: Current learning rate: 0.00198 
2024-11-22 00:08:10.767903: train_loss -0.9787 
2024-11-22 00:08:10.768043: val_loss -0.8973 
2024-11-22 00:08:10.768111: Pseudo dice [np.float32(0.9134)] 
2024-11-22 00:08:10.768186: Epoch time: 52.36 s 
2024-11-22 00:08:11.675930:  
2024-11-22 00:08:11.676079: Epoch 836 
2024-11-22 00:08:11.676152: Current learning rate: 0.00196 
2024-11-22 00:09:04.258188: train_loss -0.9793 
2024-11-22 00:09:04.258335: val_loss -0.9031 
2024-11-22 00:09:04.258386: Pseudo dice [np.float32(0.9171)] 
2024-11-22 00:09:04.258440: Epoch time: 52.58 s 
2024-11-22 00:09:05.182830:  
2024-11-22 00:09:05.182965: Epoch 837 
2024-11-22 00:09:05.183035: Current learning rate: 0.00195 
2024-11-22 00:09:57.288047: train_loss -0.9794 
2024-11-22 00:09:57.288208: val_loss -0.9021 
2024-11-22 00:09:57.288272: Pseudo dice [np.float32(0.9171)] 
2024-11-22 00:09:57.288339: Epoch time: 52.11 s 
2024-11-22 00:09:58.352747:  
2024-11-22 00:09:58.352987: Epoch 838 
2024-11-22 00:09:58.353070: Current learning rate: 0.00194 
2024-11-22 00:10:50.829291: train_loss -0.9797 
2024-11-22 00:10:50.829425: val_loss -0.899 
2024-11-22 00:10:50.829554: Pseudo dice [np.float32(0.9134)] 
2024-11-22 00:10:50.829644: Epoch time: 52.48 s 
2024-11-22 00:10:51.709644:  
2024-11-22 00:10:51.709788: Epoch 839 
2024-11-22 00:10:51.709858: Current learning rate: 0.00193 
2024-11-22 00:11:44.199243: train_loss -0.9796 
2024-11-22 00:11:44.199363: val_loss -0.8972 
2024-11-22 00:11:44.199413: Pseudo dice [np.float32(0.9138)] 
2024-11-22 00:11:44.199466: Epoch time: 52.49 s 
2024-11-22 00:11:45.474092:  
2024-11-22 00:11:45.474241: Epoch 840 
2024-11-22 00:11:45.474308: Current learning rate: 0.00192 
2024-11-22 00:12:37.857379: train_loss -0.9796 
2024-11-22 00:12:37.857529: val_loss -0.899 
2024-11-22 00:12:37.857594: Pseudo dice [np.float32(0.9145)] 
2024-11-22 00:12:37.857684: Epoch time: 52.38 s 
2024-11-22 00:12:38.815166:  
2024-11-22 00:12:38.815302: Epoch 841 
2024-11-22 00:12:38.815374: Current learning rate: 0.00191 
2024-11-22 00:13:31.294022: train_loss -0.9793 
2024-11-22 00:13:31.294167: val_loss -0.8958 
2024-11-22 00:13:31.294220: Pseudo dice [np.float32(0.9109)] 
2024-11-22 00:13:31.294276: Epoch time: 52.48 s 
2024-11-22 00:13:32.299220:  
2024-11-22 00:13:32.299400: Epoch 842 
2024-11-22 00:13:32.299493: Current learning rate: 0.0019 
2024-11-22 00:14:24.995592: train_loss -0.9789 
2024-11-22 00:14:24.995729: val_loss -0.8966 
2024-11-22 00:14:24.995780: Pseudo dice [np.float32(0.9114)] 
2024-11-22 00:14:24.995834: Epoch time: 52.7 s 
2024-11-22 00:14:25.962408:  
2024-11-22 00:14:25.962609: Epoch 843 
2024-11-22 00:14:25.962677: Current learning rate: 0.00189 
2024-11-22 00:15:18.570773: train_loss -0.9796 
2024-11-22 00:15:18.570910: val_loss -0.9015 
2024-11-22 00:15:18.571030: Pseudo dice [np.float32(0.9176)] 
2024-11-22 00:15:18.571084: Epoch time: 52.61 s 
2024-11-22 00:15:19.567338:  
2024-11-22 00:15:19.567510: Epoch 844 
2024-11-22 00:15:19.567594: Current learning rate: 0.00188 
2024-11-22 00:16:12.179573: train_loss -0.9797 
2024-11-22 00:16:12.179689: val_loss -0.9046 
2024-11-22 00:16:12.179741: Pseudo dice [np.float32(0.918)] 
2024-11-22 00:16:12.179797: Epoch time: 52.61 s 
2024-11-22 00:16:13.080123:  
2024-11-22 00:16:13.080252: Epoch 845 
2024-11-22 00:16:13.080319: Current learning rate: 0.00187 
2024-11-22 00:17:05.831145: train_loss -0.9795 
2024-11-22 00:17:05.831307: val_loss -0.8977 
2024-11-22 00:17:05.831358: Pseudo dice [np.float32(0.9133)] 
2024-11-22 00:17:05.831411: Epoch time: 52.75 s 
2024-11-22 00:17:06.749457:  
2024-11-22 00:17:06.749644: Epoch 846 
2024-11-22 00:17:06.749728: Current learning rate: 0.00186 
2024-11-22 00:17:59.506772: train_loss -0.9794 
2024-11-22 00:17:59.506893: val_loss -0.898 
2024-11-22 00:17:59.506944: Pseudo dice [np.float32(0.9128)] 
2024-11-22 00:17:59.506999: Epoch time: 52.76 s 
2024-11-22 00:18:00.385254:  
2024-11-22 00:18:00.385452: Epoch 847 
2024-11-22 00:18:00.385586: Current learning rate: 0.00185 
2024-11-22 00:18:53.002276: train_loss -0.9801 
2024-11-22 00:18:53.002387: val_loss -0.8987 
2024-11-22 00:18:53.002453: Pseudo dice [np.float32(0.9122)] 
2024-11-22 00:18:53.002541: Epoch time: 52.62 s 
2024-11-22 00:18:53.931085:  
2024-11-22 00:18:53.931237: Epoch 848 
2024-11-22 00:18:53.931302: Current learning rate: 0.00184 
2024-11-22 00:19:46.446275: train_loss -0.9794 
2024-11-22 00:19:46.446410: val_loss -0.8971 
2024-11-22 00:19:46.446481: Pseudo dice [np.float32(0.9133)] 
2024-11-22 00:19:46.446552: Epoch time: 52.52 s 
2024-11-22 00:19:47.462135:  
2024-11-22 00:19:47.462293: Epoch 849 
2024-11-22 00:19:47.462379: Current learning rate: 0.00182 
2024-11-22 00:20:40.253121: train_loss -0.9799 
2024-11-22 00:20:40.253244: val_loss -0.9007 
2024-11-22 00:20:40.253295: Pseudo dice [np.float32(0.9152)] 
2024-11-22 00:20:40.253350: Epoch time: 52.79 s 
2024-11-22 00:20:41.500885:  
2024-11-22 00:20:41.501025: Epoch 850 
2024-11-22 00:20:41.501093: Current learning rate: 0.00181 
2024-11-22 00:21:34.189939: train_loss -0.9801 
2024-11-22 00:21:34.190064: val_loss -0.899 
2024-11-22 00:21:34.190112: Pseudo dice [np.float32(0.9136)] 
2024-11-22 00:21:34.190182: Epoch time: 52.69 s 
2024-11-22 00:21:35.382205:  
2024-11-22 00:21:35.382358: Epoch 851 
2024-11-22 00:21:35.382432: Current learning rate: 0.0018 
2024-11-22 00:22:27.952848: train_loss -0.9807 
2024-11-22 00:22:27.952980: val_loss -0.8993 
2024-11-22 00:22:27.953040: Pseudo dice [np.float32(0.9143)] 
2024-11-22 00:22:27.953106: Epoch time: 52.57 s 
2024-11-22 00:22:28.840827:  
2024-11-22 00:22:28.841004: Epoch 852 
2024-11-22 00:22:28.841090: Current learning rate: 0.00179 
2024-11-22 00:23:21.618966: train_loss -0.9797 
2024-11-22 00:23:21.619084: val_loss -0.9024 
2024-11-22 00:23:21.619135: Pseudo dice [np.float32(0.917)] 
2024-11-22 00:23:21.619190: Epoch time: 52.78 s 
2024-11-22 00:23:22.501365:  
2024-11-22 00:23:22.501550: Epoch 853 
2024-11-22 00:23:22.501636: Current learning rate: 0.00178 
2024-11-22 00:24:15.156998: train_loss -0.9798 
2024-11-22 00:24:15.157126: val_loss -0.899 
2024-11-22 00:24:15.157186: Pseudo dice [np.float32(0.915)] 
2024-11-22 00:24:15.157251: Epoch time: 52.66 s 
2024-11-22 00:24:16.073862:  
2024-11-22 00:24:16.074110: Epoch 854 
2024-11-22 00:24:16.074177: Current learning rate: 0.00177 
2024-11-22 00:25:08.751328: train_loss -0.9802 
2024-11-22 00:25:08.751455: val_loss -0.8998 
2024-11-22 00:25:08.751527: Pseudo dice [np.float32(0.9159)] 
2024-11-22 00:25:08.751595: Epoch time: 52.68 s 
2024-11-22 00:25:09.765792:  
2024-11-22 00:25:09.765916: Epoch 855 
2024-11-22 00:25:09.765994: Current learning rate: 0.00176 
2024-11-22 00:26:02.278788: train_loss -0.9805 
2024-11-22 00:26:02.278965: val_loss -0.9034 
2024-11-22 00:26:02.279035: Pseudo dice [np.float32(0.9175)] 
2024-11-22 00:26:02.279127: Epoch time: 52.51 s 
2024-11-22 00:26:02.279189: Yayy! New best EMA pseudo Dice: 0.9147999882698059 
2024-11-22 00:26:03.537089:  
2024-11-22 00:26:03.537233: Epoch 856 
2024-11-22 00:26:03.537306: Current learning rate: 0.00175 
2024-11-22 00:26:56.354059: train_loss -0.98 
2024-11-22 00:26:56.354166: val_loss -0.8999 
2024-11-22 00:26:56.354233: Pseudo dice [np.float32(0.9145)] 
2024-11-22 00:26:56.354313: Epoch time: 52.82 s 
2024-11-22 00:26:57.311180:  
2024-11-22 00:26:57.311383: Epoch 857 
2024-11-22 00:26:57.311455: Current learning rate: 0.00174 
2024-11-22 00:27:50.240369: train_loss -0.9806 
2024-11-22 00:27:50.240525: val_loss -0.8981 
2024-11-22 00:27:50.240604: Pseudo dice [np.float32(0.9143)] 
2024-11-22 00:27:50.240656: Epoch time: 52.93 s 
2024-11-22 00:27:51.132626:  
2024-11-22 00:27:51.132812: Epoch 858 
2024-11-22 00:27:51.132923: Current learning rate: 0.00173 
2024-11-22 00:28:43.410821: train_loss -0.9805 
2024-11-22 00:28:43.410973: val_loss -0.8978 
2024-11-22 00:28:43.411040: Pseudo dice [np.float32(0.9119)] 
2024-11-22 00:28:43.411094: Epoch time: 52.28 s 
2024-11-22 00:28:44.422105:  
2024-11-22 00:28:44.422239: Epoch 859 
2024-11-22 00:28:44.422327: Current learning rate: 0.00172 
2024-11-22 00:29:36.858295: train_loss -0.9806 
2024-11-22 00:29:36.858462: val_loss -0.8957 
2024-11-22 00:29:36.858535: Pseudo dice [np.float32(0.9104)] 
2024-11-22 00:29:36.858604: Epoch time: 52.44 s 
2024-11-22 00:29:37.837905:  
2024-11-22 00:29:37.838073: Epoch 860 
2024-11-22 00:29:37.838143: Current learning rate: 0.0017 
2024-11-22 00:30:30.344094: train_loss -0.9802 
2024-11-22 00:30:30.344255: val_loss -0.9046 
2024-11-22 00:30:30.344322: Pseudo dice [np.float32(0.9188)] 
2024-11-22 00:30:30.344392: Epoch time: 52.51 s 
2024-11-22 00:30:31.367941:  
2024-11-22 00:30:31.368291: Epoch 861 
2024-11-22 00:30:31.368378: Current learning rate: 0.00169 
2024-11-22 00:31:23.862616: train_loss -0.9803 
2024-11-22 00:31:23.862736: val_loss -0.8989 
2024-11-22 00:31:23.862786: Pseudo dice [np.float32(0.9131)] 
2024-11-22 00:31:23.862857: Epoch time: 52.5 s 
2024-11-22 00:31:24.846046:  
2024-11-22 00:31:24.846237: Epoch 862 
2024-11-22 00:31:24.846308: Current learning rate: 0.00168 
2024-11-22 00:32:17.465871: train_loss -0.9816 
2024-11-22 00:32:17.465996: val_loss -0.9026 
2024-11-22 00:32:17.466059: Pseudo dice [np.float32(0.9165)] 
2024-11-22 00:32:17.466125: Epoch time: 52.62 s 
2024-11-22 00:32:18.697178:  
2024-11-22 00:32:18.697348: Epoch 863 
2024-11-22 00:32:18.697448: Current learning rate: 0.00167 
2024-11-22 00:33:11.133243: train_loss -0.9805 
2024-11-22 00:33:11.133384: val_loss -0.8931 
2024-11-22 00:33:11.133433: Pseudo dice [np.float32(0.9091)] 
2024-11-22 00:33:11.133500: Epoch time: 52.44 s 
2024-11-22 00:33:12.002753:  
2024-11-22 00:33:12.002916: Epoch 864 
2024-11-22 00:33:12.002984: Current learning rate: 0.00166 
2024-11-22 00:34:04.414304: train_loss -0.9796 
2024-11-22 00:34:04.414451: val_loss -0.899 
2024-11-22 00:34:04.414524: Pseudo dice [np.float32(0.9141)] 
2024-11-22 00:34:04.414592: Epoch time: 52.41 s 
2024-11-22 00:34:05.324679:  
2024-11-22 00:34:05.324799: Epoch 865 
2024-11-22 00:34:05.324874: Current learning rate: 0.00165 
2024-11-22 00:34:57.643637: train_loss -0.98 
2024-11-22 00:34:57.643753: val_loss -0.9031 
2024-11-22 00:34:57.643801: Pseudo dice [np.float32(0.918)] 
2024-11-22 00:34:57.643854: Epoch time: 52.32 s 
2024-11-22 00:34:58.592002:  
2024-11-22 00:34:58.592171: Epoch 866 
2024-11-22 00:34:58.592238: Current learning rate: 0.00164 
2024-11-22 00:35:51.209580: train_loss -0.9801 
2024-11-22 00:35:51.209734: val_loss -0.904 
2024-11-22 00:35:51.209820: Pseudo dice [np.float32(0.9188)] 
2024-11-22 00:35:51.209913: Epoch time: 52.62 s 
2024-11-22 00:35:51.209993: Yayy! New best EMA pseudo Dice: 0.914900004863739 
2024-11-22 00:35:52.541093:  
2024-11-22 00:35:52.541236: Epoch 867 
2024-11-22 00:35:52.541304: Current learning rate: 0.00163 
2024-11-22 00:36:44.893411: train_loss -0.9806 
2024-11-22 00:36:44.893531: val_loss -0.9014 
2024-11-22 00:36:44.893579: Pseudo dice [np.float32(0.9154)] 
2024-11-22 00:36:44.893632: Epoch time: 52.35 s 
2024-11-22 00:36:44.893675: Yayy! New best EMA pseudo Dice: 0.914900004863739 
2024-11-22 00:36:46.096738:  
2024-11-22 00:36:46.096890: Epoch 868 
2024-11-22 00:36:46.096968: Current learning rate: 0.00162 
2024-11-22 00:37:38.292634: train_loss -0.9801 
2024-11-22 00:37:38.292763: val_loss -0.8988 
2024-11-22 00:37:38.292811: Pseudo dice [np.float32(0.9152)] 
2024-11-22 00:37:38.292883: Epoch time: 52.2 s 
2024-11-22 00:37:38.292926: Yayy! New best EMA pseudo Dice: 0.9150000214576721 
2024-11-22 00:37:39.555681:  
2024-11-22 00:37:39.555921: Epoch 869 
2024-11-22 00:37:39.556005: Current learning rate: 0.00161 
2024-11-22 00:38:31.893117: train_loss -0.98 
2024-11-22 00:38:31.893237: val_loss -0.9011 
2024-11-22 00:38:31.893286: Pseudo dice [np.float32(0.9162)] 
2024-11-22 00:38:31.893339: Epoch time: 52.34 s 
2024-11-22 00:38:31.893385: Yayy! New best EMA pseudo Dice: 0.9150999784469604 
2024-11-22 00:38:33.197792:  
2024-11-22 00:38:33.197996: Epoch 870 
2024-11-22 00:38:33.198083: Current learning rate: 0.00159 
2024-11-22 00:39:25.557726: train_loss -0.9805 
2024-11-22 00:39:25.557891: val_loss -0.8983 
2024-11-22 00:39:25.557942: Pseudo dice [np.float32(0.9129)] 
2024-11-22 00:39:25.557996: Epoch time: 52.36 s 
2024-11-22 00:39:26.504053:  
2024-11-22 00:39:26.504219: Epoch 871 
2024-11-22 00:39:26.504307: Current learning rate: 0.00158 
2024-11-22 00:40:18.785613: train_loss -0.9805 
2024-11-22 00:40:18.785742: val_loss -0.9012 
2024-11-22 00:40:18.785803: Pseudo dice [np.float32(0.9172)] 
2024-11-22 00:40:18.785894: Epoch time: 52.28 s 
2024-11-22 00:40:18.785971: Yayy! New best EMA pseudo Dice: 0.9150999784469604 
2024-11-22 00:40:20.273713:  
2024-11-22 00:40:20.273855: Epoch 872 
2024-11-22 00:40:20.273921: Current learning rate: 0.00157 
2024-11-22 00:41:12.396658: train_loss -0.9805 
2024-11-22 00:41:12.396767: val_loss -0.8939 
2024-11-22 00:41:12.396840: Pseudo dice [np.float32(0.9107)] 
2024-11-22 00:41:12.396927: Epoch time: 52.12 s 
2024-11-22 00:41:13.333412:  
2024-11-22 00:41:13.333560: Epoch 873 
2024-11-22 00:41:13.333627: Current learning rate: 0.00156 
2024-11-22 00:42:05.654942: train_loss -0.9807 
2024-11-22 00:42:05.655098: val_loss -0.8987 
2024-11-22 00:42:05.655162: Pseudo dice [np.float32(0.913)] 
2024-11-22 00:42:05.655216: Epoch time: 52.32 s 
2024-11-22 00:42:06.551067:  
2024-11-22 00:42:06.551286: Epoch 874 
2024-11-22 00:42:06.551363: Current learning rate: 0.00155 
2024-11-22 00:42:59.334318: train_loss -0.9804 
2024-11-22 00:42:59.334441: val_loss -0.8972 
2024-11-22 00:42:59.334521: Pseudo dice [np.float32(0.912)] 
2024-11-22 00:42:59.334589: Epoch time: 52.78 s 
2024-11-22 00:43:00.580158:  
2024-11-22 00:43:00.580306: Epoch 875 
2024-11-22 00:43:00.580410: Current learning rate: 0.00154 
2024-11-22 00:43:53.386342: train_loss -0.981 
2024-11-22 00:43:53.386458: val_loss -0.895 
2024-11-22 00:43:53.386562: Pseudo dice [np.float32(0.9107)] 
2024-11-22 00:43:53.386617: Epoch time: 52.81 s 
2024-11-22 00:43:54.281434:  
2024-11-22 00:43:54.281582: Epoch 876 
2024-11-22 00:43:54.281652: Current learning rate: 0.00153 
2024-11-22 00:44:46.952620: train_loss -0.9808 
2024-11-22 00:44:46.952735: val_loss -0.8976 
2024-11-22 00:44:46.952784: Pseudo dice [np.float32(0.9131)] 
2024-11-22 00:44:46.952835: Epoch time: 52.67 s 
2024-11-22 00:44:47.965038:  
2024-11-22 00:44:47.965220: Epoch 877 
2024-11-22 00:44:47.965304: Current learning rate: 0.00152 
2024-11-22 00:45:40.573416: train_loss -0.9808 
2024-11-22 00:45:40.573616: val_loss -0.905 
2024-11-22 00:45:40.573669: Pseudo dice [np.float32(0.9188)] 
2024-11-22 00:45:40.573743: Epoch time: 52.61 s 
2024-11-22 00:45:41.494716:  
2024-11-22 00:45:41.494857: Epoch 878 
2024-11-22 00:45:41.494925: Current learning rate: 0.00151 
2024-11-22 00:46:34.307765: train_loss -0.9809 
2024-11-22 00:46:34.307902: val_loss -0.8985 
2024-11-22 00:46:34.307954: Pseudo dice [np.float32(0.9122)] 
2024-11-22 00:46:34.308024: Epoch time: 52.81 s 
2024-11-22 00:46:35.255463:  
2024-11-22 00:46:35.255647: Epoch 879 
2024-11-22 00:46:35.255714: Current learning rate: 0.00149 
2024-11-22 00:47:27.793680: train_loss -0.9813 
2024-11-22 00:47:27.793810: val_loss -0.898 
2024-11-22 00:47:27.793872: Pseudo dice [np.float32(0.913)] 
2024-11-22 00:47:27.793938: Epoch time: 52.54 s 
2024-11-22 00:47:28.747102:  
2024-11-22 00:47:28.747270: Epoch 880 
2024-11-22 00:47:28.747345: Current learning rate: 0.00148 
2024-11-22 00:48:21.277067: train_loss -0.9808 
2024-11-22 00:48:21.277203: val_loss -0.8958 
2024-11-22 00:48:21.277317: Pseudo dice [np.float32(0.911)] 
2024-11-22 00:48:21.277437: Epoch time: 52.53 s 
2024-11-22 00:48:22.237706:  
2024-11-22 00:48:22.237888: Epoch 881 
2024-11-22 00:48:22.237995: Current learning rate: 0.00147 
2024-11-22 00:49:14.769476: train_loss -0.9813 
2024-11-22 00:49:14.769663: val_loss -0.9007 
2024-11-22 00:49:14.769749: Pseudo dice [np.float32(0.9157)] 
2024-11-22 00:49:14.769823: Epoch time: 52.53 s 
2024-11-22 00:49:15.779454:  
2024-11-22 00:49:15.779598: Epoch 882 
2024-11-22 00:49:15.779933: Current learning rate: 0.00146 
2024-11-22 00:50:08.347219: train_loss -0.981 
2024-11-22 00:50:08.347337: val_loss -0.8913 
2024-11-22 00:50:08.347387: Pseudo dice [np.float32(0.9072)] 
2024-11-22 00:50:08.347439: Epoch time: 52.57 s 
2024-11-22 00:50:09.279739:  
2024-11-22 00:50:09.279876: Epoch 883 
2024-11-22 00:50:09.279944: Current learning rate: 0.00145 
2024-11-22 00:51:01.670052: train_loss -0.9808 
2024-11-22 00:51:01.670188: val_loss -0.8966 
2024-11-22 00:51:01.670241: Pseudo dice [np.float32(0.9116)] 
2024-11-22 00:51:01.670295: Epoch time: 52.39 s 
2024-11-22 00:51:02.645269:  
2024-11-22 00:51:02.645401: Epoch 884 
2024-11-22 00:51:02.645512: Current learning rate: 0.00144 
2024-11-22 00:51:55.164041: train_loss -0.9815 
2024-11-22 00:51:55.164237: val_loss -0.9017 
2024-11-22 00:51:55.164330: Pseudo dice [np.float32(0.9159)] 
2024-11-22 00:51:55.164432: Epoch time: 52.52 s 
2024-11-22 00:51:56.196143:  
2024-11-22 00:51:56.196356: Epoch 885 
2024-11-22 00:51:56.196439: Current learning rate: 0.00143 
2024-11-22 00:52:48.502881: train_loss -0.9805 
2024-11-22 00:52:48.503151: val_loss -0.9014 
2024-11-22 00:52:48.503231: Pseudo dice [np.float32(0.9157)] 
2024-11-22 00:52:48.503308: Epoch time: 52.31 s 
2024-11-22 00:52:49.504973:  
2024-11-22 00:52:49.505108: Epoch 886 
2024-11-22 00:52:49.505175: Current learning rate: 0.00142 
2024-11-22 00:53:42.152105: train_loss -0.9804 
2024-11-22 00:53:42.152276: val_loss -0.8972 
2024-11-22 00:53:42.152342: Pseudo dice [np.float32(0.9128)] 
2024-11-22 00:53:42.152423: Epoch time: 52.65 s 
2024-11-22 00:53:43.439859:  
2024-11-22 00:53:43.440089: Epoch 887 
2024-11-22 00:53:43.440286: Current learning rate: 0.00141 
2024-11-22 00:54:35.858997: train_loss -0.9809 
2024-11-22 00:54:35.859157: val_loss -0.8996 
2024-11-22 00:54:35.859234: Pseudo dice [np.float32(0.9154)] 
2024-11-22 00:54:35.859317: Epoch time: 52.42 s 
2024-11-22 00:54:36.819229:  
2024-11-22 00:54:36.819368: Epoch 888 
2024-11-22 00:54:36.819437: Current learning rate: 0.00139 
2024-11-22 00:55:29.365103: train_loss -0.9809 
2024-11-22 00:55:29.365239: val_loss -0.8966 
2024-11-22 00:55:29.365291: Pseudo dice [np.float32(0.9116)] 
2024-11-22 00:55:29.365345: Epoch time: 52.55 s 
2024-11-22 00:55:30.331764:  
2024-11-22 00:55:30.331963: Epoch 889 
2024-11-22 00:55:30.332072: Current learning rate: 0.00138 
2024-11-22 00:56:22.697809: train_loss -0.9812 
2024-11-22 00:56:22.697957: val_loss -0.9018 
2024-11-22 00:56:22.698031: Pseudo dice [np.float32(0.9161)] 
2024-11-22 00:56:22.698115: Epoch time: 52.37 s 
2024-11-22 00:56:23.558010:  
2024-11-22 00:56:23.558250: Epoch 890 
2024-11-22 00:56:23.558325: Current learning rate: 0.00137 
2024-11-22 00:57:15.892674: train_loss -0.9811 
2024-11-22 00:57:15.892812: val_loss -0.8952 
2024-11-22 00:57:15.892865: Pseudo dice [np.float32(0.9115)] 
2024-11-22 00:57:15.892952: Epoch time: 52.34 s 
2024-11-22 00:57:16.817728:  
2024-11-22 00:57:16.817918: Epoch 891 
2024-11-22 00:57:16.817985: Current learning rate: 0.00136 
2024-11-22 00:58:09.552252: train_loss -0.9811 
2024-11-22 00:58:09.552370: val_loss -0.8966 
2024-11-22 00:58:09.552455: Pseudo dice [np.float32(0.9108)] 
2024-11-22 00:58:09.552594: Epoch time: 52.74 s 
2024-11-22 00:58:10.480160:  
2024-11-22 00:58:10.480357: Epoch 892 
2024-11-22 00:58:10.480432: Current learning rate: 0.00135 
2024-11-22 00:59:03.059238: train_loss -0.9812 
2024-11-22 00:59:03.059435: val_loss -0.8982 
2024-11-22 00:59:03.059510: Pseudo dice [np.float32(0.914)] 
2024-11-22 00:59:03.059577: Epoch time: 52.58 s 
2024-11-22 00:59:04.034780:  
2024-11-22 00:59:04.034962: Epoch 893 
2024-11-22 00:59:04.035046: Current learning rate: 0.00134 
2024-11-22 00:59:56.928994: train_loss -0.981 
2024-11-22 00:59:56.929123: val_loss -0.8913 
2024-11-22 00:59:56.929185: Pseudo dice [np.float32(0.9086)] 
2024-11-22 00:59:56.929252: Epoch time: 52.9 s 
2024-11-22 00:59:57.870978:  
2024-11-22 00:59:57.871209: Epoch 894 
2024-11-22 00:59:57.871327: Current learning rate: 0.00133 
2024-11-22 01:00:50.791021: train_loss -0.9821 
2024-11-22 01:00:50.791157: val_loss -0.8977 
2024-11-22 01:00:50.791206: Pseudo dice [np.float32(0.9127)] 
2024-11-22 01:00:50.791259: Epoch time: 52.92 s 
2024-11-22 01:00:51.702451:  
2024-11-22 01:00:51.702630: Epoch 895 
2024-11-22 01:00:51.702733: Current learning rate: 0.00132 
2024-11-22 01:01:44.341937: train_loss -0.9815 
2024-11-22 01:01:44.342072: val_loss -0.898 
2024-11-22 01:01:44.342131: Pseudo dice [np.float32(0.9141)] 
2024-11-22 01:01:44.342188: Epoch time: 52.64 s 
2024-11-22 01:01:45.313747:  
2024-11-22 01:01:45.313910: Epoch 896 
2024-11-22 01:01:45.314011: Current learning rate: 0.0013 
2024-11-22 01:02:38.035251: train_loss -0.9814 
2024-11-22 01:02:38.035359: val_loss -0.9036 
2024-11-22 01:02:38.035408: Pseudo dice [np.float32(0.9188)] 
2024-11-22 01:02:38.035517: Epoch time: 52.72 s 
2024-11-22 01:02:38.936502:  
2024-11-22 01:02:38.936674: Epoch 897 
2024-11-22 01:02:38.936743: Current learning rate: 0.00129 
2024-11-22 01:03:31.575953: train_loss -0.9816 
2024-11-22 01:03:31.576108: val_loss -0.903 
2024-11-22 01:03:31.576186: Pseudo dice [np.float32(0.9173)] 
2024-11-22 01:03:31.576272: Epoch time: 52.64 s 
2024-11-22 01:03:32.596390:  
2024-11-22 01:03:32.596589: Epoch 898 
2024-11-22 01:03:32.596713: Current learning rate: 0.00128 
2024-11-22 01:04:24.832405: train_loss -0.9813 
2024-11-22 01:04:24.832661: val_loss -0.9019 
2024-11-22 01:04:24.832728: Pseudo dice [np.float32(0.9156)] 
2024-11-22 01:04:24.832806: Epoch time: 52.24 s 
2024-11-22 01:04:25.877412:  
2024-11-22 01:04:25.877568: Epoch 899 
2024-11-22 01:04:25.877689: Current learning rate: 0.00127 
2024-11-22 01:05:18.249219: train_loss -0.9814 
2024-11-22 01:05:18.249363: val_loss -0.9026 
2024-11-22 01:05:18.249443: Pseudo dice [np.float32(0.9181)] 
2024-11-22 01:05:18.249555: Epoch time: 52.37 s 
2024-11-22 01:05:19.800217:  
2024-11-22 01:05:19.800351: Epoch 900 
2024-11-22 01:05:19.800423: Current learning rate: 0.00126 
2024-11-22 01:06:12.345576: train_loss -0.9818 
2024-11-22 01:06:12.345682: val_loss -0.9002 
2024-11-22 01:06:12.345728: Pseudo dice [np.float32(0.9153)] 
2024-11-22 01:06:12.345800: Epoch time: 52.55 s 
2024-11-22 01:06:13.309772:  
2024-11-22 01:06:13.309937: Epoch 901 
2024-11-22 01:06:13.310003: Current learning rate: 0.00125 
2024-11-22 01:07:05.919883: train_loss -0.981 
2024-11-22 01:07:05.920027: val_loss -0.8969 
2024-11-22 01:07:05.920092: Pseudo dice [np.float32(0.9116)] 
2024-11-22 01:07:05.920203: Epoch time: 52.61 s 
2024-11-22 01:07:06.811517:  
2024-11-22 01:07:06.811748: Epoch 902 
2024-11-22 01:07:06.811821: Current learning rate: 0.00124 
2024-11-22 01:07:59.033225: train_loss -0.9812 
2024-11-22 01:07:59.033354: val_loss -0.9012 
2024-11-22 01:07:59.033416: Pseudo dice [np.float32(0.9156)] 
2024-11-22 01:07:59.033495: Epoch time: 52.22 s 
2024-11-22 01:07:59.956867:  
2024-11-22 01:07:59.957044: Epoch 903 
2024-11-22 01:07:59.957139: Current learning rate: 0.00122 
2024-11-22 01:08:52.380873: train_loss -0.9819 
2024-11-22 01:08:52.381009: val_loss -0.8952 
2024-11-22 01:08:52.381058: Pseudo dice [np.float32(0.9119)] 
2024-11-22 01:08:52.381111: Epoch time: 52.42 s 
2024-11-22 01:08:53.385335:  
2024-11-22 01:08:53.385530: Epoch 904 
2024-11-22 01:08:53.385615: Current learning rate: 0.00121 
2024-11-22 01:09:45.652292: train_loss -0.9822 
2024-11-22 01:09:45.652612: val_loss -0.9016 
2024-11-22 01:09:45.652687: Pseudo dice [np.float32(0.9158)] 
2024-11-22 01:09:45.652740: Epoch time: 52.27 s 
2024-11-22 01:09:46.594376:  
2024-11-22 01:09:46.594516: Epoch 905 
2024-11-22 01:09:46.594584: Current learning rate: 0.0012 
2024-11-22 01:10:38.787691: train_loss -0.9813 
2024-11-22 01:10:38.787823: val_loss -0.8896 
2024-11-22 01:10:38.787870: Pseudo dice [np.float32(0.9069)] 
2024-11-22 01:10:38.787923: Epoch time: 52.19 s 
2024-11-22 01:10:39.783529:  
2024-11-22 01:10:39.783660: Epoch 906 
2024-11-22 01:10:39.783738: Current learning rate: 0.00119 
2024-11-22 01:11:32.085637: train_loss -0.9817 
2024-11-22 01:11:32.085753: val_loss -0.8937 
2024-11-22 01:11:32.085799: Pseudo dice [np.float32(0.9098)] 
2024-11-22 01:11:32.085850: Epoch time: 52.3 s 
2024-11-22 01:11:33.016706:  
2024-11-22 01:11:33.016906: Epoch 907 
2024-11-22 01:11:33.017017: Current learning rate: 0.00118 
2024-11-22 01:12:25.663468: train_loss -0.9819 
2024-11-22 01:12:25.663646: val_loss -0.9005 
2024-11-22 01:12:25.663735: Pseudo dice [np.float32(0.9156)] 
2024-11-22 01:12:25.663823: Epoch time: 52.65 s 
2024-11-22 01:12:26.566877:  
2024-11-22 01:12:26.567019: Epoch 908 
2024-11-22 01:12:26.567100: Current learning rate: 0.00117 
2024-11-22 01:13:19.216374: train_loss -0.9815 
2024-11-22 01:13:19.216510: val_loss -0.8984 
2024-11-22 01:13:19.216557: Pseudo dice [np.float32(0.9141)] 
2024-11-22 01:13:19.216608: Epoch time: 52.65 s 
2024-11-22 01:13:20.170250:  
2024-11-22 01:13:20.170441: Epoch 909 
2024-11-22 01:13:20.170531: Current learning rate: 0.00116 
2024-11-22 01:14:12.893148: train_loss -0.9821 
2024-11-22 01:14:12.893281: val_loss -0.9017 
2024-11-22 01:14:12.893331: Pseudo dice [np.float32(0.9158)] 
2024-11-22 01:14:12.893411: Epoch time: 52.72 s 
2024-11-22 01:14:13.827320:  
2024-11-22 01:14:13.827491: Epoch 910 
2024-11-22 01:14:13.827575: Current learning rate: 0.00115 
2024-11-22 01:15:06.382032: train_loss -0.9819 
2024-11-22 01:15:06.382159: val_loss -0.8958 
2024-11-22 01:15:06.382250: Pseudo dice [np.float32(0.9126)] 
2024-11-22 01:15:06.382307: Epoch time: 52.56 s 
2024-11-22 01:15:07.289697:  
2024-11-22 01:15:07.289861: Epoch 911 
2024-11-22 01:15:07.289946: Current learning rate: 0.00113 
2024-11-22 01:15:59.714022: train_loss -0.9816 
2024-11-22 01:15:59.714133: val_loss -0.8993 
2024-11-22 01:15:59.714185: Pseudo dice [np.float32(0.9147)] 
2024-11-22 01:15:59.714264: Epoch time: 52.43 s 
2024-11-22 01:16:00.710270:  
2024-11-22 01:16:00.710424: Epoch 912 
2024-11-22 01:16:00.710522: Current learning rate: 0.00112 
2024-11-22 01:16:53.183109: train_loss -0.9809 
2024-11-22 01:16:53.183224: val_loss -0.8978 
2024-11-22 01:16:53.183303: Pseudo dice [np.float32(0.9127)] 
2024-11-22 01:16:53.183370: Epoch time: 52.47 s 
2024-11-22 01:16:54.121822:  
2024-11-22 01:16:54.121968: Epoch 913 
2024-11-22 01:16:54.122036: Current learning rate: 0.00111 
2024-11-22 01:17:46.530969: train_loss -0.9817 
2024-11-22 01:17:46.531089: val_loss -0.8952 
2024-11-22 01:17:46.531141: Pseudo dice [np.float32(0.9119)] 
2024-11-22 01:17:46.531197: Epoch time: 52.41 s 
2024-11-22 01:17:47.448596:  
2024-11-22 01:17:47.448756: Epoch 914 
2024-11-22 01:17:47.448840: Current learning rate: 0.0011 
2024-11-22 01:18:39.851857: train_loss -0.9821 
2024-11-22 01:18:39.851979: val_loss -0.9014 
2024-11-22 01:18:39.852029: Pseudo dice [np.float32(0.9165)] 
2024-11-22 01:18:39.852084: Epoch time: 52.4 s 
2024-11-22 01:18:40.825803:  
2024-11-22 01:18:40.825965: Epoch 915 
2024-11-22 01:18:40.826045: Current learning rate: 0.00109 
2024-11-22 01:19:33.165944: train_loss -0.9818 
2024-11-22 01:19:33.166077: val_loss -0.9014 
2024-11-22 01:19:33.166139: Pseudo dice [np.float32(0.9172)] 
2024-11-22 01:19:33.166192: Epoch time: 52.34 s 
2024-11-22 01:19:34.076936:  
2024-11-22 01:19:34.077070: Epoch 916 
2024-11-22 01:19:34.077136: Current learning rate: 0.00108 
2024-11-22 01:20:26.523999: train_loss -0.9816 
2024-11-22 01:20:26.524132: val_loss -0.8957 
2024-11-22 01:20:26.524183: Pseudo dice [np.float32(0.9134)] 
2024-11-22 01:20:26.524239: Epoch time: 52.45 s 
2024-11-22 01:20:27.409924:  
2024-11-22 01:20:27.410074: Epoch 917 
2024-11-22 01:20:27.410145: Current learning rate: 0.00106 
2024-11-22 01:21:20.167330: train_loss -0.9821 
2024-11-22 01:21:20.167443: val_loss -0.8995 
2024-11-22 01:21:20.167555: Pseudo dice [np.float32(0.9158)] 
2024-11-22 01:21:20.167626: Epoch time: 52.76 s 
2024-11-22 01:21:21.027564:  
2024-11-22 01:21:21.027698: Epoch 918 
2024-11-22 01:21:21.027764: Current learning rate: 0.00105 
2024-11-22 01:22:13.791427: train_loss -0.9816 
2024-11-22 01:22:13.791564: val_loss -0.8992 
2024-11-22 01:22:13.791626: Pseudo dice [np.float32(0.9142)] 
2024-11-22 01:22:13.791693: Epoch time: 52.76 s 
2024-11-22 01:22:14.828061:  
2024-11-22 01:22:14.828230: Epoch 919 
2024-11-22 01:22:14.828315: Current learning rate: 0.00104 
2024-11-22 01:23:07.267050: train_loss -0.9818 
2024-11-22 01:23:07.267185: val_loss -0.9028 
2024-11-22 01:23:07.267252: Pseudo dice [np.float32(0.9176)] 
2024-11-22 01:23:07.267322: Epoch time: 52.44 s 
2024-11-22 01:23:08.294693:  
2024-11-22 01:23:08.294873: Epoch 920 
2024-11-22 01:23:08.294961: Current learning rate: 0.00103 
2024-11-22 01:24:00.237917: train_loss -0.9818 
2024-11-22 01:24:00.238064: val_loss -0.9001 
2024-11-22 01:24:00.238146: Pseudo dice [np.float32(0.9156)] 
2024-11-22 01:24:00.238217: Epoch time: 51.94 s 
2024-11-22 01:24:01.239883:  
2024-11-22 01:24:01.240042: Epoch 921 
2024-11-22 01:24:01.240143: Current learning rate: 0.00102 
2024-11-22 01:24:53.672192: train_loss -0.9816 
2024-11-22 01:24:53.672365: val_loss -0.8973 
2024-11-22 01:24:53.672433: Pseudo dice [np.float32(0.9131)] 
2024-11-22 01:24:53.672534: Epoch time: 52.43 s 
2024-11-22 01:24:54.564925:  
2024-11-22 01:24:54.565070: Epoch 922 
2024-11-22 01:24:54.565146: Current learning rate: 0.00101 
2024-11-22 01:25:46.879751: train_loss -0.9821 
2024-11-22 01:25:46.879866: val_loss -0.8992 
2024-11-22 01:25:46.879916: Pseudo dice [np.float32(0.9154)] 
2024-11-22 01:25:46.879968: Epoch time: 52.32 s 
2024-11-22 01:25:48.111942:  
2024-11-22 01:25:48.112141: Epoch 923 
2024-11-22 01:25:48.112214: Current learning rate: 0.001 
2024-11-22 01:26:40.532266: train_loss -0.9823 
2024-11-22 01:26:40.532382: val_loss -0.9046 
2024-11-22 01:26:40.532428: Pseudo dice [np.float32(0.9186)] 
2024-11-22 01:26:40.532511: Epoch time: 52.42 s 
2024-11-22 01:26:41.477095:  
2024-11-22 01:26:41.477283: Epoch 924 
2024-11-22 01:26:41.477362: Current learning rate: 0.00098 
2024-11-22 01:27:33.786602: train_loss -0.9819 
2024-11-22 01:27:33.786716: val_loss -0.903 
2024-11-22 01:27:33.786768: Pseudo dice [np.float32(0.918)] 
2024-11-22 01:27:33.786821: Epoch time: 52.31 s 
2024-11-22 01:27:33.786904: Yayy! New best EMA pseudo Dice: 0.9153000116348267 
2024-11-22 01:27:35.097332:  
2024-11-22 01:27:35.097519: Epoch 925 
2024-11-22 01:27:35.097603: Current learning rate: 0.00097 
2024-11-22 01:28:27.573663: train_loss -0.9825 
2024-11-22 01:28:27.573803: val_loss -0.8921 
2024-11-22 01:28:27.573869: Pseudo dice [np.float32(0.9094)] 
2024-11-22 01:28:27.573940: Epoch time: 52.48 s 
2024-11-22 01:28:28.437274:  
2024-11-22 01:28:28.437448: Epoch 926 
2024-11-22 01:28:28.437539: Current learning rate: 0.00096 
2024-11-22 01:29:20.905184: train_loss -0.9825 
2024-11-22 01:29:20.905318: val_loss -0.8978 
2024-11-22 01:29:20.905377: Pseudo dice [np.float32(0.913)] 
2024-11-22 01:29:20.905451: Epoch time: 52.47 s 
2024-11-22 01:29:21.845670:  
2024-11-22 01:29:21.845859: Epoch 927 
2024-11-22 01:29:21.845960: Current learning rate: 0.00095 
2024-11-22 01:30:14.171776: train_loss -0.9832 
2024-11-22 01:30:14.171914: val_loss -0.9072 
2024-11-22 01:30:14.171965: Pseudo dice [np.float32(0.9216)] 
2024-11-22 01:30:14.172020: Epoch time: 52.33 s 
2024-11-22 01:30:15.082246:  
2024-11-22 01:30:15.082378: Epoch 928 
2024-11-22 01:30:15.082546: Current learning rate: 0.00094 
2024-11-22 01:31:07.543607: train_loss -0.9821 
2024-11-22 01:31:07.543722: val_loss -0.9024 
2024-11-22 01:31:07.543769: Pseudo dice [np.float32(0.9171)] 
2024-11-22 01:31:07.543821: Epoch time: 52.46 s 
2024-11-22 01:31:07.543863: Yayy! New best EMA pseudo Dice: 0.9154000282287598 
2024-11-22 01:31:08.809743:  
2024-11-22 01:31:08.809904: Epoch 929 
2024-11-22 01:31:08.809977: Current learning rate: 0.00092 
2024-11-22 01:32:00.953065: train_loss -0.9828 
2024-11-22 01:32:00.953182: val_loss -0.8952 
2024-11-22 01:32:00.953232: Pseudo dice [np.float32(0.9119)] 
2024-11-22 01:32:00.953286: Epoch time: 52.14 s 
2024-11-22 01:32:01.878001:  
2024-11-22 01:32:01.878116: Epoch 930 
2024-11-22 01:32:01.878258: Current learning rate: 0.00091 
2024-11-22 01:32:54.281879: train_loss -0.9821 
2024-11-22 01:32:54.282020: val_loss -0.8978 
2024-11-22 01:32:54.282087: Pseudo dice [np.float32(0.9128)] 
2024-11-22 01:32:54.282162: Epoch time: 52.4 s 
2024-11-22 01:32:55.199358:  
2024-11-22 01:32:55.199527: Epoch 931 
2024-11-22 01:32:55.199632: Current learning rate: 0.0009 
2024-11-22 01:33:47.812028: train_loss -0.9825 
2024-11-22 01:33:47.812159: val_loss -0.9004 
2024-11-22 01:33:47.812225: Pseudo dice [np.float32(0.9156)] 
2024-11-22 01:33:47.812310: Epoch time: 52.61 s 
2024-11-22 01:33:48.768262:  
2024-11-22 01:33:48.768404: Epoch 932 
2024-11-22 01:33:48.768515: Current learning rate: 0.00089 
2024-11-22 01:34:41.251817: train_loss -0.982 
2024-11-22 01:34:41.251937: val_loss -0.8985 
2024-11-22 01:34:41.252001: Pseudo dice [np.float32(0.9143)] 
2024-11-22 01:34:41.252068: Epoch time: 52.48 s 
2024-11-22 01:34:42.163800:  
2024-11-22 01:34:42.163941: Epoch 933 
2024-11-22 01:34:42.164010: Current learning rate: 0.00088 
2024-11-22 01:35:34.760723: train_loss -0.9831 
2024-11-22 01:35:34.760882: val_loss -0.8947 
2024-11-22 01:35:34.760932: Pseudo dice [np.float32(0.9123)] 
2024-11-22 01:35:34.760986: Epoch time: 52.6 s 
2024-11-22 01:35:35.719141:  
2024-11-22 01:35:35.719287: Epoch 934 
2024-11-22 01:35:35.719354: Current learning rate: 0.00087 
2024-11-22 01:36:28.475011: train_loss -0.9825 
2024-11-22 01:36:28.475147: val_loss -0.9001 
2024-11-22 01:36:28.475198: Pseudo dice [np.float32(0.9156)] 
2024-11-22 01:36:28.475255: Epoch time: 52.76 s 
2024-11-22 01:36:29.699759:  
2024-11-22 01:36:29.699921: Epoch 935 
2024-11-22 01:36:29.700001: Current learning rate: 0.00085 
2024-11-22 01:37:22.298831: train_loss -0.9825 
2024-11-22 01:37:22.298961: val_loss -0.8979 
2024-11-22 01:37:22.299010: Pseudo dice [np.float32(0.9147)] 
2024-11-22 01:37:22.299062: Epoch time: 52.6 s 
2024-11-22 01:37:23.201144:  
2024-11-22 01:37:23.201329: Epoch 936 
2024-11-22 01:37:23.201411: Current learning rate: 0.00084 
2024-11-22 01:38:15.778803: train_loss -0.9829 
2024-11-22 01:38:15.778915: val_loss -0.9053 
2024-11-22 01:38:15.778965: Pseudo dice [np.float32(0.9204)] 
2024-11-22 01:38:15.779019: Epoch time: 52.58 s 
2024-11-22 01:38:16.729374:  
2024-11-22 01:38:16.729604: Epoch 937 
2024-11-22 01:38:16.729671: Current learning rate: 0.00083 
2024-11-22 01:39:08.827262: train_loss -0.9821 
2024-11-22 01:39:08.827452: val_loss -0.8991 
2024-11-22 01:39:08.827526: Pseudo dice [np.float32(0.914)] 
2024-11-22 01:39:08.827596: Epoch time: 52.1 s 
2024-11-22 01:39:09.749591:  
2024-11-22 01:39:09.749742: Epoch 938 
2024-11-22 01:39:09.749810: Current learning rate: 0.00082 
2024-11-22 01:40:02.043226: train_loss -0.9822 
2024-11-22 01:40:02.043365: val_loss -0.8933 
2024-11-22 01:40:02.043418: Pseudo dice [np.float32(0.9087)] 
2024-11-22 01:40:02.043479: Epoch time: 52.29 s 
2024-11-22 01:40:02.985451:  
2024-11-22 01:40:02.985822: Epoch 939 
2024-11-22 01:40:02.985924: Current learning rate: 0.00081 
2024-11-22 01:40:55.430741: train_loss -0.9828 
2024-11-22 01:40:55.430952: val_loss -0.8943 
2024-11-22 01:40:55.431000: Pseudo dice [np.float32(0.9099)] 
2024-11-22 01:40:55.431072: Epoch time: 52.45 s 
2024-11-22 01:40:56.360827:  
2024-11-22 01:40:56.361011: Epoch 940 
2024-11-22 01:40:56.361079: Current learning rate: 0.00079 
2024-11-22 01:41:48.548334: train_loss -0.9832 
2024-11-22 01:41:48.548484: val_loss -0.899 
2024-11-22 01:41:48.548548: Pseudo dice [np.float32(0.9148)] 
2024-11-22 01:41:48.548615: Epoch time: 52.19 s 
2024-11-22 01:41:49.486995:  
2024-11-22 01:41:49.487171: Epoch 941 
2024-11-22 01:41:49.487253: Current learning rate: 0.00078 
2024-11-22 01:42:41.777694: train_loss -0.9827 
2024-11-22 01:42:41.777818: val_loss -0.897 
2024-11-22 01:42:41.777867: Pseudo dice [np.float32(0.912)] 
2024-11-22 01:42:41.777919: Epoch time: 52.29 s 
2024-11-22 01:42:42.705829:  
2024-11-22 01:42:42.706023: Epoch 942 
2024-11-22 01:42:42.706110: Current learning rate: 0.00077 
2024-11-22 01:43:35.176661: train_loss -0.9825 
2024-11-22 01:43:35.176856: val_loss -0.9 
2024-11-22 01:43:35.176925: Pseudo dice [np.float32(0.9145)] 
2024-11-22 01:43:35.176996: Epoch time: 52.47 s 
2024-11-22 01:43:36.195101:  
2024-11-22 01:43:36.195289: Epoch 943 
2024-11-22 01:43:36.195393: Current learning rate: 0.00076 
2024-11-22 01:44:28.527077: train_loss -0.9824 
2024-11-22 01:44:28.527242: val_loss -0.9004 
2024-11-22 01:44:28.527309: Pseudo dice [np.float32(0.9161)] 
2024-11-22 01:44:28.527360: Epoch time: 52.33 s 
2024-11-22 01:44:29.538367:  
2024-11-22 01:44:29.538538: Epoch 944 
2024-11-22 01:44:29.538652: Current learning rate: 0.00075 
2024-11-22 01:45:21.691824: train_loss -0.9827 
2024-11-22 01:45:21.691964: val_loss -0.8956 
2024-11-22 01:45:21.692016: Pseudo dice [np.float32(0.9121)] 
2024-11-22 01:45:21.692071: Epoch time: 52.15 s 
2024-11-22 01:45:22.602914:  
2024-11-22 01:45:22.603057: Epoch 945 
2024-11-22 01:45:22.603123: Current learning rate: 0.00074 
2024-11-22 01:46:15.014137: train_loss -0.9826 
2024-11-22 01:46:15.014243: val_loss -0.8995 
2024-11-22 01:46:15.014289: Pseudo dice [np.float32(0.9154)] 
2024-11-22 01:46:15.014351: Epoch time: 52.41 s 
2024-11-22 01:46:15.951069:  
2024-11-22 01:46:15.951196: Epoch 946 
2024-11-22 01:46:15.951263: Current learning rate: 0.00072 
2024-11-22 01:47:08.486513: train_loss -0.9826 
2024-11-22 01:47:08.486629: val_loss -0.8991 
2024-11-22 01:47:08.486679: Pseudo dice [np.float32(0.9148)] 
2024-11-22 01:47:08.486735: Epoch time: 52.54 s 
2024-11-22 01:47:09.359768:  
2024-11-22 01:47:09.359942: Epoch 947 
2024-11-22 01:47:09.360036: Current learning rate: 0.00071 
2024-11-22 01:48:01.828858: train_loss -0.983 
2024-11-22 01:48:01.828987: val_loss -0.903 
2024-11-22 01:48:01.829058: Pseudo dice [np.float32(0.9179)] 
2024-11-22 01:48:01.829123: Epoch time: 52.47 s 
2024-11-22 01:48:03.112265:  
2024-11-22 01:48:03.112411: Epoch 948 
2024-11-22 01:48:03.112530: Current learning rate: 0.0007 
2024-11-22 01:48:55.582474: train_loss -0.9825 
2024-11-22 01:48:55.582658: val_loss -0.8995 
2024-11-22 01:48:55.582709: Pseudo dice [np.float32(0.9141)] 
2024-11-22 01:48:55.582765: Epoch time: 52.47 s 
2024-11-22 01:48:56.632383:  
2024-11-22 01:48:56.632600: Epoch 949 
2024-11-22 01:48:56.632668: Current learning rate: 0.00069 
2024-11-22 01:49:48.960775: train_loss -0.9826 
2024-11-22 01:49:48.960889: val_loss -0.9016 
2024-11-22 01:49:48.960942: Pseudo dice [np.float32(0.9165)] 
2024-11-22 01:49:48.960995: Epoch time: 52.33 s 
2024-11-22 01:49:50.445717:  
2024-11-22 01:49:50.445858: Epoch 950 
2024-11-22 01:49:50.445953: Current learning rate: 0.00067 
2024-11-22 01:50:43.116179: train_loss -0.9831 
2024-11-22 01:50:43.116347: val_loss -0.8974 
2024-11-22 01:50:43.116413: Pseudo dice [np.float32(0.9137)] 
2024-11-22 01:50:43.116504: Epoch time: 52.67 s 
2024-11-22 01:50:44.022651:  
2024-11-22 01:50:44.022883: Epoch 951 
2024-11-22 01:50:44.022957: Current learning rate: 0.00066 
2024-11-22 01:51:36.672853: train_loss -0.9825 
2024-11-22 01:51:36.672968: val_loss -0.8952 
2024-11-22 01:51:36.673101: Pseudo dice [np.float32(0.9115)] 
2024-11-22 01:51:36.673197: Epoch time: 52.65 s 
2024-11-22 01:51:37.576389:  
2024-11-22 01:51:37.576711: Epoch 952 
2024-11-22 01:51:37.576780: Current learning rate: 0.00065 
2024-11-22 01:52:30.115270: train_loss -0.9827 
2024-11-22 01:52:30.115402: val_loss -0.8989 
2024-11-22 01:52:30.115518: Pseudo dice [np.float32(0.9156)] 
2024-11-22 01:52:30.115624: Epoch time: 52.54 s 
2024-11-22 01:52:31.063715:  
2024-11-22 01:52:31.063869: Epoch 953 
2024-11-22 01:52:31.063938: Current learning rate: 0.00064 
2024-11-22 01:53:23.677807: train_loss -0.9833 
2024-11-22 01:53:23.677920: val_loss -0.901 
2024-11-22 01:53:23.677971: Pseudo dice [np.float32(0.916)] 
2024-11-22 01:53:23.678026: Epoch time: 52.61 s 
2024-11-22 01:53:24.596318:  
2024-11-22 01:53:24.596537: Epoch 954 
2024-11-22 01:53:24.596608: Current learning rate: 0.00063 
2024-11-22 01:54:17.185004: train_loss -0.983 
2024-11-22 01:54:17.185133: val_loss -0.9036 
2024-11-22 01:54:17.185183: Pseudo dice [np.float32(0.9181)] 
2024-11-22 01:54:17.185235: Epoch time: 52.59 s 
2024-11-22 01:54:18.115884:  
2024-11-22 01:54:18.116069: Epoch 955 
2024-11-22 01:54:18.116140: Current learning rate: 0.00061 
2024-11-22 01:55:10.729030: train_loss -0.983 
2024-11-22 01:55:10.729171: val_loss -0.8955 
2024-11-22 01:55:10.729239: Pseudo dice [np.float32(0.9127)] 
2024-11-22 01:55:10.729309: Epoch time: 52.61 s 
2024-11-22 01:55:11.758957:  
2024-11-22 01:55:11.759086: Epoch 956 
2024-11-22 01:55:11.759157: Current learning rate: 0.0006 
2024-11-22 01:56:04.561443: train_loss -0.983 
2024-11-22 01:56:04.561622: val_loss -0.8999 
2024-11-22 01:56:04.561681: Pseudo dice [np.float32(0.9152)] 
2024-11-22 01:56:04.561733: Epoch time: 52.8 s 
2024-11-22 01:56:05.513916:  
2024-11-22 01:56:05.514061: Epoch 957 
2024-11-22 01:56:05.514129: Current learning rate: 0.00059 
2024-11-22 01:56:58.021323: train_loss -0.9829 
2024-11-22 01:56:58.021433: val_loss -0.8991 
2024-11-22 01:56:58.021511: Pseudo dice [np.float32(0.9145)] 
2024-11-22 01:56:58.021594: Epoch time: 52.51 s 
2024-11-22 01:56:58.975163:  
2024-11-22 01:56:58.975313: Epoch 958 
2024-11-22 01:56:58.975382: Current learning rate: 0.00058 
2024-11-22 01:57:51.178013: train_loss -0.9832 
2024-11-22 01:57:51.178140: val_loss -0.9 
2024-11-22 01:57:51.178202: Pseudo dice [np.float32(0.9158)] 
2024-11-22 01:57:51.178272: Epoch time: 52.2 s 
2024-11-22 01:57:52.149740:  
2024-11-22 01:57:52.149977: Epoch 959 
2024-11-22 01:57:52.150061: Current learning rate: 0.00056 
2024-11-22 01:58:44.489417: train_loss -0.9832 
2024-11-22 01:58:44.489622: val_loss -0.898 
2024-11-22 01:58:44.489716: Pseudo dice [np.float32(0.9136)] 
2024-11-22 01:58:44.489784: Epoch time: 52.34 s 
2024-11-22 01:58:45.819344:  
2024-11-22 01:58:45.819555: Epoch 960 
2024-11-22 01:58:45.819669: Current learning rate: 0.00055 
2024-11-22 01:59:38.137500: train_loss -0.9833 
2024-11-22 01:59:38.137674: val_loss -0.8995 
2024-11-22 01:59:38.137736: Pseudo dice [np.float32(0.9155)] 
2024-11-22 01:59:38.137792: Epoch time: 52.32 s 
2024-11-22 01:59:39.138503:  
2024-11-22 01:59:39.138730: Epoch 961 
2024-11-22 01:59:39.138805: Current learning rate: 0.00054 
2024-11-22 02:00:31.584451: train_loss -0.9835 
2024-11-22 02:00:31.584632: val_loss -0.9064 
2024-11-22 02:00:31.584684: Pseudo dice [np.float32(0.9205)] 
2024-11-22 02:00:31.584739: Epoch time: 52.45 s 
2024-11-22 02:00:32.557741:  
2024-11-22 02:00:32.557887: Epoch 962 
2024-11-22 02:00:32.557955: Current learning rate: 0.00053 
2024-11-22 02:01:24.781389: train_loss -0.9837 
2024-11-22 02:01:24.781563: val_loss -0.8982 
2024-11-22 02:01:24.781642: Pseudo dice [np.float32(0.915)] 
2024-11-22 02:01:24.781728: Epoch time: 52.22 s 
2024-11-22 02:01:25.795913:  
2024-11-22 02:01:25.796166: Epoch 963 
2024-11-22 02:01:25.796282: Current learning rate: 0.00051 
2024-11-22 02:02:18.174873: train_loss -0.9831 
2024-11-22 02:02:18.174989: val_loss -0.9027 
2024-11-22 02:02:18.175038: Pseudo dice [np.float32(0.9183)] 
2024-11-22 02:02:18.175093: Epoch time: 52.38 s 
2024-11-22 02:02:18.175138: Yayy! New best EMA pseudo Dice: 0.9156000018119812 
2024-11-22 02:02:19.503177:  
2024-11-22 02:02:19.503414: Epoch 964 
2024-11-22 02:02:19.503506: Current learning rate: 0.0005 
2024-11-22 02:03:11.903030: train_loss -0.983 
2024-11-22 02:03:11.903153: val_loss -0.8993 
2024-11-22 02:03:11.903201: Pseudo dice [np.float32(0.9147)] 
2024-11-22 02:03:11.903254: Epoch time: 52.4 s 
2024-11-22 02:03:12.865916:  
2024-11-22 02:03:12.866083: Epoch 965 
2024-11-22 02:03:12.866180: Current learning rate: 0.00049 
2024-11-22 02:04:05.418754: train_loss -0.9831 
2024-11-22 02:04:05.418911: val_loss -0.9013 
2024-11-22 02:04:05.418977: Pseudo dice [np.float32(0.9162)] 
2024-11-22 02:04:05.419046: Epoch time: 52.55 s 
2024-11-22 02:04:06.462246:  
2024-11-22 02:04:06.462428: Epoch 966 
2024-11-22 02:04:06.462522: Current learning rate: 0.00048 
2024-11-22 02:04:59.045690: train_loss -0.9841 
2024-11-22 02:04:59.045846: val_loss -0.8977 
2024-11-22 02:04:59.045900: Pseudo dice [np.float32(0.9138)] 
2024-11-22 02:04:59.045958: Epoch time: 52.58 s 
2024-11-22 02:05:00.023600:  
2024-11-22 02:05:00.023785: Epoch 967 
2024-11-22 02:05:00.023852: Current learning rate: 0.00046 
2024-11-22 02:05:51.928056: train_loss -0.9837 
2024-11-22 02:05:51.928196: val_loss -0.8938 
2024-11-22 02:05:51.928251: Pseudo dice [np.float32(0.9107)] 
2024-11-22 02:05:51.928306: Epoch time: 51.91 s 
2024-11-22 02:05:52.841084:  
2024-11-22 02:05:52.841221: Epoch 968 
2024-11-22 02:05:52.841305: Current learning rate: 0.00045 
2024-11-22 02:06:45.126150: train_loss -0.9831 
2024-11-22 02:06:45.126264: val_loss -0.899 
2024-11-22 02:06:45.126314: Pseudo dice [np.float32(0.9159)] 
2024-11-22 02:06:45.126366: Epoch time: 52.29 s 
2024-11-22 02:06:46.104375:  
2024-11-22 02:06:46.104517: Epoch 969 
2024-11-22 02:06:46.104586: Current learning rate: 0.00044 
2024-11-22 02:07:38.449924: train_loss -0.9833 
2024-11-22 02:07:38.450074: val_loss -0.8981 
2024-11-22 02:07:38.450125: Pseudo dice [np.float32(0.9142)] 
2024-11-22 02:07:38.450182: Epoch time: 52.35 s 
2024-11-22 02:07:39.484326:  
2024-11-22 02:07:39.484535: Epoch 970 
2024-11-22 02:07:39.484609: Current learning rate: 0.00043 
2024-11-22 02:08:31.775708: train_loss -0.9831 
2024-11-22 02:08:31.775819: val_loss -0.8994 
2024-11-22 02:08:31.775868: Pseudo dice [np.float32(0.9163)] 
2024-11-22 02:08:31.775922: Epoch time: 52.29 s 
2024-11-22 02:08:32.753746:  
2024-11-22 02:08:32.753927: Epoch 971 
2024-11-22 02:08:32.754009: Current learning rate: 0.00041 
2024-11-22 02:09:25.311572: train_loss -0.9837 
2024-11-22 02:09:25.311684: val_loss -0.9025 
2024-11-22 02:09:25.311732: Pseudo dice [np.float32(0.9182)] 
2024-11-22 02:09:25.311784: Epoch time: 52.56 s 
2024-11-22 02:09:26.581324:  
2024-11-22 02:09:26.581514: Epoch 972 
2024-11-22 02:09:26.581621: Current learning rate: 0.0004 
2024-11-22 02:10:18.883476: train_loss -0.9836 
2024-11-22 02:10:18.883629: val_loss -0.901 
2024-11-22 02:10:18.883679: Pseudo dice [np.float32(0.916)] 
2024-11-22 02:10:18.883733: Epoch time: 52.3 s 
2024-11-22 02:10:19.842012:  
2024-11-22 02:10:19.842155: Epoch 973 
2024-11-22 02:10:19.842223: Current learning rate: 0.00039 
2024-11-22 02:11:12.670548: train_loss -0.983 
2024-11-22 02:11:12.670679: val_loss -0.9028 
2024-11-22 02:11:12.670745: Pseudo dice [np.float32(0.9194)] 
2024-11-22 02:11:12.670815: Epoch time: 52.83 s 
2024-11-22 02:11:12.670873: Yayy! New best EMA pseudo Dice: 0.9158999919891357 
2024-11-22 02:11:14.009043:  
2024-11-22 02:11:14.009208: Epoch 974 
2024-11-22 02:11:14.009276: Current learning rate: 0.00037 
2024-11-22 02:12:06.687734: train_loss -0.9838 
2024-11-22 02:12:06.687983: val_loss -0.8959 
2024-11-22 02:12:06.688035: Pseudo dice [np.float32(0.9119)] 
2024-11-22 02:12:06.688090: Epoch time: 52.68 s 
2024-11-22 02:12:07.735894:  
2024-11-22 02:12:07.736055: Epoch 975 
2024-11-22 02:12:07.736156: Current learning rate: 0.00036 
2024-11-22 02:12:59.967034: train_loss -0.9839 
2024-11-22 02:12:59.967173: val_loss -0.8942 
2024-11-22 02:12:59.967224: Pseudo dice [np.float32(0.9114)] 
2024-11-22 02:12:59.967280: Epoch time: 52.23 s 
2024-11-22 02:13:00.861273:  
2024-11-22 02:13:00.861473: Epoch 976 
2024-11-22 02:13:00.861561: Current learning rate: 0.00035 
2024-11-22 02:13:53.028452: train_loss -0.9839 
2024-11-22 02:13:53.028591: val_loss -0.8908 
2024-11-22 02:13:53.028656: Pseudo dice [np.float32(0.9085)] 
2024-11-22 02:13:53.028725: Epoch time: 52.17 s 
2024-11-22 02:13:53.952245:  
2024-11-22 02:13:53.952433: Epoch 977 
2024-11-22 02:13:53.952525: Current learning rate: 0.00034 
2024-11-22 02:14:46.378421: train_loss -0.9835 
2024-11-22 02:14:46.378552: val_loss -0.8967 
2024-11-22 02:14:46.378614: Pseudo dice [np.float32(0.9133)] 
2024-11-22 02:14:46.378680: Epoch time: 52.43 s 
2024-11-22 02:14:47.333934:  
2024-11-22 02:14:47.334122: Epoch 978 
2024-11-22 02:14:47.334217: Current learning rate: 0.00032 
2024-11-22 02:15:39.729036: train_loss -0.9836 
2024-11-22 02:15:39.729146: val_loss -0.9021 
2024-11-22 02:15:39.729194: Pseudo dice [np.float32(0.9166)] 
2024-11-22 02:15:39.729245: Epoch time: 52.4 s 
2024-11-22 02:15:40.594368:  
2024-11-22 02:15:40.594517: Epoch 979 
2024-11-22 02:15:40.594587: Current learning rate: 0.00031 
2024-11-22 02:16:33.206596: train_loss -0.9835 
2024-11-22 02:16:33.206746: val_loss -0.8993 
2024-11-22 02:16:33.206795: Pseudo dice [np.float32(0.9152)] 
2024-11-22 02:16:33.206848: Epoch time: 52.61 s 
2024-11-22 02:16:34.160300:  
2024-11-22 02:16:34.160518: Epoch 980 
2024-11-22 02:16:34.160615: Current learning rate: 0.0003 
2024-11-22 02:17:26.246054: train_loss -0.9843 
2024-11-22 02:17:26.246184: val_loss -0.8982 
2024-11-22 02:17:26.246248: Pseudo dice [np.float32(0.9135)] 
2024-11-22 02:17:26.246317: Epoch time: 52.09 s 
2024-11-22 02:17:27.256885:  
2024-11-22 02:17:27.257067: Epoch 981 
2024-11-22 02:17:27.257154: Current learning rate: 0.00028 
2024-11-22 02:18:19.787246: train_loss -0.9836 
2024-11-22 02:18:19.787360: val_loss -0.8969 
2024-11-22 02:18:19.787408: Pseudo dice [np.float32(0.9138)] 
2024-11-22 02:18:19.787462: Epoch time: 52.53 s 
2024-11-22 02:18:20.780544:  
2024-11-22 02:18:20.780681: Epoch 982 
2024-11-22 02:18:20.780825: Current learning rate: 0.00027 
2024-11-22 02:19:13.386184: train_loss -0.9832 
2024-11-22 02:19:13.386299: val_loss -0.9032 
2024-11-22 02:19:13.386348: Pseudo dice [np.float32(0.9188)] 
2024-11-22 02:19:13.386400: Epoch time: 52.61 s 
2024-11-22 02:19:14.339338:  
2024-11-22 02:19:14.339606: Epoch 983 
2024-11-22 02:19:14.339718: Current learning rate: 0.00026 
2024-11-22 02:20:06.910232: train_loss -0.9839 
2024-11-22 02:20:06.910364: val_loss -0.8969 
2024-11-22 02:20:06.910417: Pseudo dice [np.float32(0.9142)] 
2024-11-22 02:20:06.910503: Epoch time: 52.57 s 
2024-11-22 02:20:08.153598:  
2024-11-22 02:20:08.153755: Epoch 984 
2024-11-22 02:20:08.153822: Current learning rate: 0.00024 
2024-11-22 02:21:00.835269: train_loss -0.984 
2024-11-22 02:21:00.835387: val_loss -0.8998 
2024-11-22 02:21:00.835443: Pseudo dice [np.float32(0.9175)] 
2024-11-22 02:21:00.835539: Epoch time: 52.68 s 
2024-11-22 02:21:01.809482:  
2024-11-22 02:21:01.809655: Epoch 985 
2024-11-22 02:21:01.809739: Current learning rate: 0.00023 
2024-11-22 02:21:54.361874: train_loss -0.9836 
2024-11-22 02:21:54.361999: val_loss -0.8918 
2024-11-22 02:21:54.362053: Pseudo dice [np.float32(0.9085)] 
2024-11-22 02:21:54.362107: Epoch time: 52.55 s 
2024-11-22 02:21:55.244761:  
2024-11-22 02:21:55.244937: Epoch 986 
2024-11-22 02:21:55.245039: Current learning rate: 0.00021 
2024-11-22 02:22:47.427903: train_loss -0.9841 
2024-11-22 02:22:47.428039: val_loss -0.8948 
2024-11-22 02:22:47.428089: Pseudo dice [np.float32(0.9114)] 
2024-11-22 02:22:47.428144: Epoch time: 52.18 s 
2024-11-22 02:22:48.406210:  
2024-11-22 02:22:48.406381: Epoch 987 
2024-11-22 02:22:48.406465: Current learning rate: 0.0002 
2024-11-22 02:23:40.959788: train_loss -0.9839 
2024-11-22 02:23:40.959943: val_loss -0.8957 
2024-11-22 02:23:40.960024: Pseudo dice [np.float32(0.9112)] 
2024-11-22 02:23:40.960095: Epoch time: 52.55 s 
2024-11-22 02:23:41.868330:  
2024-11-22 02:23:41.868598: Epoch 988 
2024-11-22 02:23:41.868677: Current learning rate: 0.00019 
2024-11-22 02:24:34.269140: train_loss -0.9844 
2024-11-22 02:24:34.269276: val_loss -0.8987 
2024-11-22 02:24:34.269328: Pseudo dice [np.float32(0.9166)] 
2024-11-22 02:24:34.269382: Epoch time: 52.4 s 
2024-11-22 02:24:35.297367:  
2024-11-22 02:24:35.297538: Epoch 989 
2024-11-22 02:24:35.297631: Current learning rate: 0.00017 
2024-11-22 02:25:27.824509: train_loss -0.9845 
2024-11-22 02:25:27.824672: val_loss -0.8925 
2024-11-22 02:25:27.824735: Pseudo dice [np.float32(0.9102)] 
2024-11-22 02:25:27.824803: Epoch time: 52.53 s 
2024-11-22 02:25:28.839480:  
2024-11-22 02:25:28.839712: Epoch 990 
2024-11-22 02:25:28.839799: Current learning rate: 0.00016 
2024-11-22 02:26:21.364035: train_loss -0.9836 
2024-11-22 02:26:21.364161: val_loss -0.9013 
2024-11-22 02:26:21.364239: Pseudo dice [np.float32(0.9172)] 
2024-11-22 02:26:21.364314: Epoch time: 52.53 s 
2024-11-22 02:26:22.332740:  
2024-11-22 02:26:22.332923: Epoch 991 
2024-11-22 02:26:22.333007: Current learning rate: 0.00014 
2024-11-22 02:27:14.880358: train_loss -0.9843 
2024-11-22 02:27:14.880515: val_loss -0.9027 
2024-11-22 02:27:14.880659: Pseudo dice [np.float32(0.9166)] 
2024-11-22 02:27:14.880767: Epoch time: 52.55 s 
2024-11-22 02:27:15.862787:  
2024-11-22 02:27:15.863022: Epoch 992 
2024-11-22 02:27:15.863109: Current learning rate: 0.00013 
2024-11-22 02:28:07.892396: train_loss -0.9841 
2024-11-22 02:28:07.892556: val_loss -0.902 
2024-11-22 02:28:07.892645: Pseudo dice [np.float32(0.9167)] 
2024-11-22 02:28:07.892699: Epoch time: 52.03 s 
2024-11-22 02:28:08.875994:  
2024-11-22 02:28:08.876131: Epoch 993 
2024-11-22 02:28:08.876200: Current learning rate: 0.00011 
2024-11-22 02:29:01.364993: train_loss -0.9841 
2024-11-22 02:29:01.365195: val_loss -0.9057 
2024-11-22 02:29:01.365264: Pseudo dice [np.float32(0.9198)] 
2024-11-22 02:29:01.365337: Epoch time: 52.49 s 
2024-11-22 02:29:02.317287:  
2024-11-22 02:29:02.317467: Epoch 994 
2024-11-22 02:29:02.317558: Current learning rate: 0.0001 
2024-11-22 02:29:54.950194: train_loss -0.9839 
2024-11-22 02:29:54.950392: val_loss -0.9001 
2024-11-22 02:29:54.950459: Pseudo dice [np.float32(0.915)] 
2024-11-22 02:29:54.950535: Epoch time: 52.63 s 
2024-11-22 02:29:56.027729:  
2024-11-22 02:29:56.027862: Epoch 995 
2024-11-22 02:29:56.027930: Current learning rate: 8e-05 
2024-11-22 02:30:48.446683: train_loss -0.9841 
2024-11-22 02:30:48.446808: val_loss -0.9013 
2024-11-22 02:30:48.446867: Pseudo dice [np.float32(0.9178)] 
2024-11-22 02:30:48.446934: Epoch time: 52.42 s 
2024-11-22 02:30:49.728912:  
2024-11-22 02:30:49.729059: Epoch 996 
2024-11-22 02:30:49.729131: Current learning rate: 7e-05 
2024-11-22 02:31:42.364127: train_loss -0.984 
2024-11-22 02:31:42.364326: val_loss -0.8979 
2024-11-22 02:31:42.364393: Pseudo dice [np.float32(0.914)] 
2024-11-22 02:31:42.364461: Epoch time: 52.64 s 
2024-11-22 02:31:43.297593:  
2024-11-22 02:31:43.297902: Epoch 997 
2024-11-22 02:31:43.297993: Current learning rate: 5e-05 
2024-11-22 02:32:35.984902: train_loss -0.9844 
2024-11-22 02:32:35.985096: val_loss -0.8981 
2024-11-22 02:32:35.985154: Pseudo dice [np.float32(0.9142)] 
2024-11-22 02:32:35.985211: Epoch time: 52.69 s 
2024-11-22 02:32:36.898409:  
2024-11-22 02:32:36.898817: Epoch 998 
2024-11-22 02:32:36.898907: Current learning rate: 4e-05 
2024-11-22 02:33:29.317654: train_loss -0.9843 
2024-11-22 02:33:29.317862: val_loss -0.8952 
2024-11-22 02:33:29.317928: Pseudo dice [np.float32(0.9113)] 
2024-11-22 02:33:29.318040: Epoch time: 52.42 s 
2024-11-22 02:33:30.299870:  
2024-11-22 02:33:30.300071: Epoch 999 
2024-11-22 02:33:30.300158: Current learning rate: 2e-05 
2024-11-22 02:34:22.856871: train_loss -0.9838 
2024-11-22 02:34:22.857009: val_loss -0.8986 
2024-11-22 02:34:22.857061: Pseudo dice [np.float32(0.9153)] 
2024-11-22 02:34:22.857112: Epoch time: 52.56 s 
2024-11-22 02:34:24.216211: Training done. 
2024-11-22 02:34:24.331543: Using splits from existing split file: /home/ran/deeplearning/nnUNet_preprocessed/Dataset002/splits_final.json 
2024-11-22 02:34:24.334289: The split file contains 5 splits. 
2024-11-22 02:34:24.334394: Desired fold for training: 0 
2024-11-22 02:34:24.334448: This split has 2400 training and 600 validation cases. 
2024-11-22 02:34:24.366586: predicting TCGA_CS_4941_19960909_14 
2024-11-22 02:34:24.367494: TCGA_CS_4941_19960909_14, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:36.301702: predicting TCGA_CS_4941_19960909_15 
2024-11-22 02:34:36.303903: TCGA_CS_4941_19960909_15, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:36.328088: predicting TCGA_CS_4941_19960909_20 
2024-11-22 02:34:36.328697: TCGA_CS_4941_19960909_20, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:36.361327: predicting TCGA_CS_4941_19960909_22 
2024-11-22 02:34:36.363550: TCGA_CS_4941_19960909_22, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:36.422012: predicting TCGA_CS_4941_19960909_9 
2024-11-22 02:34:36.424103: TCGA_CS_4941_19960909_9, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:36.492293: predicting TCGA_CS_4942_19970222_1 
2024-11-22 02:34:36.492869: TCGA_CS_4942_19970222_1, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:36.554888: predicting TCGA_CS_4942_19970222_17 
2024-11-22 02:34:36.555510: TCGA_CS_4942_19970222_17, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:36.584148: predicting TCGA_CS_4943_20000902_1 
2024-11-22 02:34:36.584711: TCGA_CS_4943_20000902_1, shape torch.Size([3, 1, 256, 194]), rank 0 
2024-11-22 02:34:36.656462: predicting TCGA_CS_4943_20000902_10 
2024-11-22 02:34:36.661367: TCGA_CS_4943_20000902_10, shape torch.Size([3, 1, 256, 197]), rank 0 
2024-11-22 02:34:36.719513: predicting TCGA_CS_4943_20000902_13 
2024-11-22 02:34:36.720143: TCGA_CS_4943_20000902_13, shape torch.Size([3, 1, 256, 197]), rank 0 
2024-11-22 02:34:36.783678: predicting TCGA_CS_4943_20000902_2 
2024-11-22 02:34:36.785670: TCGA_CS_4943_20000902_2, shape torch.Size([3, 1, 256, 196]), rank 0 
2024-11-22 02:34:36.815021: predicting TCGA_CS_4943_20000902_8 
2024-11-22 02:34:36.816986: TCGA_CS_4943_20000902_8, shape torch.Size([3, 1, 256, 197]), rank 0 
2024-11-22 02:34:36.879579: predicting TCGA_CS_4944_20010208_11 
2024-11-22 02:34:36.880142: TCGA_CS_4944_20010208_11, shape torch.Size([3, 1, 256, 203]), rank 0 
2024-11-22 02:34:36.939910: predicting TCGA_CS_4944_20010208_18 
2024-11-22 02:34:36.942105: TCGA_CS_4944_20010208_18, shape torch.Size([3, 1, 256, 203]), rank 0 
2024-11-22 02:34:36.971240: predicting TCGA_CS_4944_20010208_19 
2024-11-22 02:34:36.971928: TCGA_CS_4944_20010208_19, shape torch.Size([3, 1, 256, 204]), rank 0 
2024-11-22 02:34:37.023504: predicting TCGA_CS_5393_19990606_11 
2024-11-22 02:34:37.027792: TCGA_CS_5393_19990606_11, shape torch.Size([3, 1, 256, 195]), rank 0 
2024-11-22 02:34:37.056784: predicting TCGA_CS_5393_19990606_16 
2024-11-22 02:34:37.057319: TCGA_CS_5393_19990606_16, shape torch.Size([3, 1, 256, 195]), rank 0 
2024-11-22 02:34:37.132995: predicting TCGA_CS_5393_19990606_17 
2024-11-22 02:34:37.136968: TCGA_CS_5393_19990606_17, shape torch.Size([3, 1, 256, 195]), rank 0 
2024-11-22 02:34:37.183884: predicting TCGA_CS_5393_19990606_19 
2024-11-22 02:34:37.185985: TCGA_CS_5393_19990606_19, shape torch.Size([3, 1, 256, 195]), rank 0 
2024-11-22 02:34:37.210917: predicting TCGA_CS_5393_19990606_20 
2024-11-22 02:34:37.211468: TCGA_CS_5393_19990606_20, shape torch.Size([3, 1, 256, 194]), rank 0 
2024-11-22 02:34:37.254515: predicting TCGA_CS_5395_19981004_16 
2024-11-22 02:34:37.255043: TCGA_CS_5395_19981004_16, shape torch.Size([3, 1, 256, 222]), rank 0 
2024-11-22 02:34:37.320755: predicting TCGA_CS_5395_19981004_18 
2024-11-22 02:34:37.321311: TCGA_CS_5395_19981004_18, shape torch.Size([3, 1, 256, 222]), rank 0 
2024-11-22 02:34:37.351289: predicting TCGA_CS_5395_19981004_3 
2024-11-22 02:34:37.351915: TCGA_CS_5395_19981004_3, shape torch.Size([3, 1, 256, 222]), rank 0 
2024-11-22 02:34:37.388359: predicting TCGA_CS_5395_19981004_4 
2024-11-22 02:34:37.388946: TCGA_CS_5395_19981004_4, shape torch.Size([3, 1, 256, 222]), rank 0 
2024-11-22 02:34:37.443500: predicting TCGA_CS_5395_19981004_6 
2024-11-22 02:34:37.444037: TCGA_CS_5395_19981004_6, shape torch.Size([3, 1, 256, 222]), rank 0 
2024-11-22 02:34:37.499406: predicting TCGA_CS_5395_19981004_7 
2024-11-22 02:34:37.501402: TCGA_CS_5395_19981004_7, shape torch.Size([3, 1, 256, 223]), rank 0 
2024-11-22 02:34:37.534421: predicting TCGA_CS_5396_20010302_4 
2024-11-22 02:34:37.534980: TCGA_CS_5396_20010302_4, shape torch.Size([3, 1, 256, 249]), rank 0 
2024-11-22 02:34:37.561931: predicting TCGA_CS_5396_20010302_5 
2024-11-22 02:34:37.571274: TCGA_CS_5396_20010302_5, shape torch.Size([3, 1, 256, 249]), rank 0 
2024-11-22 02:34:37.635079: predicting TCGA_CS_5397_20010315_20 
2024-11-22 02:34:37.636156: TCGA_CS_5397_20010315_20, shape torch.Size([3, 1, 256, 203]), rank 0 
2024-11-22 02:34:37.664525: predicting TCGA_CS_5397_20010315_21 
2024-11-22 02:34:37.665065: TCGA_CS_5397_20010315_21, shape torch.Size([3, 1, 256, 203]), rank 0 
2024-11-22 02:34:37.723124: predicting TCGA_CS_5397_20010315_6 
2024-11-22 02:34:37.723694: TCGA_CS_5397_20010315_6, shape torch.Size([3, 1, 256, 203]), rank 0 
2024-11-22 02:34:37.758522: predicting TCGA_CS_5397_20010315_9 
2024-11-22 02:34:37.759148: TCGA_CS_5397_20010315_9, shape torch.Size([3, 1, 256, 201]), rank 0 
2024-11-22 02:34:37.837800: predicting TCGA_CS_6186_20000601_12 
2024-11-22 02:34:37.838317: TCGA_CS_6186_20000601_12, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:37.872296: predicting TCGA_CS_6186_20000601_20 
2024-11-22 02:34:37.873979: TCGA_CS_6186_20000601_20, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:37.902104: predicting TCGA_CS_6186_20000601_22 
2024-11-22 02:34:37.902635: TCGA_CS_6186_20000601_22, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:37.942423: predicting TCGA_CS_6186_20000601_3 
2024-11-22 02:34:37.942975: TCGA_CS_6186_20000601_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:38.016110: predicting TCGA_CS_6186_20000601_6 
2024-11-22 02:34:38.016667: TCGA_CS_6186_20000601_6, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:38.079538: predicting TCGA_CS_6186_20000601_8 
2024-11-22 02:34:38.080155: TCGA_CS_6186_20000601_8, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:38.116576: predicting TCGA_CS_6188_20010812_13 
2024-11-22 02:34:38.117130: TCGA_CS_6188_20010812_13, shape torch.Size([3, 1, 256, 244]), rank 0 
2024-11-22 02:34:38.155913: predicting TCGA_CS_6188_20010812_14 
2024-11-22 02:34:38.156460: TCGA_CS_6188_20010812_14, shape torch.Size([3, 1, 256, 243]), rank 0 
2024-11-22 02:34:38.216034: predicting TCGA_CS_6188_20010812_16 
2024-11-22 02:34:38.220057: TCGA_CS_6188_20010812_16, shape torch.Size([3, 1, 256, 245]), rank 0 
2024-11-22 02:34:38.254970: predicting TCGA_CS_6188_20010812_20 
2024-11-22 02:34:38.255588: TCGA_CS_6188_20010812_20, shape torch.Size([3, 1, 256, 245]), rank 0 
2024-11-22 02:34:38.304287: predicting TCGA_CS_6188_20010812_5 
2024-11-22 02:34:38.306405: TCGA_CS_6188_20010812_5, shape torch.Size([3, 1, 256, 244]), rank 0 
2024-11-22 02:34:38.340459: predicting TCGA_CS_6188_20010812_7 
2024-11-22 02:34:38.341016: TCGA_CS_6188_20010812_7, shape torch.Size([3, 1, 256, 244]), rank 0 
2024-11-22 02:34:38.426190: predicting TCGA_CS_6290_20000917_2 
2024-11-22 02:34:38.426759: TCGA_CS_6290_20000917_2, shape torch.Size([3, 1, 256, 195]), rank 0 
2024-11-22 02:34:38.465144: predicting TCGA_CS_6290_20000917_3 
2024-11-22 02:34:38.465665: TCGA_CS_6290_20000917_3, shape torch.Size([3, 1, 256, 195]), rank 0 
2024-11-22 02:34:38.496382: predicting TCGA_CS_6290_20000917_5 
2024-11-22 02:34:38.496890: TCGA_CS_6290_20000917_5, shape torch.Size([3, 1, 256, 195]), rank 0 
2024-11-22 02:34:38.527181: predicting TCGA_CS_6290_20000917_9 
2024-11-22 02:34:38.532108: TCGA_CS_6290_20000917_9, shape torch.Size([3, 1, 256, 195]), rank 0 
2024-11-22 02:34:38.599935: predicting TCGA_CS_6665_20010817_11 
2024-11-22 02:34:38.601854: TCGA_CS_6665_20010817_11, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:38.654550: predicting TCGA_CS_6665_20010817_20 
2024-11-22 02:34:38.655107: TCGA_CS_6665_20010817_20, shape torch.Size([3, 1, 256, 244]), rank 0 
2024-11-22 02:34:38.688547: predicting TCGA_CS_6665_20010817_22 
2024-11-22 02:34:38.689316: TCGA_CS_6665_20010817_22, shape torch.Size([3, 1, 256, 244]), rank 0 
2024-11-22 02:34:38.725188: predicting TCGA_CS_6665_20010817_24 
2024-11-22 02:34:38.725711: TCGA_CS_6665_20010817_24, shape torch.Size([3, 1, 256, 250]), rank 0 
2024-11-22 02:34:38.757247: predicting TCGA_CS_6665_20010817_5 
2024-11-22 02:34:38.759875: TCGA_CS_6665_20010817_5, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-22 02:34:38.784189: predicting TCGA_CS_6666_20011109_13 
2024-11-22 02:34:38.784681: TCGA_CS_6666_20011109_13, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:38.837965: predicting TCGA_CS_6666_20011109_2 
2024-11-22 02:34:38.838505: TCGA_CS_6666_20011109_2, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-22 02:34:38.921457: predicting TCGA_CS_6667_20011105_3 
2024-11-22 02:34:38.922014: TCGA_CS_6667_20011105_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:38.960165: predicting TCGA_CS_6668_20011025_10 
2024-11-22 02:34:38.960769: TCGA_CS_6668_20011025_10, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-22 02:34:38.986614: predicting TCGA_CS_6668_20011025_11 
2024-11-22 02:34:38.987110: TCGA_CS_6668_20011025_11, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:39.060018: predicting TCGA_CS_6668_20011025_15 
2024-11-22 02:34:39.062370: TCGA_CS_6668_20011025_15, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:39.107859: predicting TCGA_CS_6668_20011025_16 
2024-11-22 02:34:39.108401: TCGA_CS_6668_20011025_16, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:39.139234: predicting TCGA_CS_6668_20011025_17 
2024-11-22 02:34:39.141359: TCGA_CS_6668_20011025_17, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:39.200612: predicting TCGA_CS_6668_20011025_3 
2024-11-22 02:34:39.201208: TCGA_CS_6668_20011025_3, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:39.240875: predicting TCGA_CS_6668_20011025_9 
2024-11-22 02:34:39.241395: TCGA_CS_6668_20011025_9, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-22 02:34:39.292564: predicting TCGA_CS_6669_20020102_17 
2024-11-22 02:34:39.293147: TCGA_CS_6669_20020102_17, shape torch.Size([3, 1, 256, 243]), rank 0 
2024-11-22 02:34:39.321261: predicting TCGA_CS_6669_20020102_22 
2024-11-22 02:34:39.325763: TCGA_CS_6669_20020102_22, shape torch.Size([3, 1, 256, 244]), rank 0 
2024-11-22 02:34:39.353013: predicting TCGA_DU_5849_19950405_13 
2024-11-22 02:34:39.353513: TCGA_DU_5849_19950405_13, shape torch.Size([3, 1, 248, 251]), rank 0 
2024-11-22 02:34:39.424712: predicting TCGA_DU_5849_19950405_20 
2024-11-22 02:34:39.429153: TCGA_DU_5849_19950405_20, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-22 02:34:39.479936: predicting TCGA_DU_5849_19950405_26 
2024-11-22 02:34:39.484052: TCGA_DU_5849_19950405_26, shape torch.Size([3, 1, 248, 250]), rank 0 
2024-11-22 02:34:39.547719: predicting TCGA_DU_5849_19950405_29 
2024-11-22 02:34:39.548504: TCGA_DU_5849_19950405_29, shape torch.Size([3, 1, 250, 253]), rank 0 
2024-11-22 02:34:39.572771: predicting TCGA_DU_5849_19950405_3 
2024-11-22 02:34:39.573241: TCGA_DU_5849_19950405_3, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-22 02:34:39.608997: predicting TCGA_DU_5849_19950405_37 
2024-11-22 02:34:39.609542: TCGA_DU_5849_19950405_37, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:39.655986: predicting TCGA_DU_5849_19950405_5 
2024-11-22 02:34:39.656519: TCGA_DU_5849_19950405_5, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:34:39.688297: predicting TCGA_DU_5849_19950405_6 
2024-11-22 02:34:39.688805: TCGA_DU_5849_19950405_6, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:34:39.741403: predicting TCGA_DU_5849_19950405_8 
2024-11-22 02:34:39.741988: TCGA_DU_5849_19950405_8, shape torch.Size([3, 1, 251, 255]), rank 0 
2024-11-22 02:34:39.776380: predicting TCGA_DU_5851_19950428_13 
2024-11-22 02:34:39.776961: TCGA_DU_5851_19950428_13, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-22 02:34:39.828262: predicting TCGA_DU_5851_19950428_22 
2024-11-22 02:34:39.828843: TCGA_DU_5851_19950428_22, shape torch.Size([3, 1, 253, 254]), rank 0 
2024-11-22 02:34:39.900084: predicting TCGA_DU_5851_19950428_34 
2024-11-22 02:34:39.901871: TCGA_DU_5851_19950428_34, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:39.938953: predicting TCGA_DU_5851_19950428_40 
2024-11-22 02:34:39.939467: TCGA_DU_5851_19950428_40, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:39.991491: predicting TCGA_DU_5851_19950428_5 
2024-11-22 02:34:39.992012: TCGA_DU_5851_19950428_5, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:40.033824: predicting TCGA_DU_5852_19950709_16 
2024-11-22 02:34:40.035527: TCGA_DU_5852_19950709_16, shape torch.Size([3, 1, 248, 248]), rank 0 
2024-11-22 02:34:40.082933: predicting TCGA_DU_5852_19950709_21 
2024-11-22 02:34:40.083456: TCGA_DU_5852_19950709_21, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-22 02:34:40.119628: predicting TCGA_DU_5852_19950709_3 
2024-11-22 02:34:40.120192: TCGA_DU_5852_19950709_3, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-22 02:34:40.153721: predicting TCGA_DU_5853_19950823_15 
2024-11-22 02:34:40.155367: TCGA_DU_5853_19950823_15, shape torch.Size([3, 1, 247, 249]), rank 0 
2024-11-22 02:34:40.232117: predicting TCGA_DU_5853_19950823_19 
2024-11-22 02:34:40.233080: TCGA_DU_5853_19950823_19, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-22 02:34:40.278062: predicting TCGA_DU_5853_19950823_24 
2024-11-22 02:34:40.279991: TCGA_DU_5853_19950823_24, shape torch.Size([3, 1, 248, 249]), rank 0 
2024-11-22 02:34:40.306803: predicting TCGA_DU_5853_19950823_26 
2024-11-22 02:34:40.308735: TCGA_DU_5853_19950823_26, shape torch.Size([3, 1, 249, 251]), rank 0 
2024-11-22 02:34:40.375458: predicting TCGA_DU_5853_19950823_27 
2024-11-22 02:34:40.376111: TCGA_DU_5853_19950823_27, shape torch.Size([3, 1, 250, 252]), rank 0 
2024-11-22 02:34:40.431788: predicting TCGA_DU_5853_19950823_3 
2024-11-22 02:34:40.433683: TCGA_DU_5853_19950823_3, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:40.460202: predicting TCGA_DU_5853_19950823_32 
2024-11-22 02:34:40.460723: TCGA_DU_5853_19950823_32, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:40.490422: predicting TCGA_DU_5854_19951104_18 
2024-11-22 02:34:40.490960: TCGA_DU_5854_19951104_18, shape torch.Size([3, 1, 253, 253]), rank 0 
2024-11-22 02:34:40.538427: predicting TCGA_DU_5854_19951104_24 
2024-11-22 02:34:40.542055: TCGA_DU_5854_19951104_24, shape torch.Size([3, 1, 253, 254]), rank 0 
2024-11-22 02:34:40.594355: predicting TCGA_DU_5854_19951104_7 
2024-11-22 02:34:40.594942: TCGA_DU_5854_19951104_7, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-22 02:34:40.625135: predicting TCGA_DU_5854_19951104_8 
2024-11-22 02:34:40.625766: TCGA_DU_5854_19951104_8, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-22 02:34:40.692736: predicting TCGA_DU_5855_19951217_12 
2024-11-22 02:34:40.693312: TCGA_DU_5855_19951217_12, shape torch.Size([3, 1, 241, 215]), rank 0 
2024-11-22 02:34:40.752435: predicting TCGA_DU_5855_19951217_14 
2024-11-22 02:34:40.754353: TCGA_DU_5855_19951217_14, shape torch.Size([3, 1, 241, 215]), rank 0 
2024-11-22 02:34:40.784264: predicting TCGA_DU_5855_19951217_18 
2024-11-22 02:34:40.786397: TCGA_DU_5855_19951217_18, shape torch.Size([3, 1, 240, 214]), rank 0 
2024-11-22 02:34:40.833030: predicting TCGA_DU_5855_19951217_21 
2024-11-22 02:34:40.835282: TCGA_DU_5855_19951217_21, shape torch.Size([3, 1, 214, 213]), rank 0 
2024-11-22 02:34:40.881736: predicting TCGA_DU_5855_19951217_4 
2024-11-22 02:34:40.884063: TCGA_DU_5855_19951217_4, shape torch.Size([3, 1, 236, 215]), rank 0 
2024-11-22 02:34:40.924193: predicting TCGA_DU_5871_19941206_10 
2024-11-22 02:34:40.928964: TCGA_DU_5871_19941206_10, shape torch.Size([3, 1, 251, 252]), rank 0 
2024-11-22 02:34:40.962819: predicting TCGA_DU_5871_19941206_23 
2024-11-22 02:34:40.964923: TCGA_DU_5871_19941206_23, shape torch.Size([3, 1, 248, 250]), rank 0 
2024-11-22 02:34:41.002131: predicting TCGA_DU_5871_19941206_25 
2024-11-22 02:34:41.002693: TCGA_DU_5871_19941206_25, shape torch.Size([3, 1, 250, 250]), rank 0 
2024-11-22 02:34:41.046602: predicting TCGA_DU_5871_19941206_27 
2024-11-22 02:34:41.051084: TCGA_DU_5871_19941206_27, shape torch.Size([3, 1, 250, 252]), rank 0 
2024-11-22 02:34:41.094636: predicting TCGA_DU_5871_19941206_4 
2024-11-22 02:34:41.095147: TCGA_DU_5871_19941206_4, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:41.148581: predicting TCGA_DU_5872_19950223_13 
2024-11-22 02:34:41.149132: TCGA_DU_5872_19950223_13, shape torch.Size([3, 1, 256, 254]), rank 0 
2024-11-22 02:34:41.184902: predicting TCGA_DU_5872_19950223_23 
2024-11-22 02:34:41.186873: TCGA_DU_5872_19950223_23, shape torch.Size([3, 1, 254, 253]), rank 0 
2024-11-22 02:34:41.269585: predicting TCGA_DU_5872_19950223_30 
2024-11-22 02:34:41.271379: TCGA_DU_5872_19950223_30, shape torch.Size([3, 1, 254, 252]), rank 0 
2024-11-22 02:34:41.299450: predicting TCGA_DU_5872_19950223_32 
2024-11-22 02:34:41.303730: TCGA_DU_5872_19950223_32, shape torch.Size([3, 1, 254, 252]), rank 0 
2024-11-22 02:34:41.348515: predicting TCGA_DU_5872_19950223_35 
2024-11-22 02:34:41.349034: TCGA_DU_5872_19950223_35, shape torch.Size([3, 1, 256, 252]), rank 0 
2024-11-22 02:34:41.395612: predicting TCGA_DU_5872_19950223_36 
2024-11-22 02:34:41.396238: TCGA_DU_5872_19950223_36, shape torch.Size([3, 1, 256, 252]), rank 0 
2024-11-22 02:34:41.460459: predicting TCGA_DU_5872_19950223_51 
2024-11-22 02:34:41.462590: TCGA_DU_5872_19950223_51, shape torch.Size([3, 1, 256, 253]), rank 0 
2024-11-22 02:34:41.491578: predicting TCGA_DU_5872_19950223_55 
2024-11-22 02:34:41.494200: TCGA_DU_5872_19950223_55, shape torch.Size([3, 1, 256, 253]), rank 0 
2024-11-22 02:34:41.523177: predicting TCGA_DU_5872_19950223_57 
2024-11-22 02:34:41.525232: TCGA_DU_5872_19950223_57, shape torch.Size([3, 1, 256, 254]), rank 0 
2024-11-22 02:34:41.566589: predicting TCGA_DU_5872_19950223_58 
2024-11-22 02:34:41.567152: TCGA_DU_5872_19950223_58, shape torch.Size([3, 1, 256, 254]), rank 0 
2024-11-22 02:34:41.648230: predicting TCGA_DU_5872_19950223_61 
2024-11-22 02:34:41.648803: TCGA_DU_5872_19950223_61, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-22 02:34:41.678110: predicting TCGA_DU_5872_19950223_64 
2024-11-22 02:34:41.679742: TCGA_DU_5872_19950223_64, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-22 02:34:41.714589: predicting TCGA_DU_5872_19950223_71 
2024-11-22 02:34:41.715084: TCGA_DU_5872_19950223_71, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-22 02:34:41.769901: predicting TCGA_DU_5872_19950223_9 
2024-11-22 02:34:41.770499: TCGA_DU_5872_19950223_9, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-22 02:34:41.816621: predicting TCGA_DU_5874_19950510_15 
2024-11-22 02:34:41.817169: TCGA_DU_5874_19950510_15, shape torch.Size([3, 1, 247, 249]), rank 0 
2024-11-22 02:34:41.850690: predicting TCGA_DU_5874_19950510_28 
2024-11-22 02:34:41.854863: TCGA_DU_5874_19950510_28, shape torch.Size([3, 1, 249, 252]), rank 0 
2024-11-22 02:34:41.888591: predicting TCGA_DU_5874_19950510_29 
2024-11-22 02:34:41.889153: TCGA_DU_5874_19950510_29, shape torch.Size([3, 1, 249, 252]), rank 0 
2024-11-22 02:34:41.960430: predicting TCGA_DU_5874_19950510_30 
2024-11-22 02:34:41.962625: TCGA_DU_5874_19950510_30, shape torch.Size([3, 1, 250, 254]), rank 0 
2024-11-22 02:34:42.007231: predicting TCGA_DU_5874_19950510_32 
2024-11-22 02:34:42.012595: TCGA_DU_5874_19950510_32, shape torch.Size([3, 1, 251, 255]), rank 0 
2024-11-22 02:34:42.042345: predicting TCGA_DU_5874_19950510_35 
2024-11-22 02:34:42.043077: TCGA_DU_5874_19950510_35, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:42.090966: predicting TCGA_DU_5874_19950510_5 
2024-11-22 02:34:42.091767: TCGA_DU_5874_19950510_5, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:42.122933: predicting TCGA_DU_5874_19950510_6 
2024-11-22 02:34:42.123450: TCGA_DU_5874_19950510_6, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:34:42.159804: predicting TCGA_DU_6399_19830416_12 
2024-11-22 02:34:42.160321: TCGA_DU_6399_19830416_12, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-22 02:34:42.188327: predicting TCGA_DU_6399_19830416_2 
2024-11-22 02:34:42.193690: TCGA_DU_6399_19830416_2, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:42.235264: predicting TCGA_DU_6399_19830416_20 
2024-11-22 02:34:42.235886: TCGA_DU_6399_19830416_20, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-22 02:34:42.303596: predicting TCGA_DU_6399_19830416_21 
2024-11-22 02:34:42.304179: TCGA_DU_6399_19830416_21, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-22 02:34:42.347738: predicting TCGA_DU_6399_19830416_25 
2024-11-22 02:34:42.348675: TCGA_DU_6399_19830416_25, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-22 02:34:42.379272: predicting TCGA_DU_6399_19830416_38 
2024-11-22 02:34:42.381257: TCGA_DU_6399_19830416_38, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-22 02:34:42.451591: predicting TCGA_DU_6399_19830416_44 
2024-11-22 02:34:42.452176: TCGA_DU_6399_19830416_44, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:42.497604: predicting TCGA_DU_6399_19830416_49 
2024-11-22 02:34:42.498191: TCGA_DU_6399_19830416_49, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:42.533328: predicting TCGA_DU_6399_19830416_51 
2024-11-22 02:34:42.535292: TCGA_DU_6399_19830416_51, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:42.569275: predicting TCGA_DU_6400_19830518_19 
2024-11-22 02:34:42.569854: TCGA_DU_6400_19830518_19, shape torch.Size([3, 1, 254, 255]), rank 0 
2024-11-22 02:34:42.629163: predicting TCGA_DU_6400_19830518_20 
2024-11-22 02:34:42.634028: TCGA_DU_6400_19830518_20, shape torch.Size([3, 1, 254, 255]), rank 0 
2024-11-22 02:34:42.663606: predicting TCGA_DU_6400_19830518_28 
2024-11-22 02:34:42.664230: TCGA_DU_6400_19830518_28, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-22 02:34:42.728113: predicting TCGA_DU_6400_19830518_3 
2024-11-22 02:34:42.728705: TCGA_DU_6400_19830518_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:42.798626: predicting TCGA_DU_6400_19830518_32 
2024-11-22 02:34:42.800554: TCGA_DU_6400_19830518_32, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-22 02:34:42.826593: predicting TCGA_DU_6400_19830518_4 
2024-11-22 02:34:42.827075: TCGA_DU_6400_19830518_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:42.860173: predicting TCGA_DU_6400_19830518_42 
2024-11-22 02:34:42.860709: TCGA_DU_6400_19830518_42, shape torch.Size([3, 1, 254, 255]), rank 0 
2024-11-22 02:34:42.926664: predicting TCGA_DU_6400_19830518_44 
2024-11-22 02:34:42.927289: TCGA_DU_6400_19830518_44, shape torch.Size([3, 1, 255, 255]), rank 0 
2024-11-22 02:34:42.964037: predicting TCGA_DU_6401_19831001_10 
2024-11-22 02:34:42.964566: TCGA_DU_6401_19831001_10, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:43.009148: predicting TCGA_DU_6401_19831001_14 
2024-11-22 02:34:43.010976: TCGA_DU_6401_19831001_14, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-22 02:34:43.051596: predicting TCGA_DU_6401_19831001_22 
2024-11-22 02:34:43.052235: TCGA_DU_6401_19831001_22, shape torch.Size([3, 1, 254, 255]), rank 0 
2024-11-22 02:34:43.087303: predicting TCGA_DU_6401_19831001_25 
2024-11-22 02:34:43.088201: TCGA_DU_6401_19831001_25, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-22 02:34:43.129504: predicting TCGA_DU_6401_19831001_29 
2024-11-22 02:34:43.131607: TCGA_DU_6401_19831001_29, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-22 02:34:43.175608: predicting TCGA_DU_6401_19831001_37 
2024-11-22 02:34:43.176227: TCGA_DU_6401_19831001_37, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:43.212621: predicting TCGA_DU_6401_19831001_38 
2024-11-22 02:34:43.213241: TCGA_DU_6401_19831001_38, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:43.296414: predicting TCGA_DU_6401_19831001_4 
2024-11-22 02:34:43.303004: TCGA_DU_6401_19831001_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:43.336579: predicting TCGA_DU_6401_19831001_41 
2024-11-22 02:34:43.337084: TCGA_DU_6401_19831001_41, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:43.362931: predicting TCGA_DU_6401_19831001_49 
2024-11-22 02:34:43.368255: TCGA_DU_6401_19831001_49, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:43.410614: predicting TCGA_DU_6401_19831001_50 
2024-11-22 02:34:43.411289: TCGA_DU_6401_19831001_50, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:43.459836: predicting TCGA_DU_6404_19850629_20 
2024-11-22 02:34:43.464949: TCGA_DU_6404_19850629_20, shape torch.Size([3, 1, 255, 252]), rank 0 
2024-11-22 02:34:43.512626: predicting TCGA_DU_6404_19850629_23 
2024-11-22 02:34:43.513216: TCGA_DU_6404_19850629_23, shape torch.Size([3, 1, 255, 252]), rank 0 
2024-11-22 02:34:43.564426: predicting TCGA_DU_6404_19850629_27 
2024-11-22 02:34:43.564914: TCGA_DU_6404_19850629_27, shape torch.Size([3, 1, 255, 252]), rank 0 
2024-11-22 02:34:43.617208: predicting TCGA_DU_6404_19850629_31 
2024-11-22 02:34:43.619531: TCGA_DU_6404_19850629_31, shape torch.Size([3, 1, 255, 252]), rank 0 
2024-11-22 02:34:43.655113: predicting TCGA_DU_6404_19850629_49 
2024-11-22 02:34:43.657185: TCGA_DU_6404_19850629_49, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:43.687125: predicting TCGA_DU_6404_19850629_52 
2024-11-22 02:34:43.687645: TCGA_DU_6404_19850629_52, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:43.717055: predicting TCGA_DU_6404_19850629_53 
2024-11-22 02:34:43.717788: TCGA_DU_6404_19850629_53, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:43.770590: predicting TCGA_DU_6405_19851005_12 
2024-11-22 02:34:43.771142: TCGA_DU_6405_19851005_12, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:43.834097: predicting TCGA_DU_6405_19851005_13 
2024-11-22 02:34:43.835929: TCGA_DU_6405_19851005_13, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:43.883689: predicting TCGA_DU_6405_19851005_15 
2024-11-22 02:34:43.884253: TCGA_DU_6405_19851005_15, shape torch.Size([3, 1, 254, 255]), rank 0 
2024-11-22 02:34:43.913336: predicting TCGA_DU_6405_19851005_22 
2024-11-22 02:34:43.913903: TCGA_DU_6405_19851005_22, shape torch.Size([3, 1, 253, 254]), rank 0 
2024-11-22 02:34:43.948603: predicting TCGA_DU_6405_19851005_23 
2024-11-22 02:34:43.949107: TCGA_DU_6405_19851005_23, shape torch.Size([3, 1, 253, 254]), rank 0 
2024-11-22 02:34:43.997597: predicting TCGA_DU_6405_19851005_24 
2024-11-22 02:34:43.998109: TCGA_DU_6405_19851005_24, shape torch.Size([3, 1, 253, 254]), rank 0 
2024-11-22 02:34:44.075959: predicting TCGA_DU_6405_19851005_29 
2024-11-22 02:34:44.077916: TCGA_DU_6405_19851005_29, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-22 02:34:44.102798: predicting TCGA_DU_6405_19851005_30 
2024-11-22 02:34:44.104772: TCGA_DU_6405_19851005_30, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-22 02:34:44.141589: predicting TCGA_DU_6405_19851005_39 
2024-11-22 02:34:44.142153: TCGA_DU_6405_19851005_39, shape torch.Size([3, 1, 256, 254]), rank 0 
2024-11-22 02:34:44.191618: predicting TCGA_DU_6405_19851005_4 
2024-11-22 02:34:44.192187: TCGA_DU_6405_19851005_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:44.230974: predicting TCGA_DU_6405_19851005_57 
2024-11-22 02:34:44.231593: TCGA_DU_6405_19851005_57, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:44.292054: predicting TCGA_DU_6405_19851005_59 
2024-11-22 02:34:44.292595: TCGA_DU_6405_19851005_59, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:44.348759: predicting TCGA_DU_6405_19851005_6 
2024-11-22 02:34:44.349600: TCGA_DU_6405_19851005_6, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:44.393430: predicting TCGA_DU_6407_19860514_17 
2024-11-22 02:34:44.394046: TCGA_DU_6407_19860514_17, shape torch.Size([3, 1, 255, 255]), rank 0 
2024-11-22 02:34:44.426599: predicting TCGA_DU_6407_19860514_22 
2024-11-22 02:34:44.427130: TCGA_DU_6407_19860514_22, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-22 02:34:44.459075: predicting TCGA_DU_6407_19860514_26 
2024-11-22 02:34:44.459619: TCGA_DU_6407_19860514_26, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-22 02:34:44.517641: predicting TCGA_DU_6407_19860514_45 
2024-11-22 02:34:44.519968: TCGA_DU_6407_19860514_45, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-22 02:34:44.586679: predicting TCGA_DU_6407_19860514_51 
2024-11-22 02:34:44.587353: TCGA_DU_6407_19860514_51, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:44.614876: predicting TCGA_DU_6407_19860514_8 
2024-11-22 02:34:44.615421: TCGA_DU_6407_19860514_8, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:44.647303: predicting TCGA_DU_6408_19860521_18 
2024-11-22 02:34:44.647784: TCGA_DU_6408_19860521_18, shape torch.Size([3, 1, 255, 255]), rank 0 
2024-11-22 02:34:44.696626: predicting TCGA_DU_6408_19860521_2 
2024-11-22 02:34:44.703538: TCGA_DU_6408_19860521_2, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:44.753628: predicting TCGA_DU_6408_19860521_3 
2024-11-22 02:34:44.754123: TCGA_DU_6408_19860521_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:44.823648: predicting TCGA_DU_6408_19860521_38 
2024-11-22 02:34:44.824264: TCGA_DU_6408_19860521_38, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-22 02:34:44.868365: predicting TCGA_DU_6408_19860521_44 
2024-11-22 02:34:44.870579: TCGA_DU_6408_19860521_44, shape torch.Size([3, 1, 255, 255]), rank 0 
2024-11-22 02:34:44.894602: predicting TCGA_DU_6408_19860521_45 
2024-11-22 02:34:44.895111: TCGA_DU_6408_19860521_45, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:44.921987: predicting TCGA_DU_6408_19860521_47 
2024-11-22 02:34:44.922677: TCGA_DU_6408_19860521_47, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:44.959564: predicting TCGA_DU_6408_19860521_49 
2024-11-22 02:34:44.960091: TCGA_DU_6408_19860521_49, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:44.992258: predicting TCGA_DU_6408_19860521_55 
2024-11-22 02:34:44.992742: TCGA_DU_6408_19860521_55, shape torch.Size([3, 1, 256, 253]), rank 0 
2024-11-22 02:34:45.061878: predicting TCGA_DU_7008_19830723_1 
2024-11-22 02:34:45.062456: TCGA_DU_7008_19830723_1, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:45.148643: predicting TCGA_DU_7008_19830723_15 
2024-11-22 02:34:45.149297: TCGA_DU_7008_19830723_15, shape torch.Size([3, 1, 255, 255]), rank 0 
2024-11-22 02:34:45.191262: predicting TCGA_DU_7008_19830723_25 
2024-11-22 02:34:45.191783: TCGA_DU_7008_19830723_25, shape torch.Size([3, 1, 253, 254]), rank 0 
2024-11-22 02:34:45.222002: predicting TCGA_DU_7008_19830723_29 
2024-11-22 02:34:45.222802: TCGA_DU_7008_19830723_29, shape torch.Size([3, 1, 252, 254]), rank 0 
2024-11-22 02:34:45.267547: predicting TCGA_DU_7008_19830723_35 
2024-11-22 02:34:45.268187: TCGA_DU_7008_19830723_35, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-22 02:34:45.332934: predicting TCGA_DU_7008_19830723_39 
2024-11-22 02:34:45.342560: TCGA_DU_7008_19830723_39, shape torch.Size([3, 1, 254, 255]), rank 0 
2024-11-22 02:34:45.375666: predicting TCGA_DU_7008_19830723_40 
2024-11-22 02:34:45.376283: TCGA_DU_7008_19830723_40, shape torch.Size([3, 1, 254, 255]), rank 0 
2024-11-22 02:34:45.433475: predicting TCGA_DU_7010_19860307_1 
2024-11-22 02:34:45.434055: TCGA_DU_7010_19860307_1, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:45.469632: predicting TCGA_DU_7010_19860307_17 
2024-11-22 02:34:45.470234: TCGA_DU_7010_19860307_17, shape torch.Size([3, 1, 254, 255]), rank 0 
2024-11-22 02:34:45.498806: predicting TCGA_DU_7010_19860307_31 
2024-11-22 02:34:45.499326: TCGA_DU_7010_19860307_31, shape torch.Size([3, 1, 253, 253]), rank 0 
2024-11-22 02:34:45.556062: predicting TCGA_DU_7010_19860307_37 
2024-11-22 02:34:45.556702: TCGA_DU_7010_19860307_37, shape torch.Size([3, 1, 253, 253]), rank 0 
2024-11-22 02:34:45.607967: predicting TCGA_DU_7010_19860307_52 
2024-11-22 02:34:45.611078: TCGA_DU_7010_19860307_52, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-22 02:34:45.655402: predicting TCGA_DU_7010_19860307_54 
2024-11-22 02:34:45.655887: TCGA_DU_7010_19860307_54, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:45.682743: predicting TCGA_DU_7010_19860307_9 
2024-11-22 02:34:45.683263: TCGA_DU_7010_19860307_9, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:45.739051: predicting TCGA_DU_7013_19860523_10 
2024-11-22 02:34:45.743959: TCGA_DU_7013_19860523_10, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:45.799642: predicting TCGA_DU_7013_19860523_28 
2024-11-22 02:34:45.800215: TCGA_DU_7013_19860523_28, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-22 02:34:45.832591: predicting TCGA_DU_7013_19860523_33 
2024-11-22 02:34:45.836894: TCGA_DU_7013_19860523_33, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-22 02:34:45.887266: predicting TCGA_DU_7013_19860523_37 
2024-11-22 02:34:45.888133: TCGA_DU_7013_19860523_37, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:45.944708: predicting TCGA_DU_7014_19860618_15 
2024-11-22 02:34:45.946509: TCGA_DU_7014_19860618_15, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:45.971512: predicting TCGA_DU_7014_19860618_22 
2024-11-22 02:34:45.971993: TCGA_DU_7014_19860618_22, shape torch.Size([3, 1, 255, 255]), rank 0 
2024-11-22 02:34:46.002856: predicting TCGA_DU_7014_19860618_3 
2024-11-22 02:34:46.007352: TCGA_DU_7014_19860618_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:46.052337: predicting TCGA_DU_7014_19860618_37 
2024-11-22 02:34:46.052930: TCGA_DU_7014_19860618_37, shape torch.Size([3, 1, 255, 255]), rank 0 
2024-11-22 02:34:46.112862: predicting TCGA_DU_7014_19860618_4 
2024-11-22 02:34:46.113478: TCGA_DU_7014_19860618_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:46.159658: predicting TCGA_DU_7014_19860618_54 
2024-11-22 02:34:46.160252: TCGA_DU_7014_19860618_54, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:46.218592: predicting TCGA_DU_7014_19860618_6 
2024-11-22 02:34:46.219136: TCGA_DU_7014_19860618_6, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:46.247628: predicting TCGA_DU_7018_19911220_10 
2024-11-22 02:34:46.248235: TCGA_DU_7018_19911220_10, shape torch.Size([3, 1, 251, 252]), rank 0 
2024-11-22 02:34:46.284768: predicting TCGA_DU_7018_19911220_30 
2024-11-22 02:34:46.286438: TCGA_DU_7018_19911220_30, shape torch.Size([3, 1, 251, 254]), rank 0 
2024-11-22 02:34:46.314653: predicting TCGA_DU_7019_19940908_16 
2024-11-22 02:34:46.315220: TCGA_DU_7019_19940908_16, shape torch.Size([3, 1, 247, 249]), rank 0 
2024-11-22 02:34:46.346648: predicting TCGA_DU_7019_19940908_22 
2024-11-22 02:34:46.347151: TCGA_DU_7019_19940908_22, shape torch.Size([3, 1, 246, 249]), rank 0 
2024-11-22 02:34:46.386787: predicting TCGA_DU_7019_19940908_27 
2024-11-22 02:34:46.387351: TCGA_DU_7019_19940908_27, shape torch.Size([3, 1, 248, 252]), rank 0 
2024-11-22 02:34:46.442526: predicting TCGA_DU_7019_19940908_28 
2024-11-22 02:34:46.443089: TCGA_DU_7019_19940908_28, shape torch.Size([3, 1, 248, 252]), rank 0 
2024-11-22 02:34:46.513658: predicting TCGA_DU_7019_19940908_34 
2024-11-22 02:34:46.514277: TCGA_DU_7019_19940908_34, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:34:46.588656: predicting TCGA_DU_7019_19940908_35 
2024-11-22 02:34:46.591164: TCGA_DU_7019_19940908_35, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:46.616954: predicting TCGA_DU_7019_19940908_5 
2024-11-22 02:34:46.617467: TCGA_DU_7019_19940908_5, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:34:46.649641: predicting TCGA_DU_7019_19940908_7 
2024-11-22 02:34:46.650181: TCGA_DU_7019_19940908_7, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-22 02:34:46.697618: predicting TCGA_DU_7294_19890104_1 
2024-11-22 02:34:46.698133: TCGA_DU_7294_19890104_1, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:46.746652: predicting TCGA_DU_7294_19890104_15 
2024-11-22 02:34:46.747239: TCGA_DU_7294_19890104_15, shape torch.Size([3, 1, 248, 250]), rank 0 
2024-11-22 02:34:46.804699: predicting TCGA_DU_7294_19890104_17 
2024-11-22 02:34:46.806719: TCGA_DU_7294_19890104_17, shape torch.Size([3, 1, 248, 249]), rank 0 
2024-11-22 02:34:46.857205: predicting TCGA_DU_7294_19890104_23 
2024-11-22 02:34:46.859114: TCGA_DU_7294_19890104_23, shape torch.Size([3, 1, 249, 250]), rank 0 
2024-11-22 02:34:46.884014: predicting TCGA_DU_7294_19890104_26 
2024-11-22 02:34:46.886005: TCGA_DU_7294_19890104_26, shape torch.Size([3, 1, 251, 252]), rank 0 
2024-11-22 02:34:46.918655: predicting TCGA_DU_7294_19890104_28 
2024-11-22 02:34:46.919206: TCGA_DU_7294_19890104_28, shape torch.Size([3, 1, 253, 254]), rank 0 
2024-11-22 02:34:46.958571: predicting TCGA_DU_7294_19890104_3 
2024-11-22 02:34:46.959133: TCGA_DU_7294_19890104_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:47.006978: predicting TCGA_DU_7298_19910324_13 
2024-11-22 02:34:47.007621: TCGA_DU_7298_19910324_13, shape torch.Size([3, 1, 252, 254]), rank 0 
2024-11-22 02:34:47.048981: predicting TCGA_DU_7298_19910324_32 
2024-11-22 02:34:47.049542: TCGA_DU_7298_19910324_32, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-22 02:34:47.103144: predicting TCGA_DU_7298_19910324_7 
2024-11-22 02:34:47.103726: TCGA_DU_7298_19910324_7, shape torch.Size([3, 1, 254, 255]), rank 0 
2024-11-22 02:34:47.137425: predicting TCGA_DU_7299_19910417_2 
2024-11-22 02:34:47.145890: TCGA_DU_7299_19910417_2, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:47.211427: predicting TCGA_DU_7299_19910417_35 
2024-11-22 02:34:47.212381: TCGA_DU_7299_19910417_35, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-22 02:34:47.264256: predicting TCGA_DU_7299_19910417_6 
2024-11-22 02:34:47.267936: TCGA_DU_7299_19910417_6, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:47.297541: predicting TCGA_DU_7300_19910814_1 
2024-11-22 02:34:47.299538: TCGA_DU_7300_19910814_1, shape torch.Size([3, 1, 249, 239]), rank 0 
2024-11-22 02:34:47.328796: predicting TCGA_DU_7300_19910814_23 
2024-11-22 02:34:47.329295: TCGA_DU_7300_19910814_23, shape torch.Size([3, 1, 247, 249]), rank 0 
2024-11-22 02:34:47.379962: predicting TCGA_DU_7300_19910814_33 
2024-11-22 02:34:47.380509: TCGA_DU_7300_19910814_33, shape torch.Size([3, 1, 243, 256]), rank 0 
2024-11-22 02:34:47.426249: predicting TCGA_DU_7300_19910814_6 
2024-11-22 02:34:47.426767: TCGA_DU_7300_19910814_6, shape torch.Size([3, 1, 251, 255]), rank 0 
2024-11-22 02:34:47.489681: predicting TCGA_DU_7300_19910814_7 
2024-11-22 02:34:47.490287: TCGA_DU_7300_19910814_7, shape torch.Size([3, 1, 251, 255]), rank 0 
2024-11-22 02:34:47.538450: predicting TCGA_DU_7301_19911112_1 
2024-11-22 02:34:47.538956: TCGA_DU_7301_19911112_1, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-22 02:34:47.566335: predicting TCGA_DU_7301_19911112_12 
2024-11-22 02:34:47.566822: TCGA_DU_7301_19911112_12, shape torch.Size([3, 1, 248, 250]), rank 0 
2024-11-22 02:34:47.596944: predicting TCGA_DU_7301_19911112_15 
2024-11-22 02:34:47.597515: TCGA_DU_7301_19911112_15, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-22 02:34:47.654736: predicting TCGA_DU_7301_19911112_29 
2024-11-22 02:34:47.655243: TCGA_DU_7301_19911112_29, shape torch.Size([3, 1, 250, 254]), rank 0 
2024-11-22 02:34:47.700852: predicting TCGA_DU_7301_19911112_3 
2024-11-22 02:34:47.702738: TCGA_DU_7301_19911112_3, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:34:47.759717: predicting TCGA_DU_7301_19911112_5 
2024-11-22 02:34:47.760231: TCGA_DU_7301_19911112_5, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:34:47.822714: predicting TCGA_DU_7302_19911203_18 
2024-11-22 02:34:47.824835: TCGA_DU_7302_19911203_18, shape torch.Size([3, 1, 248, 248]), rank 0 
2024-11-22 02:34:47.849174: predicting TCGA_DU_7302_19911203_20 
2024-11-22 02:34:47.851230: TCGA_DU_7302_19911203_20, shape torch.Size([3, 1, 248, 248]), rank 0 
2024-11-22 02:34:47.887694: predicting TCGA_DU_7302_19911203_22 
2024-11-22 02:34:47.892073: TCGA_DU_7302_19911203_22, shape torch.Size([3, 1, 248, 248]), rank 0 
2024-11-22 02:34:47.929753: predicting TCGA_DU_7302_19911203_23 
2024-11-22 02:34:47.930333: TCGA_DU_7302_19911203_23, shape torch.Size([3, 1, 248, 249]), rank 0 
2024-11-22 02:34:47.992691: predicting TCGA_DU_7302_19911203_24 
2024-11-22 02:34:47.993309: TCGA_DU_7302_19911203_24, shape torch.Size([3, 1, 248, 250]), rank 0 
2024-11-22 02:34:48.020516: predicting TCGA_DU_7302_19911203_28 
2024-11-22 02:34:48.023690: TCGA_DU_7302_19911203_28, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-22 02:34:48.060547: predicting TCGA_DU_7302_19911203_29 
2024-11-22 02:34:48.062546: TCGA_DU_7302_19911203_29, shape torch.Size([3, 1, 253, 254]), rank 0 
2024-11-22 02:34:48.093497: predicting TCGA_DU_7302_19911203_8 
2024-11-22 02:34:48.100134: TCGA_DU_7302_19911203_8, shape torch.Size([3, 1, 251, 254]), rank 0 
2024-11-22 02:34:48.175698: predicting TCGA_DU_7302_19911203_9 
2024-11-22 02:34:48.176304: TCGA_DU_7302_19911203_9, shape torch.Size([3, 1, 251, 253]), rank 0 
2024-11-22 02:34:48.210271: predicting TCGA_DU_7304_19930325_22 
2024-11-22 02:34:48.215908: TCGA_DU_7304_19930325_22, shape torch.Size([3, 1, 248, 249]), rank 0 
2024-11-22 02:34:48.256005: predicting TCGA_DU_7304_19930325_23 
2024-11-22 02:34:48.256546: TCGA_DU_7304_19930325_23, shape torch.Size([3, 1, 248, 249]), rank 0 
2024-11-22 02:34:48.317178: predicting TCGA_DU_7304_19930325_24 
2024-11-22 02:34:48.320931: TCGA_DU_7304_19930325_24, shape torch.Size([3, 1, 248, 249]), rank 0 
2024-11-22 02:34:48.359685: predicting TCGA_DU_7304_19930325_26 
2024-11-22 02:34:48.360232: TCGA_DU_7304_19930325_26, shape torch.Size([3, 1, 249, 251]), rank 0 
2024-11-22 02:34:48.403522: predicting TCGA_DU_7304_19930325_28 
2024-11-22 02:34:48.404087: TCGA_DU_7304_19930325_28, shape torch.Size([3, 1, 251, 253]), rank 0 
2024-11-22 02:34:48.443599: predicting TCGA_DU_7304_19930325_30 
2024-11-22 02:34:48.445709: TCGA_DU_7304_19930325_30, shape torch.Size([3, 1, 252, 255]), rank 0 
2024-11-22 02:34:48.486643: predicting TCGA_DU_7304_19930325_31 
2024-11-22 02:34:48.487256: TCGA_DU_7304_19930325_31, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:34:48.548473: predicting TCGA_DU_7304_19930325_5 
2024-11-22 02:34:48.553025: TCGA_DU_7304_19930325_5, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-22 02:34:48.594648: predicting TCGA_DU_7306_19930512_17 
2024-11-22 02:34:48.596385: TCGA_DU_7306_19930512_17, shape torch.Size([3, 1, 246, 249]), rank 0 
2024-11-22 02:34:48.640530: predicting TCGA_DU_7306_19930512_21 
2024-11-22 02:34:48.641099: TCGA_DU_7306_19930512_21, shape torch.Size([3, 1, 246, 248]), rank 0 
2024-11-22 02:34:48.672831: predicting TCGA_DU_7306_19930512_25 
2024-11-22 02:34:48.674612: TCGA_DU_7306_19930512_25, shape torch.Size([3, 1, 247, 250]), rank 0 
2024-11-22 02:34:48.710882: predicting TCGA_DU_7306_19930512_36 
2024-11-22 02:34:48.711413: TCGA_DU_7306_19930512_36, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-22 02:34:48.758432: predicting TCGA_DU_7309_19960831_1 
2024-11-22 02:34:48.758951: TCGA_DU_7309_19960831_1, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-22 02:34:48.809691: predicting TCGA_DU_7309_19960831_24 
2024-11-22 02:34:48.810242: TCGA_DU_7309_19960831_24, shape torch.Size([3, 1, 248, 249]), rank 0 
2024-11-22 02:34:48.869068: predicting TCGA_DU_7309_19960831_26 
2024-11-22 02:34:48.877262: TCGA_DU_7309_19960831_26, shape torch.Size([3, 1, 249, 250]), rank 0 
2024-11-22 02:34:48.908688: predicting TCGA_DU_7309_19960831_30 
2024-11-22 02:34:48.909208: TCGA_DU_7309_19960831_30, shape torch.Size([3, 1, 252, 252]), rank 0 
2024-11-22 02:34:48.950673: predicting TCGA_DU_7309_19960831_37 
2024-11-22 02:34:48.951153: TCGA_DU_7309_19960831_37, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-22 02:34:48.991238: predicting TCGA_DU_7309_19960831_40 
2024-11-22 02:34:48.992081: TCGA_DU_7309_19960831_40, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-22 02:34:49.024065: predicting TCGA_DU_7309_19960831_7 
2024-11-22 02:34:49.024620: TCGA_DU_7309_19960831_7, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:49.072882: predicting TCGA_DU_8162_19961029_21 
2024-11-22 02:34:49.073441: TCGA_DU_8162_19961029_21, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-22 02:34:49.112192: predicting TCGA_DU_8162_19961029_29 
2024-11-22 02:34:49.112756: TCGA_DU_8162_19961029_29, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-22 02:34:49.159765: predicting TCGA_DU_8162_19961029_37 
2024-11-22 02:34:49.160300: TCGA_DU_8162_19961029_37, shape torch.Size([3, 1, 256, 202]), rank 0 
2024-11-22 02:34:49.228972: predicting TCGA_DU_8162_19961029_6 
2024-11-22 02:34:49.231879: TCGA_DU_8162_19961029_6, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-22 02:34:49.279371: predicting TCGA_DU_8163_19961119_11 
2024-11-22 02:34:49.279891: TCGA_DU_8163_19961119_11, shape torch.Size([3, 1, 248, 252]), rank 0 
2024-11-22 02:34:49.309690: predicting TCGA_DU_8163_19961119_18 
2024-11-22 02:34:49.310197: TCGA_DU_8163_19961119_18, shape torch.Size([3, 1, 246, 248]), rank 0 
2024-11-22 02:34:49.357054: predicting TCGA_DU_8163_19961119_2 
2024-11-22 02:34:49.357692: TCGA_DU_8163_19961119_2, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-22 02:34:49.390641: predicting TCGA_DU_8163_19961119_23 
2024-11-22 02:34:49.393842: TCGA_DU_8163_19961119_23, shape torch.Size([3, 1, 247, 250]), rank 0 
2024-11-22 02:34:49.427022: predicting TCGA_DU_8163_19961119_25 
2024-11-22 02:34:49.428856: TCGA_DU_8163_19961119_25, shape torch.Size([3, 1, 247, 250]), rank 0 
2024-11-22 02:34:49.478063: predicting TCGA_DU_8163_19961119_26 
2024-11-22 02:34:49.479958: TCGA_DU_8163_19961119_26, shape torch.Size([3, 1, 248, 250]), rank 0 
2024-11-22 02:34:49.552691: predicting TCGA_DU_8163_19961119_30 
2024-11-22 02:34:49.553291: TCGA_DU_8163_19961119_30, shape torch.Size([3, 1, 250, 254]), rank 0 
2024-11-22 02:34:49.597520: predicting TCGA_DU_8163_19961119_5 
2024-11-22 02:34:49.603901: TCGA_DU_8163_19961119_5, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-22 02:34:49.629848: predicting TCGA_DU_8163_19961119_8 
2024-11-22 02:34:49.630353: TCGA_DU_8163_19961119_8, shape torch.Size([3, 1, 251, 255]), rank 0 
2024-11-22 02:34:49.678268: predicting TCGA_DU_8164_19970111_16 
2024-11-22 02:34:49.678789: TCGA_DU_8164_19970111_16, shape torch.Size([3, 1, 248, 249]), rank 0 
2024-11-22 02:34:49.720703: predicting TCGA_DU_8164_19970111_17 
2024-11-22 02:34:49.721301: TCGA_DU_8164_19970111_17, shape torch.Size([3, 1, 248, 249]), rank 0 
2024-11-22 02:34:49.749316: predicting TCGA_DU_8164_19970111_34 
2024-11-22 02:34:49.749868: TCGA_DU_8164_19970111_34, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:49.821718: predicting TCGA_DU_8164_19970111_35 
2024-11-22 02:34:49.822367: TCGA_DU_8164_19970111_35, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-22 02:34:49.875052: predicting TCGA_DU_8164_19970111_9 
2024-11-22 02:34:49.875607: TCGA_DU_8164_19970111_9, shape torch.Size([3, 1, 250, 253]), rank 0 
2024-11-22 02:34:49.905297: predicting TCGA_DU_8165_19970205_17 
2024-11-22 02:34:49.905822: TCGA_DU_8165_19970205_17, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-22 02:34:49.947142: predicting TCGA_DU_8165_19970205_18 
2024-11-22 02:34:49.952949: TCGA_DU_8165_19970205_18, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-22 02:34:50.003887: predicting TCGA_DU_8165_19970205_20 
2024-11-22 02:34:50.005901: TCGA_DU_8165_19970205_20, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-22 02:34:50.032055: predicting TCGA_DU_8165_19970205_30 
2024-11-22 02:34:50.032850: TCGA_DU_8165_19970205_30, shape torch.Size([3, 1, 252, 255]), rank 0 
2024-11-22 02:34:50.073079: predicting TCGA_DU_8165_19970205_31 
2024-11-22 02:34:50.073576: TCGA_DU_8165_19970205_31, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:34:50.115430: predicting TCGA_DU_8165_19970205_32 
2024-11-22 02:34:50.117407: TCGA_DU_8165_19970205_32, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:50.164650: predicting TCGA_DU_8165_19970205_5 
2024-11-22 02:34:50.165173: TCGA_DU_8165_19970205_5, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:34:50.225500: predicting TCGA_DU_8166_19970322_17 
2024-11-22 02:34:50.226031: TCGA_DU_8166_19970322_17, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-22 02:34:50.255050: predicting TCGA_DU_8166_19970322_18 
2024-11-22 02:34:50.255572: TCGA_DU_8166_19970322_18, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-22 02:34:50.288004: predicting TCGA_DU_8166_19970322_26 
2024-11-22 02:34:50.289742: TCGA_DU_8166_19970322_26, shape torch.Size([3, 1, 250, 251]), rank 0 
2024-11-22 02:34:50.343711: predicting TCGA_DU_8166_19970322_30 
2024-11-22 02:34:50.344332: TCGA_DU_8166_19970322_30, shape torch.Size([3, 1, 253, 255]), rank 0 
2024-11-22 02:34:50.399553: predicting TCGA_DU_8166_19970322_6 
2024-11-22 02:34:50.400105: TCGA_DU_8166_19970322_6, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:34:50.444691: predicting TCGA_DU_8167_19970402_1 
2024-11-22 02:34:50.452082: TCGA_DU_8167_19970402_1, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-22 02:34:50.492126: predicting TCGA_DU_8167_19970402_12 
2024-11-22 02:34:50.494512: TCGA_DU_8167_19970402_12, shape torch.Size([3, 1, 248, 251]), rank 0 
2024-11-22 02:34:50.520785: predicting TCGA_DU_8167_19970402_21 
2024-11-22 02:34:50.522719: TCGA_DU_8167_19970402_21, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-22 02:34:50.551699: predicting TCGA_DU_8167_19970402_33 
2024-11-22 02:34:50.552185: TCGA_DU_8167_19970402_33, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:50.593006: predicting TCGA_DU_8168_19970503_18 
2024-11-22 02:34:50.593545: TCGA_DU_8168_19970503_18, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-22 02:34:50.643670: predicting TCGA_DU_8168_19970503_26 
2024-11-22 02:34:50.644250: TCGA_DU_8168_19970503_26, shape torch.Size([3, 1, 249, 251]), rank 0 
2024-11-22 02:34:50.673809: predicting TCGA_DU_8168_19970503_7 
2024-11-22 02:34:50.677026: TCGA_DU_8168_19970503_7, shape torch.Size([3, 1, 253, 255]), rank 0 
2024-11-22 02:34:50.720185: predicting TCGA_DU_8168_19970503_8 
2024-11-22 02:34:50.732875: TCGA_DU_8168_19970503_8, shape torch.Size([3, 1, 252, 254]), rank 0 
2024-11-22 02:34:50.811742: predicting TCGA_DU_A5TP_19970614_25 
2024-11-22 02:34:50.812334: TCGA_DU_A5TP_19970614_25, shape torch.Size([3, 1, 247, 250]), rank 0 
2024-11-22 02:34:50.839709: predicting TCGA_DU_A5TP_19970614_37 
2024-11-22 02:34:50.840801: TCGA_DU_A5TP_19970614_37, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-22 02:34:50.884811: predicting TCGA_DU_A5TR_19970726_16 
2024-11-22 02:34:50.885413: TCGA_DU_A5TR_19970726_16, shape torch.Size([3, 1, 249, 249]), rank 0 
2024-11-22 02:34:50.919644: predicting TCGA_DU_A5TR_19970726_18 
2024-11-22 02:34:50.920190: TCGA_DU_A5TR_19970726_18, shape torch.Size([3, 1, 249, 248]), rank 0 
2024-11-22 02:34:50.969393: predicting TCGA_DU_A5TR_19970726_22 
2024-11-22 02:34:50.970012: TCGA_DU_A5TR_19970726_22, shape torch.Size([3, 1, 249, 248]), rank 0 
2024-11-22 02:34:51.020147: predicting TCGA_DU_A5TS_19970726_1 
2024-11-22 02:34:51.022135: TCGA_DU_A5TS_19970726_1, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:34:51.075240: predicting TCGA_DU_A5TS_19970726_13 
2024-11-22 02:34:51.078706: TCGA_DU_A5TS_19970726_13, shape torch.Size([3, 1, 250, 254]), rank 0 
2024-11-22 02:34:51.118124: predicting TCGA_DU_A5TS_19970726_28 
2024-11-22 02:34:51.118621: TCGA_DU_A5TS_19970726_28, shape torch.Size([3, 1, 251, 256]), rank 0 
2024-11-22 02:34:51.146869: predicting TCGA_DU_A5TS_19970726_7 
2024-11-22 02:34:51.151007: TCGA_DU_A5TS_19970726_7, shape torch.Size([3, 1, 251, 256]), rank 0 
2024-11-22 02:34:51.201118: predicting TCGA_DU_A5TS_19970726_8 
2024-11-22 02:34:51.207601: TCGA_DU_A5TS_19970726_8, shape torch.Size([3, 1, 251, 255]), rank 0 
2024-11-22 02:34:51.238252: predicting TCGA_DU_A5TS_19970726_9 
2024-11-22 02:34:51.238776: TCGA_DU_A5TS_19970726_9, shape torch.Size([3, 1, 250, 255]), rank 0 
2024-11-22 02:34:51.289217: predicting TCGA_DU_A5TT_19980318_14 
2024-11-22 02:34:51.289742: TCGA_DU_A5TT_19980318_14, shape torch.Size([3, 1, 247, 203]), rank 0 
2024-11-22 02:34:51.351852: predicting TCGA_DU_A5TT_19980318_21 
2024-11-22 02:34:51.354115: TCGA_DU_A5TT_19980318_21, shape torch.Size([3, 1, 252, 203]), rank 0 
2024-11-22 02:34:51.382440: predicting TCGA_DU_A5TT_19980318_25 
2024-11-22 02:34:51.382919: TCGA_DU_A5TT_19980318_25, shape torch.Size([3, 1, 251, 204]), rank 0 
2024-11-22 02:34:51.430184: predicting TCGA_DU_A5TT_19980318_28 
2024-11-22 02:34:51.434754: TCGA_DU_A5TT_19980318_28, shape torch.Size([3, 1, 254, 203]), rank 0 
2024-11-22 02:34:51.465386: predicting TCGA_DU_A5TT_19980318_3 
2024-11-22 02:34:51.465917: TCGA_DU_A5TT_19980318_3, shape torch.Size([3, 1, 255, 203]), rank 0 
2024-11-22 02:34:51.499229: predicting TCGA_DU_A5TT_19980318_31 
2024-11-22 02:34:51.499747: TCGA_DU_A5TT_19980318_31, shape torch.Size([3, 1, 255, 205]), rank 0 
2024-11-22 02:34:51.552746: predicting TCGA_DU_A5TT_19980318_34 
2024-11-22 02:34:51.553311: TCGA_DU_A5TT_19980318_34, shape torch.Size([3, 1, 255, 204]), rank 0 
2024-11-22 02:34:51.619668: predicting TCGA_DU_A5TT_19980318_39 
2024-11-22 02:34:51.620516: TCGA_DU_A5TT_19980318_39, shape torch.Size([3, 1, 254, 205]), rank 0 
2024-11-22 02:34:51.662823: predicting TCGA_DU_A5TT_19980318_41 
2024-11-22 02:34:51.663367: TCGA_DU_A5TT_19980318_41, shape torch.Size([3, 1, 253, 206]), rank 0 
2024-11-22 02:34:51.698109: predicting TCGA_DU_A5TT_19980318_54 
2024-11-22 02:34:51.698726: TCGA_DU_A5TT_19980318_54, shape torch.Size([3, 1, 241, 205]), rank 0 
2024-11-22 02:34:51.764175: predicting TCGA_DU_A5TT_19980318_9 
2024-11-22 02:34:51.765072: TCGA_DU_A5TT_19980318_9, shape torch.Size([3, 1, 246, 203]), rank 0 
2024-11-22 02:34:51.803766: predicting TCGA_DU_A5TU_19980312_8 
2024-11-22 02:34:51.805726: TCGA_DU_A5TU_19980312_8, shape torch.Size([3, 1, 256, 241]), rank 0 
2024-11-22 02:34:51.832540: predicting TCGA_DU_A5TW_19980228_1 
2024-11-22 02:34:51.833062: TCGA_DU_A5TW_19980228_1, shape torch.Size([3, 1, 256, 215]), rank 0 
2024-11-22 02:34:51.877075: predicting TCGA_DU_A5TW_19980228_10 
2024-11-22 02:34:51.877606: TCGA_DU_A5TW_19980228_10, shape torch.Size([3, 1, 256, 225]), rank 0 
2024-11-22 02:34:51.937334: predicting TCGA_DU_A5TW_19980228_23 
2024-11-22 02:34:51.938339: TCGA_DU_A5TW_19980228_23, shape torch.Size([3, 1, 256, 228]), rank 0 
2024-11-22 02:34:52.002911: predicting TCGA_DU_A5TW_19980228_30 
2024-11-22 02:34:52.003500: TCGA_DU_A5TW_19980228_30, shape torch.Size([3, 1, 228, 176]), rank 0 
2024-11-22 02:34:52.037594: predicting TCGA_DU_A5TW_19980228_6 
2024-11-22 02:34:52.038085: TCGA_DU_A5TW_19980228_6, shape torch.Size([3, 1, 256, 226]), rank 0 
2024-11-22 02:34:52.067783: predicting TCGA_DU_A5TW_19980228_7 
2024-11-22 02:34:52.072073: TCGA_DU_A5TW_19980228_7, shape torch.Size([3, 1, 256, 226]), rank 0 
2024-11-22 02:34:52.145735: predicting TCGA_DU_A5TY_19970709_11 
2024-11-22 02:34:52.146254: TCGA_DU_A5TY_19970709_11, shape torch.Size([3, 1, 251, 251]), rank 0 
2024-11-22 02:34:52.189993: predicting TCGA_DU_A5TY_19970709_15 
2024-11-22 02:34:52.190500: TCGA_DU_A5TY_19970709_15, shape torch.Size([3, 1, 247, 249]), rank 0 
2024-11-22 02:34:52.221784: predicting TCGA_DU_A5TY_19970709_19 
2024-11-22 02:34:52.222338: TCGA_DU_A5TY_19970709_19, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-22 02:34:52.248185: predicting TCGA_DU_A5TY_19970709_28 
2024-11-22 02:34:52.249009: TCGA_DU_A5TY_19970709_28, shape torch.Size([3, 1, 252, 254]), rank 0 
2024-11-22 02:34:52.308085: predicting TCGA_DU_A5TY_19970709_3 
2024-11-22 02:34:52.308631: TCGA_DU_A5TY_19970709_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:52.343428: predicting TCGA_DU_A5TY_19970709_31 
2024-11-22 02:34:52.344034: TCGA_DU_A5TY_19970709_31, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:52.368464: predicting TCGA_DU_A5TY_19970709_35 
2024-11-22 02:34:52.368932: TCGA_DU_A5TY_19970709_35, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:52.414321: predicting TCGA_DU_A5TY_19970709_7 
2024-11-22 02:34:52.421040: TCGA_DU_A5TY_19970709_7, shape torch.Size([3, 1, 253, 255]), rank 0 
2024-11-22 02:34:52.507354: predicting TCGA_EZ_7264_20010816_13 
2024-11-22 02:34:52.509408: TCGA_EZ_7264_20010816_13, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-22 02:34:52.568305: predicting TCGA_EZ_7264_20010816_14 
2024-11-22 02:34:52.570314: TCGA_EZ_7264_20010816_14, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-22 02:34:52.595181: predicting TCGA_EZ_7264_20010816_18 
2024-11-22 02:34:52.597206: TCGA_EZ_7264_20010816_18, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-22 02:34:52.632144: predicting TCGA_EZ_7264_20010816_8 
2024-11-22 02:34:52.637002: TCGA_EZ_7264_20010816_8, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-22 02:34:52.679647: predicting TCGA_FG_5962_20000626_1 
2024-11-22 02:34:52.680176: TCGA_FG_5962_20000626_1, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:52.730670: predicting TCGA_FG_5962_20000626_12 
2024-11-22 02:34:52.731212: TCGA_FG_5962_20000626_12, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:52.771908: predicting TCGA_FG_5962_20000626_14 
2024-11-22 02:34:52.772478: TCGA_FG_5962_20000626_14, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:52.806729: predicting TCGA_FG_5962_20000626_21 
2024-11-22 02:34:52.807278: TCGA_FG_5962_20000626_21, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:52.863320: predicting TCGA_FG_5962_20000626_23 
2024-11-22 02:34:52.863896: TCGA_FG_5962_20000626_23, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:52.916822: predicting TCGA_FG_5962_20000626_33 
2024-11-22 02:34:52.920589: TCGA_FG_5962_20000626_33, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:52.955877: predicting TCGA_FG_5962_20000626_37 
2024-11-22 02:34:52.956439: TCGA_FG_5962_20000626_37, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:52.988496: predicting TCGA_FG_5962_20000626_42 
2024-11-22 02:34:52.989027: TCGA_FG_5962_20000626_42, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:53.028294: predicting TCGA_FG_5962_20000626_49 
2024-11-22 02:34:53.030212: TCGA_FG_5962_20000626_49, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:53.078281: predicting TCGA_FG_5962_20000626_9 
2024-11-22 02:34:53.083366: TCGA_FG_5962_20000626_9, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:53.156286: predicting TCGA_FG_5964_20010511_10 
2024-11-22 02:34:53.160937: TCGA_FG_5964_20010511_10, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:53.202668: predicting TCGA_FG_5964_20010511_15 
2024-11-22 02:34:53.204617: TCGA_FG_5964_20010511_15, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:53.228875: predicting TCGA_FG_5964_20010511_16 
2024-11-22 02:34:53.230911: TCGA_FG_5964_20010511_16, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:53.260194: predicting TCGA_FG_5964_20010511_20 
2024-11-22 02:34:53.260827: TCGA_FG_5964_20010511_20, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:53.287598: predicting TCGA_FG_5964_20010511_22 
2024-11-22 02:34:53.288099: TCGA_FG_5964_20010511_22, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:53.337946: predicting TCGA_FG_6688_20020215_12 
2024-11-22 02:34:53.338641: TCGA_FG_6688_20020215_12, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:53.373047: predicting TCGA_FG_6688_20020215_16 
2024-11-22 02:34:53.376963: TCGA_FG_6688_20020215_16, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:53.453758: predicting TCGA_FG_6688_20020215_3 
2024-11-22 02:34:53.454293: TCGA_FG_6688_20020215_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:53.517318: predicting TCGA_FG_6689_20020326_13 
2024-11-22 02:34:53.522047: TCGA_FG_6689_20020326_13, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:53.548704: predicting TCGA_FG_6689_20020326_15 
2024-11-22 02:34:53.549219: TCGA_FG_6689_20020326_15, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:53.579690: predicting TCGA_FG_6689_20020326_26 
2024-11-22 02:34:53.580198: TCGA_FG_6689_20020326_26, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:53.659061: predicting TCGA_FG_6689_20020326_39 
2024-11-22 02:34:53.659614: TCGA_FG_6689_20020326_39, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:53.709628: predicting TCGA_FG_6690_20020226_10 
2024-11-22 02:34:53.710158: TCGA_FG_6690_20020226_10, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-22 02:34:53.772717: predicting TCGA_FG_6690_20020226_26 
2024-11-22 02:34:53.777075: TCGA_FG_6690_20020226_26, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:53.804051: predicting TCGA_FG_6690_20020226_31 
2024-11-22 02:34:53.804569: TCGA_FG_6690_20020226_31, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:53.846614: predicting TCGA_FG_6690_20020226_34 
2024-11-22 02:34:53.847133: TCGA_FG_6690_20020226_34, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:53.897319: predicting TCGA_FG_6690_20020226_36 
2024-11-22 02:34:53.897838: TCGA_FG_6690_20020226_36, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:53.932812: predicting TCGA_FG_6690_20020226_39 
2024-11-22 02:34:53.933399: TCGA_FG_6690_20020226_39, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:53.998876: predicting TCGA_FG_6690_20020226_43 
2024-11-22 02:34:53.999396: TCGA_FG_6690_20020226_43, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:54.025238: predicting TCGA_FG_6690_20020226_44 
2024-11-22 02:34:54.027040: TCGA_FG_6690_20020226_44, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:54.058797: predicting TCGA_FG_6690_20020226_50 
2024-11-22 02:34:54.059292: TCGA_FG_6690_20020226_50, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:54.116255: predicting TCGA_FG_6690_20020226_54 
2024-11-22 02:34:54.116794: TCGA_FG_6690_20020226_54, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:54.146246: predicting TCGA_FG_6690_20020226_57 
2024-11-22 02:34:54.150034: TCGA_FG_6690_20020226_57, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:54.189600: predicting TCGA_FG_6690_20020226_58 
2024-11-22 02:34:54.190103: TCGA_FG_6690_20020226_58, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:54.267764: predicting TCGA_FG_6690_20020226_6 
2024-11-22 02:34:54.268305: TCGA_FG_6690_20020226_6, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-22 02:34:54.321764: predicting TCGA_FG_6690_20020226_9 
2024-11-22 02:34:54.322288: TCGA_FG_6690_20020226_9, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-22 02:34:54.372772: predicting TCGA_FG_6691_20020405_19 
2024-11-22 02:34:54.375015: TCGA_FG_6691_20020405_19, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:54.400206: predicting TCGA_FG_6691_20020405_25 
2024-11-22 02:34:54.400732: TCGA_FG_6691_20020405_25, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:54.434724: predicting TCGA_FG_6691_20020405_3 
2024-11-22 02:34:54.435237: TCGA_FG_6691_20020405_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:54.475432: predicting TCGA_FG_6691_20020405_36 
2024-11-22 02:34:54.476122: TCGA_FG_6691_20020405_36, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:54.523779: predicting TCGA_FG_6691_20020405_45 
2024-11-22 02:34:54.524378: TCGA_FG_6691_20020405_45, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:54.561571: predicting TCGA_FG_6691_20020405_48 
2024-11-22 02:34:54.562184: TCGA_FG_6691_20020405_48, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:54.613153: predicting TCGA_FG_6691_20020405_5 
2024-11-22 02:34:54.613680: TCGA_FG_6691_20020405_5, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:54.674356: predicting TCGA_FG_6692_20020606_11 
2024-11-22 02:34:54.678007: TCGA_FG_6692_20020606_11, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:54.731155: predicting TCGA_FG_6692_20020606_13 
2024-11-22 02:34:54.732862: TCGA_FG_6692_20020606_13, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:54.791160: predicting TCGA_FG_6692_20020606_19 
2024-11-22 02:34:54.795958: TCGA_FG_6692_20020606_19, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:54.835943: predicting TCGA_FG_6692_20020606_25 
2024-11-22 02:34:54.837764: TCGA_FG_6692_20020606_25, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:54.862009: predicting TCGA_FG_6692_20020606_7 
2024-11-22 02:34:54.863986: TCGA_FG_6692_20020606_7, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:54.895777: predicting TCGA_FG_6692_20020606_9 
2024-11-22 02:34:54.896309: TCGA_FG_6692_20020606_9, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:54.930454: predicting TCGA_FG_7634_20000128_15 
2024-11-22 02:34:54.931070: TCGA_FG_7634_20000128_15, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:54.955869: predicting TCGA_FG_7634_20000128_20 
2024-11-22 02:34:54.956410: TCGA_FG_7634_20000128_20, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.010621: predicting TCGA_FG_7634_20000128_4 
2024-11-22 02:34:55.031871: TCGA_FG_7634_20000128_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.090415: predicting TCGA_FG_7634_20000128_5 
2024-11-22 02:34:55.092156: TCGA_FG_7634_20000128_5, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.125645: predicting TCGA_FG_7634_20000128_9 
2024-11-22 02:34:55.131941: TCGA_FG_7634_20000128_9, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.185420: predicting TCGA_FG_7637_20000922_10 
2024-11-22 02:34:55.185986: TCGA_FG_7637_20000922_10, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.242686: predicting TCGA_FG_7637_20000922_16 
2024-11-22 02:34:55.243315: TCGA_FG_7637_20000922_16, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.270204: predicting TCGA_FG_7637_20000922_25 
2024-11-22 02:34:55.270715: TCGA_FG_7637_20000922_25, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.316775: predicting TCGA_FG_7637_20000922_31 
2024-11-22 02:34:55.317286: TCGA_FG_7637_20000922_31, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.358246: predicting TCGA_FG_7637_20000922_32 
2024-11-22 02:34:55.358786: TCGA_FG_7637_20000922_32, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.394998: predicting TCGA_FG_7637_20000922_43 
2024-11-22 02:34:55.397377: TCGA_FG_7637_20000922_43, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.452836: predicting TCGA_FG_7643_20021104_10 
2024-11-22 02:34:55.453413: TCGA_FG_7643_20021104_10, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.503809: predicting TCGA_FG_7643_20021104_11 
2024-11-22 02:34:55.504453: TCGA_FG_7643_20021104_11, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.568821: predicting TCGA_FG_7643_20021104_16 
2024-11-22 02:34:55.569411: TCGA_FG_7643_20021104_16, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.594715: predicting TCGA_FG_7643_20021104_25 
2024-11-22 02:34:55.595240: TCGA_FG_7643_20021104_25, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.643202: predicting TCGA_FG_7643_20021104_3 
2024-11-22 02:34:55.643741: TCGA_FG_7643_20021104_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.686440: predicting TCGA_FG_7643_20021104_38 
2024-11-22 02:34:55.687062: TCGA_FG_7643_20021104_38, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.716149: predicting TCGA_FG_7643_20021104_42 
2024-11-22 02:34:55.716685: TCGA_FG_7643_20021104_42, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.748895: predicting TCGA_FG_7643_20021104_43 
2024-11-22 02:34:55.749509: TCGA_FG_7643_20021104_43, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.803905: predicting TCGA_FG_8189_20030516_10 
2024-11-22 02:34:55.804497: TCGA_FG_8189_20030516_10, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.873055: predicting TCGA_FG_8189_20030516_19 
2024-11-22 02:34:55.874809: TCGA_FG_8189_20030516_19, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.908783: predicting TCGA_FG_8189_20030516_22 
2024-11-22 02:34:55.909405: TCGA_FG_8189_20030516_22, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:55.959494: predicting TCGA_FG_8189_20030516_24 
2024-11-22 02:34:55.960090: TCGA_FG_8189_20030516_24, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.023797: predicting TCGA_FG_8189_20030516_39 
2024-11-22 02:34:56.024422: TCGA_FG_8189_20030516_39, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.052440: predicting TCGA_FG_8189_20030516_4 
2024-11-22 02:34:56.052941: TCGA_FG_8189_20030516_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.087050: predicting TCGA_FG_8189_20030516_41 
2024-11-22 02:34:56.087576: TCGA_FG_8189_20030516_41, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.146645: predicting TCGA_FG_8189_20030516_42 
2024-11-22 02:34:56.148661: TCGA_FG_8189_20030516_42, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.180136: predicting TCGA_FG_8189_20030516_44 
2024-11-22 02:34:56.182191: TCGA_FG_8189_20030516_44, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.229801: predicting TCGA_FG_8189_20030516_48 
2024-11-22 02:34:56.230414: TCGA_FG_8189_20030516_48, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.289817: predicting TCGA_FG_8189_20030516_5 
2024-11-22 02:34:56.290479: TCGA_FG_8189_20030516_5, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.337007: predicting TCGA_FG_8189_20030516_50 
2024-11-22 02:34:56.338824: TCGA_FG_8189_20030516_50, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.363165: predicting TCGA_FG_8189_20030516_53 
2024-11-22 02:34:56.363640: TCGA_FG_8189_20030516_53, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.391541: predicting TCGA_FG_8189_20030516_55 
2024-11-22 02:34:56.395999: TCGA_FG_8189_20030516_55, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.453787: predicting TCGA_FG_A4MT_20020212_17 
2024-11-22 02:34:56.455595: TCGA_FG_A4MT_20020212_17, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.488700: predicting TCGA_FG_A4MT_20020212_29 
2024-11-22 02:34:56.489272: TCGA_FG_A4MT_20020212_29, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.518046: predicting TCGA_FG_A4MT_20020212_32 
2024-11-22 02:34:56.521950: TCGA_FG_A4MT_20020212_32, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.569460: predicting TCGA_FG_A4MT_20020212_33 
2024-11-22 02:34:56.570016: TCGA_FG_A4MT_20020212_33, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.609936: predicting TCGA_FG_A4MT_20020212_37 
2024-11-22 02:34:56.610444: TCGA_FG_A4MT_20020212_37, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.640547: predicting TCGA_FG_A4MT_20020212_45 
2024-11-22 02:34:56.644958: TCGA_FG_A4MT_20020212_45, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.687808: predicting TCGA_FG_A4MT_20020212_50 
2024-11-22 02:34:56.688344: TCGA_FG_A4MT_20020212_50, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.760299: predicting TCGA_FG_A4MU_20030903_12 
2024-11-22 02:34:56.763074: TCGA_FG_A4MU_20030903_12, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.795158: predicting TCGA_FG_A4MU_20030903_19 
2024-11-22 02:34:56.800042: TCGA_FG_A4MU_20030903_19, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.827378: predicting TCGA_FG_A4MU_20030903_30 
2024-11-22 02:34:56.827875: TCGA_FG_A4MU_20030903_30, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.861278: predicting TCGA_FG_A4MU_20030903_31 
2024-11-22 02:34:56.861873: TCGA_FG_A4MU_20030903_31, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.917995: predicting TCGA_FG_A4MU_20030903_4 
2024-11-22 02:34:56.918571: TCGA_FG_A4MU_20030903_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:56.969558: predicting TCGA_FG_A4MU_20030903_5 
2024-11-22 02:34:56.973968: TCGA_FG_A4MU_20030903_5, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:57.022019: predicting TCGA_FG_A60K_20040224_11 
2024-11-22 02:34:57.034564: TCGA_FG_A60K_20040224_11, shape torch.Size([3, 1, 241, 162]), rank 0 
2024-11-22 02:34:57.064284: predicting TCGA_FG_A60K_20040224_16 
2024-11-22 02:34:57.064766: TCGA_FG_A60K_20040224_16, shape torch.Size([3, 1, 241, 162]), rank 0 
2024-11-22 02:34:57.139048: predicting TCGA_FG_A60K_20040224_21 
2024-11-22 02:34:57.140960: TCGA_FG_A60K_20040224_21, shape torch.Size([3, 1, 241, 162]), rank 0 
2024-11-22 02:34:57.170654: predicting TCGA_FG_A60K_20040224_22 
2024-11-22 02:34:57.172493: TCGA_FG_A60K_20040224_22, shape torch.Size([3, 1, 241, 162]), rank 0 
2024-11-22 02:34:57.205089: predicting TCGA_FG_A60K_20040224_45 
2024-11-22 02:34:57.205817: TCGA_FG_A60K_20040224_45, shape torch.Size([3, 1, 241, 160]), rank 0 
2024-11-22 02:34:57.251418: predicting TCGA_FG_A60K_20040224_49 
2024-11-22 02:34:57.251992: TCGA_FG_A60K_20040224_49, shape torch.Size([3, 1, 241, 160]), rank 0 
2024-11-22 02:34:57.305397: predicting TCGA_FG_A60K_20040224_52 
2024-11-22 02:34:57.307567: TCGA_FG_A60K_20040224_52, shape torch.Size([3, 1, 241, 160]), rank 0 
2024-11-22 02:34:57.347274: predicting TCGA_FG_A60K_20040224_66 
2024-11-22 02:34:57.351827: TCGA_FG_A60K_20040224_66, shape torch.Size([3, 1, 240, 160]), rank 0 
2024-11-22 02:34:57.382540: predicting TCGA_FG_A60K_20040224_69 
2024-11-22 02:34:57.383129: TCGA_FG_A60K_20040224_69, shape torch.Size([3, 1, 240, 160]), rank 0 
2024-11-22 02:34:57.427275: predicting TCGA_HT_7473_19970826_15 
2024-11-22 02:34:57.429222: TCGA_HT_7473_19970826_15, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:57.479649: predicting TCGA_HT_7473_19970826_3 
2024-11-22 02:34:57.481788: TCGA_HT_7473_19970826_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:57.533100: predicting TCGA_HT_7473_19970826_7 
2024-11-22 02:34:57.536965: TCGA_HT_7473_19970826_7, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:57.592966: predicting TCGA_HT_7473_19970826_9 
2024-11-22 02:34:57.593457: TCGA_HT_7473_19970826_9, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:57.621567: predicting TCGA_HT_7475_19970918_10 
2024-11-22 02:34:57.622084: TCGA_HT_7475_19970918_10, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:57.653652: predicting TCGA_HT_7475_19970918_19 
2024-11-22 02:34:57.654207: TCGA_HT_7475_19970918_19, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:34:57.704407: predicting TCGA_HT_7475_19970918_2 
2024-11-22 02:34:57.704928: TCGA_HT_7475_19970918_2, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:57.753836: predicting TCGA_HT_7475_19970918_26 
2024-11-22 02:34:57.755788: TCGA_HT_7475_19970918_26, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:34:57.811152: predicting TCGA_HT_7475_19970918_28 
2024-11-22 02:34:57.811712: TCGA_HT_7475_19970918_28, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:34:57.843043: predicting TCGA_HT_7475_19970918_4 
2024-11-22 02:34:57.843582: TCGA_HT_7475_19970918_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:57.883706: predicting TCGA_HT_7602_19951103_19 
2024-11-22 02:34:57.885605: TCGA_HT_7602_19951103_19, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:57.933037: predicting TCGA_HT_7605_19950916_13 
2024-11-22 02:34:57.937004: TCGA_HT_7605_19950916_13, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:57.982353: predicting TCGA_HT_7605_19950916_18 
2024-11-22 02:34:57.982879: TCGA_HT_7605_19950916_18, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:58.016437: predicting TCGA_HT_7605_19950916_25 
2024-11-22 02:34:58.022018: TCGA_HT_7605_19950916_25, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:58.076028: predicting TCGA_HT_7605_19950916_4 
2024-11-22 02:34:58.076524: TCGA_HT_7605_19950916_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:58.130679: predicting TCGA_HT_7605_19950916_5 
2024-11-22 02:34:58.132350: TCGA_HT_7605_19950916_5, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:58.172822: predicting TCGA_HT_7605_19950916_7 
2024-11-22 02:34:58.173361: TCGA_HT_7605_19950916_7, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:58.229823: predicting TCGA_HT_7608_19940304_20 
2024-11-22 02:34:58.230357: TCGA_HT_7608_19940304_20, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:58.278175: predicting TCGA_HT_7608_19940304_23 
2024-11-22 02:34:58.278793: TCGA_HT_7608_19940304_23, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:58.305595: predicting TCGA_HT_7616_19940813_18 
2024-11-22 02:34:58.306150: TCGA_HT_7616_19940813_18, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:34:58.341671: predicting TCGA_HT_7616_19940813_21 
2024-11-22 02:34:58.343774: TCGA_HT_7616_19940813_21, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-22 02:34:58.378156: predicting TCGA_HT_7616_19940813_23 
2024-11-22 02:34:58.378749: TCGA_HT_7616_19940813_23, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-22 02:34:58.442825: predicting TCGA_HT_7616_19940813_8 
2024-11-22 02:34:58.444959: TCGA_HT_7616_19940813_8, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:58.509558: predicting TCGA_HT_7680_19970202_16 
2024-11-22 02:34:58.510303: TCGA_HT_7680_19970202_16, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:58.565164: predicting TCGA_HT_7680_19970202_3 
2024-11-22 02:34:58.567499: TCGA_HT_7680_19970202_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:58.605225: predicting TCGA_HT_7684_19950816_15 
2024-11-22 02:34:58.607236: TCGA_HT_7684_19950816_15, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:58.633611: predicting TCGA_HT_7684_19950816_25 
2024-11-22 02:34:58.635286: TCGA_HT_7684_19950816_25, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:58.663844: predicting TCGA_HT_7690_19960312_10 
2024-11-22 02:34:58.664346: TCGA_HT_7690_19960312_10, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-22 02:34:58.713564: predicting TCGA_HT_7690_19960312_12 
2024-11-22 02:34:58.714359: TCGA_HT_7690_19960312_12, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:34:58.776361: predicting TCGA_HT_7690_19960312_9 
2024-11-22 02:34:58.776962: TCGA_HT_7690_19960312_9, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-22 02:34:58.805371: predicting TCGA_HT_7692_19960724_16 
2024-11-22 02:34:58.806040: TCGA_HT_7692_19960724_16, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:58.873590: predicting TCGA_HT_7693_19950520_19 
2024-11-22 02:34:58.875815: TCGA_HT_7693_19950520_19, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:58.901444: predicting TCGA_HT_7693_19950520_4 
2024-11-22 02:34:58.905933: TCGA_HT_7693_19950520_4, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:34:58.933924: predicting TCGA_HT_7693_19950520_5 
2024-11-22 02:34:58.937973: TCGA_HT_7693_19950520_5, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:34:58.997175: predicting TCGA_HT_7693_19950520_8 
2024-11-22 02:34:58.997682: TCGA_HT_7693_19950520_8, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:59.035434: predicting TCGA_HT_7694_19950404_11 
2024-11-22 02:34:59.035999: TCGA_HT_7694_19950404_11, shape torch.Size([3, 1, 254, 239]), rank 0 
2024-11-22 02:34:59.084157: predicting TCGA_HT_7855_19951020_1 
2024-11-22 02:34:59.084683: TCGA_HT_7855_19951020_1, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:59.119912: predicting TCGA_HT_7855_19951020_10 
2024-11-22 02:34:59.121212: TCGA_HT_7855_19951020_10, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:59.166479: predicting TCGA_HT_7855_19951020_11 
2024-11-22 02:34:59.168455: TCGA_HT_7855_19951020_11, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:59.246859: predicting TCGA_HT_7855_19951020_7 
2024-11-22 02:34:59.247422: TCGA_HT_7855_19951020_7, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:59.277885: predicting TCGA_HT_7856_19950831_23 
2024-11-22 02:34:59.278996: TCGA_HT_7856_19950831_23, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:59.329242: predicting TCGA_HT_7856_19950831_26 
2024-11-22 02:34:59.331317: TCGA_HT_7856_19950831_26, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:59.361238: predicting TCGA_HT_7856_19950831_6 
2024-11-22 02:34:59.363290: TCGA_HT_7856_19950831_6, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:59.422992: predicting TCGA_HT_7856_19950831_8 
2024-11-22 02:34:59.424673: TCGA_HT_7856_19950831_8, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:59.455234: predicting TCGA_HT_7860_19960513_12 
2024-11-22 02:34:59.455890: TCGA_HT_7860_19960513_12, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:59.492249: predicting TCGA_HT_7860_19960513_5 
2024-11-22 02:34:59.495164: TCGA_HT_7860_19960513_5, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:59.534825: predicting TCGA_HT_7874_19950902_1 
2024-11-22 02:34:59.535396: TCGA_HT_7874_19950902_1, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:59.573267: predicting TCGA_HT_7874_19950902_10 
2024-11-22 02:34:59.573813: TCGA_HT_7874_19950902_10, shape torch.Size([3, 1, 255, 253]), rank 0 
2024-11-22 02:34:59.609005: predicting TCGA_HT_7874_19950902_11 
2024-11-22 02:34:59.609533: TCGA_HT_7874_19950902_11, shape torch.Size([3, 1, 255, 255]), rank 0 
2024-11-22 02:34:59.668167: predicting TCGA_HT_7874_19950902_2 
2024-11-22 02:34:59.670062: TCGA_HT_7874_19950902_2, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:34:59.721569: predicting TCGA_HT_7874_19950902_20 
2024-11-22 02:34:59.722089: TCGA_HT_7874_19950902_20, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:59.769538: predicting TCGA_HT_7874_19950902_5 
2024-11-22 02:34:59.771168: TCGA_HT_7874_19950902_5, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-22 02:34:59.810406: predicting TCGA_HT_7874_19950902_6 
2024-11-22 02:34:59.812459: TCGA_HT_7874_19950902_6, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-22 02:34:59.871226: predicting TCGA_HT_7877_19980917_1 
2024-11-22 02:34:59.871741: TCGA_HT_7877_19980917_1, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:34:59.901660: predicting TCGA_HT_7877_19980917_25 
2024-11-22 02:34:59.902195: TCGA_HT_7877_19980917_25, shape torch.Size([3, 1, 250, 253]), rank 0 
2024-11-22 02:34:59.945340: predicting TCGA_HT_7877_19980917_29 
2024-11-22 02:34:59.949888: TCGA_HT_7877_19980917_29, shape torch.Size([3, 1, 251, 256]), rank 0 
2024-11-22 02:35:00.003242: predicting TCGA_HT_7877_19980917_7 
2024-11-22 02:35:00.005260: TCGA_HT_7877_19980917_7, shape torch.Size([3, 1, 252, 251]), rank 0 
2024-11-22 02:35:00.031846: predicting TCGA_HT_7879_19981009_13 
2024-11-22 02:35:00.034613: TCGA_HT_7879_19981009_13, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:00.059615: predicting TCGA_HT_7879_19981009_18 
2024-11-22 02:35:00.060142: TCGA_HT_7879_19981009_18, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:35:00.120200: predicting TCGA_HT_7879_19981009_21 
2024-11-22 02:35:00.120749: TCGA_HT_7879_19981009_21, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-22 02:35:00.174217: predicting TCGA_HT_7879_19981009_4 
2024-11-22 02:35:00.174771: TCGA_HT_7879_19981009_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:00.237464: predicting TCGA_HT_7881_19981015_13 
2024-11-22 02:35:00.238002: TCGA_HT_7881_19981015_13, shape torch.Size([3, 1, 252, 254]), rank 0 
2024-11-22 02:35:00.266764: predicting TCGA_HT_7881_19981015_15 
2024-11-22 02:35:00.267259: TCGA_HT_7881_19981015_15, shape torch.Size([3, 1, 252, 254]), rank 0 
2024-11-22 02:35:00.300840: predicting TCGA_HT_7881_19981015_24 
2024-11-22 02:35:00.301369: TCGA_HT_7881_19981015_24, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-22 02:35:00.332135: predicting TCGA_HT_7881_19981015_33 
2024-11-22 02:35:00.332644: TCGA_HT_7881_19981015_33, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-22 02:35:00.384172: predicting TCGA_HT_7881_19981015_41 
2024-11-22 02:35:00.384733: TCGA_HT_7881_19981015_41, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-22 02:35:00.424659: predicting TCGA_HT_7881_19981015_7 
2024-11-22 02:35:00.425168: TCGA_HT_7881_19981015_7, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-22 02:35:00.471843: predicting TCGA_HT_7881_19981015_9 
2024-11-22 02:35:00.472370: TCGA_HT_7881_19981015_9, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-22 02:35:00.507082: predicting TCGA_HT_7882_19970125_12 
2024-11-22 02:35:00.511794: TCGA_HT_7882_19970125_12, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:00.591239: predicting TCGA_HT_7882_19970125_14 
2024-11-22 02:35:00.595041: TCGA_HT_7882_19970125_14, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:00.623633: predicting TCGA_HT_7882_19970125_23 
2024-11-22 02:35:00.624123: TCGA_HT_7882_19970125_23, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:00.661771: predicting TCGA_HT_7882_19970125_31 
2024-11-22 02:35:00.667996: TCGA_HT_7882_19970125_31, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:00.696784: predicting TCGA_HT_7884_19980913_13 
2024-11-22 02:35:00.698692: TCGA_HT_7884_19980913_13, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:00.774104: predicting TCGA_HT_7884_19980913_15 
2024-11-22 02:35:00.776089: TCGA_HT_7884_19980913_15, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:00.842982: predicting TCGA_HT_7884_19980913_20 
2024-11-22 02:35:00.844788: TCGA_HT_7884_19980913_20, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:00.869574: predicting TCGA_HT_7884_19980913_5 
2024-11-22 02:35:00.870052: TCGA_HT_7884_19980913_5, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:00.896122: predicting TCGA_HT_7884_19980913_7 
2024-11-22 02:35:00.897975: TCGA_HT_7884_19980913_7, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:00.938234: predicting TCGA_HT_8018_19970411_11 
2024-11-22 02:35:00.943254: TCGA_HT_8018_19970411_11, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:00.980161: predicting TCGA_HT_8018_19970411_14 
2024-11-22 02:35:00.980707: TCGA_HT_8018_19970411_14, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:01.020844: predicting TCGA_HT_8018_19970411_17 
2024-11-22 02:35:01.026973: TCGA_HT_8018_19970411_17, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:01.080943: predicting TCGA_HT_8018_19970411_7 
2024-11-22 02:35:01.081455: TCGA_HT_8018_19970411_7, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:01.132134: predicting TCGA_HT_8105_19980826_10 
2024-11-22 02:35:01.132668: TCGA_HT_8105_19980826_10, shape torch.Size([3, 1, 249, 253]), rank 0 
2024-11-22 02:35:01.198875: predicting TCGA_HT_8105_19980826_13 
2024-11-22 02:35:01.199447: TCGA_HT_8105_19980826_13, shape torch.Size([3, 1, 248, 253]), rank 0 
2024-11-22 02:35:01.236925: predicting TCGA_HT_8105_19980826_17 
2024-11-22 02:35:01.237467: TCGA_HT_8105_19980826_17, shape torch.Size([3, 1, 248, 253]), rank 0 
2024-11-22 02:35:01.272729: predicting TCGA_HT_8105_19980826_3 
2024-11-22 02:35:01.273230: TCGA_HT_8105_19980826_3, shape torch.Size([3, 1, 249, 256]), rank 0 
2024-11-22 02:35:01.304117: predicting TCGA_HT_8105_19980826_5 
2024-11-22 02:35:01.304635: TCGA_HT_8105_19980826_5, shape torch.Size([3, 1, 249, 256]), rank 0 
2024-11-22 02:35:01.385062: predicting TCGA_HT_8106_19970727_1 
2024-11-22 02:35:01.385618: TCGA_HT_8106_19970727_1, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:35:01.417940: predicting TCGA_HT_8106_19970727_15 
2024-11-22 02:35:01.418582: TCGA_HT_8106_19970727_15, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-22 02:35:01.475648: predicting TCGA_HT_8106_19970727_17 
2024-11-22 02:35:01.476265: TCGA_HT_8106_19970727_17, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-22 02:35:01.512967: predicting TCGA_HT_8107_19980708_12 
2024-11-22 02:35:01.513733: TCGA_HT_8107_19980708_12, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:35:01.543986: predicting TCGA_HT_8107_19980708_2 
2024-11-22 02:35:01.548158: TCGA_HT_8107_19980708_2, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:01.579592: predicting TCGA_HT_8111_19980330_19 
2024-11-22 02:35:01.583997: TCGA_HT_8111_19980330_19, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-22 02:35:01.643865: predicting TCGA_HT_8111_19980330_2 
2024-11-22 02:35:01.644422: TCGA_HT_8111_19980330_2, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-22 02:35:01.700142: predicting TCGA_HT_8113_19930809_13 
2024-11-22 02:35:01.702161: TCGA_HT_8113_19930809_13, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:01.739877: predicting TCGA_HT_8113_19930809_14 
2024-11-22 02:35:01.740479: TCGA_HT_8113_19930809_14, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:01.783686: predicting TCGA_HT_8113_19930809_18 
2024-11-22 02:35:01.784242: TCGA_HT_8113_19930809_18, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:01.834864: predicting TCGA_HT_8113_19930809_3 
2024-11-22 02:35:01.835443: TCGA_HT_8113_19930809_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:01.881269: predicting TCGA_HT_8114_19981030_5 
2024-11-22 02:35:01.885132: TCGA_HT_8114_19981030_5, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:01.922970: predicting TCGA_HT_8114_19981030_8 
2024-11-22 02:35:01.923491: TCGA_HT_8114_19981030_8, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:01.969863: predicting TCGA_HT_8563_19981209_11 
2024-11-22 02:35:01.970461: TCGA_HT_8563_19981209_11, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:02.008845: predicting TCGA_HT_8563_19981209_17 
2024-11-22 02:35:02.010856: TCGA_HT_8563_19981209_17, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:02.089326: predicting TCGA_HT_8563_19981209_22 
2024-11-22 02:35:02.090166: TCGA_HT_8563_19981209_22, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:02.114434: predicting TCGA_HT_8563_19981209_23 
2024-11-22 02:35:02.116193: TCGA_HT_8563_19981209_23, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:02.144799: predicting TCGA_HT_A5RC_19990831_1 
2024-11-22 02:35:02.145271: TCGA_HT_A5RC_19990831_1, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-22 02:35:02.185802: predicting TCGA_HT_A5RC_19990831_12 
2024-11-22 02:35:02.186359: TCGA_HT_A5RC_19990831_12, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:02.236212: predicting TCGA_HT_A5RC_19990831_2 
2024-11-22 02:35:02.236724: TCGA_HT_A5RC_19990831_2, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-22 02:35:02.277208: predicting TCGA_HT_A5RC_19990831_24 
2024-11-22 02:35:02.277763: TCGA_HT_A5RC_19990831_24, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:02.341312: predicting TCGA_HT_A5RC_19990831_32 
2024-11-22 02:35:02.345977: TCGA_HT_A5RC_19990831_32, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-22 02:35:02.387679: predicting TCGA_HT_A5RC_19990831_6 
2024-11-22 02:35:02.388236: TCGA_HT_A5RC_19990831_6, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-22 02:35:02.420596: predicting TCGA_HT_A616_19991226_19 
2024-11-22 02:35:02.422578: TCGA_HT_A616_19991226_19, shape torch.Size([3, 1, 249, 249]), rank 0 
2024-11-22 02:35:02.487416: predicting TCGA_HT_A616_19991226_23 
2024-11-22 02:35:02.491966: TCGA_HT_A616_19991226_23, shape torch.Size([3, 1, 251, 251]), rank 0 
2024-11-22 02:35:02.535284: predicting TCGA_HT_A616_19991226_6 
2024-11-22 02:35:02.539058: TCGA_HT_A616_19991226_6, shape torch.Size([3, 1, 249, 253]), rank 0 
2024-11-22 02:35:02.578878: predicting TCGA_HT_A61A_20000127_10 
2024-11-22 02:35:02.579480: TCGA_HT_A61A_20000127_10, shape torch.Size([3, 1, 248, 256]), rank 0 
2024-11-22 02:35:02.607793: predicting TCGA_HT_A61A_20000127_13 
2024-11-22 02:35:02.608364: TCGA_HT_A61A_20000127_13, shape torch.Size([3, 1, 247, 256]), rank 0 
2024-11-22 02:35:02.653229: predicting TCGA_HT_A61A_20000127_15 
2024-11-22 02:35:02.653737: TCGA_HT_A61A_20000127_15, shape torch.Size([3, 1, 246, 256]), rank 0 
2024-11-22 02:35:02.712076: predicting TCGA_HT_A61A_20000127_20 
2024-11-22 02:35:02.712633: TCGA_HT_A61A_20000127_20, shape torch.Size([3, 1, 245, 254]), rank 0 
2024-11-22 02:35:02.770787: predicting TCGA_HT_A61A_20000127_34 
2024-11-22 02:35:02.774154: TCGA_HT_A61A_20000127_34, shape torch.Size([3, 1, 243, 250]), rank 0 
2024-11-22 02:35:02.815103: predicting TCGA_HT_A61A_20000127_35 
2024-11-22 02:35:02.817148: TCGA_HT_A61A_20000127_35, shape torch.Size([3, 1, 242, 250]), rank 0 
2024-11-22 02:35:02.842188: predicting TCGA_HT_A61A_20000127_36 
2024-11-22 02:35:02.842688: TCGA_HT_A61A_20000127_36, shape torch.Size([3, 1, 241, 250]), rank 0 
2024-11-22 02:35:02.870492: predicting TCGA_HT_A61A_20000127_37 
2024-11-22 02:35:02.872364: TCGA_HT_A61A_20000127_37, shape torch.Size([3, 1, 242, 250]), rank 0 
2024-11-22 02:35:02.936364: predicting TCGA_HT_A61A_20000127_38 
2024-11-22 02:35:02.936976: TCGA_HT_A61A_20000127_38, shape torch.Size([3, 1, 243, 250]), rank 0 
2024-11-22 02:35:02.973089: predicting TCGA_HT_A61A_20000127_51 
2024-11-22 02:35:02.975111: TCGA_HT_A61A_20000127_51, shape torch.Size([3, 1, 244, 250]), rank 0 
2024-11-22 02:35:03.041836: predicting TCGA_HT_A61A_20000127_57 
2024-11-22 02:35:03.046073: TCGA_HT_A61A_20000127_57, shape torch.Size([3, 1, 244, 251]), rank 0 
2024-11-22 02:35:03.091310: predicting TCGA_HT_A61A_20000127_68 
2024-11-22 02:35:03.092287: TCGA_HT_A61A_20000127_68, shape torch.Size([3, 1, 247, 255]), rank 0 
2024-11-22 02:35:03.119726: predicting TCGA_HT_A61A_20000127_69 
2024-11-22 02:35:03.121731: TCGA_HT_A61A_20000127_69, shape torch.Size([3, 1, 247, 255]), rank 0 
2024-11-22 02:35:03.151487: predicting TCGA_HT_A61A_20000127_72 
2024-11-22 02:35:03.155600: TCGA_HT_A61A_20000127_72, shape torch.Size([3, 1, 248, 256]), rank 0 
2024-11-22 02:35:03.207263: predicting TCGA_HT_A61A_20000127_73 
2024-11-22 02:35:03.207817: TCGA_HT_A61A_20000127_73, shape torch.Size([3, 1, 248, 256]), rank 0 
2024-11-22 02:35:03.269383: predicting TCGA_HT_A61A_20000127_79 
2024-11-22 02:35:03.271506: TCGA_HT_A61A_20000127_79, shape torch.Size([3, 1, 251, 256]), rank 0 
2024-11-22 02:35:03.313528: predicting TCGA_HT_A61A_20000127_82 
2024-11-22 02:35:03.321036: TCGA_HT_A61A_20000127_82, shape torch.Size([3, 1, 251, 256]), rank 0 
2024-11-22 02:35:03.345502: predicting TCGA_HT_A61A_20000127_84 
2024-11-22 02:35:03.346030: TCGA_HT_A61A_20000127_84, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-22 02:35:03.387246: predicting TCGA_HT_A61A_20000127_86 
2024-11-22 02:35:03.387769: TCGA_HT_A61A_20000127_86, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-22 02:35:03.426356: predicting TCGA_HT_A61B_19991127_10 
2024-11-22 02:35:03.428329: TCGA_HT_A61B_19991127_10, shape torch.Size([3, 1, 249, 256]), rank 0 
2024-11-22 02:35:03.486528: predicting TCGA_HT_A61B_19991127_23 
2024-11-22 02:35:03.487062: TCGA_HT_A61B_19991127_23, shape torch.Size([3, 1, 246, 251]), rank 0 
2024-11-22 02:35:03.553694: predicting TCGA_HT_A61B_19991127_24 
2024-11-22 02:35:03.558019: TCGA_HT_A61B_19991127_24, shape torch.Size([3, 1, 246, 251]), rank 0 
2024-11-22 02:35:03.601319: predicting TCGA_HT_A61B_19991127_34 
2024-11-22 02:35:03.601863: TCGA_HT_A61B_19991127_34, shape torch.Size([3, 1, 244, 247]), rank 0 
2024-11-22 02:35:03.647498: predicting TCGA_HT_A61B_19991127_40 
2024-11-22 02:35:03.649236: TCGA_HT_A61B_19991127_40, shape torch.Size([3, 1, 244, 247]), rank 0 
2024-11-22 02:35:03.683289: predicting TCGA_HT_A61B_19991127_41 
2024-11-22 02:35:03.683836: TCGA_HT_A61B_19991127_41, shape torch.Size([3, 1, 244, 247]), rank 0 
2024-11-22 02:35:03.720780: predicting TCGA_HT_A61B_19991127_54 
2024-11-22 02:35:03.721320: TCGA_HT_A61B_19991127_54, shape torch.Size([3, 1, 244, 247]), rank 0 
2024-11-22 02:35:03.751532: predicting TCGA_HT_A61B_19991127_72 
2024-11-22 02:35:03.752348: TCGA_HT_A61B_19991127_72, shape torch.Size([3, 1, 247, 253]), rank 0 
2024-11-22 02:35:03.803633: predicting TCGA_HT_A61B_19991127_74 
2024-11-22 02:35:03.805652: TCGA_HT_A61B_19991127_74, shape torch.Size([3, 1, 248, 254]), rank 0 
2024-11-22 02:35:03.876400: predicting TCGA_HT_A61B_19991127_83 
2024-11-22 02:35:03.876929: TCGA_HT_A61B_19991127_83, shape torch.Size([3, 1, 251, 256]), rank 0 
2024-11-22 02:35:03.919313: predicting TCGA_HT_A61B_19991127_87 
2024-11-22 02:35:03.920040: TCGA_HT_A61B_19991127_87, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-22 02:35:08.605295: Validation complete 
2024-11-22 02:35:08.605353: Mean Validation Dice:  0.8233801938271008 
