
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-11-27 00:46:04.522738: do_dummy_2d_data_aug: False 
2024-11-27 00:46:04.534336: Using splits from existing split file: /home/ran/data/deeplearning/nnUNet_preprocessed/Dataset003/splits_final.json 
2024-11-27 00:46:04.547044: The split file contains 5 splits. 
2024-11-27 00:46:04.547095: Desired fold for training: 0 
2024-11-27 00:46:04.547124: This split has 3143 training and 786 validation cases. 
2024-11-27 00:46:33.931322: Using torch.compile... 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 49, 'patch_size': [256, 256], 'median_image_size_in_voxels': [255.0, 256.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset003', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 255, 256], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 195.0, 'mean': 54.52047687539082, 'median': 51.0, 'min': 0.0, 'percentile_00_5': 6.0, 'percentile_99_5': 154.0, 'std': 23.97098847479588}, '1': {'max': 233.0, 'mean': 82.68001875445907, 'median': 80.0, 'min': 0.0, 'percentile_00_5': 12.0, 'percentile_99_5': 169.0, 'std': 30.94985644975039}, '2': {'max': 247.0, 'mean': 53.25271916905979, 'median': 50.0, 'min': 1.0, 'percentile_00_5': 7.0, 'percentile_99_5': 156.0, 'std': 23.883217984739634}}} 
 
2024-11-27 00:46:34.584042: unpacking dataset... 
2024-11-27 00:47:11.535522: unpacking done... 
2024-11-27 00:47:11.597880: Unable to plot network architecture: nnUNet_compile is enabled! 
2024-11-27 00:47:11.609354:  
2024-11-27 00:47:11.609430: Epoch 0 
2024-11-27 00:47:11.609514: Current learning rate: 0.01 
2024-11-27 00:49:07.716480: train_loss -0.5409 
2024-11-27 00:49:07.716605: val_loss -0.7641 
2024-11-27 00:49:07.716660: Pseudo dice [np.float32(0.8089)] 
2024-11-27 00:49:07.716716: Epoch time: 116.11 s 
2024-11-27 00:49:07.716774: Yayy! New best EMA pseudo Dice: 0.808899998664856 
2024-11-27 00:49:10.751794:  
2024-11-27 00:49:10.751930: Epoch 1 
2024-11-27 00:49:10.752014: Current learning rate: 0.00999 
2024-11-27 00:49:50.433528: train_loss -0.7978 
2024-11-27 00:49:50.433658: val_loss -0.8214 
2024-11-27 00:49:50.433740: Pseudo dice [np.float32(0.855)] 
2024-11-27 00:49:50.433849: Epoch time: 39.68 s 
2024-11-27 00:49:50.433933: Yayy! New best EMA pseudo Dice: 0.8134999871253967 
2024-11-27 00:49:53.355109:  
2024-11-27 00:49:53.355187: Epoch 2 
2024-11-27 00:49:53.355265: Current learning rate: 0.00998 
2024-11-27 00:50:33.042060: train_loss -0.8407 
2024-11-27 00:50:33.042175: val_loss -0.8573 
2024-11-27 00:50:33.042230: Pseudo dice [np.float32(0.8811)] 
2024-11-27 00:50:33.042294: Epoch time: 39.69 s 
2024-11-27 00:50:33.042344: Yayy! New best EMA pseudo Dice: 0.8202999830245972 
2024-11-27 00:50:36.167799:  
2024-11-27 00:50:36.167978: Epoch 3 
2024-11-27 00:50:36.168048: Current learning rate: 0.00997 
2024-11-27 00:51:15.917713: train_loss -0.8483 
2024-11-27 00:51:15.917887: val_loss -0.8673 
2024-11-27 00:51:15.917983: Pseudo dice [np.float32(0.8919)] 
2024-11-27 00:51:15.918090: Epoch time: 39.75 s 
2024-11-27 00:51:15.918172: Yayy! New best EMA pseudo Dice: 0.8274999856948853 
2024-11-27 00:51:18.825881:  
2024-11-27 00:51:18.825979: Epoch 4 
2024-11-27 00:51:18.826051: Current learning rate: 0.00996 
2024-11-27 00:51:58.618699: train_loss -0.8594 
2024-11-27 00:51:58.618810: val_loss -0.877 
2024-11-27 00:51:58.618862: Pseudo dice [np.float32(0.8984)] 
2024-11-27 00:51:58.618952: Epoch time: 39.79 s 
2024-11-27 00:51:58.619067: Yayy! New best EMA pseudo Dice: 0.8345000147819519 
2024-11-27 00:52:01.654390:  
2024-11-27 00:52:01.654544: Epoch 5 
2024-11-27 00:52:01.654617: Current learning rate: 0.00995 
2024-11-27 00:52:41.458932: train_loss -0.8693 
2024-11-27 00:52:41.459084: val_loss -0.8811 
2024-11-27 00:52:41.459139: Pseudo dice [np.float32(0.901)] 
2024-11-27 00:52:41.459195: Epoch time: 39.81 s 
2024-11-27 00:52:41.459241: Yayy! New best EMA pseudo Dice: 0.8411999940872192 
2024-11-27 00:52:44.173168:  
2024-11-27 00:52:44.173293: Epoch 6 
2024-11-27 00:52:44.173370: Current learning rate: 0.00995 
2024-11-27 00:53:24.007163: train_loss -0.8736 
2024-11-27 00:53:24.007271: val_loss -0.8838 
2024-11-27 00:53:24.007322: Pseudo dice [np.float32(0.9035)] 
2024-11-27 00:53:24.007380: Epoch time: 39.83 s 
2024-11-27 00:53:24.007428: Yayy! New best EMA pseudo Dice: 0.8474000096321106 
2024-11-27 00:53:26.761693:  
2024-11-27 00:53:26.761792: Epoch 7 
2024-11-27 00:53:26.761865: Current learning rate: 0.00994 
2024-11-27 00:54:06.628777: train_loss -0.8739 
2024-11-27 00:54:06.628900: val_loss -0.8782 
2024-11-27 00:54:06.628954: Pseudo dice [np.float32(0.8977)] 
2024-11-27 00:54:06.629030: Epoch time: 39.87 s 
2024-11-27 00:54:06.629078: Yayy! New best EMA pseudo Dice: 0.8525000214576721 
2024-11-27 00:54:09.820621:  
2024-11-27 00:54:09.820744: Epoch 8 
2024-11-27 00:54:09.820823: Current learning rate: 0.00993 
2024-11-27 00:54:49.709394: train_loss -0.8765 
2024-11-27 00:54:49.709509: val_loss -0.8854 
2024-11-27 00:54:49.709562: Pseudo dice [np.float32(0.9053)] 
2024-11-27 00:54:49.709620: Epoch time: 39.89 s 
2024-11-27 00:54:49.709667: Yayy! New best EMA pseudo Dice: 0.857699990272522 
2024-11-27 00:54:52.554733:  
2024-11-27 00:54:52.554865: Epoch 9 
2024-11-27 00:54:52.555094: Current learning rate: 0.00992 
2024-11-27 00:55:32.467106: train_loss -0.8801 
2024-11-27 00:55:32.467221: val_loss -0.8905 
2024-11-27 00:55:32.467276: Pseudo dice [np.float32(0.9094)] 
2024-11-27 00:55:32.467335: Epoch time: 39.91 s 
2024-11-27 00:55:32.467382: Yayy! New best EMA pseudo Dice: 0.8629000186920166 
2024-11-27 00:55:36.302019:  
2024-11-27 00:55:36.302201: Epoch 10 
2024-11-27 00:55:36.302277: Current learning rate: 0.00991 
2024-11-27 00:56:16.233017: train_loss -0.8846 
2024-11-27 00:56:16.233226: val_loss -0.8855 
2024-11-27 00:56:16.233289: Pseudo dice [np.float32(0.9038)] 
2024-11-27 00:56:16.233365: Epoch time: 39.93 s 
2024-11-27 00:56:16.233429: Yayy! New best EMA pseudo Dice: 0.8669999837875366 
2024-11-27 00:56:20.221678:  
2024-11-27 00:56:20.221857: Epoch 11 
2024-11-27 00:56:20.221952: Current learning rate: 0.0099 
2024-11-27 00:57:00.161291: train_loss -0.8846 
2024-11-27 00:57:00.161405: val_loss -0.882 
2024-11-27 00:57:00.161458: Pseudo dice [np.float32(0.9039)] 
2024-11-27 00:57:00.161517: Epoch time: 39.94 s 
2024-11-27 00:57:00.161572: Yayy! New best EMA pseudo Dice: 0.8707000017166138 
2024-11-27 00:57:04.105491:  
2024-11-27 00:57:04.105606: Epoch 12 
2024-11-27 00:57:04.105683: Current learning rate: 0.00989 
2024-11-27 00:57:44.051744: train_loss -0.8839 
2024-11-27 00:57:44.051858: val_loss -0.8808 
2024-11-27 00:57:44.051974: Pseudo dice [np.float32(0.9009)] 
2024-11-27 00:57:44.052123: Epoch time: 39.95 s 
2024-11-27 00:57:44.052202: Yayy! New best EMA pseudo Dice: 0.8737000226974487 
2024-11-27 00:57:49.245640:  
2024-11-27 00:57:49.245769: Epoch 13 
2024-11-27 00:57:49.245865: Current learning rate: 0.00988 
2024-11-27 00:58:29.170054: train_loss -0.8923 
2024-11-27 00:58:29.170163: val_loss -0.8947 
2024-11-27 00:58:29.170215: Pseudo dice [np.float32(0.9122)] 
2024-11-27 00:58:29.170310: Epoch time: 39.93 s 
2024-11-27 00:58:29.170357: Yayy! New best EMA pseudo Dice: 0.8776000142097473 
2024-11-27 00:58:33.424978:  
2024-11-27 00:58:33.425086: Epoch 14 
2024-11-27 00:58:33.425158: Current learning rate: 0.00987 
2024-11-27 00:59:13.293699: train_loss -0.8942 
2024-11-27 00:59:13.293858: val_loss -0.8924 
2024-11-27 00:59:13.293939: Pseudo dice [np.float32(0.9114)] 
2024-11-27 00:59:13.293999: Epoch time: 39.87 s 
2024-11-27 00:59:13.294049: Yayy! New best EMA pseudo Dice: 0.8809000253677368 
2024-11-27 00:59:17.321377:  
2024-11-27 00:59:17.321459: Epoch 15 
2024-11-27 00:59:17.321572: Current learning rate: 0.00986 
2024-11-27 00:59:57.207694: train_loss -0.901 
2024-11-27 00:59:57.207806: val_loss -0.8963 
2024-11-27 00:59:57.207933: Pseudo dice [np.float32(0.9116)] 
2024-11-27 00:59:57.207993: Epoch time: 39.89 s 
2024-11-27 00:59:57.208041: Yayy! New best EMA pseudo Dice: 0.8840000033378601 
2024-11-27 01:00:01.458254:  
2024-11-27 01:00:01.458348: Epoch 16 
2024-11-27 01:00:01.458425: Current learning rate: 0.00986 
2024-11-27 01:00:41.397159: train_loss -0.9029 
2024-11-27 01:00:41.397276: val_loss -0.894 
2024-11-27 01:00:41.397328: Pseudo dice [np.float32(0.9101)] 
2024-11-27 01:00:41.397420: Epoch time: 39.94 s 
2024-11-27 01:00:41.397510: Yayy! New best EMA pseudo Dice: 0.8866000175476074 
2024-11-27 01:00:45.912517:  
2024-11-27 01:00:45.912722: Epoch 17 
2024-11-27 01:00:45.912816: Current learning rate: 0.00985 
2024-11-27 01:01:25.855417: train_loss -0.9024 
2024-11-27 01:01:25.855649: val_loss -0.9011 
2024-11-27 01:01:25.855703: Pseudo dice [np.float32(0.9174)] 
2024-11-27 01:01:25.855787: Epoch time: 39.94 s 
2024-11-27 01:01:25.855848: Yayy! New best EMA pseudo Dice: 0.8896999955177307 
2024-11-27 01:01:29.910058:  
2024-11-27 01:01:29.910170: Epoch 18 
2024-11-27 01:01:29.910290: Current learning rate: 0.00984 
2024-11-27 01:02:09.852934: train_loss -0.8988 
2024-11-27 01:02:09.853082: val_loss -0.8856 
2024-11-27 01:02:09.853136: Pseudo dice [np.float32(0.9046)] 
2024-11-27 01:02:09.853197: Epoch time: 39.94 s 
2024-11-27 01:02:09.853260: Yayy! New best EMA pseudo Dice: 0.8912000060081482 
2024-11-27 01:02:13.473817:  
2024-11-27 01:02:13.473911: Epoch 19 
2024-11-27 01:02:13.473985: Current learning rate: 0.00983 
2024-11-27 01:02:53.419233: train_loss -0.8933 
2024-11-27 01:02:53.419353: val_loss -0.8969 
2024-11-27 01:02:53.419431: Pseudo dice [np.float32(0.9139)] 
2024-11-27 01:02:53.419490: Epoch time: 39.95 s 
2024-11-27 01:02:53.419566: Yayy! New best EMA pseudo Dice: 0.8934000134468079 
2024-11-27 01:02:56.766040:  
2024-11-27 01:02:56.766118: Epoch 20 
2024-11-27 01:02:56.766189: Current learning rate: 0.00982 
2024-11-27 01:03:36.693299: train_loss -0.8975 
2024-11-27 01:03:36.693433: val_loss -0.8941 
2024-11-27 01:03:36.693503: Pseudo dice [np.float32(0.9106)] 
2024-11-27 01:03:36.693576: Epoch time: 39.93 s 
2024-11-27 01:03:36.693641: Yayy! New best EMA pseudo Dice: 0.8952000141143799 
2024-11-27 01:03:40.302738:  
2024-11-27 01:03:40.302840: Epoch 21 
2024-11-27 01:03:40.302947: Current learning rate: 0.00981 
2024-11-27 01:04:20.235391: train_loss -0.9012 
2024-11-27 01:04:20.235502: val_loss -0.8935 
2024-11-27 01:04:20.235555: Pseudo dice [np.float32(0.9093)] 
2024-11-27 01:04:20.235636: Epoch time: 39.93 s 
2024-11-27 01:04:20.235683: Yayy! New best EMA pseudo Dice: 0.8966000080108643 
2024-11-27 01:04:23.745026:  
2024-11-27 01:04:23.745180: Epoch 22 
2024-11-27 01:04:23.745253: Current learning rate: 0.0098 
2024-11-27 01:05:03.684372: train_loss -0.9057 
2024-11-27 01:05:03.684534: val_loss -0.8991 
2024-11-27 01:05:03.684625: Pseudo dice [np.float32(0.914)] 
2024-11-27 01:05:03.684695: Epoch time: 39.94 s 
2024-11-27 01:05:03.684758: Yayy! New best EMA pseudo Dice: 0.8982999920845032 
2024-11-27 01:05:07.599591:  
2024-11-27 01:05:07.599701: Epoch 23 
2024-11-27 01:05:07.599788: Current learning rate: 0.00979 
2024-11-27 01:05:47.556244: train_loss -0.9054 
2024-11-27 01:05:47.556353: val_loss -0.902 
2024-11-27 01:05:47.556405: Pseudo dice [np.float32(0.9182)] 
2024-11-27 01:05:47.556482: Epoch time: 39.96 s 
2024-11-27 01:05:47.556562: Yayy! New best EMA pseudo Dice: 0.9003000259399414 
2024-11-27 01:05:50.572595:  
2024-11-27 01:05:50.572685: Epoch 24 
2024-11-27 01:05:50.572758: Current learning rate: 0.00978 
2024-11-27 01:06:30.526369: train_loss -0.9068 
2024-11-27 01:06:30.526488: val_loss -0.8975 
2024-11-27 01:06:30.526542: Pseudo dice [np.float32(0.914)] 
2024-11-27 01:06:30.526597: Epoch time: 39.95 s 
2024-11-27 01:06:30.526642: Yayy! New best EMA pseudo Dice: 0.9017000198364258 
2024-11-27 01:06:34.371444:  
2024-11-27 01:06:34.371539: Epoch 25 
2024-11-27 01:06:34.371637: Current learning rate: 0.00977 
2024-11-27 01:07:14.410172: train_loss -0.9098 
2024-11-27 01:07:14.410353: val_loss -0.8973 
2024-11-27 01:07:14.410422: Pseudo dice [np.float32(0.9134)] 
2024-11-27 01:07:14.410493: Epoch time: 40.04 s 
2024-11-27 01:07:14.410554: Yayy! New best EMA pseudo Dice: 0.9028000235557556 
2024-11-27 01:07:17.674836:  
2024-11-27 01:07:17.675001: Epoch 26 
2024-11-27 01:07:17.675086: Current learning rate: 0.00977 
2024-11-27 01:07:57.712847: train_loss -0.9126 
2024-11-27 01:07:57.713058: val_loss -0.9013 
2024-11-27 01:07:57.713141: Pseudo dice [np.float32(0.9156)] 
2024-11-27 01:07:57.713198: Epoch time: 40.04 s 
2024-11-27 01:07:57.713245: Yayy! New best EMA pseudo Dice: 0.9041000008583069 
2024-11-27 01:08:00.554386:  
2024-11-27 01:08:00.554486: Epoch 27 
2024-11-27 01:08:00.554593: Current learning rate: 0.00976 
2024-11-27 01:08:40.554565: train_loss -0.9109 
2024-11-27 01:08:40.554684: val_loss -0.8985 
2024-11-27 01:08:40.554739: Pseudo dice [np.float32(0.914)] 
2024-11-27 01:08:40.554794: Epoch time: 40.0 s 
2024-11-27 01:08:40.554841: Yayy! New best EMA pseudo Dice: 0.9050999879837036 
2024-11-27 01:08:43.764943:  
2024-11-27 01:08:43.765074: Epoch 28 
2024-11-27 01:08:43.765142: Current learning rate: 0.00975 
2024-11-27 01:09:23.766685: train_loss -0.9108 
2024-11-27 01:09:23.766819: val_loss -0.907 
2024-11-27 01:09:23.766894: Pseudo dice [np.float32(0.92)] 
2024-11-27 01:09:23.766991: Epoch time: 40.0 s 
2024-11-27 01:09:23.767057: Yayy! New best EMA pseudo Dice: 0.9065999984741211 
2024-11-27 01:09:26.905343:  
2024-11-27 01:09:26.905431: Epoch 29 
2024-11-27 01:09:26.905499: Current learning rate: 0.00974 
2024-11-27 01:10:06.922420: train_loss -0.9087 
2024-11-27 01:10:06.922549: val_loss -0.8935 
2024-11-27 01:10:06.922624: Pseudo dice [np.float32(0.91)] 
2024-11-27 01:10:06.922681: Epoch time: 40.02 s 
2024-11-27 01:10:06.922766: Yayy! New best EMA pseudo Dice: 0.9068999886512756 
2024-11-27 01:10:10.176409:  
2024-11-27 01:10:10.176516: Epoch 30 
2024-11-27 01:10:10.176589: Current learning rate: 0.00973 
2024-11-27 01:10:50.132476: train_loss -0.9082 
2024-11-27 01:10:50.132613: val_loss -0.8966 
2024-11-27 01:10:50.132679: Pseudo dice [np.float32(0.9125)] 
2024-11-27 01:10:50.132751: Epoch time: 39.96 s 
2024-11-27 01:10:50.132811: Yayy! New best EMA pseudo Dice: 0.9075000286102295 
2024-11-27 01:10:53.346315:  
2024-11-27 01:10:53.346408: Epoch 31 
2024-11-27 01:10:53.346478: Current learning rate: 0.00972 
2024-11-27 01:11:33.328717: train_loss -0.9114 
2024-11-27 01:11:33.328841: val_loss -0.8969 
2024-11-27 01:11:33.328900: Pseudo dice [np.float32(0.9133)] 
2024-11-27 01:11:33.328958: Epoch time: 39.98 s 
2024-11-27 01:11:33.329005: Yayy! New best EMA pseudo Dice: 0.9081000089645386 
2024-11-27 01:11:37.622856:  
2024-11-27 01:11:37.623005: Epoch 32 
2024-11-27 01:11:37.623118: Current learning rate: 0.00971 
2024-11-27 01:12:17.623096: train_loss -0.9131 
2024-11-27 01:12:17.623286: val_loss -0.9042 
2024-11-27 01:12:17.623415: Pseudo dice [np.float32(0.9184)] 
2024-11-27 01:12:17.623520: Epoch time: 40.0 s 
2024-11-27 01:12:17.623582: Yayy! New best EMA pseudo Dice: 0.9090999960899353 
2024-11-27 01:12:20.798928:  
2024-11-27 01:12:20.799077: Epoch 33 
2024-11-27 01:12:20.799151: Current learning rate: 0.0097 
2024-11-27 01:13:00.870990: train_loss -0.9143 
2024-11-27 01:13:00.871214: val_loss -0.9018 
2024-11-27 01:13:00.871284: Pseudo dice [np.float32(0.9174)] 
2024-11-27 01:13:00.871342: Epoch time: 40.07 s 
2024-11-27 01:13:00.871390: Yayy! New best EMA pseudo Dice: 0.9099000096321106 
2024-11-27 01:13:04.632608:  
2024-11-27 01:13:04.632764: Epoch 34 
2024-11-27 01:13:04.632899: Current learning rate: 0.00969 
2024-11-27 01:13:44.592420: train_loss -0.9167 
2024-11-27 01:13:44.592534: val_loss -0.8973 
2024-11-27 01:13:44.592587: Pseudo dice [np.float32(0.9138)] 
2024-11-27 01:13:44.592644: Epoch time: 39.96 s 
2024-11-27 01:13:44.592692: Yayy! New best EMA pseudo Dice: 0.9103000164031982 
2024-11-27 01:13:47.873760:  
2024-11-27 01:13:47.873929: Epoch 35 
2024-11-27 01:13:47.874059: Current learning rate: 0.00968 
2024-11-27 01:14:27.846068: train_loss -0.9146 
2024-11-27 01:14:27.846185: val_loss -0.9081 
2024-11-27 01:14:27.846239: Pseudo dice [np.float32(0.9214)] 
2024-11-27 01:14:27.846296: Epoch time: 39.97 s 
2024-11-27 01:14:27.846343: Yayy! New best EMA pseudo Dice: 0.9114000201225281 
2024-11-27 01:14:31.890116:  
2024-11-27 01:14:31.890249: Epoch 36 
2024-11-27 01:14:31.890343: Current learning rate: 0.00968 
2024-11-27 01:15:11.883710: train_loss -0.9167 
2024-11-27 01:15:11.883822: val_loss -0.9029 
2024-11-27 01:15:11.883907: Pseudo dice [np.float32(0.9185)] 
2024-11-27 01:15:11.884016: Epoch time: 39.99 s 
2024-11-27 01:15:11.884082: Yayy! New best EMA pseudo Dice: 0.9121000170707703 
2024-11-27 01:15:15.086562:  
2024-11-27 01:15:15.086714: Epoch 37 
2024-11-27 01:15:15.086817: Current learning rate: 0.00967 
2024-11-27 01:15:55.119940: train_loss -0.9182 
2024-11-27 01:15:55.120091: val_loss -0.9075 
2024-11-27 01:15:55.120190: Pseudo dice [np.float32(0.9207)] 
2024-11-27 01:15:55.120322: Epoch time: 40.03 s 
2024-11-27 01:15:55.120432: Yayy! New best EMA pseudo Dice: 0.9129999876022339 
2024-11-27 01:15:58.217605:  
2024-11-27 01:15:58.217702: Epoch 38 
2024-11-27 01:15:58.217775: Current learning rate: 0.00966 
2024-11-27 01:16:38.195205: train_loss -0.9207 
2024-11-27 01:16:38.195329: val_loss -0.8987 
2024-11-27 01:16:38.195385: Pseudo dice [np.float32(0.913)] 
2024-11-27 01:16:38.195447: Epoch time: 39.98 s 
2024-11-27 01:16:39.106538:  
2024-11-27 01:16:39.106680: Epoch 39 
2024-11-27 01:16:39.106754: Current learning rate: 0.00965 
2024-11-27 01:17:19.182879: train_loss -0.9201 
2024-11-27 01:17:19.183013: val_loss -0.9101 
2024-11-27 01:17:19.183080: Pseudo dice [np.float32(0.9239)] 
2024-11-27 01:17:19.183152: Epoch time: 40.08 s 
2024-11-27 01:17:19.183212: Yayy! New best EMA pseudo Dice: 0.9140999913215637 
2024-11-27 01:17:22.557939:  
2024-11-27 01:17:22.558052: Epoch 40 
2024-11-27 01:17:22.558121: Current learning rate: 0.00964 
2024-11-27 01:18:02.563008: train_loss -0.9156 
2024-11-27 01:18:02.563143: val_loss -0.9052 
2024-11-27 01:18:02.563214: Pseudo dice [np.float32(0.918)] 
2024-11-27 01:18:02.563297: Epoch time: 40.01 s 
2024-11-27 01:18:02.563344: Yayy! New best EMA pseudo Dice: 0.9144999980926514 
2024-11-27 01:18:05.699711:  
2024-11-27 01:18:05.699784: Epoch 41 
2024-11-27 01:18:05.699910: Current learning rate: 0.00963 
2024-11-27 01:18:45.729828: train_loss -0.9183 
2024-11-27 01:18:45.730107: val_loss -0.9019 
2024-11-27 01:18:45.730170: Pseudo dice [np.float32(0.9166)] 
2024-11-27 01:18:45.730246: Epoch time: 40.03 s 
2024-11-27 01:18:45.730308: Yayy! New best EMA pseudo Dice: 0.9146999716758728 
2024-11-27 01:18:48.887578:  
2024-11-27 01:18:48.887733: Epoch 42 
2024-11-27 01:18:48.887835: Current learning rate: 0.00962 
2024-11-27 01:19:28.947311: train_loss -0.9206 
2024-11-27 01:19:28.947437: val_loss -0.9093 
2024-11-27 01:19:28.947492: Pseudo dice [np.float32(0.9238)] 
2024-11-27 01:19:28.947555: Epoch time: 40.06 s 
2024-11-27 01:19:28.947606: Yayy! New best EMA pseudo Dice: 0.9156000018119812 
2024-11-27 01:19:32.317823:  
2024-11-27 01:19:32.317976: Epoch 43 
2024-11-27 01:19:32.318072: Current learning rate: 0.00961 
2024-11-27 01:20:12.296148: train_loss -0.9205 
2024-11-27 01:20:12.296263: val_loss -0.9057 
2024-11-27 01:20:12.296329: Pseudo dice [np.float32(0.922)] 
2024-11-27 01:20:12.296401: Epoch time: 39.98 s 
2024-11-27 01:20:12.296464: Yayy! New best EMA pseudo Dice: 0.9161999821662903 
2024-11-27 01:20:15.889767:  
2024-11-27 01:20:15.889887: Epoch 44 
2024-11-27 01:20:15.889961: Current learning rate: 0.0096 
2024-11-27 01:20:55.945801: train_loss -0.9177 
2024-11-27 01:20:55.945923: val_loss -0.9063 
2024-11-27 01:20:55.945979: Pseudo dice [np.float32(0.9187)] 
2024-11-27 01:20:55.946039: Epoch time: 40.06 s 
2024-11-27 01:20:55.946087: Yayy! New best EMA pseudo Dice: 0.9164999723434448 
2024-11-27 01:20:59.177971:  
2024-11-27 01:20:59.178216: Epoch 45 
2024-11-27 01:20:59.178300: Current learning rate: 0.00959 
2024-11-27 01:21:39.186465: train_loss -0.9192 
2024-11-27 01:21:39.186634: val_loss -0.9049 
2024-11-27 01:21:39.186721: Pseudo dice [np.float32(0.9181)] 
2024-11-27 01:21:39.186782: Epoch time: 40.01 s 
2024-11-27 01:21:39.186832: Yayy! New best EMA pseudo Dice: 0.916700005531311 
2024-11-27 01:21:42.289677:  
2024-11-27 01:21:42.289842: Epoch 46 
2024-11-27 01:21:42.289972: Current learning rate: 0.00959 
2024-11-27 01:22:22.302919: train_loss -0.9211 
2024-11-27 01:22:22.303091: val_loss -0.9048 
2024-11-27 01:22:22.303143: Pseudo dice [np.float32(0.9221)] 
2024-11-27 01:22:22.303216: Epoch time: 40.01 s 
2024-11-27 01:22:22.303282: Yayy! New best EMA pseudo Dice: 0.9172000288963318 
2024-11-27 01:22:25.758036:  
2024-11-27 01:22:25.758136: Epoch 47 
2024-11-27 01:22:25.758247: Current learning rate: 0.00958 
2024-11-27 01:23:05.747854: train_loss -0.9223 
2024-11-27 01:23:05.748024: val_loss -0.9049 
2024-11-27 01:23:05.748074: Pseudo dice [np.float32(0.9204)] 
2024-11-27 01:23:05.748130: Epoch time: 39.99 s 
2024-11-27 01:23:05.748174: Yayy! New best EMA pseudo Dice: 0.9175000190734863 
2024-11-27 01:23:08.887642:  
2024-11-27 01:23:08.887805: Epoch 48 
2024-11-27 01:23:08.887910: Current learning rate: 0.00957 
2024-11-27 01:23:48.870159: train_loss -0.9233 
2024-11-27 01:23:48.870340: val_loss -0.9049 
2024-11-27 01:23:48.870390: Pseudo dice [np.float32(0.9216)] 
2024-11-27 01:23:48.870445: Epoch time: 39.98 s 
2024-11-27 01:23:48.870490: Yayy! New best EMA pseudo Dice: 0.917900025844574 
2024-11-27 01:23:52.030972:  
2024-11-27 01:23:52.031083: Epoch 49 
2024-11-27 01:23:52.031157: Current learning rate: 0.00956 
2024-11-27 01:24:32.056587: train_loss -0.9221 
2024-11-27 01:24:32.056760: val_loss -0.9035 
2024-11-27 01:24:32.056842: Pseudo dice [np.float32(0.9202)] 
2024-11-27 01:24:32.056927: Epoch time: 40.03 s 
2024-11-27 01:24:32.271588: Yayy! New best EMA pseudo Dice: 0.9182000160217285 
2024-11-27 01:24:35.404421:  
2024-11-27 01:24:35.404527: Epoch 50 
2024-11-27 01:24:35.404608: Current learning rate: 0.00955 
2024-11-27 01:25:15.444141: train_loss -0.9237 
2024-11-27 01:25:15.444253: val_loss -0.9073 
2024-11-27 01:25:15.444308: Pseudo dice [np.float32(0.9215)] 
2024-11-27 01:25:15.444386: Epoch time: 40.04 s 
2024-11-27 01:25:15.444434: Yayy! New best EMA pseudo Dice: 0.9185000061988831 
2024-11-27 01:25:18.556308:  
2024-11-27 01:25:18.556423: Epoch 51 
2024-11-27 01:25:18.556504: Current learning rate: 0.00954 
2024-11-27 01:25:58.594952: train_loss -0.9198 
2024-11-27 01:25:58.595124: val_loss -0.9086 
2024-11-27 01:25:58.595254: Pseudo dice [np.float32(0.9222)] 
2024-11-27 01:25:58.595380: Epoch time: 40.04 s 
2024-11-27 01:25:58.595428: Yayy! New best EMA pseudo Dice: 0.9189000129699707 
2024-11-27 01:26:01.815707:  
2024-11-27 01:26:01.815851: Epoch 52 
2024-11-27 01:26:01.815971: Current learning rate: 0.00953 
2024-11-27 01:26:41.878268: train_loss -0.9225 
2024-11-27 01:26:41.878381: val_loss -0.9056 
2024-11-27 01:26:41.878433: Pseudo dice [np.float32(0.9198)] 
2024-11-27 01:26:41.878490: Epoch time: 40.06 s 
2024-11-27 01:26:41.878537: Yayy! New best EMA pseudo Dice: 0.9190000295639038 
2024-11-27 01:26:45.095454:  
2024-11-27 01:26:45.095575: Epoch 53 
2024-11-27 01:26:45.095668: Current learning rate: 0.00952 
2024-11-27 01:27:25.126823: train_loss -0.9224 
2024-11-27 01:27:25.127001: val_loss -0.909 
2024-11-27 01:27:25.127073: Pseudo dice [np.float32(0.9238)] 
2024-11-27 01:27:25.127145: Epoch time: 40.03 s 
2024-11-27 01:27:25.127231: Yayy! New best EMA pseudo Dice: 0.9193999767303467 
2024-11-27 01:27:28.421685:  
2024-11-27 01:27:28.421812: Epoch 54 
2024-11-27 01:27:28.421908: Current learning rate: 0.00951 
2024-11-27 01:28:08.426338: train_loss -0.9237 
2024-11-27 01:28:08.426488: val_loss -0.9095 
2024-11-27 01:28:08.426558: Pseudo dice [np.float32(0.9235)] 
2024-11-27 01:28:08.426632: Epoch time: 40.01 s 
2024-11-27 01:28:08.426693: Yayy! New best EMA pseudo Dice: 0.9197999835014343 
2024-11-27 01:28:11.592416:  
2024-11-27 01:28:11.592501: Epoch 55 
2024-11-27 01:28:11.592640: Current learning rate: 0.0095 
2024-11-27 01:28:51.599644: train_loss -0.9267 
2024-11-27 01:28:51.599756: val_loss -0.9101 
2024-11-27 01:28:51.599850: Pseudo dice [np.float32(0.9242)] 
2024-11-27 01:28:51.600002: Epoch time: 40.01 s 
2024-11-27 01:28:51.600049: Yayy! New best EMA pseudo Dice: 0.9203000068664551 
2024-11-27 01:28:54.712425:  
2024-11-27 01:28:54.712627: Epoch 56 
2024-11-27 01:28:54.712714: Current learning rate: 0.00949 
2024-11-27 01:29:34.803034: train_loss -0.9264 
2024-11-27 01:29:34.803172: val_loss -0.9028 
2024-11-27 01:29:34.803242: Pseudo dice [np.float32(0.9181)] 
2024-11-27 01:29:34.803316: Epoch time: 40.09 s 
2024-11-27 01:29:35.748254:  
2024-11-27 01:29:35.748359: Epoch 57 
2024-11-27 01:29:35.748430: Current learning rate: 0.00949 
2024-11-27 01:30:15.852097: train_loss -0.9273 
2024-11-27 01:30:15.852218: val_loss -0.9045 
2024-11-27 01:30:15.852272: Pseudo dice [np.float32(0.9204)] 
2024-11-27 01:30:15.852360: Epoch time: 40.1 s 
2024-11-27 01:30:16.744778:  
2024-11-27 01:30:16.745011: Epoch 58 
2024-11-27 01:30:16.745105: Current learning rate: 0.00948 
2024-11-27 01:30:56.831689: train_loss -0.9273 
2024-11-27 01:30:56.831884: val_loss -0.9064 
2024-11-27 01:30:56.831979: Pseudo dice [np.float32(0.9213)] 
2024-11-27 01:30:56.832081: Epoch time: 40.09 s 
2024-11-27 01:30:57.714077:  
2024-11-27 01:30:57.714259: Epoch 59 
2024-11-27 01:30:57.714345: Current learning rate: 0.00947 
2024-11-27 01:31:37.762242: train_loss -0.9266 
2024-11-27 01:31:37.762355: val_loss -0.9061 
2024-11-27 01:31:37.762408: Pseudo dice [np.float32(0.9206)] 
2024-11-27 01:31:37.762466: Epoch time: 40.05 s 
2024-11-27 01:31:38.690952:  
2024-11-27 01:31:38.691065: Epoch 60 
2024-11-27 01:31:38.691145: Current learning rate: 0.00946 
2024-11-27 01:32:18.825167: train_loss -0.9267 
2024-11-27 01:32:18.825283: val_loss -0.9091 
2024-11-27 01:32:18.825337: Pseudo dice [np.float32(0.9239)] 
2024-11-27 01:32:18.825395: Epoch time: 40.14 s 
2024-11-27 01:32:18.825443: Yayy! New best EMA pseudo Dice: 0.9205999970436096 
2024-11-27 01:32:21.908322:  
2024-11-27 01:32:21.908397: Epoch 61 
2024-11-27 01:32:21.908471: Current learning rate: 0.00945 
2024-11-27 01:33:01.904395: train_loss -0.9279 
2024-11-27 01:33:01.904508: val_loss -0.9044 
2024-11-27 01:33:01.904570: Pseudo dice [np.float32(0.9194)] 
2024-11-27 01:33:01.904653: Epoch time: 40.0 s 
2024-11-27 01:33:03.267687:  
2024-11-27 01:33:03.267787: Epoch 62 
2024-11-27 01:33:03.267949: Current learning rate: 0.00944 
2024-11-27 01:33:43.460446: train_loss -0.9283 
2024-11-27 01:33:43.460561: val_loss -0.908 
2024-11-27 01:33:43.460613: Pseudo dice [np.float32(0.9215)] 
2024-11-27 01:33:43.460670: Epoch time: 40.19 s 
2024-11-27 01:33:44.367720:  
2024-11-27 01:33:44.367827: Epoch 63 
2024-11-27 01:33:44.367944: Current learning rate: 0.00943 
2024-11-27 01:34:24.514118: train_loss -0.9267 
2024-11-27 01:34:24.514252: val_loss -0.9029 
2024-11-27 01:34:24.514338: Pseudo dice [np.float32(0.918)] 
2024-11-27 01:34:24.514398: Epoch time: 40.15 s 
2024-11-27 01:34:25.487267:  
2024-11-27 01:34:25.487453: Epoch 64 
2024-11-27 01:34:25.487568: Current learning rate: 0.00942 
2024-11-27 01:35:05.591587: train_loss -0.9295 
2024-11-27 01:35:05.591697: val_loss -0.9037 
2024-11-27 01:35:05.591771: Pseudo dice [np.float32(0.9193)] 
2024-11-27 01:35:05.591850: Epoch time: 40.11 s 
2024-11-27 01:35:06.523661:  
2024-11-27 01:35:06.523788: Epoch 65 
2024-11-27 01:35:06.523927: Current learning rate: 0.00941 
2024-11-27 01:35:46.643179: train_loss -0.9271 
2024-11-27 01:35:46.643294: val_loss -0.9078 
2024-11-27 01:35:46.643349: Pseudo dice [np.float32(0.9216)] 
2024-11-27 01:35:46.643407: Epoch time: 40.12 s 
2024-11-27 01:35:47.535116:  
2024-11-27 01:35:47.535206: Epoch 66 
2024-11-27 01:35:47.535276: Current learning rate: 0.0094 
2024-11-27 01:36:27.664568: train_loss -0.9294 
2024-11-27 01:36:27.664704: val_loss -0.9033 
2024-11-27 01:36:27.664774: Pseudo dice [np.float32(0.9197)] 
2024-11-27 01:36:27.664847: Epoch time: 40.13 s 
2024-11-27 01:36:28.690039:  
2024-11-27 01:36:28.690222: Epoch 67 
2024-11-27 01:36:28.690427: Current learning rate: 0.00939 
2024-11-27 01:37:08.747015: train_loss -0.9273 
2024-11-27 01:37:08.747146: val_loss -0.9076 
2024-11-27 01:37:08.747200: Pseudo dice [np.float32(0.9212)] 
2024-11-27 01:37:08.747256: Epoch time: 40.06 s 
2024-11-27 01:37:09.731863:  
2024-11-27 01:37:09.731954: Epoch 68 
2024-11-27 01:37:09.732049: Current learning rate: 0.00939 
2024-11-27 01:37:49.902441: train_loss -0.9291 
2024-11-27 01:37:49.902616: val_loss -0.9121 
2024-11-27 01:37:49.902733: Pseudo dice [np.float32(0.9265)] 
2024-11-27 01:37:49.902809: Epoch time: 40.17 s 
2024-11-27 01:37:49.902877: Yayy! New best EMA pseudo Dice: 0.9210000038146973 
2024-11-27 01:37:53.127637:  
2024-11-27 01:37:53.127723: Epoch 69 
2024-11-27 01:37:53.127795: Current learning rate: 0.00938 
2024-11-27 01:38:33.187557: train_loss -0.9215 
2024-11-27 01:38:33.187692: val_loss -0.8816 
2024-11-27 01:38:33.187743: Pseudo dice [np.float32(0.9003)] 
2024-11-27 01:38:33.187799: Epoch time: 40.06 s 
2024-11-27 01:38:34.152473:  
2024-11-27 01:38:34.152601: Epoch 70 
2024-11-27 01:38:34.152690: Current learning rate: 0.00937 
2024-11-27 01:39:14.270286: train_loss -0.9221 
2024-11-27 01:39:14.270401: val_loss -0.9029 
2024-11-27 01:39:14.270455: Pseudo dice [np.float32(0.917)] 
2024-11-27 01:39:14.270511: Epoch time: 40.12 s 
2024-11-27 01:39:15.267977:  
2024-11-27 01:39:15.268102: Epoch 71 
2024-11-27 01:39:15.268191: Current learning rate: 0.00936 
2024-11-27 01:39:55.420356: train_loss -0.9278 
2024-11-27 01:39:55.420468: val_loss -0.9054 
2024-11-27 01:39:55.420520: Pseudo dice [np.float32(0.9194)] 
2024-11-27 01:39:55.420594: Epoch time: 40.15 s 
2024-11-27 01:39:56.459435:  
2024-11-27 01:39:56.459605: Epoch 72 
2024-11-27 01:39:56.459680: Current learning rate: 0.00935 
2024-11-27 01:40:36.552297: train_loss -0.9316 
2024-11-27 01:40:36.552431: val_loss -0.9084 
2024-11-27 01:40:36.552502: Pseudo dice [np.float32(0.9216)] 
2024-11-27 01:40:36.552603: Epoch time: 40.09 s 
2024-11-27 01:40:37.514141:  
2024-11-27 01:40:37.514225: Epoch 73 
2024-11-27 01:40:37.514318: Current learning rate: 0.00934 
2024-11-27 01:41:17.714045: train_loss -0.9307 
2024-11-27 01:41:17.714190: val_loss -0.9125 
2024-11-27 01:41:17.714289: Pseudo dice [np.float32(0.9263)] 
2024-11-27 01:41:17.714383: Epoch time: 40.2 s 
2024-11-27 01:41:18.788629:  
2024-11-27 01:41:18.788759: Epoch 74 
2024-11-27 01:41:18.788856: Current learning rate: 0.00933 
2024-11-27 01:41:58.937606: train_loss -0.9311 
2024-11-27 01:41:58.937719: val_loss -0.9058 
2024-11-27 01:41:58.937772: Pseudo dice [np.float32(0.9207)] 
2024-11-27 01:41:58.937828: Epoch time: 40.15 s 
2024-11-27 01:41:59.875453:  
2024-11-27 01:41:59.875576: Epoch 75 
2024-11-27 01:41:59.875651: Current learning rate: 0.00932 
2024-11-27 01:42:40.017914: train_loss -0.9315 
2024-11-27 01:42:40.018064: val_loss -0.9071 
2024-11-27 01:42:40.018132: Pseudo dice [np.float32(0.9213)] 
2024-11-27 01:42:40.018210: Epoch time: 40.14 s 
2024-11-27 01:42:40.950802:  
2024-11-27 01:42:40.950947: Epoch 76 
2024-11-27 01:42:40.951028: Current learning rate: 0.00931 
2024-11-27 01:43:21.068411: train_loss -0.9325 
2024-11-27 01:43:21.068541: val_loss -0.9081 
2024-11-27 01:43:21.068594: Pseudo dice [np.float32(0.9239)] 
2024-11-27 01:43:21.068650: Epoch time: 40.12 s 
2024-11-27 01:43:22.039610:  
2024-11-27 01:43:22.039711: Epoch 77 
2024-11-27 01:43:22.039822: Current learning rate: 0.0093 
2024-11-27 01:44:02.202289: train_loss -0.9332 
2024-11-27 01:44:02.202515: val_loss -0.9077 
2024-11-27 01:44:02.202636: Pseudo dice [np.float32(0.922)] 
2024-11-27 01:44:02.202733: Epoch time: 40.16 s 
2024-11-27 01:44:03.177522:  
2024-11-27 01:44:03.177613: Epoch 78 
2024-11-27 01:44:03.177683: Current learning rate: 0.0093 
2024-11-27 01:44:43.353374: train_loss -0.9341 
2024-11-27 01:44:43.353504: val_loss -0.9102 
2024-11-27 01:44:43.353557: Pseudo dice [np.float32(0.9234)] 
2024-11-27 01:44:43.353614: Epoch time: 40.18 s 
2024-11-27 01:44:44.284474:  
2024-11-27 01:44:44.284575: Epoch 79 
2024-11-27 01:44:44.284648: Current learning rate: 0.00929 
2024-11-27 01:45:24.478242: train_loss -0.9368 
2024-11-27 01:45:24.478378: val_loss -0.9103 
2024-11-27 01:45:24.478435: Pseudo dice [np.float32(0.925)] 
2024-11-27 01:45:24.478519: Epoch time: 40.19 s 
2024-11-27 01:45:24.478567: Yayy! New best EMA pseudo Dice: 0.9212999939918518 
2024-11-27 01:45:28.101682:  
2024-11-27 01:45:28.101777: Epoch 80 
2024-11-27 01:45:28.101862: Current learning rate: 0.00928 
2024-11-27 01:46:08.174164: train_loss -0.9354 
2024-11-27 01:46:08.174294: val_loss -0.9054 
2024-11-27 01:46:08.174346: Pseudo dice [np.float32(0.9187)] 
2024-11-27 01:46:08.174404: Epoch time: 40.07 s 
2024-11-27 01:46:09.116985:  
2024-11-27 01:46:09.117165: Epoch 81 
2024-11-27 01:46:09.117261: Current learning rate: 0.00927 
2024-11-27 01:46:49.306362: train_loss -0.9334 
2024-11-27 01:46:49.306535: val_loss -0.9048 
2024-11-27 01:46:49.306612: Pseudo dice [np.float32(0.9213)] 
2024-11-27 01:46:49.306674: Epoch time: 40.19 s 
2024-11-27 01:46:50.297548:  
2024-11-27 01:46:50.297726: Epoch 82 
2024-11-27 01:46:50.297821: Current learning rate: 0.00926 
2024-11-27 01:47:30.432125: train_loss -0.9344 
2024-11-27 01:47:30.432283: val_loss -0.9071 
2024-11-27 01:47:30.432336: Pseudo dice [np.float32(0.9212)] 
2024-11-27 01:47:30.432394: Epoch time: 40.14 s 
2024-11-27 01:47:31.318036:  
2024-11-27 01:47:31.318152: Epoch 83 
2024-11-27 01:47:31.318237: Current learning rate: 0.00925 
2024-11-27 01:48:11.439780: train_loss -0.935 
2024-11-27 01:48:11.439933: val_loss -0.9065 
2024-11-27 01:48:11.440033: Pseudo dice [np.float32(0.9204)] 
2024-11-27 01:48:11.440115: Epoch time: 40.12 s 
2024-11-27 01:48:12.307105:  
2024-11-27 01:48:12.307195: Epoch 84 
2024-11-27 01:48:12.307267: Current learning rate: 0.00924 
2024-11-27 01:48:52.340309: train_loss -0.9342 
2024-11-27 01:48:52.340457: val_loss -0.915 
2024-11-27 01:48:52.340549: Pseudo dice [np.float32(0.9282)] 
2024-11-27 01:48:52.340652: Epoch time: 40.03 s 
2024-11-27 01:48:52.340717: Yayy! New best EMA pseudo Dice: 0.9217000007629395 
2024-11-27 01:48:55.485563:  
2024-11-27 01:48:55.485682: Epoch 85 
2024-11-27 01:48:55.485759: Current learning rate: 0.00923 
2024-11-27 01:49:35.473119: train_loss -0.9315 
2024-11-27 01:49:35.473235: val_loss -0.9013 
2024-11-27 01:49:35.473296: Pseudo dice [np.float32(0.9175)] 
2024-11-27 01:49:35.473372: Epoch time: 39.99 s 
2024-11-27 01:49:36.399982:  
2024-11-27 01:49:36.400129: Epoch 86 
2024-11-27 01:49:36.400213: Current learning rate: 0.00922 
2024-11-27 01:50:16.485021: train_loss -0.9313 
2024-11-27 01:50:16.485164: val_loss -0.9087 
2024-11-27 01:50:16.485234: Pseudo dice [np.float32(0.9233)] 
2024-11-27 01:50:16.485309: Epoch time: 40.09 s 
2024-11-27 01:50:17.390927:  
2024-11-27 01:50:17.391053: Epoch 87 
2024-11-27 01:50:17.391172: Current learning rate: 0.00921 
2024-11-27 01:50:57.438285: train_loss -0.9322 
2024-11-27 01:50:57.438429: val_loss -0.9104 
2024-11-27 01:50:57.438496: Pseudo dice [np.float32(0.9234)] 
2024-11-27 01:50:57.438572: Epoch time: 40.05 s 
2024-11-27 01:50:58.343077:  
2024-11-27 01:50:58.343295: Epoch 88 
2024-11-27 01:50:58.343442: Current learning rate: 0.0092 
2024-11-27 01:51:38.360319: train_loss -0.9358 
2024-11-27 01:51:38.360457: val_loss -0.9035 
2024-11-27 01:51:38.360527: Pseudo dice [np.float32(0.9212)] 
2024-11-27 01:51:38.360602: Epoch time: 40.02 s 
2024-11-27 01:51:39.253678:  
2024-11-27 01:51:39.253817: Epoch 89 
2024-11-27 01:51:39.253894: Current learning rate: 0.0092 
2024-11-27 01:52:19.310528: train_loss -0.9349 
2024-11-27 01:52:19.310683: val_loss -0.9152 
2024-11-27 01:52:19.310755: Pseudo dice [np.float32(0.9277)] 
2024-11-27 01:52:19.310830: Epoch time: 40.06 s 
2024-11-27 01:52:19.310937: Yayy! New best EMA pseudo Dice: 0.9222000241279602 
2024-11-27 01:52:22.433389:  
2024-11-27 01:52:22.433539: Epoch 90 
2024-11-27 01:52:22.433614: Current learning rate: 0.00919 
2024-11-27 01:53:02.436102: train_loss -0.936 
2024-11-27 01:53:02.436243: val_loss -0.9077 
2024-11-27 01:53:02.436299: Pseudo dice [np.float32(0.9221)] 
2024-11-27 01:53:02.436357: Epoch time: 40.0 s 
2024-11-27 01:53:03.301333:  
2024-11-27 01:53:03.301428: Epoch 91 
2024-11-27 01:53:03.301505: Current learning rate: 0.00918 
2024-11-27 01:53:43.467079: train_loss -0.9349 
2024-11-27 01:53:43.467193: val_loss -0.9104 
2024-11-27 01:53:43.467244: Pseudo dice [np.float32(0.9237)] 
2024-11-27 01:53:43.467339: Epoch time: 40.17 s 
2024-11-27 01:53:43.467388: Yayy! New best EMA pseudo Dice: 0.9223999977111816 
2024-11-27 01:53:46.557179:  
2024-11-27 01:53:46.557254: Epoch 92 
2024-11-27 01:53:46.557325: Current learning rate: 0.00917 
2024-11-27 01:54:26.572782: train_loss -0.9341 
2024-11-27 01:54:26.572969: val_loss -0.9103 
2024-11-27 01:54:26.573042: Pseudo dice [np.float32(0.9232)] 
2024-11-27 01:54:26.573118: Epoch time: 40.02 s 
2024-11-27 01:54:26.573182: Yayy! New best EMA pseudo Dice: 0.9225000143051147 
2024-11-27 01:54:29.698258:  
2024-11-27 01:54:29.698376: Epoch 93 
2024-11-27 01:54:29.698492: Current learning rate: 0.00916 
2024-11-27 01:55:09.775621: train_loss -0.9353 
2024-11-27 01:55:09.775737: val_loss -0.9079 
2024-11-27 01:55:09.775840: Pseudo dice [np.float32(0.9219)] 
2024-11-27 01:55:09.775920: Epoch time: 40.08 s 
2024-11-27 01:55:10.627817:  
2024-11-27 01:55:10.627948: Epoch 94 
2024-11-27 01:55:10.628038: Current learning rate: 0.00915 
2024-11-27 01:55:50.769750: train_loss -0.9351 
2024-11-27 01:55:50.769947: val_loss -0.9117 
2024-11-27 01:55:50.770006: Pseudo dice [np.float32(0.9245)] 
2024-11-27 01:55:50.770066: Epoch time: 40.14 s 
2024-11-27 01:55:50.770116: Yayy! New best EMA pseudo Dice: 0.9225999712944031 
2024-11-27 01:55:53.894542:  
2024-11-27 01:55:53.894622: Epoch 95 
2024-11-27 01:55:53.894694: Current learning rate: 0.00914 
2024-11-27 01:56:33.952545: train_loss -0.9283 
2024-11-27 01:56:33.952661: val_loss -0.9097 
2024-11-27 01:56:33.952716: Pseudo dice [np.float32(0.9229)] 
2024-11-27 01:56:33.952774: Epoch time: 40.06 s 
2024-11-27 01:56:33.952869: Yayy! New best EMA pseudo Dice: 0.9225999712944031 
2024-11-27 01:56:36.985968:  
2024-11-27 01:56:36.986069: Epoch 96 
2024-11-27 01:56:36.986140: Current learning rate: 0.00913 
2024-11-27 01:57:17.043968: train_loss -0.9291 
2024-11-27 01:57:17.044147: val_loss -0.9104 
2024-11-27 01:57:17.044236: Pseudo dice [np.float32(0.9238)] 
2024-11-27 01:57:17.044332: Epoch time: 40.06 s 
2024-11-27 01:57:17.044464: Yayy! New best EMA pseudo Dice: 0.9228000044822693 
2024-11-27 01:57:20.154513:  
2024-11-27 01:57:20.154659: Epoch 97 
2024-11-27 01:57:20.154731: Current learning rate: 0.00912 
2024-11-27 01:58:00.216396: train_loss -0.9341 
2024-11-27 01:58:00.216512: val_loss -0.9079 
2024-11-27 01:58:00.216567: Pseudo dice [np.float32(0.9217)] 
2024-11-27 01:58:00.216628: Epoch time: 40.06 s 
2024-11-27 01:58:01.473038:  
2024-11-27 01:58:01.473181: Epoch 98 
2024-11-27 01:58:01.473262: Current learning rate: 0.00911 
2024-11-27 01:58:41.539604: train_loss -0.9348 
2024-11-27 01:58:41.539720: val_loss -0.9011 
2024-11-27 01:58:41.539772: Pseudo dice [np.float32(0.9159)] 
2024-11-27 01:58:41.539829: Epoch time: 40.07 s 
2024-11-27 01:58:42.407522:  
2024-11-27 01:58:42.407619: Epoch 99 
2024-11-27 01:58:42.407694: Current learning rate: 0.0091 
2024-11-27 01:59:22.518652: train_loss -0.9339 
2024-11-27 01:59:22.518769: val_loss -0.9063 
2024-11-27 01:59:22.518823: Pseudo dice [np.float32(0.9196)] 
2024-11-27 01:59:22.518914: Epoch time: 40.11 s 
2024-11-27 01:59:25.697131:  
2024-11-27 01:59:25.697245: Epoch 100 
2024-11-27 01:59:25.697600: Current learning rate: 0.0091 
2024-11-27 02:00:05.744862: train_loss -0.9347 
2024-11-27 02:00:05.745047: val_loss -0.9112 
2024-11-27 02:00:05.745116: Pseudo dice [np.float32(0.9249)] 
2024-11-27 02:00:05.745187: Epoch time: 40.05 s 
2024-11-27 02:00:06.630947:  
2024-11-27 02:00:06.631061: Epoch 101 
2024-11-27 02:00:06.631134: Current learning rate: 0.00909 
2024-11-27 02:00:46.777332: train_loss -0.9361 
2024-11-27 02:00:46.777464: val_loss -0.9095 
2024-11-27 02:00:46.777518: Pseudo dice [np.float32(0.9226)] 
2024-11-27 02:00:46.777574: Epoch time: 40.15 s 
2024-11-27 02:00:47.633096:  
2024-11-27 02:00:47.633228: Epoch 102 
2024-11-27 02:00:47.633305: Current learning rate: 0.00908 
2024-11-27 02:01:27.769964: train_loss -0.9342 
2024-11-27 02:01:27.770132: val_loss -0.9098 
2024-11-27 02:01:27.770203: Pseudo dice [np.float32(0.9238)] 
2024-11-27 02:01:27.770296: Epoch time: 40.14 s 
2024-11-27 02:01:28.690242:  
2024-11-27 02:01:28.690367: Epoch 103 
2024-11-27 02:01:28.690464: Current learning rate: 0.00907 
2024-11-27 02:02:08.829325: train_loss -0.9374 
2024-11-27 02:02:08.829460: val_loss -0.9103 
2024-11-27 02:02:08.829525: Pseudo dice [np.float32(0.9252)] 
2024-11-27 02:02:08.829581: Epoch time: 40.14 s 
2024-11-27 02:02:09.709365:  
2024-11-27 02:02:09.709478: Epoch 104 
2024-11-27 02:02:09.709566: Current learning rate: 0.00906 
2024-11-27 02:02:49.882623: train_loss -0.9366 
2024-11-27 02:02:49.882793: val_loss -0.9029 
2024-11-27 02:02:49.882855: Pseudo dice [np.float32(0.9174)] 
2024-11-27 02:02:49.882978: Epoch time: 40.17 s 
2024-11-27 02:02:50.817622:  
2024-11-27 02:02:50.817742: Epoch 105 
2024-11-27 02:02:50.817816: Current learning rate: 0.00905 
2024-11-27 02:03:30.968610: train_loss -0.9377 
2024-11-27 02:03:30.968739: val_loss -0.9087 
2024-11-27 02:03:30.968791: Pseudo dice [np.float32(0.9219)] 
2024-11-27 02:03:30.968848: Epoch time: 40.15 s 
2024-11-27 02:03:31.879420:  
2024-11-27 02:03:31.879544: Epoch 106 
2024-11-27 02:03:31.879624: Current learning rate: 0.00904 
2024-11-27 02:04:12.047171: train_loss -0.9372 
2024-11-27 02:04:12.047311: val_loss -0.9095 
2024-11-27 02:04:12.047381: Pseudo dice [np.float32(0.9225)] 
2024-11-27 02:04:12.047457: Epoch time: 40.17 s 
2024-11-27 02:04:12.946220:  
2024-11-27 02:04:12.946328: Epoch 107 
2024-11-27 02:04:12.946404: Current learning rate: 0.00903 
2024-11-27 02:04:53.094303: train_loss -0.9375 
2024-11-27 02:04:53.094472: val_loss -0.9078 
2024-11-27 02:04:53.094541: Pseudo dice [np.float32(0.9216)] 
2024-11-27 02:04:53.094614: Epoch time: 40.15 s 
2024-11-27 02:04:54.017416:  
2024-11-27 02:04:54.017595: Epoch 108 
2024-11-27 02:04:54.017719: Current learning rate: 0.00902 
2024-11-27 02:05:34.141286: train_loss -0.9373 
2024-11-27 02:05:34.141515: val_loss -0.9012 
2024-11-27 02:05:34.141568: Pseudo dice [np.float32(0.916)] 
2024-11-27 02:05:34.141632: Epoch time: 40.12 s 
2024-11-27 02:05:35.033816:  
2024-11-27 02:05:35.034108: Epoch 109 
2024-11-27 02:05:35.034202: Current learning rate: 0.00901 
2024-11-27 02:06:15.111068: train_loss -0.9406 
2024-11-27 02:06:15.111223: val_loss -0.9081 
2024-11-27 02:06:15.111314: Pseudo dice [np.float32(0.9219)] 
2024-11-27 02:06:15.111374: Epoch time: 40.08 s 
2024-11-27 02:06:16.052665:  
2024-11-27 02:06:16.052858: Epoch 110 
2024-11-27 02:06:16.052961: Current learning rate: 0.009 
2024-11-27 02:06:56.149204: train_loss -0.9381 
2024-11-27 02:06:56.149341: val_loss -0.908 
2024-11-27 02:06:56.149396: Pseudo dice [np.float32(0.9225)] 
2024-11-27 02:06:56.149455: Epoch time: 40.1 s 
2024-11-27 02:06:57.042701:  
2024-11-27 02:06:57.042825: Epoch 111 
2024-11-27 02:06:57.042922: Current learning rate: 0.009 
2024-11-27 02:07:37.220257: train_loss -0.9351 
2024-11-27 02:07:37.220397: val_loss -0.9029 
2024-11-27 02:07:37.220450: Pseudo dice [np.float32(0.9178)] 
2024-11-27 02:07:37.220525: Epoch time: 40.18 s 
2024-11-27 02:07:38.093603:  
2024-11-27 02:07:38.093721: Epoch 112 
2024-11-27 02:07:38.093833: Current learning rate: 0.00899 
2024-11-27 02:08:18.238068: train_loss -0.9305 
2024-11-27 02:08:18.238212: val_loss -0.9095 
2024-11-27 02:08:18.238282: Pseudo dice [np.float32(0.9223)] 
2024-11-27 02:08:18.238342: Epoch time: 40.15 s 
2024-11-27 02:08:19.189094:  
2024-11-27 02:08:19.189172: Epoch 113 
2024-11-27 02:08:19.189260: Current learning rate: 0.00898 
2024-11-27 02:08:59.324200: train_loss -0.9327 
2024-11-27 02:08:59.324335: val_loss -0.9037 
2024-11-27 02:08:59.324435: Pseudo dice [np.float32(0.9192)] 
2024-11-27 02:08:59.324509: Epoch time: 40.14 s 
2024-11-27 02:09:00.234460:  
2024-11-27 02:09:00.234555: Epoch 114 
2024-11-27 02:09:00.234640: Current learning rate: 0.00897 
2024-11-27 02:09:40.365642: train_loss -0.9359 
2024-11-27 02:09:40.365751: val_loss -0.9022 
2024-11-27 02:09:40.365813: Pseudo dice [np.float32(0.9188)] 
2024-11-27 02:09:40.365936: Epoch time: 40.13 s 
2024-11-27 02:09:41.272028:  
2024-11-27 02:09:41.272148: Epoch 115 
2024-11-27 02:09:41.272233: Current learning rate: 0.00896 
2024-11-27 02:10:21.424862: train_loss -0.9408 
2024-11-27 02:10:21.424980: val_loss -0.9156 
2024-11-27 02:10:21.425031: Pseudo dice [np.float32(0.9277)] 
2024-11-27 02:10:21.425086: Epoch time: 40.15 s 
2024-11-27 02:10:22.306558:  
2024-11-27 02:10:22.306636: Epoch 116 
2024-11-27 02:10:22.306707: Current learning rate: 0.00895 
2024-11-27 02:11:02.406129: train_loss -0.9397 
2024-11-27 02:11:02.406258: val_loss -0.9103 
2024-11-27 02:11:02.406313: Pseudo dice [np.float32(0.9246)] 
2024-11-27 02:11:02.406373: Epoch time: 40.1 s 
2024-11-27 02:11:03.785110:  
2024-11-27 02:11:03.785199: Epoch 117 
2024-11-27 02:11:03.785300: Current learning rate: 0.00894 
2024-11-27 02:11:43.979779: train_loss -0.9404 
2024-11-27 02:11:43.979938: val_loss -0.9074 
2024-11-27 02:11:43.980060: Pseudo dice [np.float32(0.9221)] 
2024-11-27 02:11:43.980118: Epoch time: 40.2 s 
2024-11-27 02:11:44.852424:  
2024-11-27 02:11:44.852586: Epoch 118 
2024-11-27 02:11:44.852683: Current learning rate: 0.00893 
2024-11-27 02:12:25.013974: train_loss -0.9391 
2024-11-27 02:12:25.014219: val_loss -0.9121 
2024-11-27 02:12:25.014294: Pseudo dice [np.float32(0.9261)] 
2024-11-27 02:12:25.014451: Epoch time: 40.16 s 
2024-11-27 02:12:25.920160:  
2024-11-27 02:12:25.920254: Epoch 119 
2024-11-27 02:12:25.920325: Current learning rate: 0.00892 
2024-11-27 02:13:06.073870: train_loss -0.9388 
2024-11-27 02:13:06.074015: val_loss -0.9054 
2024-11-27 02:13:06.074111: Pseudo dice [np.float32(0.9206)] 
2024-11-27 02:13:06.074197: Epoch time: 40.15 s 
2024-11-27 02:13:07.029068:  
2024-11-27 02:13:07.029221: Epoch 120 
2024-11-27 02:13:07.029322: Current learning rate: 0.00891 
2024-11-27 02:13:47.183239: train_loss -0.9401 
2024-11-27 02:13:47.183387: val_loss -0.9125 
2024-11-27 02:13:47.183497: Pseudo dice [np.float32(0.9254)] 
2024-11-27 02:13:47.183671: Epoch time: 40.16 s 
2024-11-27 02:13:48.251273:  
2024-11-27 02:13:48.251475: Epoch 121 
2024-11-27 02:13:48.251573: Current learning rate: 0.0089 
2024-11-27 02:14:28.357774: train_loss -0.9382 
2024-11-27 02:14:28.357977: val_loss -0.9041 
2024-11-27 02:14:28.358081: Pseudo dice [np.float32(0.9182)] 
2024-11-27 02:14:28.358156: Epoch time: 40.11 s 
2024-11-27 02:14:29.271150:  
2024-11-27 02:14:29.271265: Epoch 122 
2024-11-27 02:14:29.271362: Current learning rate: 0.00889 
2024-11-27 02:15:09.417706: train_loss -0.9415 
2024-11-27 02:15:09.417819: val_loss -0.9089 
2024-11-27 02:15:09.417906: Pseudo dice [np.float32(0.9228)] 
2024-11-27 02:15:09.417966: Epoch time: 40.15 s 
2024-11-27 02:15:10.333525:  
2024-11-27 02:15:10.333691: Epoch 123 
2024-11-27 02:15:10.333786: Current learning rate: 0.00889 
2024-11-27 02:15:50.416331: train_loss -0.941 
2024-11-27 02:15:50.416447: val_loss -0.913 
2024-11-27 02:15:50.416506: Pseudo dice [np.float32(0.9259)] 
2024-11-27 02:15:50.416564: Epoch time: 40.08 s 
2024-11-27 02:15:51.306465:  
2024-11-27 02:15:51.306578: Epoch 124 
2024-11-27 02:15:51.306707: Current learning rate: 0.00888 
2024-11-27 02:16:31.378588: train_loss -0.9419 
2024-11-27 02:16:31.378885: val_loss -0.9109 
2024-11-27 02:16:31.378967: Pseudo dice [np.float32(0.9248)] 
2024-11-27 02:16:31.379109: Epoch time: 40.07 s 
2024-11-27 02:16:32.336196:  
2024-11-27 02:16:32.336297: Epoch 125 
2024-11-27 02:16:32.336398: Current learning rate: 0.00887 
2024-11-27 02:17:12.400151: train_loss -0.9401 
2024-11-27 02:17:12.400326: val_loss -0.9051 
2024-11-27 02:17:12.400397: Pseudo dice [np.float32(0.9194)] 
2024-11-27 02:17:12.400470: Epoch time: 40.06 s 
2024-11-27 02:17:13.321105:  
2024-11-27 02:17:13.321212: Epoch 126 
2024-11-27 02:17:13.321293: Current learning rate: 0.00886 
2024-11-27 02:17:53.361915: train_loss -0.9392 
2024-11-27 02:17:53.362026: val_loss -0.9086 
2024-11-27 02:17:53.362081: Pseudo dice [np.float32(0.9218)] 
2024-11-27 02:17:53.362138: Epoch time: 40.04 s 
2024-11-27 02:17:54.331778:  
2024-11-27 02:17:54.331949: Epoch 127 
2024-11-27 02:17:54.332121: Current learning rate: 0.00885 
2024-11-27 02:18:34.405050: train_loss -0.9416 
2024-11-27 02:18:34.405175: val_loss -0.9077 
2024-11-27 02:18:34.405233: Pseudo dice [np.float32(0.9218)] 
2024-11-27 02:18:34.405322: Epoch time: 40.07 s 
2024-11-27 02:18:35.385938:  
2024-11-27 02:18:35.386129: Epoch 128 
2024-11-27 02:18:35.386230: Current learning rate: 0.00884 
2024-11-27 02:19:15.421963: train_loss -0.9399 
2024-11-27 02:19:15.422126: val_loss -0.9082 
2024-11-27 02:19:15.422186: Pseudo dice [np.float32(0.9234)] 
2024-11-27 02:19:15.422247: Epoch time: 40.04 s 
2024-11-27 02:19:16.310762:  
2024-11-27 02:19:16.310931: Epoch 129 
2024-11-27 02:19:16.311013: Current learning rate: 0.00883 
2024-11-27 02:19:56.436105: train_loss -0.9409 
2024-11-27 02:19:56.436240: val_loss -0.9032 
2024-11-27 02:19:56.436293: Pseudo dice [np.float32(0.9177)] 
2024-11-27 02:19:56.436363: Epoch time: 40.13 s 
2024-11-27 02:19:57.351321:  
2024-11-27 02:19:57.351450: Epoch 130 
2024-11-27 02:19:57.351536: Current learning rate: 0.00882 
2024-11-27 02:20:37.482296: train_loss -0.9439 
2024-11-27 02:20:37.482474: val_loss -0.9054 
2024-11-27 02:20:37.482586: Pseudo dice [np.float32(0.9213)] 
2024-11-27 02:20:37.482668: Epoch time: 40.13 s 
2024-11-27 02:20:38.426117:  
2024-11-27 02:20:38.426199: Epoch 131 
2024-11-27 02:20:38.426314: Current learning rate: 0.00881 
2024-11-27 02:21:18.554159: train_loss -0.9432 
2024-11-27 02:21:18.554291: val_loss -0.9083 
2024-11-27 02:21:18.554360: Pseudo dice [np.float32(0.922)] 
2024-11-27 02:21:18.554456: Epoch time: 40.13 s 
2024-11-27 02:21:19.532087:  
2024-11-27 02:21:19.532293: Epoch 132 
2024-11-27 02:21:19.532409: Current learning rate: 0.0088 
2024-11-27 02:21:59.610614: train_loss -0.9425 
2024-11-27 02:21:59.610727: val_loss -0.9125 
2024-11-27 02:21:59.610779: Pseudo dice [np.float32(0.9259)] 
2024-11-27 02:21:59.610834: Epoch time: 40.08 s 
2024-11-27 02:22:00.510428:  
2024-11-27 02:22:00.510519: Epoch 133 
2024-11-27 02:22:00.510628: Current learning rate: 0.00879 
2024-11-27 02:22:40.655639: train_loss -0.9427 
2024-11-27 02:22:40.655764: val_loss -0.9077 
2024-11-27 02:22:40.655816: Pseudo dice [np.float32(0.921)] 
2024-11-27 02:22:40.655876: Epoch time: 40.15 s 
2024-11-27 02:22:41.563232:  
2024-11-27 02:22:41.563332: Epoch 134 
2024-11-27 02:22:41.563417: Current learning rate: 0.00879 
2024-11-27 02:23:21.649999: train_loss -0.9379 
2024-11-27 02:23:21.650115: val_loss -0.9048 
2024-11-27 02:23:21.650170: Pseudo dice [np.float32(0.9186)] 
2024-11-27 02:23:21.650227: Epoch time: 40.09 s 
2024-11-27 02:23:23.021118:  
2024-11-27 02:23:23.021377: Epoch 135 
2024-11-27 02:23:23.021480: Current learning rate: 0.00878 
2024-11-27 02:24:03.274623: train_loss -0.933 
2024-11-27 02:24:03.274734: val_loss -0.9082 
2024-11-27 02:24:03.274783: Pseudo dice [np.float32(0.9227)] 
2024-11-27 02:24:03.274837: Epoch time: 40.25 s 
2024-11-27 02:24:04.209996:  
2024-11-27 02:24:04.210108: Epoch 136 
2024-11-27 02:24:04.210177: Current learning rate: 0.00877 
2024-11-27 02:24:44.368904: train_loss -0.9324 
2024-11-27 02:24:44.369017: val_loss -0.8995 
2024-11-27 02:24:44.369071: Pseudo dice [np.float32(0.9154)] 
2024-11-27 02:24:44.369159: Epoch time: 40.16 s 
2024-11-27 02:24:45.276201:  
2024-11-27 02:24:45.276334: Epoch 137 
2024-11-27 02:24:45.276409: Current learning rate: 0.00876 
2024-11-27 02:25:25.393080: train_loss -0.9261 
2024-11-27 02:25:25.393227: val_loss -0.9075 
2024-11-27 02:25:25.393281: Pseudo dice [np.float32(0.9216)] 
2024-11-27 02:25:25.393337: Epoch time: 40.12 s 
2024-11-27 02:25:26.303498:  
2024-11-27 02:25:26.303603: Epoch 138 
2024-11-27 02:25:26.303716: Current learning rate: 0.00875 
2024-11-27 02:26:06.418996: train_loss -0.9244 
2024-11-27 02:26:06.419187: val_loss -0.9112 
2024-11-27 02:26:06.419275: Pseudo dice [np.float32(0.9244)] 
2024-11-27 02:26:06.419354: Epoch time: 40.12 s 
2024-11-27 02:26:07.349971:  
2024-11-27 02:26:07.350086: Epoch 139 
2024-11-27 02:26:07.350181: Current learning rate: 0.00874 
2024-11-27 02:26:47.459107: train_loss -0.9191 
2024-11-27 02:26:47.459218: val_loss -0.8976 
2024-11-27 02:26:47.459268: Pseudo dice [np.float32(0.9159)] 
2024-11-27 02:26:47.459355: Epoch time: 40.11 s 
2024-11-27 02:26:48.336068:  
2024-11-27 02:26:48.336180: Epoch 140 
2024-11-27 02:26:48.336251: Current learning rate: 0.00873 
2024-11-27 02:27:28.441249: train_loss -0.9178 
2024-11-27 02:27:28.441374: val_loss -0.8843 
2024-11-27 02:27:28.441428: Pseudo dice [np.float32(0.9019)] 
2024-11-27 02:27:28.441484: Epoch time: 40.11 s 
2024-11-27 02:27:29.412215:  
2024-11-27 02:27:29.412383: Epoch 141 
2024-11-27 02:27:29.412511: Current learning rate: 0.00872 
2024-11-27 02:28:09.592200: train_loss -0.9138 
2024-11-27 02:28:09.592314: val_loss -0.8951 
2024-11-27 02:28:09.592367: Pseudo dice [np.float32(0.9109)] 
2024-11-27 02:28:09.592422: Epoch time: 40.18 s 
2024-11-27 02:28:10.523277:  
2024-11-27 02:28:10.523366: Epoch 142 
2024-11-27 02:28:10.523472: Current learning rate: 0.00871 
2024-11-27 02:28:50.533048: train_loss -0.9264 
2024-11-27 02:28:50.533179: val_loss -0.9045 
2024-11-27 02:28:50.533233: Pseudo dice [np.float32(0.92)] 
2024-11-27 02:28:50.533291: Epoch time: 40.01 s 
2024-11-27 02:28:51.484534:  
2024-11-27 02:28:51.484622: Epoch 143 
2024-11-27 02:28:51.484725: Current learning rate: 0.0087 
2024-11-27 02:29:31.494581: train_loss -0.9254 
2024-11-27 02:29:31.494691: val_loss -0.9036 
2024-11-27 02:29:31.494775: Pseudo dice [np.float32(0.9195)] 
2024-11-27 02:29:31.494870: Epoch time: 40.01 s 
2024-11-27 02:29:32.450415:  
2024-11-27 02:29:32.450656: Epoch 144 
2024-11-27 02:29:32.450752: Current learning rate: 0.00869 
2024-11-27 02:30:12.449081: train_loss -0.9314 
2024-11-27 02:30:12.449198: val_loss -0.9015 
2024-11-27 02:30:12.449252: Pseudo dice [np.float32(0.9173)] 
2024-11-27 02:30:12.449348: Epoch time: 40.0 s 
2024-11-27 02:30:13.441396:  
2024-11-27 02:30:13.441500: Epoch 145 
2024-11-27 02:30:13.441573: Current learning rate: 0.00868 
2024-11-27 02:30:53.441026: train_loss -0.9349 
2024-11-27 02:30:53.441143: val_loss -0.9109 
2024-11-27 02:30:53.441206: Pseudo dice [np.float32(0.9244)] 
2024-11-27 02:30:53.441290: Epoch time: 40.0 s 
2024-11-27 02:30:54.364811:  
2024-11-27 02:30:54.365015: Epoch 146 
2024-11-27 02:30:54.365107: Current learning rate: 0.00868 
2024-11-27 02:31:34.359966: train_loss -0.9372 
2024-11-27 02:31:34.360096: val_loss -0.9047 
2024-11-27 02:31:34.360151: Pseudo dice [np.float32(0.918)] 
2024-11-27 02:31:34.360209: Epoch time: 40.0 s 
2024-11-27 02:31:35.305223:  
2024-11-27 02:31:35.305412: Epoch 147 
2024-11-27 02:31:35.305485: Current learning rate: 0.00867 
2024-11-27 02:32:15.351814: train_loss -0.9401 
2024-11-27 02:32:15.352011: val_loss -0.9052 
2024-11-27 02:32:15.352065: Pseudo dice [np.float32(0.9204)] 
2024-11-27 02:32:15.352123: Epoch time: 40.05 s 
2024-11-27 02:32:16.373501:  
2024-11-27 02:32:16.373574: Epoch 148 
2024-11-27 02:32:16.373647: Current learning rate: 0.00866 
2024-11-27 02:32:56.453221: train_loss -0.9416 
2024-11-27 02:32:56.453352: val_loss -0.9074 
2024-11-27 02:32:56.453417: Pseudo dice [np.float32(0.9222)] 
2024-11-27 02:32:56.453493: Epoch time: 40.08 s 
2024-11-27 02:32:57.379858:  
2024-11-27 02:32:57.380017: Epoch 149 
2024-11-27 02:32:57.380177: Current learning rate: 0.00865 
2024-11-27 02:33:37.363106: train_loss -0.942 
2024-11-27 02:33:37.363215: val_loss -0.9076 
2024-11-27 02:33:37.363294: Pseudo dice [np.float32(0.9228)] 
2024-11-27 02:33:37.363350: Epoch time: 39.98 s 
2024-11-27 02:33:40.508681:  
2024-11-27 02:33:40.508758: Epoch 150 
2024-11-27 02:33:40.508829: Current learning rate: 0.00864 
2024-11-27 02:34:20.498754: train_loss -0.9421 
2024-11-27 02:34:20.498876: val_loss -0.9046 
2024-11-27 02:34:20.498966: Pseudo dice [np.float32(0.9191)] 
2024-11-27 02:34:20.499075: Epoch time: 39.99 s 
2024-11-27 02:34:21.494650:  
2024-11-27 02:34:21.494758: Epoch 151 
2024-11-27 02:34:21.494861: Current learning rate: 0.00863 
2024-11-27 02:35:01.589335: train_loss -0.9377 
2024-11-27 02:35:01.589460: val_loss -0.8872 
2024-11-27 02:35:01.589515: Pseudo dice [np.float32(0.9047)] 
2024-11-27 02:35:01.589571: Epoch time: 40.1 s 
2024-11-27 02:35:02.595725:  
2024-11-27 02:35:02.595857: Epoch 152 
2024-11-27 02:35:02.595958: Current learning rate: 0.00862 
2024-11-27 02:35:42.685921: train_loss -0.9363 
2024-11-27 02:35:42.686034: val_loss -0.9091 
2024-11-27 02:35:42.686085: Pseudo dice [np.float32(0.9214)] 
2024-11-27 02:35:42.686141: Epoch time: 40.09 s 
2024-11-27 02:35:44.061407:  
2024-11-27 02:35:44.061492: Epoch 153 
2024-11-27 02:35:44.061576: Current learning rate: 0.00861 
2024-11-27 02:36:24.215572: train_loss -0.9399 
2024-11-27 02:36:24.215716: val_loss -0.908 
2024-11-27 02:36:24.215773: Pseudo dice [np.float32(0.9241)] 
2024-11-27 02:36:24.215835: Epoch time: 40.16 s 
2024-11-27 02:36:25.142011:  
2024-11-27 02:36:25.142111: Epoch 154 
2024-11-27 02:36:25.142184: Current learning rate: 0.0086 
2024-11-27 02:37:05.295635: train_loss -0.9418 
2024-11-27 02:37:05.295799: val_loss -0.9086 
2024-11-27 02:37:05.295855: Pseudo dice [np.float32(0.9224)] 
2024-11-27 02:37:05.295965: Epoch time: 40.15 s 
2024-11-27 02:37:06.312485:  
2024-11-27 02:37:06.312626: Epoch 155 
2024-11-27 02:37:06.312748: Current learning rate: 0.00859 
2024-11-27 02:37:46.457182: train_loss -0.9353 
2024-11-27 02:37:46.457401: val_loss -0.9074 
2024-11-27 02:37:46.457460: Pseudo dice [np.float32(0.9227)] 
2024-11-27 02:37:46.457529: Epoch time: 40.15 s 
2024-11-27 02:37:47.477650:  
2024-11-27 02:37:47.477803: Epoch 156 
2024-11-27 02:37:47.477930: Current learning rate: 0.00858 
2024-11-27 02:38:27.594214: train_loss -0.9373 
2024-11-27 02:38:27.594347: val_loss -0.903 
2024-11-27 02:38:27.594404: Pseudo dice [np.float32(0.918)] 
2024-11-27 02:38:27.594459: Epoch time: 40.12 s 
2024-11-27 02:38:28.526297:  
2024-11-27 02:38:28.526590: Epoch 157 
2024-11-27 02:38:28.526696: Current learning rate: 0.00858 
2024-11-27 02:39:08.659689: train_loss -0.9382 
2024-11-27 02:39:08.659817: val_loss -0.8971 
2024-11-27 02:39:08.659962: Pseudo dice [np.float32(0.9127)] 
2024-11-27 02:39:08.660052: Epoch time: 40.13 s 
2024-11-27 02:39:09.566900:  
2024-11-27 02:39:09.567011: Epoch 158 
2024-11-27 02:39:09.567099: Current learning rate: 0.00857 
2024-11-27 02:39:49.692214: train_loss -0.9424 
2024-11-27 02:39:49.692325: val_loss -0.9118 
2024-11-27 02:39:49.692375: Pseudo dice [np.float32(0.9252)] 
2024-11-27 02:39:49.692429: Epoch time: 40.13 s 
2024-11-27 02:39:50.740109:  
2024-11-27 02:39:50.740299: Epoch 159 
2024-11-27 02:39:50.740378: Current learning rate: 0.00856 
2024-11-27 02:40:30.843683: train_loss -0.9427 
2024-11-27 02:40:30.843806: val_loss -0.9054 
2024-11-27 02:40:30.843967: Pseudo dice [np.float32(0.9204)] 
2024-11-27 02:40:30.844113: Epoch time: 40.1 s 
2024-11-27 02:40:31.854380:  
2024-11-27 02:40:31.854568: Epoch 160 
2024-11-27 02:40:31.854663: Current learning rate: 0.00855 
2024-11-27 02:41:11.988260: train_loss -0.942 
2024-11-27 02:41:11.988474: val_loss -0.9099 
2024-11-27 02:41:11.988530: Pseudo dice [np.float32(0.9223)] 
2024-11-27 02:41:11.988587: Epoch time: 40.13 s 
2024-11-27 02:41:12.934309:  
2024-11-27 02:41:12.934412: Epoch 161 
2024-11-27 02:41:12.934487: Current learning rate: 0.00854 
2024-11-27 02:41:53.008412: train_loss -0.9429 
2024-11-27 02:41:53.008553: val_loss -0.913 
2024-11-27 02:41:53.008621: Pseudo dice [np.float32(0.9271)] 
2024-11-27 02:41:53.008694: Epoch time: 40.08 s 
2024-11-27 02:41:54.103028:  
2024-11-27 02:41:54.103163: Epoch 162 
2024-11-27 02:41:54.103255: Current learning rate: 0.00853 
2024-11-27 02:42:34.237008: train_loss -0.9439 
2024-11-27 02:42:34.237125: val_loss -0.9085 
2024-11-27 02:42:34.237200: Pseudo dice [np.float32(0.9215)] 
2024-11-27 02:42:34.237276: Epoch time: 40.14 s 
2024-11-27 02:42:35.216676:  
2024-11-27 02:42:35.216822: Epoch 163 
2024-11-27 02:42:35.216920: Current learning rate: 0.00852 
2024-11-27 02:43:15.369192: train_loss -0.9454 
2024-11-27 02:43:15.369342: val_loss -0.9089 
2024-11-27 02:43:15.369395: Pseudo dice [np.float32(0.9225)] 
2024-11-27 02:43:15.369451: Epoch time: 40.15 s 
2024-11-27 02:43:16.323861:  
2024-11-27 02:43:16.323996: Epoch 164 
2024-11-27 02:43:16.324074: Current learning rate: 0.00851 
2024-11-27 02:43:56.457053: train_loss -0.945 
2024-11-27 02:43:56.457179: val_loss -0.9094 
2024-11-27 02:43:56.457251: Pseudo dice [np.float32(0.9241)] 
2024-11-27 02:43:56.457325: Epoch time: 40.13 s 
2024-11-27 02:43:57.475139:  
2024-11-27 02:43:57.475336: Epoch 165 
2024-11-27 02:43:57.475475: Current learning rate: 0.0085 
2024-11-27 02:44:37.541190: train_loss -0.9434 
2024-11-27 02:44:37.541324: val_loss -0.908 
2024-11-27 02:44:37.541375: Pseudo dice [np.float32(0.9226)] 
2024-11-27 02:44:37.541430: Epoch time: 40.07 s 
2024-11-27 02:44:38.654286:  
2024-11-27 02:44:38.654382: Epoch 166 
2024-11-27 02:44:38.654452: Current learning rate: 0.00849 
2024-11-27 02:45:18.716569: train_loss -0.9471 
2024-11-27 02:45:18.716691: val_loss -0.911 
2024-11-27 02:45:18.716781: Pseudo dice [np.float32(0.9242)] 
2024-11-27 02:45:18.716857: Epoch time: 40.06 s 
2024-11-27 02:45:19.631332:  
2024-11-27 02:45:19.631465: Epoch 167 
2024-11-27 02:45:19.631540: Current learning rate: 0.00848 
2024-11-27 02:45:59.817518: train_loss -0.9482 
2024-11-27 02:45:59.817646: val_loss -0.9096 
2024-11-27 02:45:59.817697: Pseudo dice [np.float32(0.9222)] 
2024-11-27 02:45:59.817752: Epoch time: 40.19 s 
2024-11-27 02:46:00.786411:  
2024-11-27 02:46:00.786501: Epoch 168 
2024-11-27 02:46:00.786859: Current learning rate: 0.00847 
2024-11-27 02:46:40.835395: train_loss -0.9465 
2024-11-27 02:46:40.835510: val_loss -0.9045 
2024-11-27 02:46:40.835564: Pseudo dice [np.float32(0.9192)] 
2024-11-27 02:46:40.835621: Epoch time: 40.05 s 
2024-11-27 02:46:41.806945:  
2024-11-27 02:46:41.807214: Epoch 169 
2024-11-27 02:46:41.807325: Current learning rate: 0.00847 
2024-11-27 02:47:21.877192: train_loss -0.9449 
2024-11-27 02:47:21.877355: val_loss -0.9128 
2024-11-27 02:47:21.877424: Pseudo dice [np.float32(0.9254)] 
2024-11-27 02:47:21.877495: Epoch time: 40.07 s 
2024-11-27 02:47:22.838939:  
2024-11-27 02:47:22.839041: Epoch 170 
2024-11-27 02:47:22.839114: Current learning rate: 0.00846 
2024-11-27 02:48:02.944835: train_loss -0.947 
2024-11-27 02:48:02.945044: val_loss -0.9127 
2024-11-27 02:48:02.945097: Pseudo dice [np.float32(0.926)] 
2024-11-27 02:48:02.945153: Epoch time: 40.11 s 
2024-11-27 02:48:04.294482:  
2024-11-27 02:48:04.294591: Epoch 171 
2024-11-27 02:48:04.294675: Current learning rate: 0.00845 
2024-11-27 02:48:44.375999: train_loss -0.9473 
2024-11-27 02:48:44.376144: val_loss -0.9104 
2024-11-27 02:48:44.376198: Pseudo dice [np.float32(0.9248)] 
2024-11-27 02:48:44.376256: Epoch time: 40.08 s 
2024-11-27 02:48:45.305782:  
2024-11-27 02:48:45.305988: Epoch 172 
2024-11-27 02:48:45.306063: Current learning rate: 0.00844 
2024-11-27 02:49:25.443024: train_loss -0.9455 
2024-11-27 02:49:25.443132: val_loss -0.9101 
2024-11-27 02:49:25.443183: Pseudo dice [np.float32(0.9249)] 
2024-11-27 02:49:25.443242: Epoch time: 40.14 s 
2024-11-27 02:49:26.418962:  
2024-11-27 02:49:26.419167: Epoch 173 
2024-11-27 02:49:26.419269: Current learning rate: 0.00843 
2024-11-27 02:50:06.552454: train_loss -0.9463 
2024-11-27 02:50:06.552628: val_loss -0.9099 
2024-11-27 02:50:06.552720: Pseudo dice [np.float32(0.9223)] 
2024-11-27 02:50:06.552816: Epoch time: 40.13 s 
2024-11-27 02:50:07.490639:  
2024-11-27 02:50:07.490737: Epoch 174 
2024-11-27 02:50:07.490808: Current learning rate: 0.00842 
2024-11-27 02:50:47.609319: train_loss -0.9458 
2024-11-27 02:50:47.609510: val_loss -0.9035 
2024-11-27 02:50:47.609562: Pseudo dice [np.float32(0.9177)] 
2024-11-27 02:50:47.609618: Epoch time: 40.12 s 
2024-11-27 02:50:48.585302:  
2024-11-27 02:50:48.585447: Epoch 175 
2024-11-27 02:50:48.585536: Current learning rate: 0.00841 
2024-11-27 02:51:28.720442: train_loss -0.947 
2024-11-27 02:51:28.720678: val_loss -0.9064 
2024-11-27 02:51:28.720732: Pseudo dice [np.float32(0.921)] 
2024-11-27 02:51:28.720787: Epoch time: 40.14 s 
2024-11-27 02:51:29.657811:  
2024-11-27 02:51:29.658094: Epoch 176 
2024-11-27 02:51:29.658168: Current learning rate: 0.0084 
2024-11-27 02:52:09.743799: train_loss -0.9426 
2024-11-27 02:52:09.743922: val_loss -0.9074 
2024-11-27 02:52:09.743989: Pseudo dice [np.float32(0.9205)] 
2024-11-27 02:52:09.744069: Epoch time: 40.09 s 
2024-11-27 02:52:10.628572:  
2024-11-27 02:52:10.628731: Epoch 177 
2024-11-27 02:52:10.628841: Current learning rate: 0.00839 
2024-11-27 02:52:50.641629: train_loss -0.9455 
2024-11-27 02:52:50.641737: val_loss -0.9035 
2024-11-27 02:52:50.641788: Pseudo dice [np.float32(0.9184)] 
2024-11-27 02:52:50.641844: Epoch time: 40.01 s 
2024-11-27 02:52:51.531178:  
2024-11-27 02:52:51.531328: Epoch 178 
2024-11-27 02:52:51.531398: Current learning rate: 0.00838 
2024-11-27 02:53:31.579158: train_loss -0.9478 
2024-11-27 02:53:31.579268: val_loss -0.915 
2024-11-27 02:53:31.579330: Pseudo dice [np.float32(0.9277)] 
2024-11-27 02:53:31.579407: Epoch time: 40.05 s 
2024-11-27 02:53:32.533091:  
2024-11-27 02:53:32.533219: Epoch 179 
2024-11-27 02:53:32.533354: Current learning rate: 0.00837 
2024-11-27 02:54:12.583605: train_loss -0.9473 
2024-11-27 02:54:12.583716: val_loss -0.9114 
2024-11-27 02:54:12.583769: Pseudo dice [np.float32(0.9234)] 
2024-11-27 02:54:12.583826: Epoch time: 40.05 s 
2024-11-27 02:54:13.502328:  
2024-11-27 02:54:13.502434: Epoch 180 
2024-11-27 02:54:13.502505: Current learning rate: 0.00836 
2024-11-27 02:54:53.525143: train_loss -0.9475 
2024-11-27 02:54:53.525265: val_loss -0.913 
2024-11-27 02:54:53.525315: Pseudo dice [np.float32(0.9262)] 
2024-11-27 02:54:53.525369: Epoch time: 40.02 s 
2024-11-27 02:54:54.388994:  
2024-11-27 02:54:54.389092: Epoch 181 
2024-11-27 02:54:54.389159: Current learning rate: 0.00836 
2024-11-27 02:55:34.409270: train_loss -0.9472 
2024-11-27 02:55:34.409512: val_loss -0.9146 
2024-11-27 02:55:34.409780: Pseudo dice [np.float32(0.9281)] 
2024-11-27 02:55:34.409899: Epoch time: 40.02 s 
2024-11-27 02:55:34.409949: Yayy! New best EMA pseudo Dice: 0.9232000112533569 
2024-11-27 02:55:37.807221:  
2024-11-27 02:55:37.807404: Epoch 182 
2024-11-27 02:55:37.807474: Current learning rate: 0.00835 
2024-11-27 02:56:17.707681: train_loss -0.9479 
2024-11-27 02:56:17.707793: val_loss -0.9052 
2024-11-27 02:56:17.707844: Pseudo dice [np.float32(0.92)] 
2024-11-27 02:56:17.707931: Epoch time: 39.9 s 
2024-11-27 02:56:18.642741:  
2024-11-27 02:56:18.642835: Epoch 183 
2024-11-27 02:56:18.642936: Current learning rate: 0.00834 
2024-11-27 02:56:58.591102: train_loss -0.9477 
2024-11-27 02:56:58.591210: val_loss -0.909 
2024-11-27 02:56:58.591261: Pseudo dice [np.float32(0.9222)] 
2024-11-27 02:56:58.591316: Epoch time: 39.95 s 
2024-11-27 02:56:59.480580:  
2024-11-27 02:56:59.480667: Epoch 184 
2024-11-27 02:56:59.480737: Current learning rate: 0.00833 
2024-11-27 02:57:39.490943: train_loss -0.9473 
2024-11-27 02:57:39.491130: val_loss -0.9076 
2024-11-27 02:57:39.491184: Pseudo dice [np.float32(0.9212)] 
2024-11-27 02:57:39.491241: Epoch time: 40.01 s 
2024-11-27 02:57:40.406734:  
2024-11-27 02:57:40.406906: Epoch 185 
2024-11-27 02:57:40.407009: Current learning rate: 0.00832 
2024-11-27 02:58:20.371953: train_loss -0.9478 
2024-11-27 02:58:20.372066: val_loss -0.9097 
2024-11-27 02:58:20.372119: Pseudo dice [np.float32(0.9242)] 
2024-11-27 02:58:20.372176: Epoch time: 39.97 s 
2024-11-27 02:58:21.287135:  
2024-11-27 02:58:21.287234: Epoch 186 
2024-11-27 02:58:21.287306: Current learning rate: 0.00831 
2024-11-27 02:59:01.296624: train_loss -0.949 
2024-11-27 02:59:01.296761: val_loss -0.9066 
2024-11-27 02:59:01.296813: Pseudo dice [np.float32(0.9199)] 
2024-11-27 02:59:01.296874: Epoch time: 40.01 s 
2024-11-27 02:59:02.188300:  
2024-11-27 02:59:02.188384: Epoch 187 
2024-11-27 02:59:02.188460: Current learning rate: 0.0083 
2024-11-27 02:59:42.181351: train_loss -0.9481 
2024-11-27 02:59:42.181471: val_loss -0.8926 
2024-11-27 02:59:42.181537: Pseudo dice [np.float32(0.9088)] 
2024-11-27 02:59:42.181609: Epoch time: 39.99 s 
2024-11-27 02:59:43.428131:  
2024-11-27 02:59:43.428243: Epoch 188 
2024-11-27 02:59:43.428320: Current learning rate: 0.00829 
2024-11-27 03:00:23.441097: train_loss -0.9349 
2024-11-27 03:00:23.441215: val_loss -0.9051 
2024-11-27 03:00:23.441283: Pseudo dice [np.float32(0.9201)] 
2024-11-27 03:00:23.441355: Epoch time: 40.01 s 
2024-11-27 03:00:24.379470:  
2024-11-27 03:00:24.379582: Epoch 189 
2024-11-27 03:00:24.379689: Current learning rate: 0.00828 
2024-11-27 03:01:04.450337: train_loss -0.9414 
2024-11-27 03:01:04.450470: val_loss -0.9032 
2024-11-27 03:01:04.450522: Pseudo dice [np.float32(0.9184)] 
2024-11-27 03:01:04.450579: Epoch time: 40.07 s 
2024-11-27 03:01:05.407172:  
2024-11-27 03:01:05.407281: Epoch 190 
2024-11-27 03:01:05.407354: Current learning rate: 0.00827 
2024-11-27 03:01:45.539933: train_loss -0.9427 
2024-11-27 03:01:45.540076: val_loss -0.9054 
2024-11-27 03:01:45.540129: Pseudo dice [np.float32(0.9195)] 
2024-11-27 03:01:45.540187: Epoch time: 40.13 s 
2024-11-27 03:01:46.482965:  
2024-11-27 03:01:46.483107: Epoch 191 
2024-11-27 03:01:46.483199: Current learning rate: 0.00826 
2024-11-27 03:02:26.544715: train_loss -0.9453 
2024-11-27 03:02:26.544847: val_loss -0.9106 
2024-11-27 03:02:26.544909: Pseudo dice [np.float32(0.9257)] 
2024-11-27 03:02:26.544968: Epoch time: 40.06 s 
2024-11-27 03:02:27.428178:  
2024-11-27 03:02:27.428433: Epoch 192 
2024-11-27 03:02:27.428513: Current learning rate: 0.00825 
2024-11-27 03:03:07.504065: train_loss -0.9452 
2024-11-27 03:03:07.504195: val_loss -0.9058 
2024-11-27 03:03:07.504245: Pseudo dice [np.float32(0.9203)] 
2024-11-27 03:03:07.504301: Epoch time: 40.08 s 
2024-11-27 03:03:08.508475:  
2024-11-27 03:03:08.508564: Epoch 193 
2024-11-27 03:03:08.508631: Current learning rate: 0.00824 
2024-11-27 03:03:48.545694: train_loss -0.9468 
2024-11-27 03:03:48.545805: val_loss -0.906 
2024-11-27 03:03:48.545858: Pseudo dice [np.float32(0.9201)] 
2024-11-27 03:03:48.545959: Epoch time: 40.04 s 
2024-11-27 03:03:49.504652:  
2024-11-27 03:03:49.504763: Epoch 194 
2024-11-27 03:03:49.504832: Current learning rate: 0.00824 
2024-11-27 03:04:29.534338: train_loss -0.9463 
2024-11-27 03:04:29.534454: val_loss -0.9056 
2024-11-27 03:04:29.534514: Pseudo dice [np.float32(0.9203)] 
2024-11-27 03:04:29.534587: Epoch time: 40.03 s 
2024-11-27 03:04:30.451193:  
2024-11-27 03:04:30.451374: Epoch 195 
2024-11-27 03:04:30.451444: Current learning rate: 0.00823 
2024-11-27 03:05:10.480475: train_loss -0.9387 
2024-11-27 03:05:10.480587: val_loss -0.9046 
2024-11-27 03:05:10.480640: Pseudo dice [np.float32(0.9207)] 
2024-11-27 03:05:10.480696: Epoch time: 40.03 s 
2024-11-27 03:05:11.431789:  
2024-11-27 03:05:11.431963: Epoch 196 
2024-11-27 03:05:11.432044: Current learning rate: 0.00822 
2024-11-27 03:05:51.483459: train_loss -0.9436 
2024-11-27 03:05:51.483567: val_loss -0.9077 
2024-11-27 03:05:51.483618: Pseudo dice [np.float32(0.9217)] 
2024-11-27 03:05:51.483672: Epoch time: 40.05 s 
2024-11-27 03:05:52.413747:  
2024-11-27 03:05:52.413947: Epoch 197 
2024-11-27 03:05:52.414016: Current learning rate: 0.00821 
2024-11-27 03:06:32.453987: train_loss -0.9441 
2024-11-27 03:06:32.454098: val_loss -0.9093 
2024-11-27 03:06:32.454151: Pseudo dice [np.float32(0.9235)] 
2024-11-27 03:06:32.454246: Epoch time: 40.04 s 
2024-11-27 03:06:33.337093:  
2024-11-27 03:06:33.337189: Epoch 198 
2024-11-27 03:06:33.337256: Current learning rate: 0.0082 
2024-11-27 03:07:13.351812: train_loss -0.9478 
2024-11-27 03:07:13.351983: val_loss -0.9084 
2024-11-27 03:07:13.352077: Pseudo dice [np.float32(0.9228)] 
2024-11-27 03:07:13.352134: Epoch time: 40.02 s 
2024-11-27 03:07:14.330027:  
2024-11-27 03:07:14.330125: Epoch 199 
2024-11-27 03:07:14.330219: Current learning rate: 0.00819 
2024-11-27 03:07:54.347116: train_loss -0.9479 
2024-11-27 03:07:54.347307: val_loss -0.902 
2024-11-27 03:07:54.347399: Pseudo dice [np.float32(0.9179)] 
2024-11-27 03:07:54.347458: Epoch time: 40.02 s 
2024-11-27 03:07:57.505330:  
2024-11-27 03:07:57.505448: Epoch 200 
2024-11-27 03:07:57.505517: Current learning rate: 0.00818 
2024-11-27 03:08:37.462518: train_loss -0.9452 
2024-11-27 03:08:37.462710: val_loss -0.9034 
2024-11-27 03:08:37.462762: Pseudo dice [np.float32(0.9202)] 
2024-11-27 03:08:37.462815: Epoch time: 39.96 s 
2024-11-27 03:08:38.351111:  
2024-11-27 03:08:38.351209: Epoch 201 
2024-11-27 03:08:38.351279: Current learning rate: 0.00817 
2024-11-27 03:09:18.406329: train_loss -0.9367 
2024-11-27 03:09:18.406440: val_loss -0.9007 
2024-11-27 03:09:18.406499: Pseudo dice [np.float32(0.9155)] 
2024-11-27 03:09:18.406567: Epoch time: 40.06 s 
2024-11-27 03:09:19.316017:  
2024-11-27 03:09:19.316089: Epoch 202 
2024-11-27 03:09:19.316158: Current learning rate: 0.00816 
2024-11-27 03:09:59.361184: train_loss -0.938 
2024-11-27 03:09:59.361293: val_loss -0.9116 
2024-11-27 03:09:59.361346: Pseudo dice [np.float32(0.9255)] 
2024-11-27 03:09:59.361401: Epoch time: 40.05 s 
2024-11-27 03:10:00.310695:  
2024-11-27 03:10:00.310766: Epoch 203 
2024-11-27 03:10:00.310835: Current learning rate: 0.00815 
2024-11-27 03:10:40.413714: train_loss -0.9426 
2024-11-27 03:10:40.413825: val_loss -0.9091 
2024-11-27 03:10:40.413950: Pseudo dice [np.float32(0.9235)] 
2024-11-27 03:10:40.414032: Epoch time: 40.1 s 
2024-11-27 03:10:41.368666:  
2024-11-27 03:10:41.368752: Epoch 204 
2024-11-27 03:10:41.368823: Current learning rate: 0.00814 
2024-11-27 03:11:21.458189: train_loss -0.9463 
2024-11-27 03:11:21.458314: val_loss -0.9096 
2024-11-27 03:11:21.458367: Pseudo dice [np.float32(0.9251)] 
2024-11-27 03:11:21.458423: Epoch time: 40.09 s 
2024-11-27 03:11:22.398474:  
2024-11-27 03:11:22.398621: Epoch 205 
2024-11-27 03:11:22.398745: Current learning rate: 0.00813 
2024-11-27 03:12:02.446097: train_loss -0.9465 
2024-11-27 03:12:02.446229: val_loss -0.9117 
2024-11-27 03:12:02.446280: Pseudo dice [np.float32(0.9255)] 
2024-11-27 03:12:02.446335: Epoch time: 40.05 s 
2024-11-27 03:12:03.687016:  
2024-11-27 03:12:03.687102: Epoch 206 
2024-11-27 03:12:03.687201: Current learning rate: 0.00813 
2024-11-27 03:12:43.776891: train_loss -0.9481 
2024-11-27 03:12:43.777089: val_loss -0.9042 
2024-11-27 03:12:43.777143: Pseudo dice [np.float32(0.9194)] 
2024-11-27 03:12:43.777196: Epoch time: 40.09 s 
2024-11-27 03:12:44.670077:  
2024-11-27 03:12:44.670219: Epoch 207 
2024-11-27 03:12:44.670287: Current learning rate: 0.00812 
2024-11-27 03:13:24.701546: train_loss -0.9486 
2024-11-27 03:13:24.701802: val_loss -0.911 
2024-11-27 03:13:24.701903: Pseudo dice [np.float32(0.9238)] 
2024-11-27 03:13:24.701978: Epoch time: 40.03 s 
2024-11-27 03:13:25.573079:  
2024-11-27 03:13:25.573228: Epoch 208 
2024-11-27 03:13:25.573300: Current learning rate: 0.00811 
2024-11-27 03:14:05.611170: train_loss -0.9472 
2024-11-27 03:14:05.611278: val_loss -0.9108 
2024-11-27 03:14:05.611330: Pseudo dice [np.float32(0.9249)] 
2024-11-27 03:14:05.611387: Epoch time: 40.04 s 
2024-11-27 03:14:06.478770:  
2024-11-27 03:14:06.478934: Epoch 209 
2024-11-27 03:14:06.479030: Current learning rate: 0.0081 
2024-11-27 03:14:46.525200: train_loss -0.9497 
2024-11-27 03:14:46.525311: val_loss -0.9085 
2024-11-27 03:14:46.525364: Pseudo dice [np.float32(0.9215)] 
2024-11-27 03:14:46.525421: Epoch time: 40.05 s 
2024-11-27 03:14:47.355414:  
2024-11-27 03:14:47.355580: Epoch 210 
2024-11-27 03:14:47.355655: Current learning rate: 0.00809 
2024-11-27 03:15:27.425583: train_loss -0.9491 
2024-11-27 03:15:27.425701: val_loss -0.9059 
2024-11-27 03:15:27.425759: Pseudo dice [np.float32(0.9199)] 
2024-11-27 03:15:27.425848: Epoch time: 40.07 s 
2024-11-27 03:15:28.309812:  
2024-11-27 03:15:28.309938: Epoch 211 
2024-11-27 03:15:28.310014: Current learning rate: 0.00808 
2024-11-27 03:16:08.329337: train_loss -0.9498 
2024-11-27 03:16:08.329452: val_loss -0.9058 
2024-11-27 03:16:08.329563: Pseudo dice [np.float32(0.9214)] 
2024-11-27 03:16:08.329642: Epoch time: 40.02 s 
2024-11-27 03:16:09.211088:  
2024-11-27 03:16:09.211222: Epoch 212 
2024-11-27 03:16:09.211305: Current learning rate: 0.00807 
2024-11-27 03:16:49.240772: train_loss -0.9471 
2024-11-27 03:16:49.240934: val_loss -0.9029 
2024-11-27 03:16:49.240992: Pseudo dice [np.float32(0.918)] 
2024-11-27 03:16:49.241087: Epoch time: 40.03 s 
2024-11-27 03:16:50.073605:  
2024-11-27 03:16:50.073741: Epoch 213 
2024-11-27 03:16:50.073810: Current learning rate: 0.00806 
2024-11-27 03:17:30.094931: train_loss -0.9429 
2024-11-27 03:17:30.095044: val_loss -0.9022 
2024-11-27 03:17:30.095095: Pseudo dice [np.float32(0.9166)] 
2024-11-27 03:17:30.095151: Epoch time: 40.02 s 
2024-11-27 03:17:30.980193:  
2024-11-27 03:17:30.980367: Epoch 214 
2024-11-27 03:17:30.980434: Current learning rate: 0.00805 
2024-11-27 03:18:11.013637: train_loss -0.9455 
2024-11-27 03:18:11.013762: val_loss -0.9116 
2024-11-27 03:18:11.013815: Pseudo dice [np.float32(0.9256)] 
2024-11-27 03:18:11.013907: Epoch time: 40.03 s 
2024-11-27 03:18:11.895244:  
2024-11-27 03:18:11.895353: Epoch 215 
2024-11-27 03:18:11.895425: Current learning rate: 0.00804 
2024-11-27 03:18:51.917297: train_loss -0.949 
2024-11-27 03:18:51.917412: val_loss -0.9096 
2024-11-27 03:18:51.917496: Pseudo dice [np.float32(0.9228)] 
2024-11-27 03:18:51.917582: Epoch time: 40.02 s 
2024-11-27 03:18:52.775860:  
2024-11-27 03:18:52.776048: Epoch 216 
2024-11-27 03:18:52.776155: Current learning rate: 0.00803 
2024-11-27 03:19:32.811563: train_loss -0.9522 
2024-11-27 03:19:32.811707: val_loss -0.9087 
2024-11-27 03:19:32.811765: Pseudo dice [np.float32(0.9242)] 
2024-11-27 03:19:32.811827: Epoch time: 40.04 s 
2024-11-27 03:19:33.682485:  
2024-11-27 03:19:33.682589: Epoch 217 
2024-11-27 03:19:33.682661: Current learning rate: 0.00802 
2024-11-27 03:20:13.702311: train_loss -0.9478 
2024-11-27 03:20:13.702529: val_loss -0.8996 
2024-11-27 03:20:13.702583: Pseudo dice [np.float32(0.9154)] 
2024-11-27 03:20:13.702638: Epoch time: 40.02 s 
2024-11-27 03:20:14.598013:  
2024-11-27 03:20:14.598140: Epoch 218 
2024-11-27 03:20:14.598211: Current learning rate: 0.00801 
2024-11-27 03:20:54.560967: train_loss -0.9453 
2024-11-27 03:20:54.561073: val_loss -0.9031 
2024-11-27 03:20:54.561125: Pseudo dice [np.float32(0.9174)] 
2024-11-27 03:20:54.561178: Epoch time: 39.96 s 
2024-11-27 03:20:55.428720:  
2024-11-27 03:20:55.428888: Epoch 219 
2024-11-27 03:20:55.428981: Current learning rate: 0.00801 
2024-11-27 03:21:35.448563: train_loss -0.9472 
2024-11-27 03:21:35.448715: val_loss -0.9077 
2024-11-27 03:21:35.448769: Pseudo dice [np.float32(0.9218)] 
2024-11-27 03:21:35.448826: Epoch time: 40.02 s 
2024-11-27 03:21:36.270027:  
2024-11-27 03:21:36.270118: Epoch 220 
2024-11-27 03:21:36.270187: Current learning rate: 0.008 
2024-11-27 03:22:16.307645: train_loss -0.9475 
2024-11-27 03:22:16.307752: val_loss -0.9066 
2024-11-27 03:22:16.307806: Pseudo dice [np.float32(0.9211)] 
2024-11-27 03:22:16.307863: Epoch time: 40.04 s 
2024-11-27 03:22:17.185264:  
2024-11-27 03:22:17.185340: Epoch 221 
2024-11-27 03:22:17.185428: Current learning rate: 0.00799 
2024-11-27 03:22:57.188158: train_loss -0.9492 
2024-11-27 03:22:57.188267: val_loss -0.9071 
2024-11-27 03:22:57.188318: Pseudo dice [np.float32(0.921)] 
2024-11-27 03:22:57.188373: Epoch time: 40.0 s 
2024-11-27 03:22:58.025236:  
2024-11-27 03:22:58.025362: Epoch 222 
2024-11-27 03:22:58.025432: Current learning rate: 0.00798 
2024-11-27 03:23:38.002288: train_loss -0.9498 
2024-11-27 03:23:38.002395: val_loss -0.9098 
2024-11-27 03:23:38.002447: Pseudo dice [np.float32(0.9242)] 
2024-11-27 03:23:38.002503: Epoch time: 39.98 s 
2024-11-27 03:23:38.853062:  
2024-11-27 03:23:38.853153: Epoch 223 
2024-11-27 03:23:38.853225: Current learning rate: 0.00797 
2024-11-27 03:24:18.842797: train_loss -0.9506 
2024-11-27 03:24:18.842956: val_loss -0.9153 
2024-11-27 03:24:18.843010: Pseudo dice [np.float32(0.9279)] 
2024-11-27 03:24:18.843066: Epoch time: 39.99 s 
2024-11-27 03:24:19.677459:  
2024-11-27 03:24:19.677618: Epoch 224 
2024-11-27 03:24:19.677691: Current learning rate: 0.00796 
2024-11-27 03:24:59.659578: train_loss -0.9499 
2024-11-27 03:24:59.659724: val_loss -0.91 
2024-11-27 03:24:59.659780: Pseudo dice [np.float32(0.9229)] 
2024-11-27 03:24:59.659839: Epoch time: 39.98 s 
2024-11-27 03:25:01.000456:  
2024-11-27 03:25:01.000546: Epoch 225 
2024-11-27 03:25:01.000650: Current learning rate: 0.00795 
2024-11-27 03:25:41.001330: train_loss -0.9518 
2024-11-27 03:25:41.001560: val_loss -0.9102 
2024-11-27 03:25:41.001613: Pseudo dice [np.float32(0.9231)] 
2024-11-27 03:25:41.001668: Epoch time: 40.0 s 
2024-11-27 03:25:41.875178:  
2024-11-27 03:25:41.875384: Epoch 226 
2024-11-27 03:25:41.875493: Current learning rate: 0.00794 
2024-11-27 03:26:21.939564: train_loss -0.9525 
2024-11-27 03:26:21.939671: val_loss -0.9147 
2024-11-27 03:26:21.939743: Pseudo dice [np.float32(0.9277)] 
2024-11-27 03:26:21.939800: Epoch time: 40.07 s 
2024-11-27 03:26:22.806907:  
2024-11-27 03:26:22.807020: Epoch 227 
2024-11-27 03:26:22.807085: Current learning rate: 0.00793 
2024-11-27 03:27:02.852962: train_loss -0.951 
2024-11-27 03:27:02.853089: val_loss -0.9126 
2024-11-27 03:27:02.853156: Pseudo dice [np.float32(0.9257)] 
2024-11-27 03:27:02.853215: Epoch time: 40.05 s 
2024-11-27 03:27:03.702918:  
2024-11-27 03:27:03.703062: Epoch 228 
2024-11-27 03:27:03.703133: Current learning rate: 0.00792 
2024-11-27 03:27:43.684558: train_loss -0.9516 
2024-11-27 03:27:43.684689: val_loss -0.9066 
2024-11-27 03:27:43.684740: Pseudo dice [np.float32(0.9191)] 
2024-11-27 03:27:43.684794: Epoch time: 39.98 s 
2024-11-27 03:27:44.501946:  
2024-11-27 03:27:44.502046: Epoch 229 
2024-11-27 03:27:44.502114: Current learning rate: 0.00791 
2024-11-27 03:28:24.422240: train_loss -0.9515 
2024-11-27 03:28:24.422390: val_loss -0.9108 
2024-11-27 03:28:24.422444: Pseudo dice [np.float32(0.9248)] 
2024-11-27 03:28:24.422499: Epoch time: 39.92 s 
2024-11-27 03:28:25.275869:  
2024-11-27 03:28:25.276048: Epoch 230 
2024-11-27 03:28:25.276124: Current learning rate: 0.0079 
2024-11-27 03:29:05.342449: train_loss -0.9512 
2024-11-27 03:29:05.342560: val_loss -0.9088 
2024-11-27 03:29:05.342613: Pseudo dice [np.float32(0.9227)] 
2024-11-27 03:29:05.342716: Epoch time: 40.07 s 
2024-11-27 03:29:06.192274:  
2024-11-27 03:29:06.192383: Epoch 231 
2024-11-27 03:29:06.192455: Current learning rate: 0.00789 
2024-11-27 03:29:46.216813: train_loss -0.952 
2024-11-27 03:29:46.216987: val_loss -0.9073 
2024-11-27 03:29:46.217038: Pseudo dice [np.float32(0.9201)] 
2024-11-27 03:29:46.217091: Epoch time: 40.03 s 
2024-11-27 03:29:47.061208:  
2024-11-27 03:29:47.061405: Epoch 232 
2024-11-27 03:29:47.061487: Current learning rate: 0.00789 
2024-11-27 03:30:27.082002: train_loss -0.9506 
2024-11-27 03:30:27.082104: val_loss -0.906 
2024-11-27 03:30:27.082156: Pseudo dice [np.float32(0.9208)] 
2024-11-27 03:30:27.082210: Epoch time: 40.02 s 
2024-11-27 03:30:27.923170:  
2024-11-27 03:30:27.923262: Epoch 233 
2024-11-27 03:30:27.923357: Current learning rate: 0.00788 
2024-11-27 03:31:07.967330: train_loss -0.9493 
2024-11-27 03:31:07.967459: val_loss -0.9122 
2024-11-27 03:31:07.967513: Pseudo dice [np.float32(0.9252)] 
2024-11-27 03:31:07.967571: Epoch time: 40.05 s 
2024-11-27 03:31:08.845469:  
2024-11-27 03:31:08.845696: Epoch 234 
2024-11-27 03:31:08.845787: Current learning rate: 0.00787 
2024-11-27 03:31:48.914212: train_loss -0.9465 
2024-11-27 03:31:48.914326: val_loss -0.9048 
2024-11-27 03:31:48.914413: Pseudo dice [np.float32(0.9183)] 
2024-11-27 03:31:48.914471: Epoch time: 40.07 s 
2024-11-27 03:31:49.806898:  
2024-11-27 03:31:49.807158: Epoch 235 
2024-11-27 03:31:49.807251: Current learning rate: 0.00786 
2024-11-27 03:32:29.822268: train_loss -0.9473 
2024-11-27 03:32:29.822377: val_loss -0.9077 
2024-11-27 03:32:29.822428: Pseudo dice [np.float32(0.9226)] 
2024-11-27 03:32:29.822482: Epoch time: 40.02 s 
2024-11-27 03:32:30.668865:  
2024-11-27 03:32:30.669044: Epoch 236 
2024-11-27 03:32:30.669112: Current learning rate: 0.00785 
2024-11-27 03:33:10.730210: train_loss -0.9479 
2024-11-27 03:33:10.730319: val_loss -0.9042 
2024-11-27 03:33:10.730370: Pseudo dice [np.float32(0.9204)] 
2024-11-27 03:33:10.730426: Epoch time: 40.06 s 
2024-11-27 03:33:11.626818:  
2024-11-27 03:33:11.626999: Epoch 237 
2024-11-27 03:33:11.627070: Current learning rate: 0.00784 
2024-11-27 03:33:51.686573: train_loss -0.949 
2024-11-27 03:33:51.686685: val_loss -0.9096 
2024-11-27 03:33:51.686750: Pseudo dice [np.float32(0.9247)] 
2024-11-27 03:33:51.686821: Epoch time: 40.06 s 
2024-11-27 03:33:52.564748:  
2024-11-27 03:33:52.564904: Epoch 238 
2024-11-27 03:33:52.565028: Current learning rate: 0.00783 
2024-11-27 03:34:32.629378: train_loss -0.9462 
2024-11-27 03:34:32.629485: val_loss -0.9072 
2024-11-27 03:34:32.629538: Pseudo dice [np.float32(0.9208)] 
2024-11-27 03:34:32.629592: Epoch time: 40.07 s 
2024-11-27 03:34:33.432791:  
2024-11-27 03:34:33.432884: Epoch 239 
2024-11-27 03:34:33.432954: Current learning rate: 0.00782 
2024-11-27 03:35:13.451699: train_loss -0.9496 
2024-11-27 03:35:13.451807: val_loss -0.9078 
2024-11-27 03:35:13.451860: Pseudo dice [np.float32(0.9223)] 
2024-11-27 03:35:13.451981: Epoch time: 40.02 s 
2024-11-27 03:35:14.355237:  
2024-11-27 03:35:14.355335: Epoch 240 
2024-11-27 03:35:14.355407: Current learning rate: 0.00781 
2024-11-27 03:35:54.349780: train_loss -0.9506 
2024-11-27 03:35:54.349961: val_loss -0.9134 
2024-11-27 03:35:54.350064: Pseudo dice [np.float32(0.9266)] 
2024-11-27 03:35:54.350122: Epoch time: 40.0 s 
2024-11-27 03:35:55.226846:  
2024-11-27 03:35:55.226985: Epoch 241 
2024-11-27 03:35:55.227055: Current learning rate: 0.0078 
2024-11-27 03:36:35.256322: train_loss -0.9494 
2024-11-27 03:36:35.256432: val_loss -0.91 
2024-11-27 03:36:35.256486: Pseudo dice [np.float32(0.925)] 
2024-11-27 03:36:35.256545: Epoch time: 40.03 s 
2024-11-27 03:36:36.114397:  
2024-11-27 03:36:36.114509: Epoch 242 
2024-11-27 03:36:36.114599: Current learning rate: 0.00779 
2024-11-27 03:37:16.149059: train_loss -0.9495 
2024-11-27 03:37:16.149167: val_loss -0.912 
2024-11-27 03:37:16.149221: Pseudo dice [np.float32(0.9241)] 
2024-11-27 03:37:16.149276: Epoch time: 40.04 s 
2024-11-27 03:37:16.995650:  
2024-11-27 03:37:16.995813: Epoch 243 
2024-11-27 03:37:16.995886: Current learning rate: 0.00778 
2024-11-27 03:37:57.002914: train_loss -0.9502 
2024-11-27 03:37:57.003021: val_loss -0.9074 
2024-11-27 03:37:57.003100: Pseudo dice [np.float32(0.9218)] 
2024-11-27 03:37:57.003180: Epoch time: 40.01 s 
2024-11-27 03:37:57.863657:  
2024-11-27 03:37:57.863723: Epoch 244 
2024-11-27 03:37:57.863787: Current learning rate: 0.00777 
2024-11-27 03:38:37.910179: train_loss -0.9518 
2024-11-27 03:38:37.910316: val_loss -0.9103 
2024-11-27 03:38:37.910399: Pseudo dice [np.float32(0.9221)] 
2024-11-27 03:38:37.910475: Epoch time: 40.05 s 
2024-11-27 03:38:39.229243:  
2024-11-27 03:38:39.229423: Epoch 245 
2024-11-27 03:38:39.229509: Current learning rate: 0.00777 
2024-11-27 03:39:19.338539: train_loss -0.9527 
2024-11-27 03:39:19.338651: val_loss -0.9083 
2024-11-27 03:39:19.338702: Pseudo dice [np.float32(0.9238)] 
2024-11-27 03:39:19.338758: Epoch time: 40.11 s 
2024-11-27 03:39:20.219418:  
2024-11-27 03:39:20.219602: Epoch 246 
2024-11-27 03:39:20.219717: Current learning rate: 0.00776 
2024-11-27 03:40:00.291386: train_loss -0.9531 
2024-11-27 03:40:00.291495: val_loss -0.9136 
2024-11-27 03:40:00.291546: Pseudo dice [np.float32(0.9267)] 
2024-11-27 03:40:00.291601: Epoch time: 40.07 s 
2024-11-27 03:40:00.291672: Yayy! New best EMA pseudo Dice: 0.92330002784729 
2024-11-27 03:40:03.374086:  
2024-11-27 03:40:03.374193: Epoch 247 
2024-11-27 03:40:03.374267: Current learning rate: 0.00775 
2024-11-27 03:40:43.360318: train_loss -0.9536 
2024-11-27 03:40:43.360502: val_loss -0.9074 
2024-11-27 03:40:43.360579: Pseudo dice [np.float32(0.9216)] 
2024-11-27 03:40:43.360675: Epoch time: 39.99 s 
2024-11-27 03:40:44.243552:  
2024-11-27 03:40:44.243766: Epoch 248 
2024-11-27 03:40:44.243876: Current learning rate: 0.00774 
2024-11-27 03:41:24.275507: train_loss -0.953 
2024-11-27 03:41:24.275693: val_loss -0.9076 
2024-11-27 03:41:24.275745: Pseudo dice [np.float32(0.9213)] 
2024-11-27 03:41:24.275801: Epoch time: 40.03 s 
2024-11-27 03:41:25.148536:  
2024-11-27 03:41:25.148648: Epoch 249 
2024-11-27 03:41:25.148719: Current learning rate: 0.00773 
2024-11-27 03:42:05.205242: train_loss -0.9451 
2024-11-27 03:42:05.205349: val_loss -0.9036 
2024-11-27 03:42:05.205399: Pseudo dice [np.float32(0.9191)] 
2024-11-27 03:42:05.205453: Epoch time: 40.06 s 
2024-11-27 03:42:08.278637:  
2024-11-27 03:42:08.278754: Epoch 250 
2024-11-27 03:42:08.278822: Current learning rate: 0.00772 
2024-11-27 03:42:48.254634: train_loss -0.9449 
2024-11-27 03:42:48.254744: val_loss -0.9058 
2024-11-27 03:42:48.254820: Pseudo dice [np.float32(0.9202)] 
2024-11-27 03:42:48.254903: Epoch time: 39.98 s 
2024-11-27 03:42:49.104162:  
2024-11-27 03:42:49.104299: Epoch 251 
2024-11-27 03:42:49.104388: Current learning rate: 0.00771 
2024-11-27 03:43:29.139758: train_loss -0.947 
2024-11-27 03:43:29.139880: val_loss -0.9115 
2024-11-27 03:43:29.139980: Pseudo dice [np.float32(0.9243)] 
2024-11-27 03:43:29.140038: Epoch time: 40.04 s 
2024-11-27 03:43:29.991675:  
2024-11-27 03:43:29.991793: Epoch 252 
2024-11-27 03:43:29.991957: Current learning rate: 0.0077 
2024-11-27 03:44:10.022537: train_loss -0.9515 
2024-11-27 03:44:10.022641: val_loss -0.9106 
2024-11-27 03:44:10.022720: Pseudo dice [np.float32(0.9242)] 
2024-11-27 03:44:10.022784: Epoch time: 40.03 s 
2024-11-27 03:44:10.867296:  
2024-11-27 03:44:10.867409: Epoch 253 
2024-11-27 03:44:10.867479: Current learning rate: 0.00769 
2024-11-27 03:44:50.907521: train_loss -0.9497 
2024-11-27 03:44:50.907633: val_loss -0.9053 
2024-11-27 03:44:50.907685: Pseudo dice [np.float32(0.9201)] 
2024-11-27 03:44:50.907742: Epoch time: 40.04 s 
2024-11-27 03:44:51.756914:  
2024-11-27 03:44:51.757050: Epoch 254 
2024-11-27 03:44:51.757122: Current learning rate: 0.00768 
2024-11-27 03:45:31.795041: train_loss -0.9471 
2024-11-27 03:45:31.795150: val_loss -0.9078 
2024-11-27 03:45:31.795201: Pseudo dice [np.float32(0.9222)] 
2024-11-27 03:45:31.795359: Epoch time: 40.04 s 
2024-11-27 03:45:32.600575:  
2024-11-27 03:45:32.600676: Epoch 255 
2024-11-27 03:45:32.600923: Current learning rate: 0.00767 
2024-11-27 03:46:12.649699: train_loss -0.9481 
2024-11-27 03:46:12.649857: val_loss -0.9051 
2024-11-27 03:46:12.649984: Pseudo dice [np.float32(0.9185)] 
2024-11-27 03:46:12.650078: Epoch time: 40.05 s 
2024-11-27 03:46:13.506490:  
2024-11-27 03:46:13.506601: Epoch 256 
2024-11-27 03:46:13.506671: Current learning rate: 0.00766 
2024-11-27 03:46:53.539592: train_loss -0.9469 
2024-11-27 03:46:53.539697: val_loss -0.9002 
2024-11-27 03:46:53.539749: Pseudo dice [np.float32(0.9176)] 
2024-11-27 03:46:53.539803: Epoch time: 40.03 s 
2024-11-27 03:46:54.389405:  
2024-11-27 03:46:54.389486: Epoch 257 
2024-11-27 03:46:54.389560: Current learning rate: 0.00765 
2024-11-27 03:47:34.444837: train_loss -0.9497 
2024-11-27 03:47:34.445017: val_loss -0.9098 
2024-11-27 03:47:34.445067: Pseudo dice [np.float32(0.9237)] 
2024-11-27 03:47:34.445123: Epoch time: 40.06 s 
2024-11-27 03:47:35.343859:  
2024-11-27 03:47:35.344041: Epoch 258 
2024-11-27 03:47:35.344129: Current learning rate: 0.00764 
2024-11-27 03:48:15.460025: train_loss -0.949 
2024-11-27 03:48:15.460132: val_loss -0.9082 
2024-11-27 03:48:15.460183: Pseudo dice [np.float32(0.9215)] 
2024-11-27 03:48:15.460238: Epoch time: 40.12 s 
2024-11-27 03:48:16.319124:  
2024-11-27 03:48:16.319227: Epoch 259 
2024-11-27 03:48:16.319317: Current learning rate: 0.00764 
2024-11-27 03:48:56.403466: train_loss -0.9506 
2024-11-27 03:48:56.403574: val_loss -0.9116 
2024-11-27 03:48:56.403626: Pseudo dice [np.float32(0.9256)] 
2024-11-27 03:48:56.403681: Epoch time: 40.09 s 
2024-11-27 03:48:57.286284:  
2024-11-27 03:48:57.286376: Epoch 260 
2024-11-27 03:48:57.286445: Current learning rate: 0.00763 
2024-11-27 03:49:37.310350: train_loss -0.9529 
2024-11-27 03:49:37.310541: val_loss -0.918 
2024-11-27 03:49:37.310595: Pseudo dice [np.float32(0.9304)] 
2024-11-27 03:49:37.310651: Epoch time: 40.03 s 
2024-11-27 03:49:38.168479:  
2024-11-27 03:49:38.168569: Epoch 261 
2024-11-27 03:49:38.168660: Current learning rate: 0.00762 
2024-11-27 03:50:18.175717: train_loss -0.9529 
2024-11-27 03:50:18.175825: val_loss -0.9079 
2024-11-27 03:50:18.175906: Pseudo dice [np.float32(0.922)] 
2024-11-27 03:50:18.175981: Epoch time: 40.01 s 
2024-11-27 03:50:19.048131:  
2024-11-27 03:50:19.048217: Epoch 262 
2024-11-27 03:50:19.048286: Current learning rate: 0.00761 
2024-11-27 03:50:59.072997: train_loss -0.9487 
2024-11-27 03:50:59.073111: val_loss -0.9086 
2024-11-27 03:50:59.073164: Pseudo dice [np.float32(0.922)] 
2024-11-27 03:50:59.073219: Epoch time: 40.03 s 
2024-11-27 03:50:59.933744:  
2024-11-27 03:50:59.933839: Epoch 263 
2024-11-27 03:50:59.933967: Current learning rate: 0.0076 
2024-11-27 03:51:39.942832: train_loss -0.9494 
2024-11-27 03:51:39.943006: val_loss -0.9029 
2024-11-27 03:51:39.943057: Pseudo dice [np.float32(0.9189)] 
2024-11-27 03:51:39.943126: Epoch time: 40.01 s 
2024-11-27 03:51:40.767772:  
2024-11-27 03:51:40.767839: Epoch 264 
2024-11-27 03:51:40.767915: Current learning rate: 0.00759 
2024-11-27 03:52:20.814177: train_loss -0.9515 
2024-11-27 03:52:20.814287: val_loss -0.9149 
2024-11-27 03:52:20.814338: Pseudo dice [np.float32(0.9267)] 
2024-11-27 03:52:20.814427: Epoch time: 40.05 s 
2024-11-27 03:52:22.109055:  
2024-11-27 03:52:22.109157: Epoch 265 
2024-11-27 03:52:22.109249: Current learning rate: 0.00758 
2024-11-27 03:53:02.153242: train_loss -0.9517 
2024-11-27 03:53:02.153351: val_loss -0.9115 
2024-11-27 03:53:02.153402: Pseudo dice [np.float32(0.9254)] 
2024-11-27 03:53:02.153456: Epoch time: 40.05 s 
2024-11-27 03:53:02.998906:  
2024-11-27 03:53:02.999023: Epoch 266 
2024-11-27 03:53:02.999106: Current learning rate: 0.00757 
2024-11-27 03:53:43.092329: train_loss -0.9519 
2024-11-27 03:53:43.092486: val_loss -0.908 
2024-11-27 03:53:43.092584: Pseudo dice [np.float32(0.9218)] 
2024-11-27 03:53:43.092673: Epoch time: 40.09 s 
2024-11-27 03:53:43.943748:  
2024-11-27 03:53:43.943845: Epoch 267 
2024-11-27 03:53:43.944041: Current learning rate: 0.00756 
2024-11-27 03:54:23.978954: train_loss -0.9532 
2024-11-27 03:54:23.979088: val_loss -0.9078 
2024-11-27 03:54:23.979140: Pseudo dice [np.float32(0.9214)] 
2024-11-27 03:54:23.979195: Epoch time: 40.04 s 
2024-11-27 03:54:24.831856:  
2024-11-27 03:54:24.831990: Epoch 268 
2024-11-27 03:54:24.832056: Current learning rate: 0.00755 
2024-11-27 03:55:04.875760: train_loss -0.9537 
2024-11-27 03:55:04.875892: val_loss -0.9109 
2024-11-27 03:55:04.875963: Pseudo dice [np.float32(0.9252)] 
2024-11-27 03:55:04.876062: Epoch time: 40.04 s 
2024-11-27 03:55:05.740465:  
2024-11-27 03:55:05.740576: Epoch 269 
2024-11-27 03:55:05.740666: Current learning rate: 0.00754 
2024-11-27 03:55:45.818062: train_loss -0.954 
2024-11-27 03:55:45.818176: val_loss -0.9085 
2024-11-27 03:55:45.818229: Pseudo dice [np.float32(0.9214)] 
2024-11-27 03:55:45.818288: Epoch time: 40.08 s 
2024-11-27 03:55:46.702418:  
2024-11-27 03:55:46.702619: Epoch 270 
2024-11-27 03:55:46.702724: Current learning rate: 0.00753 
2024-11-27 03:56:26.754117: train_loss -0.9553 
2024-11-27 03:56:26.754226: val_loss -0.9111 
2024-11-27 03:56:26.754278: Pseudo dice [np.float32(0.9235)] 
2024-11-27 03:56:26.754332: Epoch time: 40.05 s 
2024-11-27 03:56:27.624014:  
2024-11-27 03:56:27.624120: Epoch 271 
2024-11-27 03:56:27.624191: Current learning rate: 0.00752 
2024-11-27 03:57:07.755855: train_loss -0.9555 
2024-11-27 03:57:07.755973: val_loss -0.9084 
2024-11-27 03:57:07.756028: Pseudo dice [np.float32(0.9219)] 
2024-11-27 03:57:07.756086: Epoch time: 40.13 s 
2024-11-27 03:57:08.644060:  
2024-11-27 03:57:08.644175: Epoch 272 
2024-11-27 03:57:08.644275: Current learning rate: 0.00751 
2024-11-27 03:57:48.687689: train_loss -0.9548 
2024-11-27 03:57:48.687820: val_loss -0.9087 
2024-11-27 03:57:48.687908: Pseudo dice [np.float32(0.9223)] 
2024-11-27 03:57:48.688003: Epoch time: 40.04 s 
2024-11-27 03:57:49.599381:  
2024-11-27 03:57:49.599493: Epoch 273 
2024-11-27 03:57:49.599565: Current learning rate: 0.00751 
2024-11-27 03:58:29.608032: train_loss -0.9549 
2024-11-27 03:58:29.608138: val_loss -0.9073 
2024-11-27 03:58:29.608187: Pseudo dice [np.float32(0.9238)] 
2024-11-27 03:58:29.608239: Epoch time: 40.01 s 
2024-11-27 03:58:30.493798:  
2024-11-27 03:58:30.493942: Epoch 274 
2024-11-27 03:58:30.494040: Current learning rate: 0.0075 
2024-11-27 03:59:10.535960: train_loss -0.9526 
2024-11-27 03:59:10.536084: val_loss -0.9015 
2024-11-27 03:59:10.536134: Pseudo dice [np.float32(0.9159)] 
2024-11-27 03:59:10.536190: Epoch time: 40.04 s 
2024-11-27 03:59:11.440203:  
2024-11-27 03:59:11.440312: Epoch 275 
2024-11-27 03:59:11.440382: Current learning rate: 0.00749 
2024-11-27 03:59:51.409742: train_loss -0.9538 
2024-11-27 03:59:51.409864: val_loss -0.9047 
2024-11-27 03:59:51.409992: Pseudo dice [np.float32(0.9205)] 
2024-11-27 03:59:51.410101: Epoch time: 39.97 s 
2024-11-27 03:59:52.339604:  
2024-11-27 03:59:52.339694: Epoch 276 
2024-11-27 03:59:52.339808: Current learning rate: 0.00748 
2024-11-27 04:00:32.393301: train_loss -0.9536 
2024-11-27 04:00:32.393414: val_loss -0.9109 
2024-11-27 04:00:32.393489: Pseudo dice [np.float32(0.9244)] 
2024-11-27 04:00:32.393586: Epoch time: 40.05 s 
2024-11-27 04:00:33.251403:  
2024-11-27 04:00:33.251489: Epoch 277 
2024-11-27 04:00:33.251600: Current learning rate: 0.00747 
2024-11-27 04:01:13.270725: train_loss -0.9539 
2024-11-27 04:01:13.270834: val_loss -0.9071 
2024-11-27 04:01:13.270926: Pseudo dice [np.float32(0.921)] 
2024-11-27 04:01:13.270982: Epoch time: 40.02 s 
2024-11-27 04:01:14.100002:  
2024-11-27 04:01:14.100102: Epoch 278 
2024-11-27 04:01:14.100171: Current learning rate: 0.00746 
2024-11-27 04:01:54.160664: train_loss -0.9512 
2024-11-27 04:01:54.160776: val_loss -0.9055 
2024-11-27 04:01:54.160827: Pseudo dice [np.float32(0.9199)] 
2024-11-27 04:01:54.160919: Epoch time: 40.06 s 
2024-11-27 04:01:55.085901:  
2024-11-27 04:01:55.086090: Epoch 279 
2024-11-27 04:01:55.086194: Current learning rate: 0.00745 
2024-11-27 04:02:35.129282: train_loss -0.9522 
2024-11-27 04:02:35.129417: val_loss -0.9094 
2024-11-27 04:02:35.129486: Pseudo dice [np.float32(0.9228)] 
2024-11-27 04:02:35.129542: Epoch time: 40.04 s 
2024-11-27 04:02:35.973100:  
2024-11-27 04:02:35.973187: Epoch 280 
2024-11-27 04:02:35.973256: Current learning rate: 0.00744 
2024-11-27 04:03:15.985965: train_loss -0.9496 
2024-11-27 04:03:15.986075: val_loss -0.9059 
2024-11-27 04:03:15.986166: Pseudo dice [np.float32(0.9199)] 
2024-11-27 04:03:15.986226: Epoch time: 40.01 s 
2024-11-27 04:03:16.891771:  
2024-11-27 04:03:16.891967: Epoch 281 
2024-11-27 04:03:16.892041: Current learning rate: 0.00743 
2024-11-27 04:03:56.914524: train_loss -0.9491 
2024-11-27 04:03:56.914631: val_loss -0.9102 
2024-11-27 04:03:56.914684: Pseudo dice [np.float32(0.9237)] 
2024-11-27 04:03:56.914742: Epoch time: 40.02 s 
2024-11-27 04:03:57.816812:  
2024-11-27 04:03:57.816922: Epoch 282 
2024-11-27 04:03:57.817011: Current learning rate: 0.00742 
2024-11-27 04:04:37.849285: train_loss -0.9526 
2024-11-27 04:04:37.849396: val_loss -0.9116 
2024-11-27 04:04:37.849446: Pseudo dice [np.float32(0.925)] 
2024-11-27 04:04:37.849504: Epoch time: 40.03 s 
2024-11-27 04:04:38.743791:  
2024-11-27 04:04:38.743882: Epoch 283 
2024-11-27 04:04:38.744004: Current learning rate: 0.00741 
2024-11-27 04:05:18.763507: train_loss -0.9542 
2024-11-27 04:05:18.763620: val_loss -0.913 
2024-11-27 04:05:18.763673: Pseudo dice [np.float32(0.9274)] 
2024-11-27 04:05:18.763730: Epoch time: 40.02 s 
2024-11-27 04:05:20.115694:  
2024-11-27 04:05:20.115798: Epoch 284 
2024-11-27 04:05:20.115911: Current learning rate: 0.0074 
2024-11-27 04:06:00.193575: train_loss -0.9551 
2024-11-27 04:06:00.193711: val_loss -0.9084 
2024-11-27 04:06:00.193764: Pseudo dice [np.float32(0.9229)] 
2024-11-27 04:06:00.193819: Epoch time: 40.08 s 
2024-11-27 04:06:01.096835:  
2024-11-27 04:06:01.096925: Epoch 285 
2024-11-27 04:06:01.096993: Current learning rate: 0.00739 
2024-11-27 04:06:41.139481: train_loss -0.9563 
2024-11-27 04:06:41.139593: val_loss -0.9114 
2024-11-27 04:06:41.139713: Pseudo dice [np.float32(0.9262)] 
2024-11-27 04:06:41.139769: Epoch time: 40.04 s 
2024-11-27 04:06:42.034229:  
2024-11-27 04:06:42.034319: Epoch 286 
2024-11-27 04:06:42.034387: Current learning rate: 0.00738 
2024-11-27 04:07:22.095637: train_loss -0.9566 
2024-11-27 04:07:22.095831: val_loss -0.9121 
2024-11-27 04:07:22.096046: Pseudo dice [np.float32(0.9264)] 
2024-11-27 04:07:22.096103: Epoch time: 40.06 s 
2024-11-27 04:07:22.096149: Yayy! New best EMA pseudo Dice: 0.9235000014305115 
2024-11-27 04:07:25.172165:  
2024-11-27 04:07:25.172251: Epoch 287 
2024-11-27 04:07:25.172359: Current learning rate: 0.00738 
2024-11-27 04:08:05.169770: train_loss -0.9558 
2024-11-27 04:08:05.169886: val_loss -0.9124 
2024-11-27 04:08:05.169991: Pseudo dice [np.float32(0.9267)] 
2024-11-27 04:08:05.170073: Epoch time: 40.0 s 
2024-11-27 04:08:05.170160: Yayy! New best EMA pseudo Dice: 0.923799991607666 
2024-11-27 04:08:08.428573:  
2024-11-27 04:08:08.428773: Epoch 288 
2024-11-27 04:08:08.428851: Current learning rate: 0.00737 
2024-11-27 04:08:48.376030: train_loss -0.955 
2024-11-27 04:08:48.376137: val_loss -0.9102 
2024-11-27 04:08:48.376188: Pseudo dice [np.float32(0.9247)] 
2024-11-27 04:08:48.376242: Epoch time: 39.95 s 
2024-11-27 04:08:48.376289: Yayy! New best EMA pseudo Dice: 0.9239000082015991 
2024-11-27 04:08:51.383065:  
2024-11-27 04:08:51.383360: Epoch 289 
2024-11-27 04:08:51.383438: Current learning rate: 0.00736 
2024-11-27 04:09:31.351898: train_loss -0.9546 
2024-11-27 04:09:31.352051: val_loss -0.9085 
2024-11-27 04:09:31.352107: Pseudo dice [np.float32(0.9236)] 
2024-11-27 04:09:31.352167: Epoch time: 39.97 s 
2024-11-27 04:09:32.322162:  
2024-11-27 04:09:32.322314: Epoch 290 
2024-11-27 04:09:32.322387: Current learning rate: 0.00735 
2024-11-27 04:10:12.422334: train_loss -0.956 
2024-11-27 04:10:12.422464: val_loss -0.9054 
2024-11-27 04:10:12.422514: Pseudo dice [np.float32(0.92)] 
2024-11-27 04:10:12.422568: Epoch time: 40.1 s 
2024-11-27 04:10:13.275714:  
2024-11-27 04:10:13.275869: Epoch 291 
2024-11-27 04:10:13.275987: Current learning rate: 0.00734 
2024-11-27 04:10:53.320163: train_loss -0.9562 
2024-11-27 04:10:53.320277: val_loss -0.9077 
2024-11-27 04:10:53.320328: Pseudo dice [np.float32(0.9214)] 
2024-11-27 04:10:53.320383: Epoch time: 40.05 s 
2024-11-27 04:10:54.201673:  
2024-11-27 04:10:54.201843: Epoch 292 
2024-11-27 04:10:54.201949: Current learning rate: 0.00733 
2024-11-27 04:11:34.276181: train_loss -0.9564 
2024-11-27 04:11:34.276300: val_loss -0.9092 
2024-11-27 04:11:34.276371: Pseudo dice [np.float32(0.9236)] 
2024-11-27 04:11:34.276461: Epoch time: 40.08 s 
2024-11-27 04:11:35.152541:  
2024-11-27 04:11:35.152795: Epoch 293 
2024-11-27 04:11:35.152871: Current learning rate: 0.00732 
2024-11-27 04:12:15.221433: train_loss -0.9574 
2024-11-27 04:12:15.221539: val_loss -0.9058 
2024-11-27 04:12:15.221587: Pseudo dice [np.float32(0.9203)] 
2024-11-27 04:12:15.221640: Epoch time: 40.07 s 
2024-11-27 04:12:16.152550:  
2024-11-27 04:12:16.152686: Epoch 294 
2024-11-27 04:12:16.152755: Current learning rate: 0.00731 
2024-11-27 04:12:56.240513: train_loss -0.9581 
2024-11-27 04:12:56.240621: val_loss -0.9118 
2024-11-27 04:12:56.240672: Pseudo dice [np.float32(0.9257)] 
2024-11-27 04:12:56.240728: Epoch time: 40.09 s 
2024-11-27 04:12:57.132744:  
2024-11-27 04:12:57.132988: Epoch 295 
2024-11-27 04:12:57.133059: Current learning rate: 0.0073 
2024-11-27 04:13:37.147211: train_loss -0.9571 
2024-11-27 04:13:37.147339: val_loss -0.9079 
2024-11-27 04:13:37.147391: Pseudo dice [np.float32(0.9234)] 
2024-11-27 04:13:37.147446: Epoch time: 40.02 s 
2024-11-27 04:13:38.050817:  
2024-11-27 04:13:38.051032: Epoch 296 
2024-11-27 04:13:38.051105: Current learning rate: 0.00729 
2024-11-27 04:14:18.092263: train_loss -0.9556 
2024-11-27 04:14:18.092368: val_loss -0.911 
2024-11-27 04:14:18.092420: Pseudo dice [np.float32(0.9245)] 
2024-11-27 04:14:18.092505: Epoch time: 40.04 s 
2024-11-27 04:14:18.945842:  
2024-11-27 04:14:18.946008: Epoch 297 
2024-11-27 04:14:18.946079: Current learning rate: 0.00728 
2024-11-27 04:14:58.980011: train_loss -0.9577 
2024-11-27 04:14:58.980118: val_loss -0.9076 
2024-11-27 04:14:58.980170: Pseudo dice [np.float32(0.9235)] 
2024-11-27 04:14:58.980227: Epoch time: 40.04 s 
2024-11-27 04:14:59.903592:  
2024-11-27 04:14:59.903767: Epoch 298 
2024-11-27 04:14:59.903892: Current learning rate: 0.00727 
2024-11-27 04:15:39.931752: train_loss -0.9559 
2024-11-27 04:15:39.931921: val_loss -0.9103 
2024-11-27 04:15:39.931976: Pseudo dice [np.float32(0.9238)] 
2024-11-27 04:15:39.932032: Epoch time: 40.03 s 
2024-11-27 04:15:40.806933:  
2024-11-27 04:15:40.807142: Epoch 299 
2024-11-27 04:15:40.807212: Current learning rate: 0.00726 
2024-11-27 04:16:20.819766: train_loss -0.9565 
2024-11-27 04:16:20.819964: val_loss -0.9059 
2024-11-27 04:16:20.820038: Pseudo dice [np.float32(0.9218)] 
2024-11-27 04:16:20.820159: Epoch time: 40.01 s 
2024-11-27 04:16:24.074215:  
2024-11-27 04:16:24.074429: Epoch 300 
2024-11-27 04:16:24.074540: Current learning rate: 0.00725 
2024-11-27 04:17:04.000853: train_loss -0.9562 
2024-11-27 04:17:04.000965: val_loss -0.9073 
2024-11-27 04:17:04.001024: Pseudo dice [np.float32(0.9228)] 
2024-11-27 04:17:04.001097: Epoch time: 39.93 s 
2024-11-27 04:17:04.920059:  
2024-11-27 04:17:04.920327: Epoch 301 
2024-11-27 04:17:04.920402: Current learning rate: 0.00724 
2024-11-27 04:17:44.884541: train_loss -0.9574 
2024-11-27 04:17:44.884664: val_loss -0.9125 
2024-11-27 04:17:44.884717: Pseudo dice [np.float32(0.926)] 
2024-11-27 04:17:44.884774: Epoch time: 39.97 s 
2024-11-27 04:17:45.756109:  
2024-11-27 04:17:45.756240: Epoch 302 
2024-11-27 04:17:45.756313: Current learning rate: 0.00724 
2024-11-27 04:18:25.705315: train_loss -0.955 
2024-11-27 04:18:25.705426: val_loss -0.9098 
2024-11-27 04:18:25.705493: Pseudo dice [np.float32(0.9241)] 
2024-11-27 04:18:25.705599: Epoch time: 39.95 s 
2024-11-27 04:18:26.998811:  
2024-11-27 04:18:26.998933: Epoch 303 
2024-11-27 04:18:26.999025: Current learning rate: 0.00723 
2024-11-27 04:19:07.006447: train_loss -0.9555 
2024-11-27 04:19:07.006564: val_loss -0.9137 
2024-11-27 04:19:07.006644: Pseudo dice [np.float32(0.9265)] 
2024-11-27 04:19:07.006701: Epoch time: 40.01 s 
2024-11-27 04:19:07.915220:  
2024-11-27 04:19:07.915334: Epoch 304 
2024-11-27 04:19:07.915408: Current learning rate: 0.00722 
2024-11-27 04:19:47.976182: train_loss -0.9457 
2024-11-27 04:19:47.976291: val_loss -0.9058 
2024-11-27 04:19:47.976341: Pseudo dice [np.float32(0.9196)] 
2024-11-27 04:19:47.976396: Epoch time: 40.06 s 
2024-11-27 04:19:48.885460:  
2024-11-27 04:19:48.885648: Epoch 305 
2024-11-27 04:19:48.885716: Current learning rate: 0.00721 
2024-11-27 04:20:28.935452: train_loss -0.9387 
2024-11-27 04:20:28.935565: val_loss -0.8993 
2024-11-27 04:20:28.935616: Pseudo dice [np.float32(0.9161)] 
2024-11-27 04:20:28.935676: Epoch time: 40.05 s 
2024-11-27 04:20:29.785907:  
2024-11-27 04:20:29.786018: Epoch 306 
2024-11-27 04:20:29.786088: Current learning rate: 0.0072 
2024-11-27 04:21:09.862054: train_loss -0.9416 
2024-11-27 04:21:09.862166: val_loss -0.9038 
2024-11-27 04:21:09.862217: Pseudo dice [np.float32(0.9199)] 
2024-11-27 04:21:09.862271: Epoch time: 40.08 s 
2024-11-27 04:21:10.773230:  
2024-11-27 04:21:10.773378: Epoch 307 
2024-11-27 04:21:10.773447: Current learning rate: 0.00719 
2024-11-27 04:21:50.830829: train_loss -0.9465 
2024-11-27 04:21:50.830949: val_loss -0.9056 
2024-11-27 04:21:50.831002: Pseudo dice [np.float32(0.921)] 
2024-11-27 04:21:50.831060: Epoch time: 40.06 s 
2024-11-27 04:21:51.674272:  
2024-11-27 04:21:51.674342: Epoch 308 
2024-11-27 04:21:51.674415: Current learning rate: 0.00718 
2024-11-27 04:22:31.700341: train_loss -0.9494 
2024-11-27 04:22:31.700445: val_loss -0.908 
2024-11-27 04:22:31.700497: Pseudo dice [np.float32(0.9219)] 
2024-11-27 04:22:31.700554: Epoch time: 40.03 s 
2024-11-27 04:22:32.586132:  
2024-11-27 04:22:32.586323: Epoch 309 
2024-11-27 04:22:32.586516: Current learning rate: 0.00717 
2024-11-27 04:23:12.625203: train_loss -0.9523 
2024-11-27 04:23:12.625354: val_loss -0.9006 
2024-11-27 04:23:12.625406: Pseudo dice [np.float32(0.9173)] 
2024-11-27 04:23:12.625462: Epoch time: 40.04 s 
2024-11-27 04:23:13.524322:  
2024-11-27 04:23:13.524415: Epoch 310 
2024-11-27 04:23:13.524483: Current learning rate: 0.00716 
2024-11-27 04:23:53.560793: train_loss -0.9496 
2024-11-27 04:23:53.560911: val_loss -0.896 
2024-11-27 04:23:53.560963: Pseudo dice [np.float32(0.9142)] 
2024-11-27 04:23:53.561019: Epoch time: 40.04 s 
2024-11-27 04:23:54.411094:  
2024-11-27 04:23:54.411250: Epoch 311 
2024-11-27 04:23:54.411322: Current learning rate: 0.00715 
2024-11-27 04:24:34.470438: train_loss -0.9482 
2024-11-27 04:24:34.470546: val_loss -0.9085 
2024-11-27 04:24:34.470598: Pseudo dice [np.float32(0.9225)] 
2024-11-27 04:24:34.470654: Epoch time: 40.06 s 
2024-11-27 04:24:35.400948:  
2024-11-27 04:24:35.401033: Epoch 312 
2024-11-27 04:24:35.401182: Current learning rate: 0.00714 
2024-11-27 04:25:15.429021: train_loss -0.9478 
2024-11-27 04:25:15.429234: val_loss -0.9018 
2024-11-27 04:25:15.429287: Pseudo dice [np.float32(0.9168)] 
2024-11-27 04:25:15.429360: Epoch time: 40.03 s 
2024-11-27 04:25:16.339370:  
2024-11-27 04:25:16.339470: Epoch 313 
2024-11-27 04:25:16.339555: Current learning rate: 0.00713 
2024-11-27 04:25:56.354514: train_loss -0.9378 
2024-11-27 04:25:56.354625: val_loss -0.898 
2024-11-27 04:25:56.354679: Pseudo dice [np.float32(0.9139)] 
2024-11-27 04:25:56.354738: Epoch time: 40.02 s 
2024-11-27 04:25:57.223791:  
2024-11-27 04:25:57.223876: Epoch 314 
2024-11-27 04:25:57.224004: Current learning rate: 0.00712 
2024-11-27 04:26:37.275751: train_loss -0.9359 
2024-11-27 04:26:37.275861: val_loss -0.8884 
2024-11-27 04:26:37.275921: Pseudo dice [np.float32(0.906)] 
2024-11-27 04:26:37.275976: Epoch time: 40.05 s 
2024-11-27 04:26:38.161738:  
2024-11-27 04:26:38.161878: Epoch 315 
2024-11-27 04:26:38.161947: Current learning rate: 0.00711 
2024-11-27 04:27:18.262804: train_loss -0.9219 
2024-11-27 04:27:18.263071: val_loss -0.8994 
2024-11-27 04:27:18.263129: Pseudo dice [np.float32(0.9141)] 
2024-11-27 04:27:18.263190: Epoch time: 40.1 s 
2024-11-27 04:27:19.129022:  
2024-11-27 04:27:19.129202: Epoch 316 
2024-11-27 04:27:19.129277: Current learning rate: 0.0071 
2024-11-27 04:27:59.165269: train_loss -0.9334 
2024-11-27 04:27:59.165403: val_loss -0.8988 
2024-11-27 04:27:59.165456: Pseudo dice [np.float32(0.9153)] 
2024-11-27 04:27:59.165521: Epoch time: 40.04 s 
2024-11-27 04:28:00.010513:  
2024-11-27 04:28:00.010648: Epoch 317 
2024-11-27 04:28:00.010716: Current learning rate: 0.0071 
2024-11-27 04:28:40.074109: train_loss -0.9363 
2024-11-27 04:28:40.074223: val_loss -0.8965 
2024-11-27 04:28:40.074295: Pseudo dice [np.float32(0.9116)] 
2024-11-27 04:28:40.074367: Epoch time: 40.06 s 
2024-11-27 04:28:40.945226:  
2024-11-27 04:28:40.945303: Epoch 318 
2024-11-27 04:28:40.945374: Current learning rate: 0.00709 
2024-11-27 04:29:20.988545: train_loss -0.9385 
2024-11-27 04:29:20.988654: val_loss -0.9021 
2024-11-27 04:29:20.988704: Pseudo dice [np.float32(0.9183)] 
2024-11-27 04:29:20.988760: Epoch time: 40.04 s 
2024-11-27 04:29:21.853346:  
2024-11-27 04:29:21.853436: Epoch 319 
2024-11-27 04:29:21.853503: Current learning rate: 0.00708 
2024-11-27 04:30:01.890371: train_loss -0.9452 
2024-11-27 04:30:01.890479: val_loss -0.9059 
2024-11-27 04:30:01.890529: Pseudo dice [np.float32(0.9203)] 
2024-11-27 04:30:01.890583: Epoch time: 40.04 s 
2024-11-27 04:30:02.819977:  
2024-11-27 04:30:02.820256: Epoch 320 
2024-11-27 04:30:02.820362: Current learning rate: 0.00707 
2024-11-27 04:30:42.845587: train_loss -0.946 
2024-11-27 04:30:42.845694: val_loss -0.9076 
2024-11-27 04:30:42.845745: Pseudo dice [np.float32(0.9229)] 
2024-11-27 04:30:42.845800: Epoch time: 40.03 s 
2024-11-27 04:30:43.749387:  
2024-11-27 04:30:43.749473: Epoch 321 
2024-11-27 04:30:43.749543: Current learning rate: 0.00706 
2024-11-27 04:31:23.757049: train_loss -0.9387 
2024-11-27 04:31:23.757154: val_loss -0.9043 
2024-11-27 04:31:23.757205: Pseudo dice [np.float32(0.9187)] 
2024-11-27 04:31:23.757259: Epoch time: 40.01 s 
2024-11-27 04:31:25.066695:  
2024-11-27 04:31:25.066793: Epoch 322 
2024-11-27 04:31:25.066924: Current learning rate: 0.00705 
2024-11-27 04:32:05.156453: train_loss -0.9433 
2024-11-27 04:32:05.156565: val_loss -0.9123 
2024-11-27 04:32:05.156617: Pseudo dice [np.float32(0.9246)] 
2024-11-27 04:32:05.156673: Epoch time: 40.09 s 
2024-11-27 04:32:06.065784:  
2024-11-27 04:32:06.065940: Epoch 323 
2024-11-27 04:32:06.066011: Current learning rate: 0.00704 
2024-11-27 04:32:46.119818: train_loss -0.9483 
2024-11-27 04:32:46.119996: val_loss -0.9101 
2024-11-27 04:32:46.120049: Pseudo dice [np.float32(0.9231)] 
2024-11-27 04:32:46.120119: Epoch time: 40.06 s 
2024-11-27 04:32:46.963257:  
2024-11-27 04:32:46.963382: Epoch 324 
2024-11-27 04:32:46.963457: Current learning rate: 0.00703 
2024-11-27 04:33:27.008430: train_loss -0.9472 
2024-11-27 04:33:27.008549: val_loss -0.9108 
2024-11-27 04:33:27.008599: Pseudo dice [np.float32(0.9238)] 
2024-11-27 04:33:27.008653: Epoch time: 40.05 s 
2024-11-27 04:33:27.837196:  
2024-11-27 04:33:27.837285: Epoch 325 
2024-11-27 04:33:27.837359: Current learning rate: 0.00702 
2024-11-27 04:34:07.896231: train_loss -0.9513 
2024-11-27 04:34:07.896355: val_loss -0.9087 
2024-11-27 04:34:07.896406: Pseudo dice [np.float32(0.923)] 
2024-11-27 04:34:07.896461: Epoch time: 40.06 s 
2024-11-27 04:34:08.790630:  
2024-11-27 04:34:08.790721: Epoch 326 
2024-11-27 04:34:08.790816: Current learning rate: 0.00701 
2024-11-27 04:34:48.810824: train_loss -0.9517 
2024-11-27 04:34:48.811019: val_loss -0.9068 
2024-11-27 04:34:48.811087: Pseudo dice [np.float32(0.9203)] 
2024-11-27 04:34:48.811159: Epoch time: 40.02 s 
2024-11-27 04:34:49.654906:  
2024-11-27 04:34:49.655057: Epoch 327 
2024-11-27 04:34:49.655212: Current learning rate: 0.007 
2024-11-27 04:35:29.727154: train_loss -0.953 
2024-11-27 04:35:29.727260: val_loss -0.9115 
2024-11-27 04:35:29.727311: Pseudo dice [np.float32(0.9246)] 
2024-11-27 04:35:29.727365: Epoch time: 40.07 s 
2024-11-27 04:35:30.553647:  
2024-11-27 04:35:30.553753: Epoch 328 
2024-11-27 04:35:30.553823: Current learning rate: 0.00699 
2024-11-27 04:36:10.586627: train_loss -0.9531 
2024-11-27 04:36:10.586748: val_loss -0.9035 
2024-11-27 04:36:10.586800: Pseudo dice [np.float32(0.9178)] 
2024-11-27 04:36:10.586862: Epoch time: 40.03 s 
2024-11-27 04:36:11.426521:  
2024-11-27 04:36:11.426632: Epoch 329 
2024-11-27 04:36:11.426701: Current learning rate: 0.00698 
2024-11-27 04:36:51.437001: train_loss -0.9549 
2024-11-27 04:36:51.437110: val_loss -0.9059 
2024-11-27 04:36:51.437160: Pseudo dice [np.float32(0.92)] 
2024-11-27 04:36:51.437259: Epoch time: 40.01 s 
2024-11-27 04:36:52.287679:  
2024-11-27 04:36:52.287762: Epoch 330 
2024-11-27 04:36:52.287830: Current learning rate: 0.00697 
2024-11-27 04:37:32.359554: train_loss -0.9556 
2024-11-27 04:37:32.359661: val_loss -0.9111 
2024-11-27 04:37:32.359713: Pseudo dice [np.float32(0.9249)] 
2024-11-27 04:37:32.359769: Epoch time: 40.07 s 
2024-11-27 04:37:33.240417:  
2024-11-27 04:37:33.240504: Epoch 331 
2024-11-27 04:37:33.240574: Current learning rate: 0.00696 
2024-11-27 04:38:13.296011: train_loss -0.9526 
2024-11-27 04:38:13.296133: val_loss -0.908 
2024-11-27 04:38:13.296204: Pseudo dice [np.float32(0.9213)] 
2024-11-27 04:38:13.296280: Epoch time: 40.06 s 
2024-11-27 04:38:14.185786:  
2024-11-27 04:38:14.185943: Epoch 332 
2024-11-27 04:38:14.186084: Current learning rate: 0.00696 
2024-11-27 04:38:54.233364: train_loss -0.9497 
2024-11-27 04:38:54.233505: val_loss -0.9079 
2024-11-27 04:38:54.233558: Pseudo dice [np.float32(0.9214)] 
2024-11-27 04:38:54.233631: Epoch time: 40.05 s 
2024-11-27 04:38:55.139417:  
2024-11-27 04:38:55.139558: Epoch 333 
2024-11-27 04:38:55.139629: Current learning rate: 0.00695 
2024-11-27 04:39:35.195848: train_loss -0.9527 
2024-11-27 04:39:35.196021: val_loss -0.9075 
2024-11-27 04:39:35.196071: Pseudo dice [np.float32(0.9223)] 
2024-11-27 04:39:35.196126: Epoch time: 40.06 s 
2024-11-27 04:39:36.072994:  
2024-11-27 04:39:36.073091: Epoch 334 
2024-11-27 04:39:36.073224: Current learning rate: 0.00694 
2024-11-27 04:40:16.115297: train_loss -0.9541 
2024-11-27 04:40:16.115406: val_loss -0.9106 
2024-11-27 04:40:16.115458: Pseudo dice [np.float32(0.9241)] 
2024-11-27 04:40:16.115516: Epoch time: 40.04 s 
2024-11-27 04:40:16.980518:  
2024-11-27 04:40:16.980618: Epoch 335 
2024-11-27 04:40:16.980687: Current learning rate: 0.00693 
2024-11-27 04:40:56.996302: train_loss -0.9562 
2024-11-27 04:40:56.996412: val_loss -0.9088 
2024-11-27 04:40:56.996467: Pseudo dice [np.float32(0.9229)] 
2024-11-27 04:40:56.996559: Epoch time: 40.02 s 
2024-11-27 04:40:57.871149:  
2024-11-27 04:40:57.871242: Epoch 336 
2024-11-27 04:40:57.871312: Current learning rate: 0.00692 
2024-11-27 04:41:37.937299: train_loss -0.9569 
2024-11-27 04:41:37.937464: val_loss -0.9123 
2024-11-27 04:41:37.937528: Pseudo dice [np.float32(0.9259)] 
2024-11-27 04:41:37.937603: Epoch time: 40.07 s 
2024-11-27 04:41:38.820304:  
2024-11-27 04:41:38.820427: Epoch 337 
2024-11-27 04:41:38.820533: Current learning rate: 0.00691 
2024-11-27 04:42:18.859467: train_loss -0.9575 
2024-11-27 04:42:18.859585: val_loss -0.912 
2024-11-27 04:42:18.859679: Pseudo dice [np.float32(0.9254)] 
2024-11-27 04:42:18.859755: Epoch time: 40.04 s 
2024-11-27 04:42:19.772216:  
2024-11-27 04:42:19.772300: Epoch 338 
2024-11-27 04:42:19.772389: Current learning rate: 0.0069 
2024-11-27 04:42:59.786322: train_loss -0.9561 
2024-11-27 04:42:59.786432: val_loss -0.9113 
2024-11-27 04:42:59.786485: Pseudo dice [np.float32(0.9244)] 
2024-11-27 04:42:59.786541: Epoch time: 40.02 s 
2024-11-27 04:43:00.644706:  
2024-11-27 04:43:00.644805: Epoch 339 
2024-11-27 04:43:00.644924: Current learning rate: 0.00689 
2024-11-27 04:43:40.700034: train_loss -0.958 
2024-11-27 04:43:40.700155: val_loss -0.9118 
2024-11-27 04:43:40.700207: Pseudo dice [np.float32(0.925)] 
2024-11-27 04:43:40.700261: Epoch time: 40.06 s 
2024-11-27 04:43:41.651563:  
2024-11-27 04:43:41.651667: Epoch 340 
2024-11-27 04:43:41.651750: Current learning rate: 0.00688 
2024-11-27 04:44:21.712886: train_loss -0.9583 
2024-11-27 04:44:21.712992: val_loss -0.9129 
2024-11-27 04:44:21.713043: Pseudo dice [np.float32(0.9265)] 
2024-11-27 04:44:21.713130: Epoch time: 40.06 s 
2024-11-27 04:44:22.966926:  
2024-11-27 04:44:22.967005: Epoch 341 
2024-11-27 04:44:22.967127: Current learning rate: 0.00687 
2024-11-27 04:45:03.064964: train_loss -0.9578 
2024-11-27 04:45:03.065091: val_loss -0.9063 
2024-11-27 04:45:03.065149: Pseudo dice [np.float32(0.9215)] 
2024-11-27 04:45:03.065207: Epoch time: 40.1 s 
2024-11-27 04:45:03.998373:  
2024-11-27 04:45:03.998526: Epoch 342 
2024-11-27 04:45:03.998597: Current learning rate: 0.00686 
2024-11-27 04:45:44.063694: train_loss -0.9583 
2024-11-27 04:45:44.063798: val_loss -0.9051 
2024-11-27 04:45:44.063846: Pseudo dice [np.float32(0.9185)] 
2024-11-27 04:45:44.063939: Epoch time: 40.07 s 
2024-11-27 04:45:44.961036:  
2024-11-27 04:45:44.961268: Epoch 343 
2024-11-27 04:45:44.961345: Current learning rate: 0.00685 
2024-11-27 04:46:25.057441: train_loss -0.9583 
2024-11-27 04:46:25.057549: val_loss -0.9063 
2024-11-27 04:46:25.057600: Pseudo dice [np.float32(0.9228)] 
2024-11-27 04:46:25.057658: Epoch time: 40.1 s 
2024-11-27 04:46:25.983736:  
2024-11-27 04:46:25.983879: Epoch 344 
2024-11-27 04:46:25.984006: Current learning rate: 0.00684 
2024-11-27 04:47:06.057243: train_loss -0.9591 
2024-11-27 04:47:06.057352: val_loss -0.9144 
2024-11-27 04:47:06.057410: Pseudo dice [np.float32(0.9266)] 
2024-11-27 04:47:06.057484: Epoch time: 40.07 s 
2024-11-27 04:47:06.932783:  
2024-11-27 04:47:06.932968: Epoch 345 
2024-11-27 04:47:06.933050: Current learning rate: 0.00683 
2024-11-27 04:47:47.023740: train_loss -0.9577 
2024-11-27 04:47:47.023859: val_loss -0.9128 
2024-11-27 04:47:47.023964: Pseudo dice [np.float32(0.927)] 
2024-11-27 04:47:47.024021: Epoch time: 40.09 s 
2024-11-27 04:47:47.935156:  
2024-11-27 04:47:47.935251: Epoch 346 
2024-11-27 04:47:47.935319: Current learning rate: 0.00682 
2024-11-27 04:48:28.042226: train_loss -0.9581 
2024-11-27 04:48:28.042490: val_loss -0.9005 
2024-11-27 04:48:28.042549: Pseudo dice [np.float32(0.9159)] 
2024-11-27 04:48:28.042605: Epoch time: 40.11 s 
2024-11-27 04:48:28.906803:  
2024-11-27 04:48:28.906972: Epoch 347 
2024-11-27 04:48:28.907059: Current learning rate: 0.00681 
2024-11-27 04:49:08.946687: train_loss -0.9582 
2024-11-27 04:49:08.946797: val_loss -0.9137 
2024-11-27 04:49:08.946847: Pseudo dice [np.float32(0.9271)] 
2024-11-27 04:49:08.946973: Epoch time: 40.04 s 
2024-11-27 04:49:09.882478:  
2024-11-27 04:49:09.882748: Epoch 348 
2024-11-27 04:49:09.882843: Current learning rate: 0.0068 
2024-11-27 04:49:49.939358: train_loss -0.9593 
2024-11-27 04:49:49.939566: val_loss -0.9106 
2024-11-27 04:49:49.939620: Pseudo dice [np.float32(0.9248)] 
2024-11-27 04:49:49.939677: Epoch time: 40.06 s 
2024-11-27 04:49:50.885663:  
2024-11-27 04:49:50.885759: Epoch 349 
2024-11-27 04:49:50.885828: Current learning rate: 0.0068 
2024-11-27 04:50:30.939459: train_loss -0.9586 
2024-11-27 04:50:30.939578: val_loss -0.9125 
2024-11-27 04:50:30.939627: Pseudo dice [np.float32(0.9256)] 
2024-11-27 04:50:30.939681: Epoch time: 40.05 s 
2024-11-27 04:50:34.189127:  
2024-11-27 04:50:34.189226: Epoch 350 
2024-11-27 04:50:34.189295: Current learning rate: 0.00679 
2024-11-27 04:51:14.153713: train_loss -0.9591 
2024-11-27 04:51:14.153844: val_loss -0.91 
2024-11-27 04:51:14.153965: Pseudo dice [np.float32(0.9242)] 
2024-11-27 04:51:14.154022: Epoch time: 39.97 s 
2024-11-27 04:51:15.065995:  
2024-11-27 04:51:15.066079: Epoch 351 
2024-11-27 04:51:15.066215: Current learning rate: 0.00678 
2024-11-27 04:51:55.056427: train_loss -0.959 
2024-11-27 04:51:55.056603: val_loss -0.9119 
2024-11-27 04:51:55.056657: Pseudo dice [np.float32(0.9251)] 
2024-11-27 04:51:55.056739: Epoch time: 39.99 s 
2024-11-27 04:51:55.911762:  
2024-11-27 04:51:55.911831: Epoch 352 
2024-11-27 04:51:55.911929: Current learning rate: 0.00677 
2024-11-27 04:52:35.909627: train_loss -0.9596 
2024-11-27 04:52:35.909754: val_loss -0.9058 
2024-11-27 04:52:35.909857: Pseudo dice [np.float32(0.92)] 
2024-11-27 04:52:35.909932: Epoch time: 40.0 s 
2024-11-27 04:52:36.828942:  
2024-11-27 04:52:36.829042: Epoch 353 
2024-11-27 04:52:36.829108: Current learning rate: 0.00676 
2024-11-27 04:53:16.921160: train_loss -0.9592 
2024-11-27 04:53:16.921270: val_loss -0.9084 
2024-11-27 04:53:16.921322: Pseudo dice [np.float32(0.9224)] 
2024-11-27 04:53:16.921377: Epoch time: 40.09 s 
2024-11-27 04:53:17.878270:  
2024-11-27 04:53:17.878444: Epoch 354 
2024-11-27 04:53:17.878533: Current learning rate: 0.00675 
2024-11-27 04:53:57.938292: train_loss -0.9566 
2024-11-27 04:53:57.938416: val_loss -0.9057 
2024-11-27 04:53:57.938468: Pseudo dice [np.float32(0.9204)] 
2024-11-27 04:53:57.938525: Epoch time: 40.06 s 
2024-11-27 04:53:58.880204:  
2024-11-27 04:53:58.880279: Epoch 355 
2024-11-27 04:53:58.880348: Current learning rate: 0.00674 
2024-11-27 04:54:38.913358: train_loss -0.9592 
2024-11-27 04:54:38.913729: val_loss -0.9085 
2024-11-27 04:54:38.913815: Pseudo dice [np.float32(0.9211)] 
2024-11-27 04:54:38.913932: Epoch time: 40.03 s 
2024-11-27 04:54:39.827612:  
2024-11-27 04:54:39.827689: Epoch 356 
2024-11-27 04:54:39.827767: Current learning rate: 0.00673 
2024-11-27 04:55:19.893399: train_loss -0.959 
2024-11-27 04:55:19.893516: val_loss -0.9119 
2024-11-27 04:55:19.893583: Pseudo dice [np.float32(0.9258)] 
2024-11-27 04:55:19.893670: Epoch time: 40.07 s 
2024-11-27 04:55:20.818670:  
2024-11-27 04:55:20.818762: Epoch 357 
2024-11-27 04:55:20.818831: Current learning rate: 0.00672 
2024-11-27 04:56:00.856395: train_loss -0.9604 
2024-11-27 04:56:00.856523: val_loss -0.9103 
2024-11-27 04:56:00.856592: Pseudo dice [np.float32(0.9246)] 
2024-11-27 04:56:00.856665: Epoch time: 40.04 s 
2024-11-27 04:56:01.770382:  
2024-11-27 04:56:01.770473: Epoch 358 
2024-11-27 04:56:01.770566: Current learning rate: 0.00671 
2024-11-27 04:56:41.814577: train_loss -0.9601 
2024-11-27 04:56:41.814707: val_loss -0.9121 
2024-11-27 04:56:41.814776: Pseudo dice [np.float32(0.9255)] 
2024-11-27 04:56:41.814850: Epoch time: 40.05 s 
2024-11-27 04:56:43.093152:  
2024-11-27 04:56:43.093227: Epoch 359 
2024-11-27 04:56:43.093302: Current learning rate: 0.0067 
2024-11-27 04:57:23.178417: train_loss -0.9607 
2024-11-27 04:57:23.178540: val_loss -0.9094 
2024-11-27 04:57:23.178591: Pseudo dice [np.float32(0.9237)] 
2024-11-27 04:57:23.178645: Epoch time: 40.09 s 
2024-11-27 04:57:24.061549:  
2024-11-27 04:57:24.061799: Epoch 360 
2024-11-27 04:57:24.061936: Current learning rate: 0.00669 
2024-11-27 04:58:04.120450: train_loss -0.9609 
2024-11-27 04:58:04.120562: val_loss -0.912 
2024-11-27 04:58:04.120615: Pseudo dice [np.float32(0.9245)] 
2024-11-27 04:58:04.120671: Epoch time: 40.06 s 
2024-11-27 04:58:05.021734:  
2024-11-27 04:58:05.021819: Epoch 361 
2024-11-27 04:58:05.021893: Current learning rate: 0.00668 
2024-11-27 04:58:45.061316: train_loss -0.9598 
2024-11-27 04:58:45.061434: val_loss -0.9105 
2024-11-27 04:58:45.061500: Pseudo dice [np.float32(0.9253)] 
2024-11-27 04:58:45.061573: Epoch time: 40.04 s 
2024-11-27 04:58:45.952287:  
2024-11-27 04:58:45.952386: Epoch 362 
2024-11-27 04:58:45.952474: Current learning rate: 0.00667 
2024-11-27 04:59:26.013531: train_loss -0.9617 
2024-11-27 04:59:26.013665: val_loss -0.9108 
2024-11-27 04:59:26.013720: Pseudo dice [np.float32(0.9237)] 
2024-11-27 04:59:26.013775: Epoch time: 40.06 s 
2024-11-27 04:59:26.859534:  
2024-11-27 04:59:26.859643: Epoch 363 
2024-11-27 04:59:26.859712: Current learning rate: 0.00666 
2024-11-27 05:00:06.946157: train_loss -0.9602 
2024-11-27 05:00:06.946268: val_loss -0.9124 
2024-11-27 05:00:06.946346: Pseudo dice [np.float32(0.9271)] 
2024-11-27 05:00:06.946403: Epoch time: 40.09 s 
2024-11-27 05:00:06.946447: Yayy! New best EMA pseudo Dice: 0.9240999817848206 
2024-11-27 05:00:10.127413:  
2024-11-27 05:00:10.127611: Epoch 364 
2024-11-27 05:00:10.127708: Current learning rate: 0.00665 
2024-11-27 05:00:50.057832: train_loss -0.9593 
2024-11-27 05:00:50.058013: val_loss -0.9082 
2024-11-27 05:00:50.058065: Pseudo dice [np.float32(0.9217)] 
2024-11-27 05:00:50.058121: Epoch time: 39.93 s 
2024-11-27 05:00:50.919999:  
2024-11-27 05:00:50.920112: Epoch 365 
2024-11-27 05:00:50.920181: Current learning rate: 0.00665 
2024-11-27 05:01:30.932181: train_loss -0.9601 
2024-11-27 05:01:30.932286: val_loss -0.91 
2024-11-27 05:01:30.932336: Pseudo dice [np.float32(0.9243)] 
2024-11-27 05:01:30.932390: Epoch time: 40.01 s 
2024-11-27 05:01:31.839620:  
2024-11-27 05:01:31.839745: Epoch 366 
2024-11-27 05:01:31.839863: Current learning rate: 0.00664 
2024-11-27 05:02:11.871667: train_loss -0.9599 
2024-11-27 05:02:11.871824: val_loss -0.9159 
2024-11-27 05:02:11.871915: Pseudo dice [np.float32(0.9277)] 
2024-11-27 05:02:11.872010: Epoch time: 40.03 s 
2024-11-27 05:02:11.872055: Yayy! New best EMA pseudo Dice: 0.9243000149726868 
2024-11-27 05:02:15.064592:  
2024-11-27 05:02:15.064696: Epoch 367 
2024-11-27 05:02:15.064793: Current learning rate: 0.00663 
2024-11-27 05:02:54.997374: train_loss -0.9603 
2024-11-27 05:02:54.997501: val_loss -0.9195 
2024-11-27 05:02:54.997552: Pseudo dice [np.float32(0.9326)] 
2024-11-27 05:02:54.997605: Epoch time: 39.93 s 
2024-11-27 05:02:54.997649: Yayy! New best EMA pseudo Dice: 0.9251000285148621 
2024-11-27 05:02:58.219035:  
2024-11-27 05:02:58.219169: Epoch 368 
2024-11-27 05:02:58.219241: Current learning rate: 0.00662 
2024-11-27 05:03:38.204448: train_loss -0.9599 
2024-11-27 05:03:38.204577: val_loss -0.9107 
2024-11-27 05:03:38.204643: Pseudo dice [np.float32(0.9242)] 
2024-11-27 05:03:38.204715: Epoch time: 39.99 s 
2024-11-27 05:03:39.129424:  
2024-11-27 05:03:39.129638: Epoch 369 
2024-11-27 05:03:39.129708: Current learning rate: 0.00661 
2024-11-27 05:04:19.154214: train_loss -0.9588 
2024-11-27 05:04:19.154321: val_loss -0.9109 
2024-11-27 05:04:19.154373: Pseudo dice [np.float32(0.9251)] 
2024-11-27 05:04:19.154468: Epoch time: 40.03 s 
2024-11-27 05:04:20.033678:  
2024-11-27 05:04:20.033785: Epoch 370 
2024-11-27 05:04:20.033854: Current learning rate: 0.0066 
2024-11-27 05:05:00.066801: train_loss -0.9583 
2024-11-27 05:05:00.066961: val_loss -0.9073 
2024-11-27 05:05:00.067061: Pseudo dice [np.float32(0.9215)] 
2024-11-27 05:05:00.067117: Epoch time: 40.03 s 
2024-11-27 05:05:01.041152:  
2024-11-27 05:05:01.041314: Epoch 371 
2024-11-27 05:05:01.041401: Current learning rate: 0.00659 
2024-11-27 05:05:41.104324: train_loss -0.9604 
2024-11-27 05:05:41.104434: val_loss -0.9117 
2024-11-27 05:05:41.104487: Pseudo dice [np.float32(0.9249)] 
2024-11-27 05:05:41.104580: Epoch time: 40.06 s 
2024-11-27 05:05:42.009568:  
2024-11-27 05:05:42.009645: Epoch 372 
2024-11-27 05:05:42.009714: Current learning rate: 0.00658 
2024-11-27 05:06:22.065653: train_loss -0.9602 
2024-11-27 05:06:22.065759: val_loss -0.9082 
2024-11-27 05:06:22.065810: Pseudo dice [np.float32(0.9227)] 
2024-11-27 05:06:22.065865: Epoch time: 40.06 s 
2024-11-27 05:06:23.002327:  
2024-11-27 05:06:23.002402: Epoch 373 
2024-11-27 05:06:23.002468: Current learning rate: 0.00657 
2024-11-27 05:07:03.068588: train_loss -0.9609 
2024-11-27 05:07:03.068792: val_loss -0.9143 
2024-11-27 05:07:03.068848: Pseudo dice [np.float32(0.9277)] 
2024-11-27 05:07:03.068956: Epoch time: 40.07 s 
2024-11-27 05:07:03.972577:  
2024-11-27 05:07:03.972807: Epoch 374 
2024-11-27 05:07:03.972931: Current learning rate: 0.00656 
2024-11-27 05:07:44.025764: train_loss -0.9593 
2024-11-27 05:07:44.025876: val_loss -0.9087 
2024-11-27 05:07:44.025927: Pseudo dice [np.float32(0.9228)] 
2024-11-27 05:07:44.025982: Epoch time: 40.05 s 
2024-11-27 05:07:44.892311:  
2024-11-27 05:07:44.892513: Epoch 375 
2024-11-27 05:07:44.892581: Current learning rate: 0.00655 
2024-11-27 05:08:24.980263: train_loss -0.9613 
2024-11-27 05:08:24.980367: val_loss -0.9024 
2024-11-27 05:08:24.980416: Pseudo dice [np.float32(0.9177)] 
2024-11-27 05:08:24.980484: Epoch time: 40.09 s 
2024-11-27 05:08:25.859322:  
2024-11-27 05:08:25.859409: Epoch 376 
2024-11-27 05:08:25.859478: Current learning rate: 0.00654 
2024-11-27 05:09:05.977119: train_loss -0.9602 
2024-11-27 05:09:05.977237: val_loss -0.9067 
2024-11-27 05:09:05.977306: Pseudo dice [np.float32(0.9218)] 
2024-11-27 05:09:05.977378: Epoch time: 40.12 s 
2024-11-27 05:09:06.850697:  
2024-11-27 05:09:06.850852: Epoch 377 
2024-11-27 05:09:06.850939: Current learning rate: 0.00653 
2024-11-27 05:09:46.898488: train_loss -0.953 
2024-11-27 05:09:46.898594: val_loss -0.9003 
2024-11-27 05:09:46.898643: Pseudo dice [np.float32(0.9171)] 
2024-11-27 05:09:46.898698: Epoch time: 40.05 s 
2024-11-27 05:09:48.243088:  
2024-11-27 05:09:48.243219: Epoch 378 
2024-11-27 05:09:48.243314: Current learning rate: 0.00652 
2024-11-27 05:10:28.321036: train_loss -0.9489 
2024-11-27 05:10:28.321162: val_loss -0.9041 
2024-11-27 05:10:28.321213: Pseudo dice [np.float32(0.919)] 
2024-11-27 05:10:28.321268: Epoch time: 40.08 s 
2024-11-27 05:10:29.247676:  
2024-11-27 05:10:29.247872: Epoch 379 
2024-11-27 05:10:29.247958: Current learning rate: 0.00651 
2024-11-27 05:11:09.356549: train_loss -0.9531 
2024-11-27 05:11:09.356659: val_loss -0.907 
2024-11-27 05:11:09.356712: Pseudo dice [np.float32(0.9206)] 
2024-11-27 05:11:09.356796: Epoch time: 40.11 s 
2024-11-27 05:11:10.266943:  
2024-11-27 05:11:10.267076: Epoch 380 
2024-11-27 05:11:10.267145: Current learning rate: 0.0065 
2024-11-27 05:11:50.340513: train_loss -0.9446 
2024-11-27 05:11:50.340626: val_loss -0.9065 
2024-11-27 05:11:50.340680: Pseudo dice [np.float32(0.9228)] 
2024-11-27 05:11:50.340737: Epoch time: 40.07 s 
2024-11-27 05:11:51.261074:  
2024-11-27 05:11:51.261330: Epoch 381 
2024-11-27 05:11:51.261403: Current learning rate: 0.00649 
2024-11-27 05:12:31.334143: train_loss -0.9224 
2024-11-27 05:12:31.334262: val_loss -0.8972 
2024-11-27 05:12:31.334315: Pseudo dice [np.float32(0.9148)] 
2024-11-27 05:12:31.334372: Epoch time: 40.07 s 
2024-11-27 05:12:32.287141:  
2024-11-27 05:12:32.287241: Epoch 382 
2024-11-27 05:12:32.287307: Current learning rate: 0.00648 
2024-11-27 05:13:12.347170: train_loss -0.9318 
2024-11-27 05:13:12.347302: val_loss -0.9028 
2024-11-27 05:13:12.347355: Pseudo dice [np.float32(0.9168)] 
2024-11-27 05:13:12.347411: Epoch time: 40.06 s 
2024-11-27 05:13:13.317390:  
2024-11-27 05:13:13.317551: Epoch 383 
2024-11-27 05:13:13.317641: Current learning rate: 0.00648 
2024-11-27 05:13:53.333489: train_loss -0.9423 
2024-11-27 05:13:53.333624: val_loss -0.9107 
2024-11-27 05:13:53.333686: Pseudo dice [np.float32(0.9245)] 
2024-11-27 05:13:53.333741: Epoch time: 40.02 s 
2024-11-27 05:13:54.254572:  
2024-11-27 05:13:54.254682: Epoch 384 
2024-11-27 05:13:54.254749: Current learning rate: 0.00647 
2024-11-27 05:14:34.306453: train_loss -0.946 
2024-11-27 05:14:34.306585: val_loss -0.9038 
2024-11-27 05:14:34.306695: Pseudo dice [np.float32(0.9207)] 
2024-11-27 05:14:34.306829: Epoch time: 40.05 s 
2024-11-27 05:14:35.197299:  
2024-11-27 05:14:35.197483: Epoch 385 
2024-11-27 05:14:35.197572: Current learning rate: 0.00646 
2024-11-27 05:15:15.214545: train_loss -0.9426 
2024-11-27 05:15:15.214670: val_loss -0.9075 
2024-11-27 05:15:15.214723: Pseudo dice [np.float32(0.9221)] 
2024-11-27 05:15:15.214780: Epoch time: 40.02 s 
2024-11-27 05:15:16.186432:  
2024-11-27 05:15:16.186517: Epoch 386 
2024-11-27 05:15:16.186585: Current learning rate: 0.00645 
2024-11-27 05:15:56.215458: train_loss -0.9465 
2024-11-27 05:15:56.215565: val_loss -0.8999 
2024-11-27 05:15:56.215618: Pseudo dice [np.float32(0.9163)] 
2024-11-27 05:15:56.215675: Epoch time: 40.03 s 
2024-11-27 05:15:57.117741:  
2024-11-27 05:15:57.117930: Epoch 387 
2024-11-27 05:15:57.118018: Current learning rate: 0.00644 
2024-11-27 05:16:37.126848: train_loss -0.9519 
2024-11-27 05:16:37.127027: val_loss -0.9124 
2024-11-27 05:16:37.127079: Pseudo dice [np.float32(0.9249)] 
2024-11-27 05:16:37.127135: Epoch time: 40.01 s 
2024-11-27 05:16:38.081408:  
2024-11-27 05:16:38.081635: Epoch 388 
2024-11-27 05:16:38.081728: Current learning rate: 0.00643 
2024-11-27 05:17:18.108189: train_loss -0.9526 
2024-11-27 05:17:18.108325: val_loss -0.9095 
2024-11-27 05:17:18.108394: Pseudo dice [np.float32(0.9235)] 
2024-11-27 05:17:18.108469: Epoch time: 40.03 s 
2024-11-27 05:17:19.020418:  
2024-11-27 05:17:19.020500: Epoch 389 
2024-11-27 05:17:19.020602: Current learning rate: 0.00642 
2024-11-27 05:17:59.038041: train_loss -0.9544 
2024-11-27 05:17:59.038159: val_loss -0.9092 
2024-11-27 05:17:59.038209: Pseudo dice [np.float32(0.9244)] 
2024-11-27 05:17:59.038265: Epoch time: 40.02 s 
2024-11-27 05:17:59.968159:  
2024-11-27 05:17:59.968244: Epoch 390 
2024-11-27 05:17:59.968313: Current learning rate: 0.00641 
2024-11-27 05:18:39.968399: train_loss -0.9543 
2024-11-27 05:18:39.968526: val_loss -0.9089 
2024-11-27 05:18:39.968588: Pseudo dice [np.float32(0.9229)] 
2024-11-27 05:18:39.968663: Epoch time: 40.0 s 
2024-11-27 05:18:40.943958:  
2024-11-27 05:18:40.944152: Epoch 391 
2024-11-27 05:18:40.944256: Current learning rate: 0.0064 
2024-11-27 05:19:20.952176: train_loss -0.9544 
2024-11-27 05:19:20.952348: val_loss -0.907 
2024-11-27 05:19:20.952419: Pseudo dice [np.float32(0.9213)] 
2024-11-27 05:19:20.952478: Epoch time: 40.01 s 
2024-11-27 05:19:21.837640:  
2024-11-27 05:19:21.837762: Epoch 392 
2024-11-27 05:19:21.837831: Current learning rate: 0.00639 
2024-11-27 05:20:01.884955: train_loss -0.9574 
2024-11-27 05:20:01.885127: val_loss -0.9073 
2024-11-27 05:20:01.885177: Pseudo dice [np.float32(0.9229)] 
2024-11-27 05:20:01.885233: Epoch time: 40.05 s 
2024-11-27 05:20:02.834433:  
2024-11-27 05:20:02.834557: Epoch 393 
2024-11-27 05:20:02.834642: Current learning rate: 0.00638 
2024-11-27 05:20:42.843257: train_loss -0.9559 
2024-11-27 05:20:42.843622: val_loss -0.9091 
2024-11-27 05:20:42.843682: Pseudo dice [np.float32(0.9238)] 
2024-11-27 05:20:42.843739: Epoch time: 40.01 s 
2024-11-27 05:20:43.799473:  
2024-11-27 05:20:43.799573: Epoch 394 
2024-11-27 05:20:43.799642: Current learning rate: 0.00637 
2024-11-27 05:21:23.807922: train_loss -0.9544 
2024-11-27 05:21:23.808323: val_loss -0.907 
2024-11-27 05:21:23.808398: Pseudo dice [np.float32(0.9222)] 
2024-11-27 05:21:23.808476: Epoch time: 40.01 s 
2024-11-27 05:21:24.736563:  
2024-11-27 05:21:24.736658: Epoch 395 
2024-11-27 05:21:24.736774: Current learning rate: 0.00636 
2024-11-27 05:22:04.761590: train_loss -0.9548 
2024-11-27 05:22:04.761716: val_loss -0.905 
2024-11-27 05:22:04.761781: Pseudo dice [np.float32(0.9206)] 
2024-11-27 05:22:04.761858: Epoch time: 40.03 s 
2024-11-27 05:22:06.100372:  
2024-11-27 05:22:06.100449: Epoch 396 
2024-11-27 05:22:06.100553: Current learning rate: 0.00635 
2024-11-27 05:22:46.133287: train_loss -0.9557 
2024-11-27 05:22:46.133406: val_loss -0.9121 
2024-11-27 05:22:46.133456: Pseudo dice [np.float32(0.9267)] 
2024-11-27 05:22:46.133510: Epoch time: 40.03 s 
2024-11-27 05:22:47.009699:  
2024-11-27 05:22:47.009852: Epoch 397 
2024-11-27 05:22:47.009988: Current learning rate: 0.00634 
2024-11-27 05:23:27.051455: train_loss -0.958 
2024-11-27 05:23:27.051603: val_loss -0.909 
2024-11-27 05:23:27.051684: Pseudo dice [np.float32(0.923)] 
2024-11-27 05:23:27.051750: Epoch time: 40.04 s 
2024-11-27 05:23:27.948624:  
2024-11-27 05:23:27.948735: Epoch 398 
2024-11-27 05:23:27.948803: Current learning rate: 0.00633 
2024-11-27 05:24:08.016412: train_loss -0.9585 
2024-11-27 05:24:08.016524: val_loss -0.9042 
2024-11-27 05:24:08.016577: Pseudo dice [np.float32(0.9195)] 
2024-11-27 05:24:08.016633: Epoch time: 40.07 s 
2024-11-27 05:24:08.896509:  
2024-11-27 05:24:08.896614: Epoch 399 
2024-11-27 05:24:08.896684: Current learning rate: 0.00632 
2024-11-27 05:24:48.926990: train_loss -0.9583 
2024-11-27 05:24:48.927162: val_loss -0.9123 
2024-11-27 05:24:48.927216: Pseudo dice [np.float32(0.9257)] 
2024-11-27 05:24:48.927272: Epoch time: 40.03 s 
2024-11-27 05:24:52.289707:  
2024-11-27 05:24:52.289820: Epoch 400 
2024-11-27 05:24:52.289989: Current learning rate: 0.00631 
2024-11-27 05:25:32.261933: train_loss -0.9594 
2024-11-27 05:25:32.262082: val_loss -0.9117 
2024-11-27 05:25:32.262135: Pseudo dice [np.float32(0.9252)] 
2024-11-27 05:25:32.262190: Epoch time: 39.97 s 
2024-11-27 05:25:33.174783:  
2024-11-27 05:25:33.175000: Epoch 401 
2024-11-27 05:25:33.175089: Current learning rate: 0.0063 
2024-11-27 05:26:13.260159: train_loss -0.9588 
2024-11-27 05:26:13.260286: val_loss -0.9135 
2024-11-27 05:26:13.260338: Pseudo dice [np.float32(0.9272)] 
2024-11-27 05:26:13.260401: Epoch time: 40.09 s 
2024-11-27 05:26:14.222447:  
2024-11-27 05:26:14.222671: Epoch 402 
2024-11-27 05:26:14.222775: Current learning rate: 0.0063 
2024-11-27 05:26:54.291168: train_loss -0.9603 
2024-11-27 05:26:54.291284: val_loss -0.9098 
2024-11-27 05:26:54.291367: Pseudo dice [np.float32(0.9238)] 
2024-11-27 05:26:54.291425: Epoch time: 40.07 s 
2024-11-27 05:26:55.220824:  
2024-11-27 05:26:55.220952: Epoch 403 
2024-11-27 05:26:55.221041: Current learning rate: 0.00629 
2024-11-27 05:27:35.277490: train_loss -0.96 
2024-11-27 05:27:35.277604: val_loss -0.9043 
2024-11-27 05:27:35.277819: Pseudo dice [np.float32(0.9181)] 
2024-11-27 05:27:35.277900: Epoch time: 40.06 s 
2024-11-27 05:27:36.160199:  
2024-11-27 05:27:36.160389: Epoch 404 
2024-11-27 05:27:36.160460: Current learning rate: 0.00628 
2024-11-27 05:28:16.228618: train_loss -0.9583 
2024-11-27 05:28:16.228740: val_loss -0.908 
2024-11-27 05:28:16.228792: Pseudo dice [np.float32(0.922)] 
2024-11-27 05:28:16.228847: Epoch time: 40.07 s 
2024-11-27 05:28:17.141275:  
2024-11-27 05:28:17.141374: Epoch 405 
2024-11-27 05:28:17.141446: Current learning rate: 0.00627 
2024-11-27 05:28:57.231035: train_loss -0.9579 
2024-11-27 05:28:57.231142: val_loss -0.9044 
2024-11-27 05:28:57.231195: Pseudo dice [np.float32(0.9213)] 
2024-11-27 05:28:57.231249: Epoch time: 40.09 s 
2024-11-27 05:28:58.155349:  
2024-11-27 05:28:58.155454: Epoch 406 
2024-11-27 05:28:58.155524: Current learning rate: 0.00626 
2024-11-27 05:29:38.176501: train_loss -0.9558 
2024-11-27 05:29:38.176606: val_loss -0.9044 
2024-11-27 05:29:38.176657: Pseudo dice [np.float32(0.9194)] 
2024-11-27 05:29:38.176711: Epoch time: 40.02 s 
2024-11-27 05:29:39.077025:  
2024-11-27 05:29:39.077116: Epoch 407 
2024-11-27 05:29:39.077197: Current learning rate: 0.00625 
2024-11-27 05:30:19.159346: train_loss -0.9563 
2024-11-27 05:30:19.159486: val_loss -0.9086 
2024-11-27 05:30:19.159536: Pseudo dice [np.float32(0.9228)] 
2024-11-27 05:30:19.159590: Epoch time: 40.08 s 
2024-11-27 05:30:20.031211:  
2024-11-27 05:30:20.031332: Epoch 408 
2024-11-27 05:30:20.031408: Current learning rate: 0.00624 
2024-11-27 05:31:00.078506: train_loss -0.9542 
2024-11-27 05:31:00.078614: val_loss -0.9063 
2024-11-27 05:31:00.078665: Pseudo dice [np.float32(0.9205)] 
2024-11-27 05:31:00.078719: Epoch time: 40.05 s 
2024-11-27 05:31:00.970738:  
2024-11-27 05:31:00.970815: Epoch 409 
2024-11-27 05:31:00.970932: Current learning rate: 0.00623 
2024-11-27 05:31:40.987012: train_loss -0.958 
2024-11-27 05:31:40.987120: val_loss -0.9087 
2024-11-27 05:31:40.987188: Pseudo dice [np.float32(0.9227)] 
2024-11-27 05:31:40.987264: Epoch time: 40.02 s 
2024-11-27 05:31:41.914510:  
2024-11-27 05:31:41.914600: Epoch 410 
2024-11-27 05:31:41.914713: Current learning rate: 0.00622 
2024-11-27 05:32:21.955685: train_loss -0.9594 
2024-11-27 05:32:21.955814: val_loss -0.9066 
2024-11-27 05:32:21.955872: Pseudo dice [np.float32(0.9217)] 
2024-11-27 05:32:21.955971: Epoch time: 40.04 s 
2024-11-27 05:32:22.848511:  
2024-11-27 05:32:22.848628: Epoch 411 
2024-11-27 05:32:22.848753: Current learning rate: 0.00621 
2024-11-27 05:33:02.842067: train_loss -0.9604 
2024-11-27 05:33:02.842178: val_loss -0.9126 
2024-11-27 05:33:02.842234: Pseudo dice [np.float32(0.9277)] 
2024-11-27 05:33:02.842292: Epoch time: 39.99 s 
2024-11-27 05:33:03.715433:  
2024-11-27 05:33:03.715504: Epoch 412 
2024-11-27 05:33:03.715572: Current learning rate: 0.0062 
2024-11-27 05:33:43.686586: train_loss -0.9592 
2024-11-27 05:33:43.686699: val_loss -0.9164 
2024-11-27 05:33:43.686760: Pseudo dice [np.float32(0.9289)] 
2024-11-27 05:33:43.686899: Epoch time: 39.97 s 
2024-11-27 05:33:44.593107:  
2024-11-27 05:33:44.593181: Epoch 413 
2024-11-27 05:33:44.593267: Current learning rate: 0.00619 
2024-11-27 05:34:24.603014: train_loss -0.9602 
2024-11-27 05:34:24.603121: val_loss -0.9048 
2024-11-27 05:34:24.603173: Pseudo dice [np.float32(0.9189)] 
2024-11-27 05:34:24.603229: Epoch time: 40.01 s 
2024-11-27 05:34:25.921047:  
2024-11-27 05:34:25.921179: Epoch 414 
2024-11-27 05:34:25.921288: Current learning rate: 0.00618 
2024-11-27 05:35:05.965744: train_loss -0.9611 
2024-11-27 05:35:05.965852: val_loss -0.9122 
2024-11-27 05:35:05.965950: Pseudo dice [np.float32(0.9258)] 
2024-11-27 05:35:05.966061: Epoch time: 40.05 s 
2024-11-27 05:35:06.836003:  
2024-11-27 05:35:06.836120: Epoch 415 
2024-11-27 05:35:06.836190: Current learning rate: 0.00617 
2024-11-27 05:35:46.834373: train_loss -0.9623 
2024-11-27 05:35:46.834483: val_loss -0.9072 
2024-11-27 05:35:46.834533: Pseudo dice [np.float32(0.9225)] 
2024-11-27 05:35:46.834619: Epoch time: 40.0 s 
2024-11-27 05:35:47.674799:  
2024-11-27 05:35:47.674999: Epoch 416 
2024-11-27 05:35:47.675067: Current learning rate: 0.00616 
2024-11-27 05:36:27.695516: train_loss -0.962 
2024-11-27 05:36:27.695642: val_loss -0.9092 
2024-11-27 05:36:27.695694: Pseudo dice [np.float32(0.924)] 
2024-11-27 05:36:27.695750: Epoch time: 40.02 s 
2024-11-27 05:36:28.547326:  
2024-11-27 05:36:28.547617: Epoch 417 
2024-11-27 05:36:28.547707: Current learning rate: 0.00615 
2024-11-27 05:37:08.607716: train_loss -0.9607 
2024-11-27 05:37:08.607826: val_loss -0.9106 
2024-11-27 05:37:08.607915: Pseudo dice [np.float32(0.9242)] 
2024-11-27 05:37:08.608034: Epoch time: 40.06 s 
2024-11-27 05:37:09.492523:  
2024-11-27 05:37:09.492728: Epoch 418 
2024-11-27 05:37:09.492818: Current learning rate: 0.00614 
2024-11-27 05:37:49.566215: train_loss -0.9613 
2024-11-27 05:37:49.566351: val_loss -0.9162 
2024-11-27 05:37:49.566405: Pseudo dice [np.float32(0.9299)] 
2024-11-27 05:37:49.566463: Epoch time: 40.07 s 
2024-11-27 05:37:50.399554:  
2024-11-27 05:37:50.399666: Epoch 419 
2024-11-27 05:37:50.399736: Current learning rate: 0.00613 
2024-11-27 05:38:30.385057: train_loss -0.9617 
2024-11-27 05:38:30.385166: val_loss -0.9095 
2024-11-27 05:38:30.385219: Pseudo dice [np.float32(0.9231)] 
2024-11-27 05:38:30.385275: Epoch time: 39.99 s 
2024-11-27 05:38:31.289513:  
2024-11-27 05:38:31.289628: Epoch 420 
2024-11-27 05:38:31.289697: Current learning rate: 0.00612 
2024-11-27 05:39:11.311285: train_loss -0.9614 
2024-11-27 05:39:11.311399: val_loss -0.9109 
2024-11-27 05:39:11.311498: Pseudo dice [np.float32(0.9239)] 
2024-11-27 05:39:11.311554: Epoch time: 40.02 s 
2024-11-27 05:39:12.194772:  
2024-11-27 05:39:12.194875: Epoch 421 
2024-11-27 05:39:12.194962: Current learning rate: 0.00612 
2024-11-27 05:39:52.238333: train_loss -0.9588 
2024-11-27 05:39:52.238560: val_loss -0.9147 
2024-11-27 05:39:52.238618: Pseudo dice [np.float32(0.9274)] 
2024-11-27 05:39:52.238709: Epoch time: 40.04 s 
2024-11-27 05:39:53.112873:  
2024-11-27 05:39:53.113018: Epoch 422 
2024-11-27 05:39:53.113103: Current learning rate: 0.00611 
2024-11-27 05:40:33.129274: train_loss -0.9611 
2024-11-27 05:40:33.129535: val_loss -0.916 
2024-11-27 05:40:33.129586: Pseudo dice [np.float32(0.9284)] 
2024-11-27 05:40:33.129642: Epoch time: 40.02 s 
2024-11-27 05:40:34.009359:  
2024-11-27 05:40:34.009460: Epoch 423 
2024-11-27 05:40:34.009544: Current learning rate: 0.0061 
2024-11-27 05:41:14.099654: train_loss -0.9624 
2024-11-27 05:41:14.099765: val_loss -0.9118 
2024-11-27 05:41:14.099818: Pseudo dice [np.float32(0.9264)] 
2024-11-27 05:41:14.099881: Epoch time: 40.09 s 
2024-11-27 05:41:14.943991:  
2024-11-27 05:41:14.944091: Epoch 424 
2024-11-27 05:41:14.944160: Current learning rate: 0.00609 
2024-11-27 05:41:54.984113: train_loss -0.9625 
2024-11-27 05:41:54.984225: val_loss -0.9129 
2024-11-27 05:41:54.984278: Pseudo dice [np.float32(0.9272)] 
2024-11-27 05:41:54.984352: Epoch time: 40.04 s 
2024-11-27 05:41:55.810745:  
2024-11-27 05:41:55.810874: Epoch 425 
2024-11-27 05:41:55.810961: Current learning rate: 0.00608 
2024-11-27 05:42:35.842284: train_loss -0.9613 
2024-11-27 05:42:35.842399: val_loss -0.9109 
2024-11-27 05:42:35.842449: Pseudo dice [np.float32(0.9248)] 
2024-11-27 05:42:35.842502: Epoch time: 40.03 s 
2024-11-27 05:42:36.681157:  
2024-11-27 05:42:36.681319: Epoch 426 
2024-11-27 05:42:36.681391: Current learning rate: 0.00607 
2024-11-27 05:43:16.727358: train_loss -0.9618 
2024-11-27 05:43:16.727508: val_loss -0.9079 
2024-11-27 05:43:16.727561: Pseudo dice [np.float32(0.9236)] 
2024-11-27 05:43:16.727615: Epoch time: 40.05 s 
2024-11-27 05:43:17.594784:  
2024-11-27 05:43:17.594915: Epoch 427 
2024-11-27 05:43:17.595002: Current learning rate: 0.00606 
2024-11-27 05:43:57.605718: train_loss -0.9613 
2024-11-27 05:43:57.605835: val_loss -0.9107 
2024-11-27 05:43:57.605940: Pseudo dice [np.float32(0.9246)] 
2024-11-27 05:43:57.606010: Epoch time: 40.01 s 
2024-11-27 05:43:58.509009:  
2024-11-27 05:43:58.509120: Epoch 428 
2024-11-27 05:43:58.509191: Current learning rate: 0.00605 
2024-11-27 05:44:38.570078: train_loss -0.962 
2024-11-27 05:44:38.570217: val_loss -0.9085 
2024-11-27 05:44:38.570268: Pseudo dice [np.float32(0.9225)] 
2024-11-27 05:44:38.570323: Epoch time: 40.06 s 
2024-11-27 05:44:39.395802:  
2024-11-27 05:44:39.395969: Epoch 429 
2024-11-27 05:44:39.396122: Current learning rate: 0.00604 
2024-11-27 05:45:19.453861: train_loss -0.9628 
2024-11-27 05:45:19.454017: val_loss -0.907 
2024-11-27 05:45:19.454136: Pseudo dice [np.float32(0.921)] 
2024-11-27 05:45:19.454264: Epoch time: 40.06 s 
2024-11-27 05:45:20.279841:  
2024-11-27 05:45:20.279966: Epoch 430 
2024-11-27 05:45:20.280056: Current learning rate: 0.00603 
2024-11-27 05:46:00.300732: train_loss -0.9606 
2024-11-27 05:46:00.300843: val_loss -0.9096 
2024-11-27 05:46:00.300964: Pseudo dice [np.float32(0.9232)] 
2024-11-27 05:46:00.301021: Epoch time: 40.02 s 
2024-11-27 05:46:01.124126:  
2024-11-27 05:46:01.124258: Epoch 431 
2024-11-27 05:46:01.124330: Current learning rate: 0.00602 
2024-11-27 05:46:41.185402: train_loss -0.9601 
2024-11-27 05:46:41.185510: val_loss -0.911 
2024-11-27 05:46:41.185584: Pseudo dice [np.float32(0.9238)] 
2024-11-27 05:46:41.185654: Epoch time: 40.06 s 
2024-11-27 05:46:41.999308:  
2024-11-27 05:46:41.999399: Epoch 432 
2024-11-27 05:46:41.999468: Current learning rate: 0.00601 
2024-11-27 05:47:22.029754: train_loss -0.9625 
2024-11-27 05:47:22.029933: val_loss -0.9106 
2024-11-27 05:47:22.030004: Pseudo dice [np.float32(0.9242)] 
2024-11-27 05:47:22.030058: Epoch time: 40.03 s 
2024-11-27 05:47:22.921228:  
2024-11-27 05:47:22.921444: Epoch 433 
2024-11-27 05:47:22.921519: Current learning rate: 0.006 
2024-11-27 05:48:02.951069: train_loss -0.9628 
2024-11-27 05:48:02.951180: val_loss -0.9058 
2024-11-27 05:48:02.951231: Pseudo dice [np.float32(0.92)] 
2024-11-27 05:48:02.951301: Epoch time: 40.03 s 
2024-11-27 05:48:04.262384:  
2024-11-27 05:48:04.262515: Epoch 434 
2024-11-27 05:48:04.262607: Current learning rate: 0.00599 
2024-11-27 05:48:44.285874: train_loss -0.9628 
2024-11-27 05:48:44.285985: val_loss -0.9093 
2024-11-27 05:48:44.286037: Pseudo dice [np.float32(0.9229)] 
2024-11-27 05:48:44.286095: Epoch time: 40.02 s 
2024-11-27 05:48:45.131470:  
2024-11-27 05:48:45.131646: Epoch 435 
2024-11-27 05:48:45.131745: Current learning rate: 0.00598 
2024-11-27 05:49:25.209330: train_loss -0.9629 
2024-11-27 05:49:25.209482: val_loss -0.9103 
2024-11-27 05:49:25.209555: Pseudo dice [np.float32(0.9247)] 
2024-11-27 05:49:25.209615: Epoch time: 40.08 s 
2024-11-27 05:49:26.131537:  
2024-11-27 05:49:26.131742: Epoch 436 
2024-11-27 05:49:26.131814: Current learning rate: 0.00597 
2024-11-27 05:50:06.229313: train_loss -0.9619 
2024-11-27 05:50:06.229420: val_loss -0.8985 
2024-11-27 05:50:06.229471: Pseudo dice [np.float32(0.9166)] 
2024-11-27 05:50:06.229527: Epoch time: 40.1 s 
2024-11-27 05:50:07.075384:  
2024-11-27 05:50:07.075531: Epoch 437 
2024-11-27 05:50:07.075627: Current learning rate: 0.00596 
2024-11-27 05:50:47.131134: train_loss -0.9632 
2024-11-27 05:50:47.131257: val_loss -0.9138 
2024-11-27 05:50:47.131309: Pseudo dice [np.float32(0.9276)] 
2024-11-27 05:50:47.131384: Epoch time: 40.06 s 
2024-11-27 05:50:47.998685:  
2024-11-27 05:50:47.998830: Epoch 438 
2024-11-27 05:50:47.998903: Current learning rate: 0.00595 
2024-11-27 05:51:28.031607: train_loss -0.9642 
2024-11-27 05:51:28.031735: val_loss -0.9105 
2024-11-27 05:51:28.031793: Pseudo dice [np.float32(0.9235)] 
2024-11-27 05:51:28.031847: Epoch time: 40.03 s 
2024-11-27 05:51:28.913447:  
2024-11-27 05:51:28.913601: Epoch 439 
2024-11-27 05:51:28.913669: Current learning rate: 0.00594 
2024-11-27 05:52:08.960817: train_loss -0.9636 
2024-11-27 05:52:08.961022: val_loss -0.9124 
2024-11-27 05:52:08.961124: Pseudo dice [np.float32(0.9263)] 
2024-11-27 05:52:08.961204: Epoch time: 40.05 s 
2024-11-27 05:52:09.856300:  
2024-11-27 05:52:09.856484: Epoch 440 
2024-11-27 05:52:09.856555: Current learning rate: 0.00593 
2024-11-27 05:52:49.890936: train_loss -0.9632 
2024-11-27 05:52:49.891065: val_loss -0.9087 
2024-11-27 05:52:49.891118: Pseudo dice [np.float32(0.9223)] 
2024-11-27 05:52:49.891176: Epoch time: 40.04 s 
2024-11-27 05:52:50.744004:  
2024-11-27 05:52:50.744196: Epoch 441 
2024-11-27 05:52:50.744311: Current learning rate: 0.00592 
2024-11-27 05:53:30.813529: train_loss -0.962 
2024-11-27 05:53:30.813640: val_loss -0.9076 
2024-11-27 05:53:30.813719: Pseudo dice [np.float32(0.9217)] 
2024-11-27 05:53:30.813774: Epoch time: 40.07 s 
2024-11-27 05:53:31.721334:  
2024-11-27 05:53:31.721504: Epoch 442 
2024-11-27 05:53:31.721573: Current learning rate: 0.00592 
2024-11-27 05:54:11.766306: train_loss -0.9625 
2024-11-27 05:54:11.766415: val_loss -0.9109 
2024-11-27 05:54:11.766465: Pseudo dice [np.float32(0.9261)] 
2024-11-27 05:54:11.766520: Epoch time: 40.05 s 
2024-11-27 05:54:12.654621:  
2024-11-27 05:54:12.654823: Epoch 443 
2024-11-27 05:54:12.654942: Current learning rate: 0.00591 
2024-11-27 05:54:52.696614: train_loss -0.9632 
2024-11-27 05:54:52.696732: val_loss -0.9148 
2024-11-27 05:54:52.696784: Pseudo dice [np.float32(0.9284)] 
2024-11-27 05:54:52.696841: Epoch time: 40.04 s 
2024-11-27 05:54:53.559921:  
2024-11-27 05:54:53.560057: Epoch 444 
2024-11-27 05:54:53.560170: Current learning rate: 0.0059 
2024-11-27 05:55:33.636804: train_loss -0.9647 
2024-11-27 05:55:33.636963: val_loss -0.912 
2024-11-27 05:55:33.637015: Pseudo dice [np.float32(0.9266)] 
2024-11-27 05:55:33.637070: Epoch time: 40.08 s 
2024-11-27 05:55:34.458929:  
2024-11-27 05:55:34.459060: Epoch 445 
2024-11-27 05:55:34.459129: Current learning rate: 0.00589 
2024-11-27 05:56:14.445214: train_loss -0.9633 
2024-11-27 05:56:14.445334: val_loss -0.9096 
2024-11-27 05:56:14.445393: Pseudo dice [np.float32(0.9248)] 
2024-11-27 05:56:14.445494: Epoch time: 39.99 s 
2024-11-27 05:56:15.370811:  
2024-11-27 05:56:15.371164: Epoch 446 
2024-11-27 05:56:15.371242: Current learning rate: 0.00588 
2024-11-27 05:56:55.422782: train_loss -0.9635 
2024-11-27 05:56:55.422937: val_loss -0.909 
2024-11-27 05:56:55.423033: Pseudo dice [np.float32(0.9239)] 
2024-11-27 05:56:55.423110: Epoch time: 40.05 s 
2024-11-27 05:56:56.310440:  
2024-11-27 05:56:56.310589: Epoch 447 
2024-11-27 05:56:56.310679: Current learning rate: 0.00587 
2024-11-27 05:57:36.350754: train_loss -0.963 
2024-11-27 05:57:36.350909: val_loss -0.912 
2024-11-27 05:57:36.351011: Pseudo dice [np.float32(0.9254)] 
2024-11-27 05:57:36.351066: Epoch time: 40.04 s 
2024-11-27 05:57:37.197756:  
2024-11-27 05:57:37.197905: Epoch 448 
2024-11-27 05:57:37.197976: Current learning rate: 0.00586 
2024-11-27 05:58:17.236189: train_loss -0.9642 
2024-11-27 05:58:17.236297: val_loss -0.9082 
2024-11-27 05:58:17.236353: Pseudo dice [np.float32(0.9234)] 
2024-11-27 05:58:17.236426: Epoch time: 40.04 s 
2024-11-27 05:58:18.074507:  
2024-11-27 05:58:18.074677: Epoch 449 
2024-11-27 05:58:18.074745: Current learning rate: 0.00585 
2024-11-27 05:58:58.070172: train_loss -0.9639 
2024-11-27 05:58:58.070298: val_loss -0.9124 
2024-11-27 05:58:58.070350: Pseudo dice [np.float32(0.9252)] 
2024-11-27 05:58:58.070405: Epoch time: 40.0 s 
2024-11-27 05:59:01.268398:  
2024-11-27 05:59:01.268571: Epoch 450 
2024-11-27 05:59:01.268653: Current learning rate: 0.00584 
2024-11-27 05:59:41.162724: train_loss -0.9636 
2024-11-27 05:59:41.162858: val_loss -0.9057 
2024-11-27 05:59:41.162966: Pseudo dice [np.float32(0.9205)] 
2024-11-27 05:59:41.163063: Epoch time: 39.9 s 
2024-11-27 05:59:42.085934:  
2024-11-27 05:59:42.086087: Epoch 451 
2024-11-27 05:59:42.086182: Current learning rate: 0.00583 
2024-11-27 06:00:22.096185: train_loss -0.9621 
2024-11-27 06:00:22.096291: val_loss -0.9073 
2024-11-27 06:00:22.096343: Pseudo dice [np.float32(0.923)] 
2024-11-27 06:00:22.096398: Epoch time: 40.01 s 
2024-11-27 06:00:23.006593:  
2024-11-27 06:00:23.006746: Epoch 452 
2024-11-27 06:00:23.006817: Current learning rate: 0.00582 
2024-11-27 06:01:03.023128: train_loss -0.9633 
2024-11-27 06:01:03.023238: val_loss -0.9156 
2024-11-27 06:01:03.023291: Pseudo dice [np.float32(0.9297)] 
2024-11-27 06:01:03.023350: Epoch time: 40.02 s 
2024-11-27 06:01:03.857728:  
2024-11-27 06:01:03.857945: Epoch 453 
2024-11-27 06:01:03.858025: Current learning rate: 0.00581 
2024-11-27 06:01:43.868575: train_loss -0.9632 
2024-11-27 06:01:43.868693: val_loss -0.9104 
2024-11-27 06:01:43.868745: Pseudo dice [np.float32(0.9239)] 
2024-11-27 06:01:43.868801: Epoch time: 40.01 s 
2024-11-27 06:01:45.145493:  
2024-11-27 06:01:45.145666: Epoch 454 
2024-11-27 06:01:45.145751: Current learning rate: 0.0058 
2024-11-27 06:02:25.202636: train_loss -0.961 
2024-11-27 06:02:25.202768: val_loss -0.9063 
2024-11-27 06:02:25.202822: Pseudo dice [np.float32(0.922)] 
2024-11-27 06:02:25.202960: Epoch time: 40.06 s 
2024-11-27 06:02:26.057857:  
2024-11-27 06:02:26.058108: Epoch 455 
2024-11-27 06:02:26.058178: Current learning rate: 0.00579 
2024-11-27 06:03:06.092044: train_loss -0.9616 
2024-11-27 06:03:06.092180: val_loss -0.9062 
2024-11-27 06:03:06.092263: Pseudo dice [np.float32(0.9219)] 
2024-11-27 06:03:06.092321: Epoch time: 40.04 s 
2024-11-27 06:03:06.950822:  
2024-11-27 06:03:06.951080: Epoch 456 
2024-11-27 06:03:06.951174: Current learning rate: 0.00578 
2024-11-27 06:03:46.937670: train_loss -0.9607 
2024-11-27 06:03:46.937777: val_loss -0.9054 
2024-11-27 06:03:46.937827: Pseudo dice [np.float32(0.9205)] 
2024-11-27 06:03:46.937886: Epoch time: 39.99 s 
2024-11-27 06:03:47.806791:  
2024-11-27 06:03:47.807005: Epoch 457 
2024-11-27 06:03:47.807074: Current learning rate: 0.00577 
2024-11-27 06:04:27.889025: train_loss -0.9619 
2024-11-27 06:04:27.889132: val_loss -0.9099 
2024-11-27 06:04:27.889183: Pseudo dice [np.float32(0.9235)] 
2024-11-27 06:04:27.889236: Epoch time: 40.08 s 
2024-11-27 06:04:28.754638:  
2024-11-27 06:04:28.754795: Epoch 458 
2024-11-27 06:04:28.754869: Current learning rate: 0.00576 
2024-11-27 06:05:08.824861: train_loss -0.9606 
2024-11-27 06:05:08.825027: val_loss -0.9078 
2024-11-27 06:05:08.825081: Pseudo dice [np.float32(0.9209)] 
2024-11-27 06:05:08.825140: Epoch time: 40.07 s 
2024-11-27 06:05:09.731005:  
2024-11-27 06:05:09.731159: Epoch 459 
2024-11-27 06:05:09.731230: Current learning rate: 0.00575 
2024-11-27 06:05:49.791446: train_loss -0.9627 
2024-11-27 06:05:49.791551: val_loss -0.911 
2024-11-27 06:05:49.791601: Pseudo dice [np.float32(0.9254)] 
2024-11-27 06:05:49.791655: Epoch time: 40.06 s 
2024-11-27 06:05:50.657906:  
2024-11-27 06:05:50.658090: Epoch 460 
2024-11-27 06:05:50.658158: Current learning rate: 0.00574 
2024-11-27 06:06:30.653347: train_loss -0.9631 
2024-11-27 06:06:30.653455: val_loss -0.9143 
2024-11-27 06:06:30.653506: Pseudo dice [np.float32(0.9275)] 
2024-11-27 06:06:30.653562: Epoch time: 40.0 s 
2024-11-27 06:06:31.499409:  
2024-11-27 06:06:31.499598: Epoch 461 
2024-11-27 06:06:31.499725: Current learning rate: 0.00573 
2024-11-27 06:07:11.507159: train_loss -0.964 
2024-11-27 06:07:11.507266: val_loss -0.9107 
2024-11-27 06:07:11.507318: Pseudo dice [np.float32(0.9254)] 
2024-11-27 06:07:11.507374: Epoch time: 40.01 s 
2024-11-27 06:07:12.381953:  
2024-11-27 06:07:12.382109: Epoch 462 
2024-11-27 06:07:12.382177: Current learning rate: 0.00572 
2024-11-27 06:07:52.430813: train_loss -0.9633 
2024-11-27 06:07:52.430997: val_loss -0.9083 
2024-11-27 06:07:52.431072: Pseudo dice [np.float32(0.9225)] 
2024-11-27 06:07:52.431127: Epoch time: 40.05 s 
2024-11-27 06:07:53.285183:  
2024-11-27 06:07:53.285319: Epoch 463 
2024-11-27 06:07:53.285396: Current learning rate: 0.00571 
2024-11-27 06:08:33.323548: train_loss -0.9635 
2024-11-27 06:08:33.323661: val_loss -0.9088 
2024-11-27 06:08:33.323713: Pseudo dice [np.float32(0.9234)] 
2024-11-27 06:08:33.323769: Epoch time: 40.04 s 
2024-11-27 06:08:34.194005:  
2024-11-27 06:08:34.194156: Epoch 464 
2024-11-27 06:08:34.194224: Current learning rate: 0.0057 
2024-11-27 06:09:14.266832: train_loss -0.9632 
2024-11-27 06:09:14.267001: val_loss -0.9115 
2024-11-27 06:09:14.267051: Pseudo dice [np.float32(0.9265)] 
2024-11-27 06:09:14.267105: Epoch time: 40.07 s 
2024-11-27 06:09:15.128067:  
2024-11-27 06:09:15.128302: Epoch 465 
2024-11-27 06:09:15.128371: Current learning rate: 0.0057 
2024-11-27 06:09:55.182377: train_loss -0.9622 
2024-11-27 06:09:55.182485: val_loss -0.9102 
2024-11-27 06:09:55.182535: Pseudo dice [np.float32(0.925)] 
2024-11-27 06:09:55.182589: Epoch time: 40.06 s 
2024-11-27 06:09:56.080141:  
2024-11-27 06:09:56.080277: Epoch 466 
2024-11-27 06:09:56.080346: Current learning rate: 0.00569 
2024-11-27 06:10:36.126008: train_loss -0.9604 
2024-11-27 06:10:36.126121: val_loss -0.9107 
2024-11-27 06:10:36.126172: Pseudo dice [np.float32(0.9253)] 
2024-11-27 06:10:36.126225: Epoch time: 40.05 s 
2024-11-27 06:10:36.955112:  
2024-11-27 06:10:36.955319: Epoch 467 
2024-11-27 06:10:36.955388: Current learning rate: 0.00568 
2024-11-27 06:11:17.002083: train_loss -0.9617 
2024-11-27 06:11:17.002188: val_loss -0.9122 
2024-11-27 06:11:17.002276: Pseudo dice [np.float32(0.9247)] 
2024-11-27 06:11:17.002329: Epoch time: 40.05 s 
2024-11-27 06:11:17.865926:  
2024-11-27 06:11:17.866232: Epoch 468 
2024-11-27 06:11:17.866302: Current learning rate: 0.00567 
2024-11-27 06:11:57.853326: train_loss -0.9634 
2024-11-27 06:11:57.853548: val_loss -0.9124 
2024-11-27 06:11:57.853626: Pseudo dice [np.float32(0.9255)] 
2024-11-27 06:11:57.853701: Epoch time: 39.99 s 
2024-11-27 06:11:58.686060:  
2024-11-27 06:11:58.686190: Epoch 469 
2024-11-27 06:11:58.686280: Current learning rate: 0.00566 
2024-11-27 06:12:38.734952: train_loss -0.9639 
2024-11-27 06:12:38.735060: val_loss -0.9118 
2024-11-27 06:12:38.735110: Pseudo dice [np.float32(0.9262)] 
2024-11-27 06:12:38.735167: Epoch time: 40.05 s 
2024-11-27 06:12:39.631927:  
2024-11-27 06:12:39.632108: Epoch 470 
2024-11-27 06:12:39.632196: Current learning rate: 0.00565 
2024-11-27 06:13:19.668181: train_loss -0.9636 
2024-11-27 06:13:19.668294: val_loss -0.905 
2024-11-27 06:13:19.668343: Pseudo dice [np.float32(0.9206)] 
2024-11-27 06:13:19.668397: Epoch time: 40.04 s 
2024-11-27 06:13:20.533446:  
2024-11-27 06:13:20.533612: Epoch 471 
2024-11-27 06:13:20.533681: Current learning rate: 0.00564 
2024-11-27 06:14:00.564171: train_loss -0.9634 
2024-11-27 06:14:00.564284: val_loss -0.9116 
2024-11-27 06:14:00.564338: Pseudo dice [np.float32(0.9269)] 
2024-11-27 06:14:00.564395: Epoch time: 40.03 s 
2024-11-27 06:14:01.456338:  
2024-11-27 06:14:01.456540: Epoch 472 
2024-11-27 06:14:01.456613: Current learning rate: 0.00563 
2024-11-27 06:14:41.497512: train_loss -0.9642 
2024-11-27 06:14:41.497621: val_loss -0.9049 
2024-11-27 06:14:41.497671: Pseudo dice [np.float32(0.9198)] 
2024-11-27 06:14:41.497726: Epoch time: 40.04 s 
2024-11-27 06:14:42.340625:  
2024-11-27 06:14:42.340818: Epoch 473 
2024-11-27 06:14:42.340910: Current learning rate: 0.00562 
2024-11-27 06:15:22.376486: train_loss -0.9638 
2024-11-27 06:15:22.376595: val_loss -0.9105 
2024-11-27 06:15:22.376647: Pseudo dice [np.float32(0.9242)] 
2024-11-27 06:15:22.376706: Epoch time: 40.04 s 
2024-11-27 06:15:23.684059:  
2024-11-27 06:15:23.684211: Epoch 474 
2024-11-27 06:15:23.684317: Current learning rate: 0.00561 
2024-11-27 06:16:03.737956: train_loss -0.9641 
2024-11-27 06:16:03.738077: val_loss -0.9111 
2024-11-27 06:16:03.738129: Pseudo dice [np.float32(0.9255)] 
2024-11-27 06:16:03.738184: Epoch time: 40.05 s 
2024-11-27 06:16:04.574816:  
2024-11-27 06:16:04.574982: Epoch 475 
2024-11-27 06:16:04.575054: Current learning rate: 0.0056 
2024-11-27 06:16:44.645597: train_loss -0.9644 
2024-11-27 06:16:44.645728: val_loss -0.9118 
2024-11-27 06:16:44.645785: Pseudo dice [np.float32(0.9262)] 
2024-11-27 06:16:44.645844: Epoch time: 40.07 s 
2024-11-27 06:16:45.513916:  
2024-11-27 06:16:45.514103: Epoch 476 
2024-11-27 06:16:45.514175: Current learning rate: 0.00559 
2024-11-27 06:17:25.587522: train_loss -0.965 
2024-11-27 06:17:25.587650: val_loss -0.9103 
2024-11-27 06:17:25.587702: Pseudo dice [np.float32(0.9246)] 
2024-11-27 06:17:25.587758: Epoch time: 40.07 s 
2024-11-27 06:17:26.478833:  
2024-11-27 06:17:26.479091: Epoch 477 
2024-11-27 06:17:26.479240: Current learning rate: 0.00558 
2024-11-27 06:18:06.531421: train_loss -0.9627 
2024-11-27 06:18:06.531637: val_loss -0.9086 
2024-11-27 06:18:06.531730: Pseudo dice [np.float32(0.9244)] 
2024-11-27 06:18:06.531790: Epoch time: 40.05 s 
2024-11-27 06:18:07.472567:  
2024-11-27 06:18:07.472793: Epoch 478 
2024-11-27 06:18:07.472885: Current learning rate: 0.00557 
2024-11-27 06:18:47.517254: train_loss -0.9613 
2024-11-27 06:18:47.517362: val_loss -0.9054 
2024-11-27 06:18:47.517415: Pseudo dice [np.float32(0.92)] 
2024-11-27 06:18:47.517524: Epoch time: 40.05 s 
2024-11-27 06:18:48.404259:  
2024-11-27 06:18:48.404446: Epoch 479 
2024-11-27 06:18:48.404519: Current learning rate: 0.00556 
2024-11-27 06:19:28.441698: train_loss -0.9579 
2024-11-27 06:19:28.441809: val_loss -0.9039 
2024-11-27 06:19:28.441859: Pseudo dice [np.float32(0.9199)] 
2024-11-27 06:19:28.441993: Epoch time: 40.04 s 
2024-11-27 06:19:29.299179:  
2024-11-27 06:19:29.299368: Epoch 480 
2024-11-27 06:19:29.299436: Current learning rate: 0.00555 
2024-11-27 06:20:09.366705: train_loss -0.9592 
2024-11-27 06:20:09.366814: val_loss -0.9098 
2024-11-27 06:20:09.366870: Pseudo dice [np.float32(0.9229)] 
2024-11-27 06:20:09.366926: Epoch time: 40.07 s 
2024-11-27 06:20:10.299952:  
2024-11-27 06:20:10.300121: Epoch 481 
2024-11-27 06:20:10.300190: Current learning rate: 0.00554 
2024-11-27 06:20:50.295601: train_loss -0.9619 
2024-11-27 06:20:50.295717: val_loss -0.9115 
2024-11-27 06:20:50.295773: Pseudo dice [np.float32(0.9262)] 
2024-11-27 06:20:50.295831: Epoch time: 40.0 s 
2024-11-27 06:20:51.167166:  
2024-11-27 06:20:51.167340: Epoch 482 
2024-11-27 06:20:51.167431: Current learning rate: 0.00553 
2024-11-27 06:21:31.258602: train_loss -0.9605 
2024-11-27 06:21:31.258713: val_loss -0.9092 
2024-11-27 06:21:31.258763: Pseudo dice [np.float32(0.9237)] 
2024-11-27 06:21:31.258819: Epoch time: 40.09 s 
2024-11-27 06:21:32.145144:  
2024-11-27 06:21:32.145365: Epoch 483 
2024-11-27 06:21:32.145452: Current learning rate: 0.00552 
2024-11-27 06:22:12.201812: train_loss -0.9625 
2024-11-27 06:22:12.202004: val_loss -0.9104 
2024-11-27 06:22:12.202075: Pseudo dice [np.float32(0.9236)] 
2024-11-27 06:22:12.202150: Epoch time: 40.06 s 
2024-11-27 06:22:13.089374:  
2024-11-27 06:22:13.089584: Epoch 484 
2024-11-27 06:22:13.089656: Current learning rate: 0.00551 
2024-11-27 06:22:53.137518: train_loss -0.9605 
2024-11-27 06:22:53.137628: val_loss -0.909 
2024-11-27 06:22:53.137682: Pseudo dice [np.float32(0.9248)] 
2024-11-27 06:22:53.137764: Epoch time: 40.05 s 
2024-11-27 06:22:54.051991:  
2024-11-27 06:22:54.052172: Epoch 485 
2024-11-27 06:22:54.052260: Current learning rate: 0.0055 
2024-11-27 06:23:34.100565: train_loss -0.9621 
2024-11-27 06:23:34.100678: val_loss -0.911 
2024-11-27 06:23:34.100730: Pseudo dice [np.float32(0.9243)] 
2024-11-27 06:23:34.100819: Epoch time: 40.05 s 
2024-11-27 06:23:35.007059:  
2024-11-27 06:23:35.007233: Epoch 486 
2024-11-27 06:23:35.007336: Current learning rate: 0.00549 
2024-11-27 06:24:14.964177: train_loss -0.9614 
2024-11-27 06:24:14.964288: val_loss -0.9139 
2024-11-27 06:24:14.964342: Pseudo dice [np.float32(0.9274)] 
2024-11-27 06:24:14.964399: Epoch time: 39.96 s 
2024-11-27 06:24:15.806773:  
2024-11-27 06:24:15.806929: Epoch 487 
2024-11-27 06:24:15.807011: Current learning rate: 0.00548 
2024-11-27 06:24:55.922813: train_loss -0.9621 
2024-11-27 06:24:55.922991: val_loss -0.9079 
2024-11-27 06:24:55.923044: Pseudo dice [np.float32(0.9214)] 
2024-11-27 06:24:55.923108: Epoch time: 40.12 s 
2024-11-27 06:24:56.801425:  
2024-11-27 06:24:56.801657: Epoch 488 
2024-11-27 06:24:56.801731: Current learning rate: 0.00547 
2024-11-27 06:25:36.800641: train_loss -0.9641 
2024-11-27 06:25:36.800752: val_loss -0.9051 
2024-11-27 06:25:36.800805: Pseudo dice [np.float32(0.9205)] 
2024-11-27 06:25:36.800863: Epoch time: 40.0 s 
2024-11-27 06:25:37.666523:  
2024-11-27 06:25:37.666699: Epoch 489 
2024-11-27 06:25:37.666770: Current learning rate: 0.00546 
2024-11-27 06:26:17.661644: train_loss -0.9637 
2024-11-27 06:26:17.661784: val_loss -0.9095 
2024-11-27 06:26:17.661855: Pseudo dice [np.float32(0.9245)] 
2024-11-27 06:26:17.661940: Epoch time: 40.0 s 
2024-11-27 06:26:18.647785:  
2024-11-27 06:26:18.647970: Epoch 490 
2024-11-27 06:26:18.648059: Current learning rate: 0.00546 
2024-11-27 06:26:58.647664: train_loss -0.9635 
2024-11-27 06:26:58.647795: val_loss -0.9107 
2024-11-27 06:26:58.647848: Pseudo dice [np.float32(0.9251)] 
2024-11-27 06:26:58.647971: Epoch time: 40.0 s 
2024-11-27 06:26:59.511221:  
2024-11-27 06:26:59.511378: Epoch 491 
2024-11-27 06:26:59.511601: Current learning rate: 0.00545 
2024-11-27 06:27:39.506768: train_loss -0.9634 
2024-11-27 06:27:39.506933: val_loss -0.9108 
2024-11-27 06:27:39.506988: Pseudo dice [np.float32(0.9248)] 
2024-11-27 06:27:39.507046: Epoch time: 40.0 s 
2024-11-27 06:27:40.347813:  
2024-11-27 06:27:40.348025: Epoch 492 
2024-11-27 06:27:40.348096: Current learning rate: 0.00544 
2024-11-27 06:28:20.363417: train_loss -0.9621 
2024-11-27 06:28:20.363530: val_loss -0.9096 
2024-11-27 06:28:20.363586: Pseudo dice [np.float32(0.9251)] 
2024-11-27 06:28:20.363647: Epoch time: 40.02 s 
2024-11-27 06:28:21.224498:  
2024-11-27 06:28:21.224642: Epoch 493 
2024-11-27 06:28:21.224711: Current learning rate: 0.00543 
2024-11-27 06:29:01.241796: train_loss -0.9608 
2024-11-27 06:29:01.241938: val_loss -0.9084 
2024-11-27 06:29:01.241993: Pseudo dice [np.float32(0.9224)] 
2024-11-27 06:29:01.242051: Epoch time: 40.02 s 
2024-11-27 06:29:02.543017:  
2024-11-27 06:29:02.543174: Epoch 494 
2024-11-27 06:29:02.543246: Current learning rate: 0.00542 
2024-11-27 06:29:42.564628: train_loss -0.9594 
2024-11-27 06:29:42.564794: val_loss -0.9064 
2024-11-27 06:29:42.564857: Pseudo dice [np.float32(0.921)] 
2024-11-27 06:29:42.564976: Epoch time: 40.02 s 
2024-11-27 06:29:43.425274:  
2024-11-27 06:29:43.425530: Epoch 495 
2024-11-27 06:29:43.425604: Current learning rate: 0.00541 
2024-11-27 06:30:23.487076: train_loss -0.958 
2024-11-27 06:30:23.487184: val_loss -0.9046 
2024-11-27 06:30:23.487235: Pseudo dice [np.float32(0.9193)] 
2024-11-27 06:30:23.487291: Epoch time: 40.06 s 
2024-11-27 06:30:24.420814:  
2024-11-27 06:30:24.421015: Epoch 496 
2024-11-27 06:30:24.421088: Current learning rate: 0.0054 
2024-11-27 06:31:04.483356: train_loss -0.9595 
2024-11-27 06:31:04.483465: val_loss -0.9092 
2024-11-27 06:31:04.483518: Pseudo dice [np.float32(0.9232)] 
2024-11-27 06:31:04.483575: Epoch time: 40.06 s 
2024-11-27 06:31:05.377376:  
2024-11-27 06:31:05.377630: Epoch 497 
2024-11-27 06:31:05.377744: Current learning rate: 0.00539 
2024-11-27 06:31:45.438211: train_loss -0.9578 
2024-11-27 06:31:45.438314: val_loss -0.911 
2024-11-27 06:31:45.438370: Pseudo dice [np.float32(0.9245)] 
2024-11-27 06:31:45.438427: Epoch time: 40.06 s 
2024-11-27 06:31:46.309190:  
2024-11-27 06:31:46.309452: Epoch 498 
2024-11-27 06:31:46.309522: Current learning rate: 0.00538 
2024-11-27 06:32:26.379129: train_loss -0.9598 
2024-11-27 06:32:26.379240: val_loss -0.9093 
2024-11-27 06:32:26.379305: Pseudo dice [np.float32(0.9231)] 
2024-11-27 06:32:26.379360: Epoch time: 40.07 s 
2024-11-27 06:32:27.226104:  
2024-11-27 06:32:27.226311: Epoch 499 
2024-11-27 06:32:27.226406: Current learning rate: 0.00537 
2024-11-27 06:33:07.310921: train_loss -0.9602 
2024-11-27 06:33:07.311049: val_loss -0.9089 
2024-11-27 06:33:07.311101: Pseudo dice [np.float32(0.9248)] 
2024-11-27 06:33:07.311155: Epoch time: 40.09 s 
2024-11-27 06:33:10.405771:  
2024-11-27 06:33:10.406091: Epoch 500 
2024-11-27 06:33:10.406160: Current learning rate: 0.00536 
2024-11-27 06:33:50.331486: train_loss -0.961 
2024-11-27 06:33:50.331599: val_loss -0.9033 
2024-11-27 06:33:50.331659: Pseudo dice [np.float32(0.918)] 
2024-11-27 06:33:50.331713: Epoch time: 39.93 s 
2024-11-27 06:33:51.163723:  
2024-11-27 06:33:51.163939: Epoch 501 
2024-11-27 06:33:51.164006: Current learning rate: 0.00535 
2024-11-27 06:34:31.240794: train_loss -0.962 
2024-11-27 06:34:31.240956: val_loss -0.9147 
2024-11-27 06:34:31.241009: Pseudo dice [np.float32(0.9282)] 
2024-11-27 06:34:31.241062: Epoch time: 40.08 s 
2024-11-27 06:34:32.148144:  
2024-11-27 06:34:32.148318: Epoch 502 
2024-11-27 06:34:32.148388: Current learning rate: 0.00534 
2024-11-27 06:35:12.186166: train_loss -0.9617 
2024-11-27 06:35:12.186272: val_loss -0.9027 
2024-11-27 06:35:12.186321: Pseudo dice [np.float32(0.9191)] 
2024-11-27 06:35:12.186374: Epoch time: 40.04 s 
2024-11-27 06:35:13.043259:  
2024-11-27 06:35:13.043398: Epoch 503 
2024-11-27 06:35:13.043479: Current learning rate: 0.00533 
2024-11-27 06:35:53.063694: train_loss -0.9581 
2024-11-27 06:35:53.063823: val_loss -0.9084 
2024-11-27 06:35:53.063881: Pseudo dice [np.float32(0.9223)] 
2024-11-27 06:35:53.063984: Epoch time: 40.02 s 
2024-11-27 06:35:54.000716:  
2024-11-27 06:35:54.000950: Epoch 504 
2024-11-27 06:35:54.001117: Current learning rate: 0.00532 
2024-11-27 06:36:34.047537: train_loss -0.959 
2024-11-27 06:36:34.047699: val_loss -0.9086 
2024-11-27 06:36:34.047770: Pseudo dice [np.float32(0.9217)] 
2024-11-27 06:36:34.047844: Epoch time: 40.05 s 
2024-11-27 06:36:34.950036:  
2024-11-27 06:36:34.950474: Epoch 505 
2024-11-27 06:36:34.950603: Current learning rate: 0.00531 
2024-11-27 06:37:14.977645: train_loss -0.961 
2024-11-27 06:37:14.977771: val_loss -0.9099 
2024-11-27 06:37:14.977826: Pseudo dice [np.float32(0.9231)] 
2024-11-27 06:37:14.977935: Epoch time: 40.03 s 
2024-11-27 06:37:15.858394:  
2024-11-27 06:37:15.858527: Epoch 506 
2024-11-27 06:37:15.858597: Current learning rate: 0.0053 
2024-11-27 06:37:55.897110: train_loss -0.9608 
2024-11-27 06:37:55.897245: val_loss -0.9092 
2024-11-27 06:37:55.897297: Pseudo dice [np.float32(0.9236)] 
2024-11-27 06:37:55.897352: Epoch time: 40.04 s 
2024-11-27 06:37:56.785946:  
2024-11-27 06:37:56.786189: Epoch 507 
2024-11-27 06:37:56.786360: Current learning rate: 0.00529 
2024-11-27 06:38:36.870032: train_loss -0.9604 
2024-11-27 06:38:36.870158: val_loss -0.9025 
2024-11-27 06:38:36.870209: Pseudo dice [np.float32(0.917)] 
2024-11-27 06:38:36.870266: Epoch time: 40.08 s 
2024-11-27 06:38:37.756433:  
2024-11-27 06:38:37.756569: Epoch 508 
2024-11-27 06:38:37.756639: Current learning rate: 0.00528 
2024-11-27 06:39:17.823889: train_loss -0.9576 
2024-11-27 06:39:17.824029: val_loss -0.9121 
2024-11-27 06:39:17.824098: Pseudo dice [np.float32(0.9261)] 
2024-11-27 06:39:17.824172: Epoch time: 40.07 s 
2024-11-27 06:39:18.683397:  
2024-11-27 06:39:18.683536: Epoch 509 
2024-11-27 06:39:18.683605: Current learning rate: 0.00527 
2024-11-27 06:39:58.725285: train_loss -0.9617 
2024-11-27 06:39:58.725393: val_loss -0.9071 
2024-11-27 06:39:58.725444: Pseudo dice [np.float32(0.9224)] 
2024-11-27 06:39:58.725500: Epoch time: 40.04 s 
2024-11-27 06:39:59.629395:  
2024-11-27 06:39:59.629558: Epoch 510 
2024-11-27 06:39:59.629628: Current learning rate: 0.00526 
2024-11-27 06:40:39.701848: train_loss -0.9593 
2024-11-27 06:40:39.702006: val_loss -0.9073 
2024-11-27 06:40:39.702056: Pseudo dice [np.float32(0.9222)] 
2024-11-27 06:40:39.702110: Epoch time: 40.07 s 
2024-11-27 06:40:40.598385:  
2024-11-27 06:40:40.598594: Epoch 511 
2024-11-27 06:40:40.598700: Current learning rate: 0.00525 
2024-11-27 06:41:20.637606: train_loss -0.9573 
2024-11-27 06:41:20.637714: val_loss -0.9054 
2024-11-27 06:41:20.637767: Pseudo dice [np.float32(0.9189)] 
2024-11-27 06:41:20.637823: Epoch time: 40.04 s 
2024-11-27 06:41:21.563294:  
2024-11-27 06:41:21.563493: Epoch 512 
2024-11-27 06:41:21.563589: Current learning rate: 0.00524 
2024-11-27 06:42:01.590223: train_loss -0.9617 
2024-11-27 06:42:01.590330: val_loss -0.9083 
2024-11-27 06:42:01.590382: Pseudo dice [np.float32(0.9244)] 
2024-11-27 06:42:01.590439: Epoch time: 40.03 s 
2024-11-27 06:42:02.909335:  
2024-11-27 06:42:02.909493: Epoch 513 
2024-11-27 06:42:02.909576: Current learning rate: 0.00523 
2024-11-27 06:42:42.998561: train_loss -0.9596 
2024-11-27 06:42:42.998683: val_loss -0.9016 
2024-11-27 06:42:42.998734: Pseudo dice [np.float32(0.9174)] 
2024-11-27 06:42:42.998789: Epoch time: 40.09 s 
2024-11-27 06:42:43.837534:  
2024-11-27 06:42:43.837699: Epoch 514 
2024-11-27 06:42:43.837770: Current learning rate: 0.00522 
2024-11-27 06:43:23.896340: train_loss -0.9496 
2024-11-27 06:43:23.896475: val_loss -0.9018 
2024-11-27 06:43:23.896528: Pseudo dice [np.float32(0.9169)] 
2024-11-27 06:43:23.896617: Epoch time: 40.06 s 
2024-11-27 06:43:24.773240:  
2024-11-27 06:43:24.773436: Epoch 515 
2024-11-27 06:43:24.773545: Current learning rate: 0.00521 
2024-11-27 06:44:04.861923: train_loss -0.9512 
2024-11-27 06:44:04.862055: val_loss -0.9084 
2024-11-27 06:44:04.862107: Pseudo dice [np.float32(0.9233)] 
2024-11-27 06:44:04.862162: Epoch time: 40.09 s 
2024-11-27 06:44:05.756999:  
2024-11-27 06:44:05.757223: Epoch 516 
2024-11-27 06:44:05.757298: Current learning rate: 0.0052 
2024-11-27 06:44:45.815966: train_loss -0.9435 
2024-11-27 06:44:45.816155: val_loss -0.8975 
2024-11-27 06:44:45.816230: Pseudo dice [np.float32(0.9143)] 
2024-11-27 06:44:45.816340: Epoch time: 40.06 s 
2024-11-27 06:44:46.706558:  
2024-11-27 06:44:46.706773: Epoch 517 
2024-11-27 06:44:46.706872: Current learning rate: 0.00519 
2024-11-27 06:45:26.728053: train_loss -0.9489 
2024-11-27 06:45:26.728161: val_loss -0.9062 
2024-11-27 06:45:26.728211: Pseudo dice [np.float32(0.921)] 
2024-11-27 06:45:26.728265: Epoch time: 40.02 s 
2024-11-27 06:45:27.578962:  
2024-11-27 06:45:27.579217: Epoch 518 
2024-11-27 06:45:27.579287: Current learning rate: 0.00518 
2024-11-27 06:46:07.605635: train_loss -0.9565 
2024-11-27 06:46:07.605741: val_loss -0.9041 
2024-11-27 06:46:07.605795: Pseudo dice [np.float32(0.919)] 
2024-11-27 06:46:07.605851: Epoch time: 40.03 s 
2024-11-27 06:46:08.494229:  
2024-11-27 06:46:08.494422: Epoch 519 
2024-11-27 06:46:08.494502: Current learning rate: 0.00518 
2024-11-27 06:46:48.511890: train_loss -0.9598 
2024-11-27 06:46:48.511999: val_loss -0.9078 
2024-11-27 06:46:48.512048: Pseudo dice [np.float32(0.9222)] 
2024-11-27 06:46:48.512102: Epoch time: 40.02 s 
2024-11-27 06:46:49.347765:  
2024-11-27 06:46:49.347945: Epoch 520 
2024-11-27 06:46:49.348015: Current learning rate: 0.00517 
2024-11-27 06:47:29.352285: train_loss -0.9598 
2024-11-27 06:47:29.352404: val_loss -0.9108 
2024-11-27 06:47:29.352486: Pseudo dice [np.float32(0.9248)] 
2024-11-27 06:47:29.352562: Epoch time: 40.01 s 
2024-11-27 06:47:30.260545:  
2024-11-27 06:47:30.260710: Epoch 521 
2024-11-27 06:47:30.260813: Current learning rate: 0.00516 
2024-11-27 06:48:10.300881: train_loss -0.9615 
2024-11-27 06:48:10.301050: val_loss -0.9127 
2024-11-27 06:48:10.301103: Pseudo dice [np.float32(0.9263)] 
2024-11-27 06:48:10.301160: Epoch time: 40.04 s 
2024-11-27 06:48:11.171451:  
2024-11-27 06:48:11.171625: Epoch 522 
2024-11-27 06:48:11.171705: Current learning rate: 0.00515 
2024-11-27 06:48:51.229375: train_loss -0.9618 
2024-11-27 06:48:51.229485: val_loss -0.9026 
2024-11-27 06:48:51.229539: Pseudo dice [np.float32(0.9173)] 
2024-11-27 06:48:51.229653: Epoch time: 40.06 s 
2024-11-27 06:48:52.207772:  
2024-11-27 06:48:52.207954: Epoch 523 
2024-11-27 06:48:52.208043: Current learning rate: 0.00514 
2024-11-27 06:49:32.235658: train_loss -0.9629 
2024-11-27 06:49:32.235785: val_loss -0.9093 
2024-11-27 06:49:32.235836: Pseudo dice [np.float32(0.9235)] 
2024-11-27 06:49:32.235893: Epoch time: 40.03 s 
2024-11-27 06:49:33.118472:  
2024-11-27 06:49:33.118603: Epoch 524 
2024-11-27 06:49:33.118670: Current learning rate: 0.00513 
2024-11-27 06:50:13.163458: train_loss -0.9615 
2024-11-27 06:50:13.163582: val_loss -0.9148 
2024-11-27 06:50:13.163639: Pseudo dice [np.float32(0.9276)] 
2024-11-27 06:50:13.163694: Epoch time: 40.05 s 
2024-11-27 06:50:14.028055:  
2024-11-27 06:50:14.028175: Epoch 525 
2024-11-27 06:50:14.028255: Current learning rate: 0.00512 
2024-11-27 06:50:54.084794: train_loss -0.962 
2024-11-27 06:50:54.084960: val_loss -0.9123 
2024-11-27 06:50:54.085017: Pseudo dice [np.float32(0.9266)] 
2024-11-27 06:50:54.085074: Epoch time: 40.06 s 
2024-11-27 06:50:54.968705:  
2024-11-27 06:50:54.968837: Epoch 526 
2024-11-27 06:50:54.968959: Current learning rate: 0.00511 
2024-11-27 06:51:34.989335: train_loss -0.9628 
2024-11-27 06:51:34.989444: val_loss -0.9117 
2024-11-27 06:51:34.989495: Pseudo dice [np.float32(0.9262)] 
2024-11-27 06:51:34.989581: Epoch time: 40.02 s 
2024-11-27 06:51:35.860816:  
2024-11-27 06:51:35.861149: Epoch 527 
2024-11-27 06:51:35.861222: Current learning rate: 0.0051 
2024-11-27 06:52:15.892304: train_loss -0.9639 
2024-11-27 06:52:15.892412: val_loss -0.91 
2024-11-27 06:52:15.892462: Pseudo dice [np.float32(0.9249)] 
2024-11-27 06:52:15.892518: Epoch time: 40.03 s 
2024-11-27 06:52:16.767779:  
2024-11-27 06:52:16.767946: Epoch 528 
2024-11-27 06:52:16.768014: Current learning rate: 0.00509 
2024-11-27 06:52:56.801156: train_loss -0.9632 
2024-11-27 06:52:56.801270: val_loss -0.9124 
2024-11-27 06:52:56.801325: Pseudo dice [np.float32(0.9269)] 
2024-11-27 06:52:56.801382: Epoch time: 40.03 s 
2024-11-27 06:52:57.683105:  
2024-11-27 06:52:57.683263: Epoch 529 
2024-11-27 06:52:57.683337: Current learning rate: 0.00508 
2024-11-27 06:53:37.746181: train_loss -0.9632 
2024-11-27 06:53:37.746293: val_loss -0.9062 
2024-11-27 06:53:37.746345: Pseudo dice [np.float32(0.9201)] 
2024-11-27 06:53:37.746439: Epoch time: 40.06 s 
2024-11-27 06:53:38.638700:  
2024-11-27 06:53:38.638931: Epoch 530 
2024-11-27 06:53:38.639021: Current learning rate: 0.00507 
2024-11-27 06:54:18.652518: train_loss -0.9637 
2024-11-27 06:54:18.652625: val_loss -0.9091 
2024-11-27 06:54:18.652677: Pseudo dice [np.float32(0.9227)] 
2024-11-27 06:54:18.652734: Epoch time: 40.01 s 
2024-11-27 06:54:19.564267:  
2024-11-27 06:54:19.564519: Epoch 531 
2024-11-27 06:54:19.564606: Current learning rate: 0.00506 
2024-11-27 06:54:59.591482: train_loss -0.9639 
2024-11-27 06:54:59.591592: val_loss -0.9045 
2024-11-27 06:54:59.591643: Pseudo dice [np.float32(0.9208)] 
2024-11-27 06:54:59.591735: Epoch time: 40.03 s 
2024-11-27 06:55:00.479750:  
2024-11-27 06:55:00.479921: Epoch 532 
2024-11-27 06:55:00.480021: Current learning rate: 0.00505 
2024-11-27 06:55:40.525270: train_loss -0.9641 
2024-11-27 06:55:40.525426: val_loss -0.9085 
2024-11-27 06:55:40.525495: Pseudo dice [np.float32(0.9226)] 
2024-11-27 06:55:40.525569: Epoch time: 40.05 s 
2024-11-27 06:55:41.880294:  
2024-11-27 06:55:41.880464: Epoch 533 
2024-11-27 06:55:41.880545: Current learning rate: 0.00504 
2024-11-27 06:56:21.964327: train_loss -0.9645 
2024-11-27 06:56:21.964450: val_loss -0.9066 
2024-11-27 06:56:21.964521: Pseudo dice [np.float32(0.9212)] 
2024-11-27 06:56:21.964575: Epoch time: 40.08 s 
2024-11-27 06:56:22.849054:  
2024-11-27 06:56:22.849211: Epoch 534 
2024-11-27 06:56:22.849281: Current learning rate: 0.00503 
2024-11-27 06:57:02.909274: train_loss -0.9623 
2024-11-27 06:57:02.909387: val_loss -0.9015 
2024-11-27 06:57:02.909439: Pseudo dice [np.float32(0.917)] 
2024-11-27 06:57:02.909532: Epoch time: 40.06 s 
2024-11-27 06:57:03.835243:  
2024-11-27 06:57:03.835398: Epoch 535 
2024-11-27 06:57:03.835469: Current learning rate: 0.00502 
2024-11-27 06:57:44.033177: train_loss -0.9644 
2024-11-27 06:57:44.033306: val_loss -0.9081 
2024-11-27 06:57:44.033359: Pseudo dice [np.float32(0.9221)] 
2024-11-27 06:57:44.033416: Epoch time: 40.2 s 
2024-11-27 06:57:44.881972:  
2024-11-27 06:57:44.882117: Epoch 536 
2024-11-27 06:57:44.882187: Current learning rate: 0.00501 
2024-11-27 06:58:25.066152: train_loss -0.9663 
2024-11-27 06:58:25.066368: val_loss -0.9126 
2024-11-27 06:58:25.066420: Pseudo dice [np.float32(0.9269)] 
2024-11-27 06:58:25.066483: Epoch time: 40.19 s 
2024-11-27 06:58:25.923255:  
2024-11-27 06:58:25.923524: Epoch 537 
2024-11-27 06:58:25.923594: Current learning rate: 0.005 
2024-11-27 06:59:05.990545: train_loss -0.9644 
2024-11-27 06:59:05.990700: val_loss -0.9066 
2024-11-27 06:59:05.990752: Pseudo dice [np.float32(0.9215)] 
2024-11-27 06:59:05.990807: Epoch time: 40.07 s 
2024-11-27 06:59:06.856068:  
2024-11-27 06:59:06.856244: Epoch 538 
2024-11-27 06:59:06.856313: Current learning rate: 0.00499 
2024-11-27 06:59:46.893395: train_loss -0.9622 
2024-11-27 06:59:46.893526: val_loss -0.9111 
2024-11-27 06:59:46.893579: Pseudo dice [np.float32(0.9254)] 
2024-11-27 06:59:46.893635: Epoch time: 40.04 s 
2024-11-27 06:59:47.794306:  
2024-11-27 06:59:47.794538: Epoch 539 
2024-11-27 06:59:47.794624: Current learning rate: 0.00498 
2024-11-27 07:00:27.850761: train_loss -0.9613 
2024-11-27 07:00:27.850930: val_loss -0.9024 
2024-11-27 07:00:27.850984: Pseudo dice [np.float32(0.9166)] 
2024-11-27 07:00:27.851042: Epoch time: 40.06 s 
2024-11-27 07:00:28.759483:  
2024-11-27 07:00:28.759774: Epoch 540 
2024-11-27 07:00:28.759863: Current learning rate: 0.00497 
2024-11-27 07:01:08.788666: train_loss -0.9617 
2024-11-27 07:01:08.788816: val_loss -0.9032 
2024-11-27 07:01:08.788903: Pseudo dice [np.float32(0.9187)] 
2024-11-27 07:01:08.788980: Epoch time: 40.03 s 
2024-11-27 07:01:09.694012:  
2024-11-27 07:01:09.694158: Epoch 541 
2024-11-27 07:01:09.694231: Current learning rate: 0.00496 
2024-11-27 07:01:49.705301: train_loss -0.9648 
2024-11-27 07:01:49.705458: val_loss -0.9081 
2024-11-27 07:01:49.705562: Pseudo dice [np.float32(0.9215)] 
2024-11-27 07:01:49.705664: Epoch time: 40.01 s 
2024-11-27 07:01:50.619545:  
2024-11-27 07:01:50.619687: Epoch 542 
2024-11-27 07:01:50.619776: Current learning rate: 0.00495 
2024-11-27 07:02:30.641885: train_loss -0.9659 
2024-11-27 07:02:30.642015: val_loss -0.9089 
2024-11-27 07:02:30.642067: Pseudo dice [np.float32(0.923)] 
2024-11-27 07:02:30.642123: Epoch time: 40.02 s 
2024-11-27 07:02:31.555146:  
2024-11-27 07:02:31.555277: Epoch 543 
2024-11-27 07:02:31.555347: Current learning rate: 0.00494 
2024-11-27 07:03:11.558093: train_loss -0.964 
2024-11-27 07:03:11.558249: val_loss -0.9125 
2024-11-27 07:03:11.558303: Pseudo dice [np.float32(0.9257)] 
2024-11-27 07:03:11.558356: Epoch time: 40.0 s 
2024-11-27 07:03:12.398349:  
2024-11-27 07:03:12.398515: Epoch 544 
2024-11-27 07:03:12.398584: Current learning rate: 0.00493 
2024-11-27 07:03:52.385650: train_loss -0.9614 
2024-11-27 07:03:52.385865: val_loss -0.9106 
2024-11-27 07:03:52.385968: Pseudo dice [np.float32(0.9257)] 
2024-11-27 07:03:52.386022: Epoch time: 39.99 s 
2024-11-27 07:03:53.246987:  
2024-11-27 07:03:53.247130: Epoch 545 
2024-11-27 07:03:53.247229: Current learning rate: 0.00492 
2024-11-27 07:04:33.311621: train_loss -0.963 
2024-11-27 07:04:33.311750: val_loss -0.9064 
2024-11-27 07:04:33.311804: Pseudo dice [np.float32(0.9211)] 
2024-11-27 07:04:33.311861: Epoch time: 40.07 s 
2024-11-27 07:04:34.149377:  
2024-11-27 07:04:34.149518: Epoch 546 
2024-11-27 07:04:34.149589: Current learning rate: 0.00491 
2024-11-27 07:05:14.154451: train_loss -0.9645 
2024-11-27 07:05:14.154581: val_loss -0.912 
2024-11-27 07:05:14.154632: Pseudo dice [np.float32(0.9265)] 
2024-11-27 07:05:14.154686: Epoch time: 40.01 s 
2024-11-27 07:05:15.008228:  
2024-11-27 07:05:15.008362: Epoch 547 
2024-11-27 07:05:15.008429: Current learning rate: 0.0049 
2024-11-27 07:05:54.990567: train_loss -0.9635 
2024-11-27 07:05:54.990680: val_loss -0.9131 
2024-11-27 07:05:54.990750: Pseudo dice [np.float32(0.9273)] 
2024-11-27 07:05:54.990807: Epoch time: 39.98 s 
2024-11-27 07:05:55.899240:  
2024-11-27 07:05:55.899345: Epoch 548 
2024-11-27 07:05:55.899415: Current learning rate: 0.00489 
2024-11-27 07:06:35.925250: train_loss -0.9643 
2024-11-27 07:06:35.925409: val_loss -0.9142 
2024-11-27 07:06:35.925505: Pseudo dice [np.float32(0.9282)] 
2024-11-27 07:06:35.925579: Epoch time: 40.03 s 
2024-11-27 07:06:36.808587:  
2024-11-27 07:06:36.808762: Epoch 549 
2024-11-27 07:06:36.808845: Current learning rate: 0.00488 
2024-11-27 07:07:16.822818: train_loss -0.9652 
2024-11-27 07:07:16.822931: val_loss -0.9149 
2024-11-27 07:07:16.822983: Pseudo dice [np.float32(0.9271)] 
2024-11-27 07:07:16.823040: Epoch time: 40.02 s 
2024-11-27 07:07:20.129539:  
2024-11-27 07:07:20.129667: Epoch 550 
2024-11-27 07:07:20.129739: Current learning rate: 0.00487 
2024-11-27 07:08:00.067569: train_loss -0.9656 
2024-11-27 07:08:00.067705: val_loss -0.9095 
2024-11-27 07:08:00.067773: Pseudo dice [np.float32(0.9236)] 
2024-11-27 07:08:00.067845: Epoch time: 39.94 s 
2024-11-27 07:08:00.958977:  
2024-11-27 07:08:00.959226: Epoch 551 
2024-11-27 07:08:00.959420: Current learning rate: 0.00486 
2024-11-27 07:08:40.991136: train_loss -0.9656 
2024-11-27 07:08:40.991247: val_loss -0.9033 
2024-11-27 07:08:40.991298: Pseudo dice [np.float32(0.9191)] 
2024-11-27 07:08:40.991380: Epoch time: 40.03 s 
2024-11-27 07:08:42.304811:  
2024-11-27 07:08:42.305007: Epoch 552 
2024-11-27 07:08:42.305087: Current learning rate: 0.00485 
2024-11-27 07:09:22.431607: train_loss -0.9649 
2024-11-27 07:09:22.431718: val_loss -0.9049 
2024-11-27 07:09:22.431771: Pseudo dice [np.float32(0.9215)] 
2024-11-27 07:09:22.431827: Epoch time: 40.13 s 
2024-11-27 07:09:23.332566:  
2024-11-27 07:09:23.332830: Epoch 553 
2024-11-27 07:09:23.332931: Current learning rate: 0.00484 
2024-11-27 07:10:03.403292: train_loss -0.964 
2024-11-27 07:10:03.403428: val_loss -0.9108 
2024-11-27 07:10:03.403527: Pseudo dice [np.float32(0.9247)] 
2024-11-27 07:10:03.403600: Epoch time: 40.07 s 
2024-11-27 07:10:04.262141:  
2024-11-27 07:10:04.262368: Epoch 554 
2024-11-27 07:10:04.262441: Current learning rate: 0.00484 
2024-11-27 07:10:44.387055: train_loss -0.9651 
2024-11-27 07:10:44.387168: val_loss -0.9073 
2024-11-27 07:10:44.387221: Pseudo dice [np.float32(0.9206)] 
2024-11-27 07:10:44.387379: Epoch time: 40.13 s 
2024-11-27 07:10:45.292825:  
2024-11-27 07:10:45.293195: Epoch 555 
2024-11-27 07:10:45.293268: Current learning rate: 0.00483 
2024-11-27 07:11:25.333394: train_loss -0.9661 
2024-11-27 07:11:25.333513: val_loss -0.9103 
2024-11-27 07:11:25.333562: Pseudo dice [np.float32(0.9239)] 
2024-11-27 07:11:25.333616: Epoch time: 40.04 s 
2024-11-27 07:11:26.203104:  
2024-11-27 07:11:26.203250: Epoch 556 
2024-11-27 07:11:26.203317: Current learning rate: 0.00482 
2024-11-27 07:12:06.260256: train_loss -0.967 
2024-11-27 07:12:06.260368: val_loss -0.911 
2024-11-27 07:12:06.260421: Pseudo dice [np.float32(0.9253)] 
2024-11-27 07:12:06.260477: Epoch time: 40.06 s 
2024-11-27 07:12:07.160769:  
2024-11-27 07:12:07.160969: Epoch 557 
2024-11-27 07:12:07.161039: Current learning rate: 0.00481 
2024-11-27 07:12:47.194460: train_loss -0.9667 
2024-11-27 07:12:47.194655: val_loss -0.9095 
2024-11-27 07:12:47.194723: Pseudo dice [np.float32(0.9249)] 
2024-11-27 07:12:47.194781: Epoch time: 40.03 s 
2024-11-27 07:12:48.095365:  
2024-11-27 07:12:48.095519: Epoch 558 
2024-11-27 07:12:48.095592: Current learning rate: 0.0048 
2024-11-27 07:13:28.113403: train_loss -0.9668 
2024-11-27 07:13:28.113513: val_loss -0.9115 
2024-11-27 07:13:28.113565: Pseudo dice [np.float32(0.9258)] 
2024-11-27 07:13:28.113749: Epoch time: 40.02 s 
2024-11-27 07:13:29.001261:  
2024-11-27 07:13:29.001472: Epoch 559 
2024-11-27 07:13:29.001559: Current learning rate: 0.00479 
2024-11-27 07:14:09.067427: train_loss -0.9662 
2024-11-27 07:14:09.067544: val_loss -0.911 
2024-11-27 07:14:09.067627: Pseudo dice [np.float32(0.9263)] 
2024-11-27 07:14:09.067686: Epoch time: 40.07 s 
2024-11-27 07:14:09.976195:  
2024-11-27 07:14:09.976369: Epoch 560 
2024-11-27 07:14:09.976444: Current learning rate: 0.00478 
2024-11-27 07:14:50.048364: train_loss -0.9681 
2024-11-27 07:14:50.048473: val_loss -0.9099 
2024-11-27 07:14:50.048591: Pseudo dice [np.float32(0.9243)] 
2024-11-27 07:14:50.048647: Epoch time: 40.07 s 
2024-11-27 07:14:50.902713:  
2024-11-27 07:14:50.902835: Epoch 561 
2024-11-27 07:14:50.902962: Current learning rate: 0.00477 
2024-11-27 07:15:30.933203: train_loss -0.9676 
2024-11-27 07:15:30.933339: val_loss -0.9052 
2024-11-27 07:15:30.933413: Pseudo dice [np.float32(0.9203)] 
2024-11-27 07:15:30.933472: Epoch time: 40.03 s 
2024-11-27 07:15:31.842376:  
2024-11-27 07:15:31.842549: Epoch 562 
2024-11-27 07:15:31.842625: Current learning rate: 0.00476 
2024-11-27 07:16:11.855651: train_loss -0.9671 
2024-11-27 07:16:11.855757: val_loss -0.913 
2024-11-27 07:16:11.855847: Pseudo dice [np.float32(0.9268)] 
2024-11-27 07:16:11.855958: Epoch time: 40.01 s 
2024-11-27 07:16:12.717695:  
2024-11-27 07:16:12.717844: Epoch 563 
2024-11-27 07:16:12.717949: Current learning rate: 0.00475 
2024-11-27 07:16:52.712115: train_loss -0.9665 
2024-11-27 07:16:52.712227: val_loss -0.9081 
2024-11-27 07:16:52.712276: Pseudo dice [np.float32(0.9233)] 
2024-11-27 07:16:52.712390: Epoch time: 40.0 s 
2024-11-27 07:16:53.578750:  
2024-11-27 07:16:53.578919: Epoch 564 
2024-11-27 07:16:53.579028: Current learning rate: 0.00474 
2024-11-27 07:17:33.611957: train_loss -0.9664 
2024-11-27 07:17:33.612106: val_loss -0.9084 
2024-11-27 07:17:33.612157: Pseudo dice [np.float32(0.9222)] 
2024-11-27 07:17:33.612213: Epoch time: 40.03 s 
2024-11-27 07:17:34.494309:  
2024-11-27 07:17:34.494567: Epoch 565 
2024-11-27 07:17:34.494693: Current learning rate: 0.00473 
2024-11-27 07:18:14.538562: train_loss -0.9665 
2024-11-27 07:18:14.538692: val_loss -0.9085 
2024-11-27 07:18:14.538746: Pseudo dice [np.float32(0.924)] 
2024-11-27 07:18:14.538803: Epoch time: 40.05 s 
2024-11-27 07:18:15.430044:  
2024-11-27 07:18:15.430240: Epoch 566 
2024-11-27 07:18:15.430315: Current learning rate: 0.00472 
2024-11-27 07:18:55.451362: train_loss -0.9667 
2024-11-27 07:18:55.451471: val_loss -0.9092 
2024-11-27 07:18:55.451524: Pseudo dice [np.float32(0.9241)] 
2024-11-27 07:18:55.451581: Epoch time: 40.02 s 
2024-11-27 07:18:56.310051:  
2024-11-27 07:18:56.310180: Epoch 567 
2024-11-27 07:18:56.310308: Current learning rate: 0.00471 
2024-11-27 07:19:36.350562: train_loss -0.9663 
2024-11-27 07:19:36.350688: val_loss -0.9154 
2024-11-27 07:19:36.350740: Pseudo dice [np.float32(0.9284)] 
2024-11-27 07:19:36.350797: Epoch time: 40.04 s 
2024-11-27 07:19:37.219695:  
2024-11-27 07:19:37.219846: Epoch 568 
2024-11-27 07:19:37.219980: Current learning rate: 0.0047 
2024-11-27 07:20:17.315244: train_loss -0.9673 
2024-11-27 07:20:17.315354: val_loss -0.9107 
2024-11-27 07:20:17.315408: Pseudo dice [np.float32(0.9241)] 
2024-11-27 07:20:17.315464: Epoch time: 40.1 s 
2024-11-27 07:20:18.197880:  
2024-11-27 07:20:18.198082: Epoch 569 
2024-11-27 07:20:18.198167: Current learning rate: 0.00469 
2024-11-27 07:20:58.206026: train_loss -0.9672 
2024-11-27 07:20:58.206134: val_loss -0.9103 
2024-11-27 07:20:58.206184: Pseudo dice [np.float32(0.9255)] 
2024-11-27 07:20:58.206238: Epoch time: 40.01 s 
2024-11-27 07:20:59.062864:  
2024-11-27 07:20:59.062941: Epoch 570 
2024-11-27 07:20:59.063036: Current learning rate: 0.00468 
2024-11-27 07:21:39.115589: train_loss -0.9675 
2024-11-27 07:21:39.115716: val_loss -0.9105 
2024-11-27 07:21:39.115768: Pseudo dice [np.float32(0.9247)] 
2024-11-27 07:21:39.115824: Epoch time: 40.05 s 
2024-11-27 07:21:39.994150:  
2024-11-27 07:21:39.994281: Epoch 571 
2024-11-27 07:21:39.994351: Current learning rate: 0.00467 
2024-11-27 07:22:20.018146: train_loss -0.9676 
2024-11-27 07:22:20.018248: val_loss -0.9099 
2024-11-27 07:22:20.018297: Pseudo dice [np.float32(0.9248)] 
2024-11-27 07:22:20.018350: Epoch time: 40.02 s 
2024-11-27 07:22:21.322128:  
2024-11-27 07:22:21.322335: Epoch 572 
2024-11-27 07:22:21.322404: Current learning rate: 0.00466 
2024-11-27 07:23:01.400744: train_loss -0.9675 
2024-11-27 07:23:01.400854: val_loss -0.9117 
2024-11-27 07:23:01.400974: Pseudo dice [np.float32(0.9252)] 
2024-11-27 07:23:01.401028: Epoch time: 40.08 s 
2024-11-27 07:23:02.254021:  
2024-11-27 07:23:02.254170: Epoch 573 
2024-11-27 07:23:02.254241: Current learning rate: 0.00465 
2024-11-27 07:23:42.367440: train_loss -0.9677 
2024-11-27 07:23:42.367597: val_loss -0.9078 
2024-11-27 07:23:42.367650: Pseudo dice [np.float32(0.9225)] 
2024-11-27 07:23:42.367710: Epoch time: 40.11 s 
2024-11-27 07:23:43.318454:  
2024-11-27 07:23:43.318692: Epoch 574 
2024-11-27 07:23:43.318783: Current learning rate: 0.00464 
2024-11-27 07:24:23.346349: train_loss -0.9672 
2024-11-27 07:24:23.346458: val_loss -0.9114 
2024-11-27 07:24:23.346511: Pseudo dice [np.float32(0.9256)] 
2024-11-27 07:24:23.346568: Epoch time: 40.03 s 
2024-11-27 07:24:24.263296:  
2024-11-27 07:24:24.263447: Epoch 575 
2024-11-27 07:24:24.263518: Current learning rate: 0.00463 
2024-11-27 07:25:04.340067: train_loss -0.967 
2024-11-27 07:25:04.340195: val_loss -0.9131 
2024-11-27 07:25:04.340249: Pseudo dice [np.float32(0.9269)] 
2024-11-27 07:25:04.340330: Epoch time: 40.08 s 
2024-11-27 07:25:05.265714:  
2024-11-27 07:25:05.265877: Epoch 576 
2024-11-27 07:25:05.266001: Current learning rate: 0.00462 
2024-11-27 07:25:45.283356: train_loss -0.968 
2024-11-27 07:25:45.283467: val_loss -0.9107 
2024-11-27 07:25:45.283563: Pseudo dice [np.float32(0.9256)] 
2024-11-27 07:25:45.283631: Epoch time: 40.02 s 
2024-11-27 07:25:46.220568:  
2024-11-27 07:25:46.220712: Epoch 577 
2024-11-27 07:25:46.220796: Current learning rate: 0.00461 
2024-11-27 07:26:26.284511: train_loss -0.968 
2024-11-27 07:26:26.284681: val_loss -0.9078 
2024-11-27 07:26:26.284734: Pseudo dice [np.float32(0.9226)] 
2024-11-27 07:26:26.284788: Epoch time: 40.06 s 
2024-11-27 07:26:27.164259:  
2024-11-27 07:26:27.164420: Epoch 578 
2024-11-27 07:26:27.164521: Current learning rate: 0.0046 
2024-11-27 07:27:07.203689: train_loss -0.9681 
2024-11-27 07:27:07.203816: val_loss -0.9123 
2024-11-27 07:27:07.203871: Pseudo dice [np.float32(0.926)] 
2024-11-27 07:27:07.203928: Epoch time: 40.04 s 
2024-11-27 07:27:08.077608:  
2024-11-27 07:27:08.077802: Epoch 579 
2024-11-27 07:27:08.077925: Current learning rate: 0.00459 
2024-11-27 07:27:48.146439: train_loss -0.9643 
2024-11-27 07:27:48.146550: val_loss -0.9087 
2024-11-27 07:27:48.146601: Pseudo dice [np.float32(0.9247)] 
2024-11-27 07:27:48.146657: Epoch time: 40.07 s 
2024-11-27 07:27:49.071831:  
2024-11-27 07:27:49.072010: Epoch 580 
2024-11-27 07:27:49.072101: Current learning rate: 0.00458 
2024-11-27 07:28:29.104612: train_loss -0.9661 
2024-11-27 07:28:29.104722: val_loss -0.9067 
2024-11-27 07:28:29.104773: Pseudo dice [np.float32(0.922)] 
2024-11-27 07:28:29.104829: Epoch time: 40.03 s 
2024-11-27 07:28:30.025225:  
2024-11-27 07:28:30.025404: Epoch 581 
2024-11-27 07:28:30.025489: Current learning rate: 0.00457 
2024-11-27 07:29:10.039933: train_loss -0.9668 
2024-11-27 07:29:10.040066: val_loss -0.9134 
2024-11-27 07:29:10.040120: Pseudo dice [np.float32(0.9277)] 
2024-11-27 07:29:10.040177: Epoch time: 40.02 s 
2024-11-27 07:29:10.991466:  
2024-11-27 07:29:10.991615: Epoch 582 
2024-11-27 07:29:10.991685: Current learning rate: 0.00456 
2024-11-27 07:29:50.997611: train_loss -0.967 
2024-11-27 07:29:50.997736: val_loss -0.9091 
2024-11-27 07:29:50.997787: Pseudo dice [np.float32(0.9237)] 
2024-11-27 07:29:50.997843: Epoch time: 40.01 s 
2024-11-27 07:29:51.929502:  
2024-11-27 07:29:51.929724: Epoch 583 
2024-11-27 07:29:51.929794: Current learning rate: 0.00455 
2024-11-27 07:30:31.941187: train_loss -0.9666 
2024-11-27 07:30:31.941308: val_loss -0.9088 
2024-11-27 07:30:31.941391: Pseudo dice [np.float32(0.9229)] 
2024-11-27 07:30:31.941480: Epoch time: 40.01 s 
2024-11-27 07:30:32.892167:  
2024-11-27 07:30:32.892371: Epoch 584 
2024-11-27 07:30:32.892441: Current learning rate: 0.00454 
2024-11-27 07:31:12.917797: train_loss -0.9665 
2024-11-27 07:31:12.917955: val_loss -0.9076 
2024-11-27 07:31:12.918065: Pseudo dice [np.float32(0.9219)] 
2024-11-27 07:31:12.918149: Epoch time: 40.03 s 
2024-11-27 07:31:13.875215:  
2024-11-27 07:31:13.875324: Epoch 585 
2024-11-27 07:31:13.875414: Current learning rate: 0.00453 
2024-11-27 07:31:53.913020: train_loss -0.9666 
2024-11-27 07:31:53.913135: val_loss -0.9099 
2024-11-27 07:31:53.913188: Pseudo dice [np.float32(0.924)] 
2024-11-27 07:31:53.913245: Epoch time: 40.04 s 
2024-11-27 07:31:54.829091:  
2024-11-27 07:31:54.829391: Epoch 586 
2024-11-27 07:31:54.829483: Current learning rate: 0.00452 
2024-11-27 07:32:34.834390: train_loss -0.9674 
2024-11-27 07:32:34.834516: val_loss -0.9106 
2024-11-27 07:32:34.834593: Pseudo dice [np.float32(0.9247)] 
2024-11-27 07:32:34.834662: Epoch time: 40.01 s 
2024-11-27 07:32:35.708632:  
2024-11-27 07:32:35.708765: Epoch 587 
2024-11-27 07:32:35.708836: Current learning rate: 0.00451 
2024-11-27 07:33:15.740017: train_loss -0.9663 
2024-11-27 07:33:15.740127: val_loss -0.9108 
2024-11-27 07:33:15.740178: Pseudo dice [np.float32(0.9259)] 
2024-11-27 07:33:15.740232: Epoch time: 40.03 s 
2024-11-27 07:33:16.625123:  
2024-11-27 07:33:16.625247: Epoch 588 
2024-11-27 07:33:16.625316: Current learning rate: 0.0045 
2024-11-27 07:33:56.663377: train_loss -0.9681 
2024-11-27 07:33:56.663507: val_loss -0.9068 
2024-11-27 07:33:56.663561: Pseudo dice [np.float32(0.9228)] 
2024-11-27 07:33:56.663619: Epoch time: 40.04 s 
2024-11-27 07:33:57.575631:  
2024-11-27 07:33:57.575801: Epoch 589 
2024-11-27 07:33:57.575907: Current learning rate: 0.00449 
2024-11-27 07:34:37.614876: train_loss -0.9677 
2024-11-27 07:34:37.615027: val_loss -0.9066 
2024-11-27 07:34:37.615077: Pseudo dice [np.float32(0.9212)] 
2024-11-27 07:34:37.615132: Epoch time: 40.04 s 
2024-11-27 07:34:38.504167:  
2024-11-27 07:34:38.504339: Epoch 590 
2024-11-27 07:34:38.504411: Current learning rate: 0.00448 
2024-11-27 07:35:18.542360: train_loss -0.9659 
2024-11-27 07:35:18.542473: val_loss -0.9077 
2024-11-27 07:35:18.542552: Pseudo dice [np.float32(0.9225)] 
2024-11-27 07:35:18.542610: Epoch time: 40.04 s 
2024-11-27 07:35:19.915478:  
2024-11-27 07:35:19.915637: Epoch 591 
2024-11-27 07:35:19.915718: Current learning rate: 0.00447 
2024-11-27 07:35:59.967573: train_loss -0.968 
2024-11-27 07:35:59.967708: val_loss -0.9108 
2024-11-27 07:35:59.967782: Pseudo dice [np.float32(0.9251)] 
2024-11-27 07:35:59.967843: Epoch time: 40.05 s 
2024-11-27 07:36:00.894162:  
2024-11-27 07:36:00.894312: Epoch 592 
2024-11-27 07:36:00.894381: Current learning rate: 0.00446 
2024-11-27 07:36:40.935736: train_loss -0.9656 
2024-11-27 07:36:40.935884: val_loss -0.908 
2024-11-27 07:36:40.935940: Pseudo dice [np.float32(0.9231)] 
2024-11-27 07:36:40.935995: Epoch time: 40.04 s 
2024-11-27 07:36:41.863519:  
2024-11-27 07:36:41.863718: Epoch 593 
2024-11-27 07:36:41.863787: Current learning rate: 0.00445 
2024-11-27 07:37:21.917588: train_loss -0.9602 
2024-11-27 07:37:21.917697: val_loss -0.9011 
2024-11-27 07:37:21.917750: Pseudo dice [np.float32(0.9174)] 
2024-11-27 07:37:21.917807: Epoch time: 40.05 s 
2024-11-27 07:37:22.823371:  
2024-11-27 07:37:22.823535: Epoch 594 
2024-11-27 07:37:22.823606: Current learning rate: 0.00444 
2024-11-27 07:38:02.867316: train_loss -0.9624 
2024-11-27 07:38:02.867427: val_loss -0.9072 
2024-11-27 07:38:02.867477: Pseudo dice [np.float32(0.9219)] 
2024-11-27 07:38:02.867533: Epoch time: 40.04 s 
2024-11-27 07:38:03.778630:  
2024-11-27 07:38:03.778823: Epoch 595 
2024-11-27 07:38:03.778941: Current learning rate: 0.00443 
2024-11-27 07:38:43.784714: train_loss -0.9629 
2024-11-27 07:38:43.784825: val_loss -0.9104 
2024-11-27 07:38:43.784913: Pseudo dice [np.float32(0.9262)] 
2024-11-27 07:38:43.785020: Epoch time: 40.01 s 
2024-11-27 07:38:44.709234:  
2024-11-27 07:38:44.709381: Epoch 596 
2024-11-27 07:38:44.709454: Current learning rate: 0.00442 
2024-11-27 07:39:24.707582: train_loss -0.9648 
2024-11-27 07:39:24.707690: val_loss -0.9162 
2024-11-27 07:39:24.707740: Pseudo dice [np.float32(0.9293)] 
2024-11-27 07:39:24.707795: Epoch time: 40.0 s 
2024-11-27 07:39:25.672016:  
2024-11-27 07:39:25.672249: Epoch 597 
2024-11-27 07:39:25.672339: Current learning rate: 0.00441 
2024-11-27 07:40:05.707654: train_loss -0.9659 
2024-11-27 07:40:05.707762: val_loss -0.9043 
2024-11-27 07:40:05.707814: Pseudo dice [np.float32(0.9207)] 
2024-11-27 07:40:05.707872: Epoch time: 40.04 s 
2024-11-27 07:40:06.656542:  
2024-11-27 07:40:06.656753: Epoch 598 
2024-11-27 07:40:06.656848: Current learning rate: 0.0044 
2024-11-27 07:40:46.658129: train_loss -0.9668 
2024-11-27 07:40:46.658280: val_loss -0.9093 
2024-11-27 07:40:46.658332: Pseudo dice [np.float32(0.9227)] 
2024-11-27 07:40:46.658386: Epoch time: 40.0 s 
2024-11-27 07:40:47.556576:  
2024-11-27 07:40:47.556757: Epoch 599 
2024-11-27 07:40:47.556862: Current learning rate: 0.00439 
2024-11-27 07:41:27.568565: train_loss -0.9667 
2024-11-27 07:41:27.568678: val_loss -0.9079 
2024-11-27 07:41:27.568734: Pseudo dice [np.float32(0.9229)] 
2024-11-27 07:41:27.568795: Epoch time: 40.01 s 
2024-11-27 07:41:30.843041:  
2024-11-27 07:41:30.843221: Epoch 600 
2024-11-27 07:41:30.843291: Current learning rate: 0.00438 
2024-11-27 07:42:10.771329: train_loss -0.9671 
2024-11-27 07:42:10.771545: val_loss -0.9094 
2024-11-27 07:42:10.771596: Pseudo dice [np.float32(0.9243)] 
2024-11-27 07:42:10.771651: Epoch time: 39.93 s 
2024-11-27 07:42:11.616937:  
2024-11-27 07:42:11.617121: Epoch 601 
2024-11-27 07:42:11.617192: Current learning rate: 0.00437 
2024-11-27 07:42:51.668084: train_loss -0.9652 
2024-11-27 07:42:51.668195: val_loss -0.9076 
2024-11-27 07:42:51.668248: Pseudo dice [np.float32(0.9224)] 
2024-11-27 07:42:51.668304: Epoch time: 40.05 s 
2024-11-27 07:42:52.529063:  
2024-11-27 07:42:52.529230: Epoch 602 
2024-11-27 07:42:52.529315: Current learning rate: 0.00436 
2024-11-27 07:43:32.550071: train_loss -0.9585 
2024-11-27 07:43:32.550179: val_loss -0.9123 
2024-11-27 07:43:32.550231: Pseudo dice [np.float32(0.9259)] 
2024-11-27 07:43:32.550287: Epoch time: 40.02 s 
2024-11-27 07:43:33.478559:  
2024-11-27 07:43:33.478687: Epoch 603 
2024-11-27 07:43:33.478762: Current learning rate: 0.00435 
2024-11-27 07:44:13.442242: train_loss -0.9602 
2024-11-27 07:44:13.442354: val_loss -0.9022 
2024-11-27 07:44:13.442405: Pseudo dice [np.float32(0.9163)] 
2024-11-27 07:44:13.442461: Epoch time: 39.96 s 
2024-11-27 07:44:14.320254:  
2024-11-27 07:44:14.320417: Epoch 604 
2024-11-27 07:44:14.320486: Current learning rate: 0.00434 
2024-11-27 07:44:54.322245: train_loss -0.9585 
2024-11-27 07:44:54.322368: val_loss -0.9033 
2024-11-27 07:44:54.322435: Pseudo dice [np.float32(0.9182)] 
2024-11-27 07:44:54.322489: Epoch time: 40.0 s 
2024-11-27 07:44:55.208516:  
2024-11-27 07:44:55.208658: Epoch 605 
2024-11-27 07:44:55.208728: Current learning rate: 0.00433 
2024-11-27 07:45:35.184322: train_loss -0.9616 
2024-11-27 07:45:35.184449: val_loss -0.9129 
2024-11-27 07:45:35.184516: Pseudo dice [np.float32(0.9262)] 
2024-11-27 07:45:35.184589: Epoch time: 39.98 s 
2024-11-27 07:45:36.092847:  
2024-11-27 07:45:36.093032: Epoch 606 
2024-11-27 07:45:36.093101: Current learning rate: 0.00432 
2024-11-27 07:46:16.130314: train_loss -0.9626 
2024-11-27 07:46:16.130461: val_loss -0.9086 
2024-11-27 07:46:16.130515: Pseudo dice [np.float32(0.9226)] 
2024-11-27 07:46:16.130571: Epoch time: 40.04 s 
2024-11-27 07:46:17.025232:  
2024-11-27 07:46:17.025355: Epoch 607 
2024-11-27 07:46:17.025425: Current learning rate: 0.00431 
2024-11-27 07:46:57.061215: train_loss -0.9638 
2024-11-27 07:46:57.061319: val_loss -0.9024 
2024-11-27 07:46:57.061369: Pseudo dice [np.float32(0.9175)] 
2024-11-27 07:46:57.061424: Epoch time: 40.04 s 
2024-11-27 07:46:57.935311:  
2024-11-27 07:46:57.935492: Epoch 608 
2024-11-27 07:46:57.935560: Current learning rate: 0.0043 
2024-11-27 07:47:37.934384: train_loss -0.9657 
2024-11-27 07:47:37.934596: val_loss -0.9054 
2024-11-27 07:47:37.934650: Pseudo dice [np.float32(0.9217)] 
2024-11-27 07:47:37.934708: Epoch time: 40.0 s 
2024-11-27 07:47:38.844192:  
2024-11-27 07:47:38.844452: Epoch 609 
2024-11-27 07:47:38.844603: Current learning rate: 0.00429 
2024-11-27 07:48:18.848442: train_loss -0.9658 
2024-11-27 07:48:18.848551: val_loss -0.9112 
2024-11-27 07:48:18.848601: Pseudo dice [np.float32(0.9254)] 
2024-11-27 07:48:18.848691: Epoch time: 40.01 s 
2024-11-27 07:48:20.151723:  
2024-11-27 07:48:20.151871: Epoch 610 
2024-11-27 07:48:20.152005: Current learning rate: 0.00429 
2024-11-27 07:49:00.222242: train_loss -0.9665 
2024-11-27 07:49:00.222389: val_loss -0.9111 
2024-11-27 07:49:00.222470: Pseudo dice [np.float32(0.9249)] 
2024-11-27 07:49:00.222523: Epoch time: 40.07 s 
2024-11-27 07:49:01.090378:  
2024-11-27 07:49:01.090536: Epoch 611 
2024-11-27 07:49:01.090603: Current learning rate: 0.00428 
2024-11-27 07:49:41.146335: train_loss -0.9664 
2024-11-27 07:49:41.146447: val_loss -0.9097 
2024-11-27 07:49:41.146499: Pseudo dice [np.float32(0.9238)] 
2024-11-27 07:49:41.146557: Epoch time: 40.06 s 
2024-11-27 07:49:42.050288:  
2024-11-27 07:49:42.050493: Epoch 612 
2024-11-27 07:49:42.050565: Current learning rate: 0.00427 
2024-11-27 07:50:22.105389: train_loss -0.9667 
2024-11-27 07:50:22.105585: val_loss -0.9089 
2024-11-27 07:50:22.105639: Pseudo dice [np.float32(0.9231)] 
2024-11-27 07:50:22.105696: Epoch time: 40.06 s 
2024-11-27 07:50:23.004054:  
2024-11-27 07:50:23.004328: Epoch 613 
2024-11-27 07:50:23.004399: Current learning rate: 0.00426 
2024-11-27 07:51:03.037585: train_loss -0.9663 
2024-11-27 07:51:03.037720: val_loss -0.9071 
2024-11-27 07:51:03.037807: Pseudo dice [np.float32(0.9219)] 
2024-11-27 07:51:03.037923: Epoch time: 40.03 s 
2024-11-27 07:51:03.951842:  
2024-11-27 07:51:03.952160: Epoch 614 
2024-11-27 07:51:03.952285: Current learning rate: 0.00425 
2024-11-27 07:51:43.986365: train_loss -0.9675 
2024-11-27 07:51:43.986499: val_loss -0.9077 
2024-11-27 07:51:43.986585: Pseudo dice [np.float32(0.9215)] 
2024-11-27 07:51:43.986661: Epoch time: 40.04 s 
2024-11-27 07:51:44.912911:  
2024-11-27 07:51:44.913073: Epoch 615 
2024-11-27 07:51:44.913168: Current learning rate: 0.00424 
2024-11-27 07:52:24.951302: train_loss -0.9673 
2024-11-27 07:52:24.951429: val_loss -0.9082 
2024-11-27 07:52:24.951479: Pseudo dice [np.float32(0.9231)] 
2024-11-27 07:52:24.951534: Epoch time: 40.04 s 
2024-11-27 07:52:25.850615:  
2024-11-27 07:52:25.850837: Epoch 616 
2024-11-27 07:52:25.850985: Current learning rate: 0.00423 
2024-11-27 07:53:05.937219: train_loss -0.9679 
2024-11-27 07:53:05.937361: val_loss -0.9094 
2024-11-27 07:53:05.937413: Pseudo dice [np.float32(0.925)] 
2024-11-27 07:53:05.937468: Epoch time: 40.09 s 
2024-11-27 07:53:06.814291:  
2024-11-27 07:53:06.814445: Epoch 617 
2024-11-27 07:53:06.814513: Current learning rate: 0.00422 
2024-11-27 07:53:46.829704: train_loss -0.967 
2024-11-27 07:53:46.829817: val_loss -0.9066 
2024-11-27 07:53:46.829902: Pseudo dice [np.float32(0.9221)] 
2024-11-27 07:53:46.829994: Epoch time: 40.02 s 
2024-11-27 07:53:47.733241:  
2024-11-27 07:53:47.733390: Epoch 618 
2024-11-27 07:53:47.733462: Current learning rate: 0.00421 
2024-11-27 07:54:27.793979: train_loss -0.9681 
2024-11-27 07:54:27.794141: val_loss -0.9078 
2024-11-27 07:54:27.794195: Pseudo dice [np.float32(0.9217)] 
2024-11-27 07:54:27.794252: Epoch time: 40.06 s 
2024-11-27 07:54:28.689297:  
2024-11-27 07:54:28.689430: Epoch 619 
2024-11-27 07:54:28.689503: Current learning rate: 0.0042 
2024-11-27 07:55:08.726933: train_loss -0.9686 
2024-11-27 07:55:08.727061: val_loss -0.9133 
2024-11-27 07:55:08.727114: Pseudo dice [np.float32(0.9268)] 
2024-11-27 07:55:08.727172: Epoch time: 40.04 s 
2024-11-27 07:55:09.608960:  
2024-11-27 07:55:09.609106: Epoch 620 
2024-11-27 07:55:09.609177: Current learning rate: 0.00419 
2024-11-27 07:55:49.664553: train_loss -0.9686 
2024-11-27 07:55:49.664664: val_loss -0.9091 
2024-11-27 07:55:49.664717: Pseudo dice [np.float32(0.9233)] 
2024-11-27 07:55:49.664776: Epoch time: 40.06 s 
2024-11-27 07:55:50.568229:  
2024-11-27 07:55:50.568411: Epoch 621 
2024-11-27 07:55:50.568483: Current learning rate: 0.00418 
2024-11-27 07:56:30.628368: train_loss -0.9688 
2024-11-27 07:56:30.628475: val_loss -0.9127 
2024-11-27 07:56:30.628525: Pseudo dice [np.float32(0.9271)] 
2024-11-27 07:56:30.628579: Epoch time: 40.06 s 
2024-11-27 07:56:31.508715:  
2024-11-27 07:56:31.508858: Epoch 622 
2024-11-27 07:56:31.508982: Current learning rate: 0.00417 
2024-11-27 07:57:11.518144: train_loss -0.9689 
2024-11-27 07:57:11.518251: val_loss -0.909 
2024-11-27 07:57:11.518301: Pseudo dice [np.float32(0.9237)] 
2024-11-27 07:57:11.518362: Epoch time: 40.01 s 
2024-11-27 07:57:12.410677:  
2024-11-27 07:57:12.410832: Epoch 623 
2024-11-27 07:57:12.410946: Current learning rate: 0.00416 
2024-11-27 07:57:52.464331: train_loss -0.9684 
2024-11-27 07:57:52.464525: val_loss -0.9071 
2024-11-27 07:57:52.464577: Pseudo dice [np.float32(0.9222)] 
2024-11-27 07:57:52.464653: Epoch time: 40.05 s 
2024-11-27 07:57:53.391530:  
2024-11-27 07:57:53.391694: Epoch 624 
2024-11-27 07:57:53.391766: Current learning rate: 0.00415 
2024-11-27 07:58:33.449241: train_loss -0.9694 
2024-11-27 07:58:33.449352: val_loss -0.9122 
2024-11-27 07:58:33.449405: Pseudo dice [np.float32(0.9261)] 
2024-11-27 07:58:33.449498: Epoch time: 40.06 s 
2024-11-27 07:58:34.420756:  
2024-11-27 07:58:34.420948: Epoch 625 
2024-11-27 07:58:34.421019: Current learning rate: 0.00414 
2024-11-27 07:59:14.470309: train_loss -0.9689 
2024-11-27 07:59:14.470418: val_loss -0.9062 
2024-11-27 07:59:14.470469: Pseudo dice [np.float32(0.9217)] 
2024-11-27 07:59:14.470525: Epoch time: 40.05 s 
2024-11-27 07:59:15.378231:  
2024-11-27 07:59:15.378366: Epoch 626 
2024-11-27 07:59:15.378443: Current learning rate: 0.00413 
2024-11-27 07:59:55.412645: train_loss -0.9689 
2024-11-27 07:59:55.412796: val_loss -0.9112 
2024-11-27 07:59:55.412850: Pseudo dice [np.float32(0.9247)] 
2024-11-27 07:59:55.412947: Epoch time: 40.04 s 
2024-11-27 07:59:56.320919:  
2024-11-27 07:59:56.321078: Epoch 627 
2024-11-27 07:59:56.321146: Current learning rate: 0.00412 
2024-11-27 08:00:36.371955: train_loss -0.9693 
2024-11-27 08:00:36.372137: val_loss -0.9092 
2024-11-27 08:00:36.372204: Pseudo dice [np.float32(0.9244)] 
2024-11-27 08:00:36.372260: Epoch time: 40.05 s 
2024-11-27 08:00:37.305630:  
2024-11-27 08:00:37.305756: Epoch 628 
2024-11-27 08:00:37.305847: Current learning rate: 0.00411 
2024-11-27 08:01:17.313165: train_loss -0.9686 
2024-11-27 08:01:17.313275: val_loss -0.9089 
2024-11-27 08:01:17.313326: Pseudo dice [np.float32(0.9227)] 
2024-11-27 08:01:17.313382: Epoch time: 40.01 s 
2024-11-27 08:01:18.590016:  
2024-11-27 08:01:18.590152: Epoch 629 
2024-11-27 08:01:18.590250: Current learning rate: 0.0041 
2024-11-27 08:01:58.630922: train_loss -0.9688 
2024-11-27 08:01:58.631036: val_loss -0.9119 
2024-11-27 08:01:58.631094: Pseudo dice [np.float32(0.926)] 
2024-11-27 08:01:58.631169: Epoch time: 40.04 s 
2024-11-27 08:01:59.600409:  
2024-11-27 08:01:59.600566: Epoch 630 
2024-11-27 08:01:59.600637: Current learning rate: 0.00409 
2024-11-27 08:02:39.690566: train_loss -0.969 
2024-11-27 08:02:39.690711: val_loss -0.9063 
2024-11-27 08:02:39.690780: Pseudo dice [np.float32(0.9231)] 
2024-11-27 08:02:39.690854: Epoch time: 40.09 s 
2024-11-27 08:02:40.597086:  
2024-11-27 08:02:40.597468: Epoch 631 
2024-11-27 08:02:40.597542: Current learning rate: 0.00408 
2024-11-27 08:03:20.638277: train_loss -0.9684 
2024-11-27 08:03:20.638466: val_loss -0.9115 
2024-11-27 08:03:20.638516: Pseudo dice [np.float32(0.926)] 
2024-11-27 08:03:20.638570: Epoch time: 40.04 s 
2024-11-27 08:03:21.550333:  
2024-11-27 08:03:21.550481: Epoch 632 
2024-11-27 08:03:21.550562: Current learning rate: 0.00407 
2024-11-27 08:04:01.655489: train_loss -0.9688 
2024-11-27 08:04:01.655627: val_loss -0.9135 
2024-11-27 08:04:01.655697: Pseudo dice [np.float32(0.928)] 
2024-11-27 08:04:01.655858: Epoch time: 40.11 s 
2024-11-27 08:04:02.628682:  
2024-11-27 08:04:02.628928: Epoch 633 
2024-11-27 08:04:02.629021: Current learning rate: 0.00406 
2024-11-27 08:04:42.679606: train_loss -0.969 
2024-11-27 08:04:42.679742: val_loss -0.9102 
2024-11-27 08:04:42.679795: Pseudo dice [np.float32(0.9236)] 
2024-11-27 08:04:42.679852: Epoch time: 40.05 s 
2024-11-27 08:04:43.583926:  
2024-11-27 08:04:43.584083: Epoch 634 
2024-11-27 08:04:43.584153: Current learning rate: 0.00405 
2024-11-27 08:05:23.636992: train_loss -0.9684 
2024-11-27 08:05:23.637195: val_loss -0.9061 
2024-11-27 08:05:23.637277: Pseudo dice [np.float32(0.9208)] 
2024-11-27 08:05:23.637335: Epoch time: 40.05 s 
2024-11-27 08:05:24.579354:  
2024-11-27 08:05:24.579504: Epoch 635 
2024-11-27 08:05:24.579575: Current learning rate: 0.00404 
2024-11-27 08:06:04.672474: train_loss -0.9687 
2024-11-27 08:06:04.672611: val_loss -0.9065 
2024-11-27 08:06:04.672699: Pseudo dice [np.float32(0.9212)] 
2024-11-27 08:06:04.672797: Epoch time: 40.09 s 
2024-11-27 08:06:05.580077:  
2024-11-27 08:06:05.580371: Epoch 636 
2024-11-27 08:06:05.580454: Current learning rate: 0.00403 
2024-11-27 08:06:45.616983: train_loss -0.9684 
2024-11-27 08:06:45.617097: val_loss -0.9097 
2024-11-27 08:06:45.617149: Pseudo dice [np.float32(0.9228)] 
2024-11-27 08:06:45.617231: Epoch time: 40.04 s 
2024-11-27 08:06:46.553580:  
2024-11-27 08:06:46.553853: Epoch 637 
2024-11-27 08:06:46.553948: Current learning rate: 0.00402 
2024-11-27 08:07:26.628223: train_loss -0.9684 
2024-11-27 08:07:26.628337: val_loss -0.908 
2024-11-27 08:07:26.628388: Pseudo dice [np.float32(0.9245)] 
2024-11-27 08:07:26.628445: Epoch time: 40.08 s 
2024-11-27 08:07:27.613507:  
2024-11-27 08:07:27.613706: Epoch 638 
2024-11-27 08:07:27.613955: Current learning rate: 0.00401 
2024-11-27 08:08:07.658934: train_loss -0.9686 
2024-11-27 08:08:07.659040: val_loss -0.9061 
2024-11-27 08:08:07.659091: Pseudo dice [np.float32(0.9221)] 
2024-11-27 08:08:07.659172: Epoch time: 40.05 s 
2024-11-27 08:08:08.583181:  
2024-11-27 08:08:08.583413: Epoch 639 
2024-11-27 08:08:08.583500: Current learning rate: 0.004 
2024-11-27 08:08:48.631371: train_loss -0.9696 
2024-11-27 08:08:48.631480: val_loss -0.9126 
2024-11-27 08:08:48.631533: Pseudo dice [np.float32(0.9259)] 
2024-11-27 08:08:48.631589: Epoch time: 40.05 s 
2024-11-27 08:08:49.576517:  
2024-11-27 08:08:49.576701: Epoch 640 
2024-11-27 08:08:49.576790: Current learning rate: 0.00399 
2024-11-27 08:09:29.573585: train_loss -0.9691 
2024-11-27 08:09:29.573711: val_loss -0.9106 
2024-11-27 08:09:29.573763: Pseudo dice [np.float32(0.9268)] 
2024-11-27 08:09:29.573817: Epoch time: 40.0 s 
2024-11-27 08:09:30.457131:  
2024-11-27 08:09:30.457279: Epoch 641 
2024-11-27 08:09:30.457351: Current learning rate: 0.00398 
2024-11-27 08:10:10.479937: train_loss -0.9699 
2024-11-27 08:10:10.480088: val_loss -0.906 
2024-11-27 08:10:10.480155: Pseudo dice [np.float32(0.921)] 
2024-11-27 08:10:10.480225: Epoch time: 40.02 s 
2024-11-27 08:10:11.364973:  
2024-11-27 08:10:11.365107: Epoch 642 
2024-11-27 08:10:11.365177: Current learning rate: 0.00397 
2024-11-27 08:10:51.375777: train_loss -0.9691 
2024-11-27 08:10:51.375909: val_loss -0.909 
2024-11-27 08:10:51.375973: Pseudo dice [np.float32(0.9241)] 
2024-11-27 08:10:51.376041: Epoch time: 40.01 s 
2024-11-27 08:10:52.265718:  
2024-11-27 08:10:52.265855: Epoch 643 
2024-11-27 08:10:52.265941: Current learning rate: 0.00396 
2024-11-27 08:11:32.277591: train_loss -0.9696 
2024-11-27 08:11:32.277704: val_loss -0.9144 
2024-11-27 08:11:32.277791: Pseudo dice [np.float32(0.9282)] 
2024-11-27 08:11:32.277906: Epoch time: 40.01 s 
2024-11-27 08:11:33.153047:  
2024-11-27 08:11:33.153339: Epoch 644 
2024-11-27 08:11:33.153423: Current learning rate: 0.00395 
2024-11-27 08:12:13.195422: train_loss -0.969 
2024-11-27 08:12:13.195533: val_loss -0.91 
2024-11-27 08:12:13.195585: Pseudo dice [np.float32(0.924)] 
2024-11-27 08:12:13.195676: Epoch time: 40.04 s 
2024-11-27 08:12:14.123073:  
2024-11-27 08:12:14.123239: Epoch 645 
2024-11-27 08:12:14.123321: Current learning rate: 0.00394 
2024-11-27 08:12:54.150105: train_loss -0.9704 
2024-11-27 08:12:54.150233: val_loss -0.9149 
2024-11-27 08:12:54.150290: Pseudo dice [np.float32(0.9275)] 
2024-11-27 08:12:54.150351: Epoch time: 40.03 s 
2024-11-27 08:12:55.089128:  
2024-11-27 08:12:55.089365: Epoch 646 
2024-11-27 08:12:55.089441: Current learning rate: 0.00393 
2024-11-27 08:13:35.139167: train_loss -0.9699 
2024-11-27 08:13:35.139277: val_loss -0.9038 
2024-11-27 08:13:35.139365: Pseudo dice [np.float32(0.9198)] 
2024-11-27 08:13:35.139421: Epoch time: 40.05 s 
2024-11-27 08:13:36.050876:  
2024-11-27 08:13:36.051008: Epoch 647 
2024-11-27 08:13:36.051080: Current learning rate: 0.00392 
2024-11-27 08:14:16.094584: train_loss -0.9707 
2024-11-27 08:14:16.094691: val_loss -0.906 
2024-11-27 08:14:16.094742: Pseudo dice [np.float32(0.9219)] 
2024-11-27 08:14:16.094799: Epoch time: 40.04 s 
2024-11-27 08:14:17.411905:  
2024-11-27 08:14:17.412051: Epoch 648 
2024-11-27 08:14:17.412143: Current learning rate: 0.00391 
2024-11-27 08:14:57.536204: train_loss -0.9699 
2024-11-27 08:14:57.536336: val_loss -0.9165 
2024-11-27 08:14:57.536388: Pseudo dice [np.float32(0.9303)] 
2024-11-27 08:14:57.536445: Epoch time: 40.13 s 
2024-11-27 08:14:58.399918:  
2024-11-27 08:14:58.400141: Epoch 649 
2024-11-27 08:14:58.400212: Current learning rate: 0.0039 
2024-11-27 08:15:38.463519: train_loss -0.97 
2024-11-27 08:15:38.463627: val_loss -0.9114 
2024-11-27 08:15:38.463676: Pseudo dice [np.float32(0.9263)] 
2024-11-27 08:15:38.463729: Epoch time: 40.06 s 
2024-11-27 08:15:41.658546:  
2024-11-27 08:15:41.658710: Epoch 650 
2024-11-27 08:15:41.658779: Current learning rate: 0.00389 
2024-11-27 08:16:21.647726: train_loss -0.9706 
2024-11-27 08:16:21.647851: val_loss -0.9077 
2024-11-27 08:16:21.648006: Pseudo dice [np.float32(0.9235)] 
2024-11-27 08:16:21.648070: Epoch time: 39.99 s 
2024-11-27 08:16:22.503776:  
2024-11-27 08:16:22.504016: Epoch 651 
2024-11-27 08:16:22.504092: Current learning rate: 0.00388 
2024-11-27 08:17:02.567669: train_loss -0.9706 
2024-11-27 08:17:02.567778: val_loss -0.9162 
2024-11-27 08:17:02.567863: Pseudo dice [np.float32(0.9294)] 
2024-11-27 08:17:02.567925: Epoch time: 40.06 s 
2024-11-27 08:17:03.480684:  
2024-11-27 08:17:03.480942: Epoch 652 
2024-11-27 08:17:03.481013: Current learning rate: 0.00387 
2024-11-27 08:17:43.501826: train_loss -0.9705 
2024-11-27 08:17:43.501976: val_loss -0.9063 
2024-11-27 08:17:43.502029: Pseudo dice [np.float32(0.9222)] 
2024-11-27 08:17:43.502117: Epoch time: 40.02 s 
2024-11-27 08:17:44.366051:  
2024-11-27 08:17:44.366213: Epoch 653 
2024-11-27 08:17:44.366286: Current learning rate: 0.00386 
2024-11-27 08:18:24.409769: train_loss -0.9708 
2024-11-27 08:18:24.409942: val_loss -0.8985 
2024-11-27 08:18:24.410017: Pseudo dice [np.float32(0.9201)] 
2024-11-27 08:18:24.410071: Epoch time: 40.04 s 
2024-11-27 08:18:25.294240:  
2024-11-27 08:18:25.294483: Epoch 654 
2024-11-27 08:18:25.294567: Current learning rate: 0.00385 
2024-11-27 08:19:05.382425: train_loss -0.9667 
2024-11-27 08:19:05.382552: val_loss -0.905 
2024-11-27 08:19:05.382605: Pseudo dice [np.float32(0.921)] 
2024-11-27 08:19:05.382659: Epoch time: 40.09 s 
2024-11-27 08:19:06.282333:  
2024-11-27 08:19:06.282475: Epoch 655 
2024-11-27 08:19:06.282543: Current learning rate: 0.00384 
2024-11-27 08:19:46.332915: train_loss -0.9546 
2024-11-27 08:19:46.333035: val_loss -0.9046 
2024-11-27 08:19:46.333142: Pseudo dice [np.float32(0.9201)] 
2024-11-27 08:19:46.333215: Epoch time: 40.05 s 
2024-11-27 08:19:47.203577:  
2024-11-27 08:19:47.203711: Epoch 656 
2024-11-27 08:19:47.203800: Current learning rate: 0.00383 
2024-11-27 08:20:27.255724: train_loss -0.9566 
2024-11-27 08:20:27.255833: val_loss -0.9038 
2024-11-27 08:20:27.255933: Pseudo dice [np.float32(0.9183)] 
2024-11-27 08:20:27.256043: Epoch time: 40.05 s 
2024-11-27 08:20:28.200079:  
2024-11-27 08:20:28.200215: Epoch 657 
2024-11-27 08:20:28.200288: Current learning rate: 0.00382 
2024-11-27 08:21:08.314782: train_loss -0.961 
2024-11-27 08:21:08.314940: val_loss -0.8983 
2024-11-27 08:21:08.314993: Pseudo dice [np.float32(0.9145)] 
2024-11-27 08:21:08.315093: Epoch time: 40.12 s 
2024-11-27 08:21:09.201431:  
2024-11-27 08:21:09.201571: Epoch 658 
2024-11-27 08:21:09.201659: Current learning rate: 0.00381 
2024-11-27 08:21:49.203208: train_loss -0.9616 
2024-11-27 08:21:49.203317: val_loss -0.9102 
2024-11-27 08:21:49.203366: Pseudo dice [np.float32(0.9241)] 
2024-11-27 08:21:49.203419: Epoch time: 40.0 s 
2024-11-27 08:21:50.068754:  
2024-11-27 08:21:50.068892: Epoch 659 
2024-11-27 08:21:50.068965: Current learning rate: 0.0038 
2024-11-27 08:22:30.080167: train_loss -0.9613 
2024-11-27 08:22:30.080278: val_loss -0.9066 
2024-11-27 08:22:30.080338: Pseudo dice [np.float32(0.9212)] 
2024-11-27 08:22:30.080394: Epoch time: 40.01 s 
2024-11-27 08:22:30.954911:  
2024-11-27 08:22:30.955067: Epoch 660 
2024-11-27 08:22:30.955220: Current learning rate: 0.00379 
2024-11-27 08:23:10.952395: train_loss -0.9637 
2024-11-27 08:23:10.952501: val_loss -0.9125 
2024-11-27 08:23:10.952553: Pseudo dice [np.float32(0.9254)] 
2024-11-27 08:23:10.952607: Epoch time: 40.0 s 
2024-11-27 08:23:11.827485:  
2024-11-27 08:23:11.827660: Epoch 661 
2024-11-27 08:23:11.827745: Current learning rate: 0.00378 
2024-11-27 08:23:51.784053: train_loss -0.9653 
2024-11-27 08:23:51.784163: val_loss -0.911 
2024-11-27 08:23:51.784214: Pseudo dice [np.float32(0.9253)] 
2024-11-27 08:23:51.784275: Epoch time: 39.96 s 
2024-11-27 08:23:52.636496:  
2024-11-27 08:23:52.636695: Epoch 662 
2024-11-27 08:23:52.636773: Current learning rate: 0.00377 
2024-11-27 08:24:32.653700: train_loss -0.9672 
2024-11-27 08:24:32.653816: val_loss -0.9056 
2024-11-27 08:24:32.653917: Pseudo dice [np.float32(0.9201)] 
2024-11-27 08:24:32.654047: Epoch time: 40.02 s 
2024-11-27 08:24:33.550165:  
2024-11-27 08:24:33.550358: Epoch 663 
2024-11-27 08:24:33.550441: Current learning rate: 0.00376 
2024-11-27 08:25:13.527536: train_loss -0.9669 
2024-11-27 08:25:13.527646: val_loss -0.9119 
2024-11-27 08:25:13.527699: Pseudo dice [np.float32(0.9261)] 
2024-11-27 08:25:13.527757: Epoch time: 39.98 s 
2024-11-27 08:25:14.437799:  
2024-11-27 08:25:14.437987: Epoch 664 
2024-11-27 08:25:14.438059: Current learning rate: 0.00375 
2024-11-27 08:25:54.437159: train_loss -0.967 
2024-11-27 08:25:54.437284: val_loss -0.9072 
2024-11-27 08:25:54.437348: Pseudo dice [np.float32(0.9225)] 
2024-11-27 08:25:54.437404: Epoch time: 40.0 s 
2024-11-27 08:25:55.368954:  
2024-11-27 08:25:55.369115: Epoch 665 
2024-11-27 08:25:55.369185: Current learning rate: 0.00374 
2024-11-27 08:26:35.364387: train_loss -0.9674 
2024-11-27 08:26:35.364500: val_loss -0.9097 
2024-11-27 08:26:35.364553: Pseudo dice [np.float32(0.9244)] 
2024-11-27 08:26:35.364609: Epoch time: 40.0 s 
2024-11-27 08:26:36.267299:  
2024-11-27 08:26:36.267477: Epoch 666 
2024-11-27 08:26:36.267572: Current learning rate: 0.00373 
2024-11-27 08:27:16.250374: train_loss -0.9684 
2024-11-27 08:27:16.250485: val_loss -0.9093 
2024-11-27 08:27:16.250538: Pseudo dice [np.float32(0.9228)] 
2024-11-27 08:27:16.250596: Epoch time: 39.98 s 
2024-11-27 08:27:17.583428:  
2024-11-27 08:27:17.583590: Epoch 667 
2024-11-27 08:27:17.583662: Current learning rate: 0.00372 
2024-11-27 08:27:57.603346: train_loss -0.9683 
2024-11-27 08:27:57.603457: val_loss -0.9092 
2024-11-27 08:27:57.603508: Pseudo dice [np.float32(0.9235)] 
2024-11-27 08:27:57.603562: Epoch time: 40.02 s 
2024-11-27 08:27:58.528022:  
2024-11-27 08:27:58.528340: Epoch 668 
2024-11-27 08:27:58.528411: Current learning rate: 0.00371 
2024-11-27 08:28:38.573764: train_loss -0.968 
2024-11-27 08:28:38.573912: val_loss -0.9045 
2024-11-27 08:28:38.574002: Pseudo dice [np.float32(0.9202)] 
2024-11-27 08:28:38.574057: Epoch time: 40.05 s 
2024-11-27 08:28:39.479908:  
2024-11-27 08:28:39.480174: Epoch 669 
2024-11-27 08:28:39.480266: Current learning rate: 0.0037 
2024-11-27 08:29:19.501864: train_loss -0.969 
2024-11-27 08:29:19.502038: val_loss -0.9024 
2024-11-27 08:29:19.502179: Pseudo dice [np.float32(0.918)] 
2024-11-27 08:29:19.502280: Epoch time: 40.02 s 
2024-11-27 08:29:20.413408:  
2024-11-27 08:29:20.413563: Epoch 670 
2024-11-27 08:29:20.413636: Current learning rate: 0.00369 
2024-11-27 08:30:00.415744: train_loss -0.969 
2024-11-27 08:30:00.415881: val_loss -0.9087 
2024-11-27 08:30:00.415954: Pseudo dice [np.float32(0.9227)] 
2024-11-27 08:30:00.416028: Epoch time: 40.0 s 
2024-11-27 08:30:01.328363:  
2024-11-27 08:30:01.328525: Epoch 671 
2024-11-27 08:30:01.328596: Current learning rate: 0.00368 
2024-11-27 08:30:41.344805: train_loss -0.9678 
2024-11-27 08:30:41.344924: val_loss -0.9121 
2024-11-27 08:30:41.344978: Pseudo dice [np.float32(0.926)] 
2024-11-27 08:30:41.345036: Epoch time: 40.02 s 
2024-11-27 08:30:42.232014:  
2024-11-27 08:30:42.232186: Epoch 672 
2024-11-27 08:30:42.232300: Current learning rate: 0.00367 
2024-11-27 08:31:22.234511: train_loss -0.9699 
2024-11-27 08:31:22.234665: val_loss -0.9093 
2024-11-27 08:31:22.234717: Pseudo dice [np.float32(0.9237)] 
2024-11-27 08:31:22.234773: Epoch time: 40.0 s 
2024-11-27 08:31:23.206369:  
2024-11-27 08:31:23.206540: Epoch 673 
2024-11-27 08:31:23.206614: Current learning rate: 0.00366 
2024-11-27 08:32:03.206120: train_loss -0.97 
2024-11-27 08:32:03.206255: val_loss -0.9056 
2024-11-27 08:32:03.206352: Pseudo dice [np.float32(0.9228)] 
2024-11-27 08:32:03.206443: Epoch time: 40.0 s 
2024-11-27 08:32:04.166974:  
2024-11-27 08:32:04.167156: Epoch 674 
2024-11-27 08:32:04.167223: Current learning rate: 0.00365 
2024-11-27 08:32:44.151455: train_loss -0.9699 
2024-11-27 08:32:44.151567: val_loss -0.9109 
2024-11-27 08:32:44.151620: Pseudo dice [np.float32(0.9258)] 
2024-11-27 08:32:44.151679: Epoch time: 39.99 s 
2024-11-27 08:32:45.038318:  
2024-11-27 08:32:45.038511: Epoch 675 
2024-11-27 08:32:45.038589: Current learning rate: 0.00364 
2024-11-27 08:33:25.027389: train_loss -0.9685 
2024-11-27 08:33:25.027515: val_loss -0.9067 
2024-11-27 08:33:25.027566: Pseudo dice [np.float32(0.9214)] 
2024-11-27 08:33:25.027621: Epoch time: 39.99 s 
2024-11-27 08:33:25.932792:  
2024-11-27 08:33:25.932978: Epoch 676 
2024-11-27 08:33:25.933111: Current learning rate: 0.00363 
2024-11-27 08:34:05.891838: train_loss -0.9698 
2024-11-27 08:34:05.891999: val_loss -0.9116 
2024-11-27 08:34:05.892055: Pseudo dice [np.float32(0.9256)] 
2024-11-27 08:34:05.892113: Epoch time: 39.96 s 
2024-11-27 08:34:06.817499:  
2024-11-27 08:34:06.817641: Epoch 677 
2024-11-27 08:34:06.817714: Current learning rate: 0.00362 
2024-11-27 08:34:46.836820: train_loss -0.9674 
2024-11-27 08:34:46.837025: val_loss -0.9083 
2024-11-27 08:34:46.837079: Pseudo dice [np.float32(0.9241)] 
2024-11-27 08:34:46.837135: Epoch time: 40.02 s 
2024-11-27 08:34:47.727468:  
2024-11-27 08:34:47.727597: Epoch 678 
2024-11-27 08:34:47.727666: Current learning rate: 0.00361 
2024-11-27 08:35:27.721474: train_loss -0.9672 
2024-11-27 08:35:27.721585: val_loss -0.9087 
2024-11-27 08:35:27.721663: Pseudo dice [np.float32(0.9238)] 
2024-11-27 08:35:27.721745: Epoch time: 39.99 s 
2024-11-27 08:35:28.621147:  
2024-11-27 08:35:28.621304: Epoch 679 
2024-11-27 08:35:28.621396: Current learning rate: 0.0036 
2024-11-27 08:36:08.635489: train_loss -0.967 
2024-11-27 08:36:08.635621: val_loss -0.9062 
2024-11-27 08:36:08.635680: Pseudo dice [np.float32(0.9213)] 
2024-11-27 08:36:08.635742: Epoch time: 40.02 s 
2024-11-27 08:36:09.509214:  
2024-11-27 08:36:09.509433: Epoch 680 
2024-11-27 08:36:09.509510: Current learning rate: 0.00359 
2024-11-27 08:36:49.502064: train_loss -0.9677 
2024-11-27 08:36:49.502176: val_loss -0.9096 
2024-11-27 08:36:49.502229: Pseudo dice [np.float32(0.924)] 
2024-11-27 08:36:49.502286: Epoch time: 39.99 s 
2024-11-27 08:36:50.442035:  
2024-11-27 08:36:50.442170: Epoch 681 
2024-11-27 08:36:50.442244: Current learning rate: 0.00358 
2024-11-27 08:37:30.449653: train_loss -0.9697 
2024-11-27 08:37:30.449760: val_loss -0.9139 
2024-11-27 08:37:30.449812: Pseudo dice [np.float32(0.9276)] 
2024-11-27 08:37:30.449895: Epoch time: 40.01 s 
2024-11-27 08:37:31.374854:  
2024-11-27 08:37:31.375065: Epoch 682 
2024-11-27 08:37:31.375135: Current learning rate: 0.00357 
2024-11-27 08:38:11.367399: train_loss -0.9697 
2024-11-27 08:38:11.367510: val_loss -0.9058 
2024-11-27 08:38:11.367668: Pseudo dice [np.float32(0.9209)] 
2024-11-27 08:38:11.367724: Epoch time: 39.99 s 
2024-11-27 08:38:12.300200:  
2024-11-27 08:38:12.300482: Epoch 683 
2024-11-27 08:38:12.300553: Current learning rate: 0.00356 
2024-11-27 08:38:52.290581: train_loss -0.9696 
2024-11-27 08:38:52.290694: val_loss -0.9105 
2024-11-27 08:38:52.290749: Pseudo dice [np.float32(0.9264)] 
2024-11-27 08:38:52.290832: Epoch time: 39.99 s 
2024-11-27 08:38:53.233240:  
2024-11-27 08:38:53.233398: Epoch 684 
2024-11-27 08:38:53.233470: Current learning rate: 0.00355 
2024-11-27 08:39:33.246954: train_loss -0.9696 
2024-11-27 08:39:33.247096: val_loss -0.9063 
2024-11-27 08:39:33.247151: Pseudo dice [np.float32(0.9222)] 
2024-11-27 08:39:33.247251: Epoch time: 40.01 s 
2024-11-27 08:39:34.567406:  
2024-11-27 08:39:34.567583: Epoch 685 
2024-11-27 08:39:34.567665: Current learning rate: 0.00354 
2024-11-27 08:40:14.614435: train_loss -0.97 
2024-11-27 08:40:14.614568: val_loss -0.9134 
2024-11-27 08:40:14.614621: Pseudo dice [np.float32(0.9269)] 
2024-11-27 08:40:14.614679: Epoch time: 40.05 s 
2024-11-27 08:40:15.562807:  
2024-11-27 08:40:15.562999: Epoch 686 
2024-11-27 08:40:15.563070: Current learning rate: 0.00353 
2024-11-27 08:40:55.540749: train_loss -0.9699 
2024-11-27 08:40:55.540933: val_loss -0.9073 
2024-11-27 08:40:55.541054: Pseudo dice [np.float32(0.9223)] 
2024-11-27 08:40:55.541160: Epoch time: 39.98 s 
2024-11-27 08:40:56.427444:  
2024-11-27 08:40:56.427613: Epoch 687 
2024-11-27 08:40:56.427686: Current learning rate: 0.00352 
2024-11-27 08:41:36.450440: train_loss -0.9704 
2024-11-27 08:41:36.450565: val_loss -0.908 
2024-11-27 08:41:36.450653: Pseudo dice [np.float32(0.9233)] 
2024-11-27 08:41:36.450711: Epoch time: 40.02 s 
2024-11-27 08:41:37.369205:  
2024-11-27 08:41:37.369453: Epoch 688 
2024-11-27 08:41:37.369526: Current learning rate: 0.00351 
2024-11-27 08:42:17.448158: train_loss -0.9701 
2024-11-27 08:42:17.448362: val_loss -0.9123 
2024-11-27 08:42:17.448413: Pseudo dice [np.float32(0.9264)] 
2024-11-27 08:42:17.448467: Epoch time: 40.08 s 
2024-11-27 08:42:18.331521:  
2024-11-27 08:42:18.331676: Epoch 689 
2024-11-27 08:42:18.331756: Current learning rate: 0.0035 
2024-11-27 08:42:58.388605: train_loss -0.971 
2024-11-27 08:42:58.388776: val_loss -0.9115 
2024-11-27 08:42:58.388856: Pseudo dice [np.float32(0.9265)] 
2024-11-27 08:42:58.388988: Epoch time: 40.06 s 
2024-11-27 08:42:59.293887:  
2024-11-27 08:42:59.294038: Epoch 690 
2024-11-27 08:42:59.294109: Current learning rate: 0.00349 
2024-11-27 08:43:39.363470: train_loss -0.9708 
2024-11-27 08:43:39.363585: val_loss -0.9125 
2024-11-27 08:43:39.363638: Pseudo dice [np.float32(0.9268)] 
2024-11-27 08:43:39.363695: Epoch time: 40.07 s 
2024-11-27 08:43:40.250676:  
2024-11-27 08:43:40.250835: Epoch 691 
2024-11-27 08:43:40.250941: Current learning rate: 0.00348 
2024-11-27 08:44:20.297053: train_loss -0.9708 
2024-11-27 08:44:20.297179: val_loss -0.9169 
2024-11-27 08:44:20.297230: Pseudo dice [np.float32(0.9306)] 
2024-11-27 08:44:20.297286: Epoch time: 40.05 s 
2024-11-27 08:44:21.228603:  
2024-11-27 08:44:21.228795: Epoch 692 
2024-11-27 08:44:21.228888: Current learning rate: 0.00346 
2024-11-27 08:45:01.265823: train_loss -0.9705 
2024-11-27 08:45:01.265939: val_loss -0.9096 
2024-11-27 08:45:01.265991: Pseudo dice [np.float32(0.9234)] 
2024-11-27 08:45:01.266047: Epoch time: 40.04 s 
2024-11-27 08:45:02.142678:  
2024-11-27 08:45:02.142846: Epoch 693 
2024-11-27 08:45:02.142969: Current learning rate: 0.00345 
2024-11-27 08:45:42.190620: train_loss -0.9705 
2024-11-27 08:45:42.190733: val_loss -0.9128 
2024-11-27 08:45:42.190865: Pseudo dice [np.float32(0.9274)] 
2024-11-27 08:45:42.190964: Epoch time: 40.05 s 
2024-11-27 08:45:42.191011: Yayy! New best EMA pseudo Dice: 0.9251999855041504 
2024-11-27 08:45:45.361329:  
2024-11-27 08:45:45.361462: Epoch 694 
2024-11-27 08:45:45.361531: Current learning rate: 0.00344 
2024-11-27 08:46:25.290695: train_loss -0.9709 
2024-11-27 08:46:25.290827: val_loss -0.9104 
2024-11-27 08:46:25.290883: Pseudo dice [np.float32(0.9245)] 
2024-11-27 08:46:25.290942: Epoch time: 39.93 s 
2024-11-27 08:46:26.221488:  
2024-11-27 08:46:26.221619: Epoch 695 
2024-11-27 08:46:26.221689: Current learning rate: 0.00343 
2024-11-27 08:47:06.224346: train_loss -0.9711 
2024-11-27 08:47:06.224454: val_loss -0.9057 
2024-11-27 08:47:06.224504: Pseudo dice [np.float32(0.9219)] 
2024-11-27 08:47:06.224558: Epoch time: 40.0 s 
2024-11-27 08:47:07.178919:  
2024-11-27 08:47:07.179085: Epoch 696 
2024-11-27 08:47:07.179155: Current learning rate: 0.00342 
2024-11-27 08:47:47.198601: train_loss -0.9711 
2024-11-27 08:47:47.198715: val_loss -0.9117 
2024-11-27 08:47:47.198768: Pseudo dice [np.float32(0.9264)] 
2024-11-27 08:47:47.198860: Epoch time: 40.02 s 
2024-11-27 08:47:48.135993:  
2024-11-27 08:47:48.136161: Epoch 697 
2024-11-27 08:47:48.136233: Current learning rate: 0.00341 
2024-11-27 08:48:28.162497: train_loss -0.9715 
2024-11-27 08:48:28.162632: val_loss -0.9108 
2024-11-27 08:48:28.162683: Pseudo dice [np.float32(0.9254)] 
2024-11-27 08:48:28.162739: Epoch time: 40.03 s 
2024-11-27 08:48:29.052899:  
2024-11-27 08:48:29.053128: Epoch 698 
2024-11-27 08:48:29.053200: Current learning rate: 0.0034 
2024-11-27 08:49:09.038346: train_loss -0.9706 
2024-11-27 08:49:09.038539: val_loss -0.9077 
2024-11-27 08:49:09.038591: Pseudo dice [np.float32(0.9226)] 
2024-11-27 08:49:09.038647: Epoch time: 39.99 s 
2024-11-27 08:49:09.937918:  
2024-11-27 08:49:09.938041: Epoch 699 
2024-11-27 08:49:09.938113: Current learning rate: 0.00339 
2024-11-27 08:49:49.954665: train_loss -0.9704 
2024-11-27 08:49:49.954819: val_loss -0.9095 
2024-11-27 08:49:49.954881: Pseudo dice [np.float32(0.9256)] 
2024-11-27 08:49:49.954970: Epoch time: 40.02 s 
2024-11-27 08:49:53.224325:  
2024-11-27 08:49:53.224450: Epoch 700 
2024-11-27 08:49:53.224519: Current learning rate: 0.00338 
2024-11-27 08:50:33.128575: train_loss -0.9703 
2024-11-27 08:50:33.128682: val_loss -0.9077 
2024-11-27 08:50:33.128733: Pseudo dice [np.float32(0.923)] 
2024-11-27 08:50:33.128787: Epoch time: 39.91 s 
2024-11-27 08:50:34.019940:  
2024-11-27 08:50:34.020110: Epoch 701 
2024-11-27 08:50:34.020211: Current learning rate: 0.00337 
2024-11-27 08:51:13.977828: train_loss -0.9714 
2024-11-27 08:51:13.978011: val_loss -0.9056 
2024-11-27 08:51:13.978065: Pseudo dice [np.float32(0.9213)] 
2024-11-27 08:51:13.978154: Epoch time: 39.96 s 
2024-11-27 08:51:14.891541:  
2024-11-27 08:51:14.891682: Epoch 702 
2024-11-27 08:51:14.891754: Current learning rate: 0.00336 
2024-11-27 08:51:54.875150: train_loss -0.9721 
2024-11-27 08:51:54.875257: val_loss -0.91 
2024-11-27 08:51:54.875314: Pseudo dice [np.float32(0.925)] 
2024-11-27 08:51:54.875370: Epoch time: 39.98 s 
2024-11-27 08:51:55.793076:  
2024-11-27 08:51:55.793307: Epoch 703 
2024-11-27 08:51:55.793384: Current learning rate: 0.00335 
2024-11-27 08:52:36.310022: train_loss -0.9714 
2024-11-27 08:52:36.310136: val_loss -0.9078 
2024-11-27 08:52:36.310187: Pseudo dice [np.float32(0.9233)] 
2024-11-27 08:52:36.310242: Epoch time: 40.52 s 
2024-11-27 08:52:37.188800:  
2024-11-27 08:52:37.189029: Epoch 704 
2024-11-27 08:52:37.189106: Current learning rate: 0.00334 
2024-11-27 08:53:17.196982: train_loss -0.9708 
2024-11-27 08:53:17.197303: val_loss -0.9126 
2024-11-27 08:53:17.197417: Pseudo dice [np.float32(0.9289)] 
2024-11-27 08:53:17.197503: Epoch time: 40.01 s 
2024-11-27 08:53:18.146124:  
2024-11-27 08:53:18.146265: Epoch 705 
2024-11-27 08:53:18.146336: Current learning rate: 0.00333 
2024-11-27 08:53:58.120436: train_loss -0.9711 
2024-11-27 08:53:58.120549: val_loss -0.9054 
2024-11-27 08:53:58.120628: Pseudo dice [np.float32(0.921)] 
2024-11-27 08:53:58.120686: Epoch time: 39.98 s 
2024-11-27 08:53:59.043597:  
2024-11-27 08:53:59.043742: Epoch 706 
2024-11-27 08:53:59.043812: Current learning rate: 0.00332 
2024-11-27 08:54:39.102305: train_loss -0.971 
2024-11-27 08:54:39.102411: val_loss -0.9143 
2024-11-27 08:54:39.102462: Pseudo dice [np.float32(0.9285)] 
2024-11-27 08:54:39.102517: Epoch time: 40.06 s 
2024-11-27 08:54:39.996305:  
2024-11-27 08:54:39.996452: Epoch 707 
2024-11-27 08:54:39.996521: Current learning rate: 0.00331 
2024-11-27 08:55:20.051844: train_loss -0.9711 
2024-11-27 08:55:20.052029: val_loss -0.9108 
2024-11-27 08:55:20.052082: Pseudo dice [np.float32(0.9262)] 
2024-11-27 08:55:20.052174: Epoch time: 40.06 s 
2024-11-27 08:55:20.940833:  
2024-11-27 08:55:20.941043: Epoch 708 
2024-11-27 08:55:20.941115: Current learning rate: 0.0033 
2024-11-27 08:56:01.069286: train_loss -0.9715 
2024-11-27 08:56:01.069395: val_loss -0.9091 
2024-11-27 08:56:01.069453: Pseudo dice [np.float32(0.9231)] 
2024-11-27 08:56:01.069508: Epoch time: 40.13 s 
2024-11-27 08:56:01.999377:  
2024-11-27 08:56:01.999518: Epoch 709 
2024-11-27 08:56:01.999597: Current learning rate: 0.00329 
2024-11-27 08:56:42.048651: train_loss -0.9719 
2024-11-27 08:56:42.048759: val_loss -0.9089 
2024-11-27 08:56:42.048811: Pseudo dice [np.float32(0.9236)] 
2024-11-27 08:56:42.048871: Epoch time: 40.05 s 
2024-11-27 08:56:42.974160:  
2024-11-27 08:56:42.974320: Epoch 710 
2024-11-27 08:56:42.974407: Current learning rate: 0.00328 
2024-11-27 08:57:23.007463: train_loss -0.9716 
2024-11-27 08:57:23.007575: val_loss -0.9074 
2024-11-27 08:57:23.007628: Pseudo dice [np.float32(0.9231)] 
2024-11-27 08:57:23.007685: Epoch time: 40.03 s 
2024-11-27 08:57:23.946800:  
2024-11-27 08:57:23.946987: Epoch 711 
2024-11-27 08:57:23.947070: Current learning rate: 0.00327 
2024-11-27 08:58:04.000286: train_loss -0.9711 
2024-11-27 08:58:04.000396: val_loss -0.9103 
2024-11-27 08:58:04.000458: Pseudo dice [np.float32(0.9236)] 
2024-11-27 08:58:04.000535: Epoch time: 40.05 s 
2024-11-27 08:58:04.930974:  
2024-11-27 08:58:04.931224: Epoch 712 
2024-11-27 08:58:04.931309: Current learning rate: 0.00326 
2024-11-27 08:58:44.954861: train_loss -0.9715 
2024-11-27 08:58:44.954998: val_loss -0.911 
2024-11-27 08:58:44.955065: Pseudo dice [np.float32(0.927)] 
2024-11-27 08:58:44.955143: Epoch time: 40.02 s 
2024-11-27 08:58:45.891905:  
2024-11-27 08:58:45.892056: Epoch 713 
2024-11-27 08:58:45.892138: Current learning rate: 0.00325 
2024-11-27 08:59:25.958534: train_loss -0.9704 
2024-11-27 08:59:25.958647: val_loss -0.9044 
2024-11-27 08:59:25.958733: Pseudo dice [np.float32(0.9207)] 
2024-11-27 08:59:25.958792: Epoch time: 40.07 s 
2024-11-27 08:59:26.924440:  
2024-11-27 08:59:26.924574: Epoch 714 
2024-11-27 08:59:26.924647: Current learning rate: 0.00324 
2024-11-27 09:00:06.909651: train_loss -0.972 
2024-11-27 09:00:06.909819: val_loss -0.909 
2024-11-27 09:00:06.909900: Pseudo dice [np.float32(0.9238)] 
2024-11-27 09:00:06.909978: Epoch time: 39.99 s 
2024-11-27 09:00:07.862736:  
2024-11-27 09:00:07.862966: Epoch 715 
2024-11-27 09:00:07.863053: Current learning rate: 0.00323 
2024-11-27 09:00:47.870773: train_loss -0.9726 
2024-11-27 09:00:47.871013: val_loss -0.9142 
2024-11-27 09:00:47.871067: Pseudo dice [np.float32(0.9286)] 
2024-11-27 09:00:47.871124: Epoch time: 40.01 s 
2024-11-27 09:00:48.808543:  
2024-11-27 09:00:48.808681: Epoch 716 
2024-11-27 09:00:48.808753: Current learning rate: 0.00322 
2024-11-27 09:01:28.851699: train_loss -0.972 
2024-11-27 09:01:28.851806: val_loss -0.909 
2024-11-27 09:01:28.851855: Pseudo dice [np.float32(0.9238)] 
2024-11-27 09:01:28.851969: Epoch time: 40.04 s 
2024-11-27 09:01:29.762095:  
2024-11-27 09:01:29.762226: Epoch 717 
2024-11-27 09:01:29.762295: Current learning rate: 0.00321 
2024-11-27 09:02:09.818738: train_loss -0.9722 
2024-11-27 09:02:09.818846: val_loss -0.9078 
2024-11-27 09:02:09.818925: Pseudo dice [np.float32(0.9232)] 
2024-11-27 09:02:09.818983: Epoch time: 40.06 s 
2024-11-27 09:02:10.732467:  
2024-11-27 09:02:10.732635: Epoch 718 
2024-11-27 09:02:10.732760: Current learning rate: 0.0032 
2024-11-27 09:02:50.727648: train_loss -0.9732 
2024-11-27 09:02:50.727760: val_loss -0.9104 
2024-11-27 09:02:50.727846: Pseudo dice [np.float32(0.9252)] 
2024-11-27 09:02:50.727962: Epoch time: 40.0 s 
2024-11-27 09:02:51.689065:  
2024-11-27 09:02:51.689225: Epoch 719 
2024-11-27 09:02:51.689294: Current learning rate: 0.00319 
2024-11-27 09:03:31.668775: train_loss -0.9721 
2024-11-27 09:03:31.668928: val_loss -0.904 
2024-11-27 09:03:31.669011: Pseudo dice [np.float32(0.9201)] 
2024-11-27 09:03:31.669065: Epoch time: 39.98 s 
2024-11-27 09:03:32.594374:  
2024-11-27 09:03:32.594507: Epoch 720 
2024-11-27 09:03:32.594575: Current learning rate: 0.00318 
2024-11-27 09:04:12.618488: train_loss -0.9708 
2024-11-27 09:04:12.618598: val_loss -0.9112 
2024-11-27 09:04:12.618652: Pseudo dice [np.float32(0.925)] 
2024-11-27 09:04:12.618708: Epoch time: 40.02 s 
2024-11-27 09:04:13.564775:  
2024-11-27 09:04:13.564957: Epoch 721 
2024-11-27 09:04:13.565027: Current learning rate: 0.00317 
2024-11-27 09:04:53.531679: train_loss -0.9708 
2024-11-27 09:04:53.531802: val_loss -0.9135 
2024-11-27 09:04:53.531862: Pseudo dice [np.float32(0.927)] 
2024-11-27 09:04:53.532004: Epoch time: 39.97 s 
2024-11-27 09:04:54.914424:  
2024-11-27 09:04:54.914562: Epoch 722 
2024-11-27 09:04:54.914665: Current learning rate: 0.00316 
2024-11-27 09:05:34.952218: train_loss -0.972 
2024-11-27 09:05:34.952325: val_loss -0.906 
2024-11-27 09:05:34.952376: Pseudo dice [np.float32(0.9221)] 
2024-11-27 09:05:34.952430: Epoch time: 40.04 s 
2024-11-27 09:05:35.861728:  
2024-11-27 09:05:35.861904: Epoch 723 
2024-11-27 09:05:35.861976: Current learning rate: 0.00315 
2024-11-27 09:06:15.949361: train_loss -0.9716 
2024-11-27 09:06:15.949469: val_loss -0.9109 
2024-11-27 09:06:15.949522: Pseudo dice [np.float32(0.9233)] 
2024-11-27 09:06:15.949580: Epoch time: 40.09 s 
2024-11-27 09:06:16.834474:  
2024-11-27 09:06:16.834676: Epoch 724 
2024-11-27 09:06:16.834747: Current learning rate: 0.00314 
2024-11-27 09:06:56.912254: train_loss -0.9717 
2024-11-27 09:06:56.912387: val_loss -0.9114 
2024-11-27 09:06:56.912455: Pseudo dice [np.float32(0.9256)] 
2024-11-27 09:06:56.912526: Epoch time: 40.08 s 
2024-11-27 09:06:57.782598:  
2024-11-27 09:06:57.782751: Epoch 725 
2024-11-27 09:06:57.782842: Current learning rate: 0.00313 
2024-11-27 09:07:37.822166: train_loss -0.9716 
2024-11-27 09:07:37.822277: val_loss -0.9061 
2024-11-27 09:07:37.822327: Pseudo dice [np.float32(0.9231)] 
2024-11-27 09:07:37.822381: Epoch time: 40.04 s 
2024-11-27 09:07:38.725297:  
2024-11-27 09:07:38.725461: Epoch 726 
2024-11-27 09:07:38.725546: Current learning rate: 0.00312 
2024-11-27 09:08:18.797686: train_loss -0.9724 
2024-11-27 09:08:18.797798: val_loss -0.9112 
2024-11-27 09:08:18.797851: Pseudo dice [np.float32(0.9251)] 
2024-11-27 09:08:18.797954: Epoch time: 40.07 s 
2024-11-27 09:08:19.684638:  
2024-11-27 09:08:19.684845: Epoch 727 
2024-11-27 09:08:19.684965: Current learning rate: 0.00311 
2024-11-27 09:08:59.748319: train_loss -0.9723 
2024-11-27 09:08:59.748456: val_loss -0.9084 
2024-11-27 09:08:59.748509: Pseudo dice [np.float32(0.9235)] 
2024-11-27 09:08:59.748565: Epoch time: 40.06 s 
2024-11-27 09:09:00.635020:  
2024-11-27 09:09:00.635270: Epoch 728 
2024-11-27 09:09:00.635355: Current learning rate: 0.0031 
2024-11-27 09:09:40.695537: train_loss -0.9722 
2024-11-27 09:09:40.695676: val_loss -0.9042 
2024-11-27 09:09:40.695747: Pseudo dice [np.float32(0.9211)] 
2024-11-27 09:09:40.695820: Epoch time: 40.06 s 
2024-11-27 09:09:41.644734:  
2024-11-27 09:09:41.644917: Epoch 729 
2024-11-27 09:09:41.645036: Current learning rate: 0.00309 
2024-11-27 09:10:21.758125: train_loss -0.9718 
2024-11-27 09:10:21.758265: val_loss -0.9063 
2024-11-27 09:10:21.758332: Pseudo dice [np.float32(0.9222)] 
2024-11-27 09:10:21.758403: Epoch time: 40.11 s 
2024-11-27 09:10:22.697373:  
2024-11-27 09:10:22.697511: Epoch 730 
2024-11-27 09:10:22.697617: Current learning rate: 0.00308 
2024-11-27 09:11:02.738864: train_loss -0.972 
2024-11-27 09:11:02.739044: val_loss -0.9099 
2024-11-27 09:11:02.739105: Pseudo dice [np.float32(0.9252)] 
2024-11-27 09:11:02.739182: Epoch time: 40.04 s 
2024-11-27 09:11:03.648008:  
2024-11-27 09:11:03.648481: Epoch 731 
2024-11-27 09:11:03.648587: Current learning rate: 0.00307 
2024-11-27 09:11:43.623348: train_loss -0.9709 
2024-11-27 09:11:43.623465: val_loss -0.9103 
2024-11-27 09:11:43.623579: Pseudo dice [np.float32(0.9231)] 
2024-11-27 09:11:43.623691: Epoch time: 39.98 s 
2024-11-27 09:11:44.521411:  
2024-11-27 09:11:44.521592: Epoch 732 
2024-11-27 09:11:44.521662: Current learning rate: 0.00306 
2024-11-27 09:12:24.592055: train_loss -0.972 
2024-11-27 09:12:24.592166: val_loss -0.907 
2024-11-27 09:12:24.592216: Pseudo dice [np.float32(0.9221)] 
2024-11-27 09:12:24.592272: Epoch time: 40.07 s 
2024-11-27 09:12:25.519725:  
2024-11-27 09:12:25.519902: Epoch 733 
2024-11-27 09:12:25.520028: Current learning rate: 0.00305 
2024-11-27 09:13:05.543861: train_loss -0.972 
2024-11-27 09:13:05.544038: val_loss -0.9034 
2024-11-27 09:13:05.544113: Pseudo dice [np.float32(0.923)] 
2024-11-27 09:13:05.544168: Epoch time: 40.02 s 
2024-11-27 09:13:06.464267:  
2024-11-27 09:13:06.464404: Epoch 734 
2024-11-27 09:13:06.464476: Current learning rate: 0.00304 
2024-11-27 09:13:46.514128: train_loss -0.9723 
2024-11-27 09:13:46.514231: val_loss -0.914 
2024-11-27 09:13:46.514282: Pseudo dice [np.float32(0.9278)] 
2024-11-27 09:13:46.514334: Epoch time: 40.05 s 
2024-11-27 09:13:47.406115:  
2024-11-27 09:13:47.406327: Epoch 735 
2024-11-27 09:13:47.406400: Current learning rate: 0.00303 
2024-11-27 09:14:27.472000: train_loss -0.9731 
2024-11-27 09:14:27.472106: val_loss -0.9099 
2024-11-27 09:14:27.472157: Pseudo dice [np.float32(0.9259)] 
2024-11-27 09:14:27.472210: Epoch time: 40.07 s 
2024-11-27 09:14:28.349424:  
2024-11-27 09:14:28.349563: Epoch 736 
2024-11-27 09:14:28.349633: Current learning rate: 0.00302 
2024-11-27 09:15:08.351047: train_loss -0.9725 
2024-11-27 09:15:08.351221: val_loss -0.9114 
2024-11-27 09:15:08.351296: Pseudo dice [np.float32(0.9257)] 
2024-11-27 09:15:08.351371: Epoch time: 40.0 s 
2024-11-27 09:15:09.273917:  
2024-11-27 09:15:09.274043: Epoch 737 
2024-11-27 09:15:09.274132: Current learning rate: 0.00301 
2024-11-27 09:15:49.272602: train_loss -0.9726 
2024-11-27 09:15:49.272736: val_loss -0.9115 
2024-11-27 09:15:49.272838: Pseudo dice [np.float32(0.9273)] 
2024-11-27 09:15:49.272918: Epoch time: 40.0 s 
2024-11-27 09:15:50.179509:  
2024-11-27 09:15:50.179644: Epoch 738 
2024-11-27 09:15:50.179713: Current learning rate: 0.003 
2024-11-27 09:16:30.177657: train_loss -0.9735 
2024-11-27 09:16:30.177793: val_loss -0.9095 
2024-11-27 09:16:30.177844: Pseudo dice [np.float32(0.9252)] 
2024-11-27 09:16:30.177949: Epoch time: 40.0 s 
2024-11-27 09:16:31.058810:  
2024-11-27 09:16:31.058989: Epoch 739 
2024-11-27 09:16:31.059058: Current learning rate: 0.00299 
2024-11-27 09:17:11.065205: train_loss -0.9722 
2024-11-27 09:17:11.065317: val_loss -0.9106 
2024-11-27 09:17:11.065368: Pseudo dice [np.float32(0.9255)] 
2024-11-27 09:17:11.065424: Epoch time: 40.01 s 
2024-11-27 09:17:11.944982:  
2024-11-27 09:17:11.945161: Epoch 740 
2024-11-27 09:17:11.945233: Current learning rate: 0.00297 
2024-11-27 09:17:52.354625: train_loss -0.9725 
2024-11-27 09:17:52.354787: val_loss -0.9099 
2024-11-27 09:17:52.354857: Pseudo dice [np.float32(0.9252)] 
2024-11-27 09:17:52.354936: Epoch time: 40.41 s 
2024-11-27 09:17:53.302096:  
2024-11-27 09:17:53.302352: Epoch 741 
2024-11-27 09:17:53.302464: Current learning rate: 0.00296 
2024-11-27 09:18:33.382095: train_loss -0.9734 
2024-11-27 09:18:33.382245: val_loss -0.91 
2024-11-27 09:18:33.382351: Pseudo dice [np.float32(0.9254)] 
2024-11-27 09:18:33.382427: Epoch time: 40.08 s 
2024-11-27 09:18:34.354384:  
2024-11-27 09:18:34.354635: Epoch 742 
2024-11-27 09:18:34.354711: Current learning rate: 0.00295 
2024-11-27 09:19:14.445053: train_loss -0.9726 
2024-11-27 09:19:14.445167: val_loss -0.9111 
2024-11-27 09:19:14.445219: Pseudo dice [np.float32(0.9263)] 
2024-11-27 09:19:14.445317: Epoch time: 40.09 s 
2024-11-27 09:19:15.336912:  
2024-11-27 09:19:15.337190: Epoch 743 
2024-11-27 09:19:15.337383: Current learning rate: 0.00294 
2024-11-27 09:19:55.403101: train_loss -0.9725 
2024-11-27 09:19:55.403245: val_loss -0.9079 
2024-11-27 09:19:55.403305: Pseudo dice [np.float32(0.9249)] 
2024-11-27 09:19:55.403378: Epoch time: 40.07 s 
2024-11-27 09:19:56.335465:  
2024-11-27 09:19:56.335628: Epoch 744 
2024-11-27 09:19:56.335719: Current learning rate: 0.00293 
2024-11-27 09:20:36.354686: train_loss -0.9731 
2024-11-27 09:20:36.354796: val_loss -0.9107 
2024-11-27 09:20:36.354850: Pseudo dice [np.float32(0.9257)] 
2024-11-27 09:20:36.354959: Epoch time: 40.02 s 
2024-11-27 09:20:37.339345:  
2024-11-27 09:20:37.339492: Epoch 745 
2024-11-27 09:20:37.339564: Current learning rate: 0.00292 
2024-11-27 09:21:17.401304: train_loss -0.9727 
2024-11-27 09:21:17.401421: val_loss -0.9118 
2024-11-27 09:21:17.401472: Pseudo dice [np.float32(0.9262)] 
2024-11-27 09:21:17.401526: Epoch time: 40.06 s 
2024-11-27 09:21:17.401606: Yayy! New best EMA pseudo Dice: 0.9251999855041504 
2024-11-27 09:21:20.624250:  
2024-11-27 09:21:20.624397: Epoch 746 
2024-11-27 09:21:20.624464: Current learning rate: 0.00291 
2024-11-27 09:22:00.570298: train_loss -0.9723 
2024-11-27 09:22:00.570409: val_loss -0.9065 
2024-11-27 09:22:00.570462: Pseudo dice [np.float32(0.9222)] 
2024-11-27 09:22:00.570519: Epoch time: 39.95 s 
2024-11-27 09:22:01.515385:  
2024-11-27 09:22:01.515518: Epoch 747 
2024-11-27 09:22:01.515599: Current learning rate: 0.0029 
2024-11-27 09:22:41.569593: train_loss -0.9736 
2024-11-27 09:22:41.569705: val_loss -0.9072 
2024-11-27 09:22:41.569759: Pseudo dice [np.float32(0.9216)] 
2024-11-27 09:22:41.569814: Epoch time: 40.06 s 
2024-11-27 09:22:42.488023:  
2024-11-27 09:22:42.488168: Epoch 748 
2024-11-27 09:22:42.488238: Current learning rate: 0.00289 
2024-11-27 09:23:22.577898: train_loss -0.9731 
2024-11-27 09:23:22.578278: val_loss -0.9092 
2024-11-27 09:23:22.578388: Pseudo dice [np.float32(0.924)] 
2024-11-27 09:23:22.578465: Epoch time: 40.09 s 
2024-11-27 09:23:23.466764:  
2024-11-27 09:23:23.467012: Epoch 749 
2024-11-27 09:23:23.467094: Current learning rate: 0.00288 
2024-11-27 09:24:03.508981: train_loss -0.9733 
2024-11-27 09:24:03.509091: val_loss -0.9116 
2024-11-27 09:24:03.509141: Pseudo dice [np.float32(0.9256)] 
2024-11-27 09:24:03.509196: Epoch time: 40.04 s 
2024-11-27 09:24:06.735778:  
2024-11-27 09:24:06.735961: Epoch 750 
2024-11-27 09:24:06.736054: Current learning rate: 0.00287 
2024-11-27 09:24:46.684861: train_loss -0.9733 
2024-11-27 09:24:46.685037: val_loss -0.9101 
2024-11-27 09:24:46.685088: Pseudo dice [np.float32(0.9271)] 
2024-11-27 09:24:46.685143: Epoch time: 39.95 s 
2024-11-27 09:24:47.613059:  
2024-11-27 09:24:47.613171: Epoch 751 
2024-11-27 09:24:47.613240: Current learning rate: 0.00286 
2024-11-27 09:25:27.649484: train_loss -0.9729 
2024-11-27 09:25:27.649594: val_loss -0.9078 
2024-11-27 09:25:27.649647: Pseudo dice [np.float32(0.9241)] 
2024-11-27 09:25:27.649703: Epoch time: 40.04 s 
2024-11-27 09:25:28.602370:  
2024-11-27 09:25:28.602544: Epoch 752 
2024-11-27 09:25:28.602709: Current learning rate: 0.00285 
2024-11-27 09:26:08.675586: train_loss -0.9732 
2024-11-27 09:26:08.675705: val_loss -0.9091 
2024-11-27 09:26:08.675755: Pseudo dice [np.float32(0.9256)] 
2024-11-27 09:26:08.675809: Epoch time: 40.07 s 
2024-11-27 09:26:09.601987:  
2024-11-27 09:26:09.602145: Epoch 753 
2024-11-27 09:26:09.602245: Current learning rate: 0.00284 
2024-11-27 09:26:49.638277: train_loss -0.9733 
2024-11-27 09:26:49.638384: val_loss -0.9141 
2024-11-27 09:26:49.638436: Pseudo dice [np.float32(0.9283)] 
2024-11-27 09:26:49.638538: Epoch time: 40.04 s 
2024-11-27 09:26:49.638584: Yayy! New best EMA pseudo Dice: 0.9251999855041504 
2024-11-27 09:26:53.064564:  
2024-11-27 09:26:53.064775: Epoch 754 
2024-11-27 09:26:53.064848: Current learning rate: 0.00283 
2024-11-27 09:27:33.009020: train_loss -0.9735 
2024-11-27 09:27:33.009145: val_loss -0.9081 
2024-11-27 09:27:33.009200: Pseudo dice [np.float32(0.9226)] 
2024-11-27 09:27:33.009257: Epoch time: 39.95 s 
2024-11-27 09:27:33.926509:  
2024-11-27 09:27:33.926664: Epoch 755 
2024-11-27 09:27:33.926735: Current learning rate: 0.00282 
2024-11-27 09:28:13.887796: train_loss -0.9733 
2024-11-27 09:28:13.887964: val_loss -0.9105 
2024-11-27 09:28:13.888071: Pseudo dice [np.float32(0.9249)] 
2024-11-27 09:28:13.888128: Epoch time: 39.96 s 
2024-11-27 09:28:14.832466:  
2024-11-27 09:28:14.832777: Epoch 756 
2024-11-27 09:28:14.832929: Current learning rate: 0.00281 
2024-11-27 09:28:54.805021: train_loss -0.9737 
2024-11-27 09:28:54.805357: val_loss -0.9041 
2024-11-27 09:28:54.805411: Pseudo dice [np.float32(0.9206)] 
2024-11-27 09:28:54.805547: Epoch time: 39.97 s 
2024-11-27 09:28:55.695961:  
2024-11-27 09:28:55.696152: Epoch 757 
2024-11-27 09:28:55.696248: Current learning rate: 0.0028 
2024-11-27 09:29:35.741162: train_loss -0.9739 
2024-11-27 09:29:35.741268: val_loss -0.9061 
2024-11-27 09:29:35.741318: Pseudo dice [np.float32(0.9226)] 
2024-11-27 09:29:35.741391: Epoch time: 40.05 s 
2024-11-27 09:29:37.031145:  
2024-11-27 09:29:37.031308: Epoch 758 
2024-11-27 09:29:37.031390: Current learning rate: 0.00279 
2024-11-27 09:30:17.058837: train_loss -0.974 
2024-11-27 09:30:17.058996: val_loss -0.9061 
2024-11-27 09:30:17.059049: Pseudo dice [np.float32(0.9211)] 
2024-11-27 09:30:17.059103: Epoch time: 40.03 s 
2024-11-27 09:30:17.993418:  
2024-11-27 09:30:17.993568: Epoch 759 
2024-11-27 09:30:17.993637: Current learning rate: 0.00278 
2024-11-27 09:30:58.056394: train_loss -0.9736 
2024-11-27 09:30:58.056553: val_loss -0.9066 
2024-11-27 09:30:58.056660: Pseudo dice [np.float32(0.9246)] 
2024-11-27 09:30:58.056736: Epoch time: 40.06 s 
2024-11-27 09:30:58.994115:  
2024-11-27 09:30:58.994263: Epoch 760 
2024-11-27 09:30:58.994332: Current learning rate: 0.00277 
2024-11-27 09:31:39.043430: train_loss -0.9733 
2024-11-27 09:31:39.043533: val_loss -0.9112 
2024-11-27 09:31:39.043585: Pseudo dice [np.float32(0.9264)] 
2024-11-27 09:31:39.043643: Epoch time: 40.05 s 
2024-11-27 09:31:39.979286:  
2024-11-27 09:31:39.979439: Epoch 761 
2024-11-27 09:31:39.979509: Current learning rate: 0.00276 
2024-11-27 09:32:20.013552: train_loss -0.9729 
2024-11-27 09:32:20.013658: val_loss -0.9106 
2024-11-27 09:32:20.013708: Pseudo dice [np.float32(0.9251)] 
2024-11-27 09:32:20.013761: Epoch time: 40.04 s 
2024-11-27 09:32:20.907928:  
2024-11-27 09:32:20.908084: Epoch 762 
2024-11-27 09:32:20.908155: Current learning rate: 0.00275 
2024-11-27 09:33:00.977139: train_loss -0.9732 
2024-11-27 09:33:00.977253: val_loss -0.9126 
2024-11-27 09:33:00.977306: Pseudo dice [np.float32(0.9259)] 
2024-11-27 09:33:00.977362: Epoch time: 40.07 s 
2024-11-27 09:33:01.884948:  
2024-11-27 09:33:01.885154: Epoch 763 
2024-11-27 09:33:01.885380: Current learning rate: 0.00274 
2024-11-27 09:33:41.991612: train_loss -0.9739 
2024-11-27 09:33:41.991802: val_loss -0.9143 
2024-11-27 09:33:41.991876: Pseudo dice [np.float32(0.9288)] 
2024-11-27 09:33:41.991956: Epoch time: 40.11 s 
2024-11-27 09:33:42.928161:  
2024-11-27 09:33:42.928260: Epoch 764 
2024-11-27 09:33:42.928489: Current learning rate: 0.00273 
2024-11-27 09:34:23.045092: train_loss -0.974 
2024-11-27 09:34:23.045199: val_loss -0.91 
2024-11-27 09:34:23.045250: Pseudo dice [np.float32(0.927)] 
2024-11-27 09:34:23.045304: Epoch time: 40.12 s 
2024-11-27 09:34:23.946045:  
2024-11-27 09:34:23.946223: Epoch 765 
2024-11-27 09:34:23.946309: Current learning rate: 0.00272 
2024-11-27 09:35:03.980200: train_loss -0.9737 
2024-11-27 09:35:03.980310: val_loss -0.9043 
2024-11-27 09:35:03.980361: Pseudo dice [np.float32(0.9211)] 
2024-11-27 09:35:03.980416: Epoch time: 40.04 s 
2024-11-27 09:35:04.933178:  
2024-11-27 09:35:04.933411: Epoch 766 
2024-11-27 09:35:04.933501: Current learning rate: 0.00271 
2024-11-27 09:35:45.012892: train_loss -0.9737 
2024-11-27 09:35:45.013083: val_loss -0.9097 
2024-11-27 09:35:45.013148: Pseudo dice [np.float32(0.9256)] 
2024-11-27 09:35:45.013206: Epoch time: 40.08 s 
2024-11-27 09:35:45.971421:  
2024-11-27 09:35:45.971560: Epoch 767 
2024-11-27 09:35:45.971631: Current learning rate: 0.0027 
2024-11-27 09:36:26.070224: train_loss -0.9744 
2024-11-27 09:36:26.070356: val_loss -0.9106 
2024-11-27 09:36:26.070409: Pseudo dice [np.float32(0.9261)] 
2024-11-27 09:36:26.070466: Epoch time: 40.1 s 
2024-11-27 09:36:26.965941:  
2024-11-27 09:36:26.966142: Epoch 768 
2024-11-27 09:36:26.966214: Current learning rate: 0.00268 
2024-11-27 09:37:06.995698: train_loss -0.9735 
2024-11-27 09:37:06.995830: val_loss -0.9033 
2024-11-27 09:37:06.995890: Pseudo dice [np.float32(0.9212)] 
2024-11-27 09:37:06.995948: Epoch time: 40.03 s 
2024-11-27 09:37:07.924791:  
2024-11-27 09:37:07.924999: Epoch 769 
2024-11-27 09:37:07.925069: Current learning rate: 0.00267 
2024-11-27 09:37:47.949840: train_loss -0.9739 
2024-11-27 09:37:47.949984: val_loss -0.9104 
2024-11-27 09:37:47.950050: Pseudo dice [np.float32(0.9257)] 
2024-11-27 09:37:47.950122: Epoch time: 40.03 s 
2024-11-27 09:37:48.910985:  
2024-11-27 09:37:48.911242: Epoch 770 
2024-11-27 09:37:48.911365: Current learning rate: 0.00266 
2024-11-27 09:38:28.966100: train_loss -0.9738 
2024-11-27 09:38:28.966205: val_loss -0.9078 
2024-11-27 09:38:28.966257: Pseudo dice [np.float32(0.9232)] 
2024-11-27 09:38:28.966313: Epoch time: 40.06 s 
2024-11-27 09:38:29.862734:  
2024-11-27 09:38:29.862983: Epoch 771 
2024-11-27 09:38:29.863061: Current learning rate: 0.00265 
2024-11-27 09:39:09.915401: train_loss -0.9739 
2024-11-27 09:39:09.915510: val_loss -0.9116 
2024-11-27 09:39:09.915560: Pseudo dice [np.float32(0.9261)] 
2024-11-27 09:39:09.915614: Epoch time: 40.05 s 
2024-11-27 09:39:10.840994:  
2024-11-27 09:39:10.841127: Epoch 772 
2024-11-27 09:39:10.841208: Current learning rate: 0.00264 
2024-11-27 09:39:50.872133: train_loss -0.974 
2024-11-27 09:39:50.872245: val_loss -0.9085 
2024-11-27 09:39:50.872296: Pseudo dice [np.float32(0.9249)] 
2024-11-27 09:39:50.872351: Epoch time: 40.03 s 
2024-11-27 09:39:51.833574:  
2024-11-27 09:39:51.833750: Epoch 773 
2024-11-27 09:39:51.833841: Current learning rate: 0.00263 
2024-11-27 09:40:31.859626: train_loss -0.9738 
2024-11-27 09:40:31.859737: val_loss -0.9125 
2024-11-27 09:40:31.859788: Pseudo dice [np.float32(0.9264)] 
2024-11-27 09:40:31.859877: Epoch time: 40.03 s 
2024-11-27 09:40:32.738070:  
2024-11-27 09:40:32.738217: Epoch 774 
2024-11-27 09:40:32.738317: Current learning rate: 0.00262 
2024-11-27 09:41:12.753532: train_loss -0.9735 
2024-11-27 09:41:12.753656: val_loss -0.9124 
2024-11-27 09:41:12.753707: Pseudo dice [np.float32(0.9263)] 
2024-11-27 09:41:12.753761: Epoch time: 40.02 s 
2024-11-27 09:41:13.655545:  
2024-11-27 09:41:13.655749: Epoch 775 
2024-11-27 09:41:13.655820: Current learning rate: 0.00261 
2024-11-27 09:41:53.673222: train_loss -0.9734 
2024-11-27 09:41:53.673332: val_loss -0.9077 
2024-11-27 09:41:53.673384: Pseudo dice [np.float32(0.9247)] 
2024-11-27 09:41:53.673441: Epoch time: 40.02 s 
2024-11-27 09:41:55.046407:  
2024-11-27 09:41:55.046556: Epoch 776 
2024-11-27 09:41:55.046638: Current learning rate: 0.0026 
2024-11-27 09:42:35.087035: train_loss -0.9737 
2024-11-27 09:42:35.087199: val_loss -0.9112 
2024-11-27 09:42:35.087252: Pseudo dice [np.float32(0.9263)] 
2024-11-27 09:42:35.087308: Epoch time: 40.04 s 
2024-11-27 09:42:36.090939:  
2024-11-27 09:42:36.091189: Epoch 777 
2024-11-27 09:42:36.091279: Current learning rate: 0.00259 
2024-11-27 09:43:16.194875: train_loss -0.9737 
2024-11-27 09:43:16.195028: val_loss -0.9074 
2024-11-27 09:43:16.195083: Pseudo dice [np.float32(0.9232)] 
2024-11-27 09:43:16.195141: Epoch time: 40.1 s 
2024-11-27 09:43:17.139772:  
2024-11-27 09:43:17.139985: Epoch 778 
2024-11-27 09:43:17.140058: Current learning rate: 0.00258 
2024-11-27 09:43:57.193527: train_loss -0.9738 
2024-11-27 09:43:57.193654: val_loss -0.9135 
2024-11-27 09:43:57.193720: Pseudo dice [np.float32(0.9277)] 
2024-11-27 09:43:57.193776: Epoch time: 40.05 s 
2024-11-27 09:43:57.193821: Yayy! New best EMA pseudo Dice: 0.9251999855041504 
2024-11-27 09:44:00.462822:  
2024-11-27 09:44:00.463026: Epoch 779 
2024-11-27 09:44:00.463099: Current learning rate: 0.00257 
2024-11-27 09:44:40.374543: train_loss -0.9735 
2024-11-27 09:44:40.374651: val_loss -0.906 
2024-11-27 09:44:40.374703: Pseudo dice [np.float32(0.9223)] 
2024-11-27 09:44:40.374760: Epoch time: 39.91 s 
2024-11-27 09:44:41.297832:  
2024-11-27 09:44:41.297997: Epoch 780 
2024-11-27 09:44:41.298069: Current learning rate: 0.00256 
2024-11-27 09:45:21.342542: train_loss -0.9739 
2024-11-27 09:45:21.342667: val_loss -0.9022 
2024-11-27 09:45:21.342719: Pseudo dice [np.float32(0.9192)] 
2024-11-27 09:45:21.342775: Epoch time: 40.05 s 
2024-11-27 09:45:22.294152:  
2024-11-27 09:45:22.294440: Epoch 781 
2024-11-27 09:45:22.294528: Current learning rate: 0.00255 
2024-11-27 09:46:02.366084: train_loss -0.9713 
2024-11-27 09:46:02.366200: val_loss -0.9045 
2024-11-27 09:46:02.366496: Pseudo dice [np.float32(0.9208)] 
2024-11-27 09:46:02.366590: Epoch time: 40.07 s 
2024-11-27 09:46:03.285478:  
2024-11-27 09:46:03.285723: Epoch 782 
2024-11-27 09:46:03.285796: Current learning rate: 0.00254 
2024-11-27 09:46:43.344236: train_loss -0.9722 
2024-11-27 09:46:43.344441: val_loss -0.8988 
2024-11-27 09:46:43.344494: Pseudo dice [np.float32(0.9181)] 
2024-11-27 09:46:43.344550: Epoch time: 40.06 s 
2024-11-27 09:46:44.290941:  
2024-11-27 09:46:44.291091: Epoch 783 
2024-11-27 09:46:44.291162: Current learning rate: 0.00253 
2024-11-27 09:47:24.384687: train_loss -0.9728 
2024-11-27 09:47:24.384797: val_loss -0.9086 
2024-11-27 09:47:24.384872: Pseudo dice [np.float32(0.9242)] 
2024-11-27 09:47:24.384944: Epoch time: 40.09 s 
2024-11-27 09:47:25.322180:  
2024-11-27 09:47:25.322383: Epoch 784 
2024-11-27 09:47:25.322637: Current learning rate: 0.00252 
2024-11-27 09:48:05.422624: train_loss -0.9733 
2024-11-27 09:48:05.422727: val_loss -0.9137 
2024-11-27 09:48:05.422776: Pseudo dice [np.float32(0.9279)] 
2024-11-27 09:48:05.422828: Epoch time: 40.1 s 
2024-11-27 09:48:06.302921:  
2024-11-27 09:48:06.303059: Epoch 785 
2024-11-27 09:48:06.303129: Current learning rate: 0.00251 
2024-11-27 09:48:46.348800: train_loss -0.9739 
2024-11-27 09:48:46.349121: val_loss -0.911 
2024-11-27 09:48:46.349176: Pseudo dice [np.float32(0.9276)] 
2024-11-27 09:48:46.349232: Epoch time: 40.05 s 
2024-11-27 09:48:47.285572:  
2024-11-27 09:48:47.285756: Epoch 786 
2024-11-27 09:48:47.285829: Current learning rate: 0.0025 
2024-11-27 09:49:27.315451: train_loss -0.9737 
2024-11-27 09:49:27.315580: val_loss -0.9086 
2024-11-27 09:49:27.315633: Pseudo dice [np.float32(0.9241)] 
2024-11-27 09:49:27.315691: Epoch time: 40.03 s 
2024-11-27 09:49:28.255021:  
2024-11-27 09:49:28.255199: Epoch 787 
2024-11-27 09:49:28.255281: Current learning rate: 0.00249 
2024-11-27 09:50:08.300173: train_loss -0.9736 
2024-11-27 09:50:08.300282: val_loss -0.9097 
2024-11-27 09:50:08.300332: Pseudo dice [np.float32(0.9244)] 
2024-11-27 09:50:08.300385: Epoch time: 40.05 s 
2024-11-27 09:50:09.234000:  
2024-11-27 09:50:09.234248: Epoch 788 
2024-11-27 09:50:09.234317: Current learning rate: 0.00248 
2024-11-27 09:50:49.285029: train_loss -0.972 
2024-11-27 09:50:49.285141: val_loss -0.9127 
2024-11-27 09:50:49.285195: Pseudo dice [np.float32(0.9277)] 
2024-11-27 09:50:49.285251: Epoch time: 40.05 s 
2024-11-27 09:50:50.186316:  
2024-11-27 09:50:50.186467: Epoch 789 
2024-11-27 09:50:50.186537: Current learning rate: 0.00247 
2024-11-27 09:51:30.189314: train_loss -0.9735 
2024-11-27 09:51:30.189422: val_loss -0.909 
2024-11-27 09:51:30.189472: Pseudo dice [np.float32(0.9252)] 
2024-11-27 09:51:30.189525: Epoch time: 40.0 s 
2024-11-27 09:51:31.133502:  
2024-11-27 09:51:31.133794: Epoch 790 
2024-11-27 09:51:31.133889: Current learning rate: 0.00245 
2024-11-27 09:52:11.162127: train_loss -0.9734 
2024-11-27 09:52:11.162338: val_loss -0.9113 
2024-11-27 09:52:11.162446: Pseudo dice [np.float32(0.926)] 
2024-11-27 09:52:11.162522: Epoch time: 40.03 s 
2024-11-27 09:52:12.107731:  
2024-11-27 09:52:12.107858: Epoch 791 
2024-11-27 09:52:12.108016: Current learning rate: 0.00244 
2024-11-27 09:52:52.160566: train_loss -0.974 
2024-11-27 09:52:52.160691: val_loss -0.9106 
2024-11-27 09:52:52.160744: Pseudo dice [np.float32(0.9268)] 
2024-11-27 09:52:52.160802: Epoch time: 40.05 s 
2024-11-27 09:52:53.081283:  
2024-11-27 09:52:53.081406: Epoch 792 
2024-11-27 09:52:53.081475: Current learning rate: 0.00243 
2024-11-27 09:53:33.121526: train_loss -0.974 
2024-11-27 09:53:33.121648: val_loss -0.9111 
2024-11-27 09:53:33.121700: Pseudo dice [np.float32(0.9261)] 
2024-11-27 09:53:33.121755: Epoch time: 40.04 s 
2024-11-27 09:53:34.133343:  
2024-11-27 09:53:34.133464: Epoch 793 
2024-11-27 09:53:34.133532: Current learning rate: 0.00242 
2024-11-27 09:54:14.184629: train_loss -0.9746 
2024-11-27 09:54:14.184762: val_loss -0.9097 
2024-11-27 09:54:14.184816: Pseudo dice [np.float32(0.9248)] 
2024-11-27 09:54:14.184922: Epoch time: 40.05 s 
2024-11-27 09:54:15.558553:  
2024-11-27 09:54:15.558700: Epoch 794 
2024-11-27 09:54:15.558780: Current learning rate: 0.00241 
2024-11-27 09:54:55.613254: train_loss -0.9736 
2024-11-27 09:54:55.613518: val_loss -0.9133 
2024-11-27 09:54:55.613606: Pseudo dice [np.float32(0.926)] 
2024-11-27 09:54:55.613677: Epoch time: 40.06 s 
2024-11-27 09:54:56.547407:  
2024-11-27 09:54:56.547589: Epoch 795 
2024-11-27 09:54:56.547689: Current learning rate: 0.0024 
2024-11-27 09:55:36.588169: train_loss -0.9737 
2024-11-27 09:55:36.588277: val_loss -0.9055 
2024-11-27 09:55:36.588331: Pseudo dice [np.float32(0.9215)] 
2024-11-27 09:55:36.588387: Epoch time: 40.04 s 
2024-11-27 09:55:37.549862:  
2024-11-27 09:55:37.550106: Epoch 796 
2024-11-27 09:55:37.550191: Current learning rate: 0.00239 
2024-11-27 09:56:17.630206: train_loss -0.9742 
2024-11-27 09:56:17.630310: val_loss -0.9081 
2024-11-27 09:56:17.630359: Pseudo dice [np.float32(0.9235)] 
2024-11-27 09:56:17.630414: Epoch time: 40.08 s 
2024-11-27 09:56:18.497022:  
2024-11-27 09:56:18.497165: Epoch 797 
2024-11-27 09:56:18.497239: Current learning rate: 0.00238 
2024-11-27 09:56:58.622348: train_loss -0.9745 
2024-11-27 09:56:58.622522: val_loss -0.9082 
2024-11-27 09:56:58.622597: Pseudo dice [np.float32(0.9233)] 
2024-11-27 09:56:58.622736: Epoch time: 40.13 s 
2024-11-27 09:56:59.573545:  
2024-11-27 09:56:59.573712: Epoch 798 
2024-11-27 09:56:59.573781: Current learning rate: 0.00237 
2024-11-27 09:57:39.663783: train_loss -0.975 
2024-11-27 09:57:39.663896: val_loss -0.9092 
2024-11-27 09:57:39.663947: Pseudo dice [np.float32(0.9251)] 
2024-11-27 09:57:39.664001: Epoch time: 40.09 s 
2024-11-27 09:57:40.607784:  
2024-11-27 09:57:40.607975: Epoch 799 
2024-11-27 09:57:40.608081: Current learning rate: 0.00236 
2024-11-27 09:58:20.633802: train_loss -0.9748 
2024-11-27 09:58:20.633990: val_loss -0.9096 
2024-11-27 09:58:20.634043: Pseudo dice [np.float32(0.9243)] 
2024-11-27 09:58:20.634098: Epoch time: 40.03 s 
2024-11-27 09:58:23.923834:  
2024-11-27 09:58:23.924053: Epoch 800 
2024-11-27 09:58:23.924139: Current learning rate: 0.00235 
2024-11-27 09:59:03.887972: train_loss -0.9745 
2024-11-27 09:59:03.888170: val_loss -0.9082 
2024-11-27 09:59:03.888249: Pseudo dice [np.float32(0.9247)] 
2024-11-27 09:59:03.888308: Epoch time: 39.96 s 
2024-11-27 09:59:04.807478:  
2024-11-27 09:59:04.807656: Epoch 801 
2024-11-27 09:59:04.807727: Current learning rate: 0.00234 
2024-11-27 09:59:44.832386: train_loss -0.9743 
2024-11-27 09:59:44.832500: val_loss -0.9041 
2024-11-27 09:59:44.832555: Pseudo dice [np.float32(0.9204)] 
2024-11-27 09:59:44.832613: Epoch time: 40.03 s 
2024-11-27 09:59:45.753259:  
2024-11-27 09:59:45.753443: Epoch 802 
2024-11-27 09:59:45.753532: Current learning rate: 0.00233 
2024-11-27 10:00:25.804343: train_loss -0.9748 
2024-11-27 10:00:25.804475: val_loss -0.9086 
2024-11-27 10:00:25.804529: Pseudo dice [np.float32(0.9239)] 
2024-11-27 10:00:25.804586: Epoch time: 40.05 s 
2024-11-27 10:00:26.723910:  
2024-11-27 10:00:26.724179: Epoch 803 
2024-11-27 10:00:26.724250: Current learning rate: 0.00232 
2024-11-27 10:01:06.785230: train_loss -0.9741 
2024-11-27 10:01:06.785451: val_loss -0.9075 
2024-11-27 10:01:06.785505: Pseudo dice [np.float32(0.9249)] 
2024-11-27 10:01:06.785562: Epoch time: 40.06 s 
2024-11-27 10:01:07.751671:  
2024-11-27 10:01:07.751834: Epoch 804 
2024-11-27 10:01:07.751960: Current learning rate: 0.00231 
2024-11-27 10:01:47.792340: train_loss -0.9746 
2024-11-27 10:01:47.792452: val_loss -0.9112 
2024-11-27 10:01:47.792541: Pseudo dice [np.float32(0.9258)] 
2024-11-27 10:01:47.792600: Epoch time: 40.04 s 
2024-11-27 10:01:48.753155:  
2024-11-27 10:01:48.753387: Epoch 805 
2024-11-27 10:01:48.753458: Current learning rate: 0.0023 
2024-11-27 10:02:28.821595: train_loss -0.9747 
2024-11-27 10:02:28.821703: val_loss -0.9087 
2024-11-27 10:02:28.821754: Pseudo dice [np.float32(0.9233)] 
2024-11-27 10:02:28.821808: Epoch time: 40.07 s 
2024-11-27 10:02:29.843164:  
2024-11-27 10:02:29.843354: Epoch 806 
2024-11-27 10:02:29.843447: Current learning rate: 0.00229 
2024-11-27 10:03:09.894827: train_loss -0.9747 
2024-11-27 10:03:09.894940: val_loss -0.9085 
2024-11-27 10:03:09.894993: Pseudo dice [np.float32(0.924)] 
2024-11-27 10:03:09.895098: Epoch time: 40.05 s 
2024-11-27 10:03:10.839175:  
2024-11-27 10:03:10.839340: Epoch 807 
2024-11-27 10:03:10.839427: Current learning rate: 0.00228 
2024-11-27 10:03:50.873142: train_loss -0.9743 
2024-11-27 10:03:50.873285: val_loss -0.9073 
2024-11-27 10:03:50.873339: Pseudo dice [np.float32(0.9234)] 
2024-11-27 10:03:50.873394: Epoch time: 40.04 s 
2024-11-27 10:03:51.854548:  
2024-11-27 10:03:51.854681: Epoch 808 
2024-11-27 10:03:51.854758: Current learning rate: 0.00226 
2024-11-27 10:04:31.865801: train_loss -0.9748 
2024-11-27 10:04:31.865947: val_loss -0.9136 
2024-11-27 10:04:31.866057: Pseudo dice [np.float32(0.9283)] 
2024-11-27 10:04:31.866113: Epoch time: 40.01 s 
2024-11-27 10:04:32.831208:  
2024-11-27 10:04:32.831341: Epoch 809 
2024-11-27 10:04:32.831409: Current learning rate: 0.00225 
2024-11-27 10:05:12.847216: train_loss -0.975 
2024-11-27 10:05:12.847327: val_loss -0.909 
2024-11-27 10:05:12.847380: Pseudo dice [np.float32(0.9251)] 
2024-11-27 10:05:12.847437: Epoch time: 40.02 s 
2024-11-27 10:05:13.798085:  
2024-11-27 10:05:13.798309: Epoch 810 
2024-11-27 10:05:13.798383: Current learning rate: 0.00224 
2024-11-27 10:05:53.817072: train_loss -0.975 
2024-11-27 10:05:53.817188: val_loss -0.9143 
2024-11-27 10:05:53.817244: Pseudo dice [np.float32(0.9289)] 
2024-11-27 10:05:53.817305: Epoch time: 40.02 s 
2024-11-27 10:05:54.744513:  
2024-11-27 10:05:54.744662: Epoch 811 
2024-11-27 10:05:54.744753: Current learning rate: 0.00223 
2024-11-27 10:06:34.749579: train_loss -0.9744 
2024-11-27 10:06:34.749697: val_loss -0.9022 
2024-11-27 10:06:34.749793: Pseudo dice [np.float32(0.9204)] 
2024-11-27 10:06:34.749944: Epoch time: 40.01 s 
2024-11-27 10:06:36.135510:  
2024-11-27 10:06:36.135694: Epoch 812 
2024-11-27 10:06:36.135781: Current learning rate: 0.00222 
2024-11-27 10:07:16.200118: train_loss -0.9748 
2024-11-27 10:07:16.200231: val_loss -0.9087 
2024-11-27 10:07:16.200284: Pseudo dice [np.float32(0.9244)] 
2024-11-27 10:07:16.200341: Epoch time: 40.07 s 
2024-11-27 10:07:17.137881:  
2024-11-27 10:07:17.138167: Epoch 813 
2024-11-27 10:07:17.138252: Current learning rate: 0.00221 
2024-11-27 10:07:57.203938: train_loss -0.9751 
2024-11-27 10:07:57.204070: val_loss -0.9119 
2024-11-27 10:07:57.204120: Pseudo dice [np.float32(0.928)] 
2024-11-27 10:07:57.204175: Epoch time: 40.07 s 
2024-11-27 10:07:58.103543:  
2024-11-27 10:07:58.103732: Epoch 814 
2024-11-27 10:07:58.103817: Current learning rate: 0.0022 
2024-11-27 10:08:38.146842: train_loss -0.975 
2024-11-27 10:08:38.146957: val_loss -0.9119 
2024-11-27 10:08:38.147010: Pseudo dice [np.float32(0.9264)] 
2024-11-27 10:08:38.147066: Epoch time: 40.04 s 
2024-11-27 10:08:39.080115:  
2024-11-27 10:08:39.080366: Epoch 815 
2024-11-27 10:08:39.080439: Current learning rate: 0.00219 
2024-11-27 10:09:19.126140: train_loss -0.9747 
2024-11-27 10:09:19.126268: val_loss -0.9093 
2024-11-27 10:09:19.126323: Pseudo dice [np.float32(0.9256)] 
2024-11-27 10:09:19.126423: Epoch time: 40.05 s 
2024-11-27 10:09:20.129605:  
2024-11-27 10:09:20.129754: Epoch 816 
2024-11-27 10:09:20.129826: Current learning rate: 0.00218 
2024-11-27 10:10:00.159410: train_loss -0.9749 
2024-11-27 10:10:00.159522: val_loss -0.9086 
2024-11-27 10:10:00.159575: Pseudo dice [np.float32(0.9243)] 
2024-11-27 10:10:00.159632: Epoch time: 40.03 s 
2024-11-27 10:10:01.159089:  
2024-11-27 10:10:01.159317: Epoch 817 
2024-11-27 10:10:01.159403: Current learning rate: 0.00217 
2024-11-27 10:10:41.222430: train_loss -0.9762 
2024-11-27 10:10:41.222539: val_loss -0.912 
2024-11-27 10:10:41.222591: Pseudo dice [np.float32(0.9275)] 
2024-11-27 10:10:41.222646: Epoch time: 40.06 s 
2024-11-27 10:10:41.222692: Yayy! New best EMA pseudo Dice: 0.9253000020980835 
2024-11-27 10:10:44.480458:  
2024-11-27 10:10:44.480624: Epoch 818 
2024-11-27 10:10:44.480704: Current learning rate: 0.00216 
2024-11-27 10:11:24.427617: train_loss -0.9742 
2024-11-27 10:11:24.427732: val_loss -0.9105 
2024-11-27 10:11:24.427850: Pseudo dice [np.float32(0.9267)] 
2024-11-27 10:11:24.427933: Epoch time: 39.95 s 
2024-11-27 10:11:24.428006: Yayy! New best EMA pseudo Dice: 0.9254000186920166 
2024-11-27 10:11:27.762952:  
2024-11-27 10:11:27.763104: Epoch 819 
2024-11-27 10:11:27.763183: Current learning rate: 0.00215 
2024-11-27 10:12:07.688272: train_loss -0.9752 
2024-11-27 10:12:07.688381: val_loss -0.9123 
2024-11-27 10:12:07.688440: Pseudo dice [np.float32(0.9272)] 
2024-11-27 10:12:07.688513: Epoch time: 39.93 s 
2024-11-27 10:12:07.688567: Yayy! New best EMA pseudo Dice: 0.925599992275238 
2024-11-27 10:12:10.860471:  
2024-11-27 10:12:10.860625: Epoch 820 
2024-11-27 10:12:10.860702: Current learning rate: 0.00214 
2024-11-27 10:12:50.863048: train_loss -0.9755 
2024-11-27 10:12:50.863170: val_loss -0.9108 
2024-11-27 10:12:50.863221: Pseudo dice [np.float32(0.9264)] 
2024-11-27 10:12:50.863275: Epoch time: 40.0 s 
2024-11-27 10:12:50.863320: Yayy! New best EMA pseudo Dice: 0.9257000088691711 
2024-11-27 10:12:53.939000:  
2024-11-27 10:12:53.939243: Epoch 821 
2024-11-27 10:12:53.939324: Current learning rate: 0.00213 
2024-11-27 10:13:33.879426: train_loss -0.9756 
2024-11-27 10:13:33.879533: val_loss -0.916 
2024-11-27 10:13:33.879581: Pseudo dice [np.float32(0.9296)] 
2024-11-27 10:13:33.879659: Epoch time: 39.94 s 
2024-11-27 10:13:33.879734: Yayy! New best EMA pseudo Dice: 0.9261000156402588 
2024-11-27 10:13:37.099760:  
2024-11-27 10:13:37.099953: Epoch 822 
2024-11-27 10:13:37.100053: Current learning rate: 0.00212 
2024-11-27 10:14:17.054330: train_loss -0.9752 
2024-11-27 10:14:17.054552: val_loss -0.9063 
2024-11-27 10:14:17.054612: Pseudo dice [np.float32(0.9225)] 
2024-11-27 10:14:17.054673: Epoch time: 39.96 s 
2024-11-27 10:14:17.940598:  
2024-11-27 10:14:17.940750: Epoch 823 
2024-11-27 10:14:17.940817: Current learning rate: 0.0021 
2024-11-27 10:14:57.934808: train_loss -0.9755 
2024-11-27 10:14:57.934970: val_loss -0.9135 
2024-11-27 10:14:57.935020: Pseudo dice [np.float32(0.9279)] 
2024-11-27 10:14:57.935074: Epoch time: 40.0 s 
2024-11-27 10:14:58.781085:  
2024-11-27 10:14:58.781227: Epoch 824 
2024-11-27 10:14:58.781341: Current learning rate: 0.00209 
2024-11-27 10:15:38.764333: train_loss -0.9752 
2024-11-27 10:15:38.764466: val_loss -0.9094 
2024-11-27 10:15:38.764517: Pseudo dice [np.float32(0.9244)] 
2024-11-27 10:15:38.764574: Epoch time: 39.98 s 
2024-11-27 10:15:39.681286:  
2024-11-27 10:15:39.681424: Epoch 825 
2024-11-27 10:15:39.681494: Current learning rate: 0.00208 
2024-11-27 10:16:19.685223: train_loss -0.975 
2024-11-27 10:16:19.685332: val_loss -0.9069 
2024-11-27 10:16:19.685538: Pseudo dice [np.float32(0.9207)] 
2024-11-27 10:16:19.685596: Epoch time: 40.0 s 
2024-11-27 10:16:20.552665:  
2024-11-27 10:16:20.552820: Epoch 826 
2024-11-27 10:16:20.552953: Current learning rate: 0.00207 
2024-11-27 10:17:00.548035: train_loss -0.975 
2024-11-27 10:17:00.548143: val_loss -0.9083 
2024-11-27 10:17:00.548195: Pseudo dice [np.float32(0.9224)] 
2024-11-27 10:17:00.548251: Epoch time: 40.0 s 
2024-11-27 10:17:01.415653:  
2024-11-27 10:17:01.415819: Epoch 827 
2024-11-27 10:17:01.415954: Current learning rate: 0.00206 
2024-11-27 10:17:41.395721: train_loss -0.9755 
2024-11-27 10:17:41.395836: val_loss -0.9096 
2024-11-27 10:17:41.395967: Pseudo dice [np.float32(0.9252)] 
2024-11-27 10:17:41.396044: Epoch time: 39.98 s 
2024-11-27 10:17:42.270228:  
2024-11-27 10:17:42.270387: Epoch 828 
2024-11-27 10:17:42.270470: Current learning rate: 0.00205 
2024-11-27 10:18:22.266689: train_loss -0.975 
2024-11-27 10:18:22.266798: val_loss -0.9072 
2024-11-27 10:18:22.266859: Pseudo dice [np.float32(0.9243)] 
2024-11-27 10:18:22.267087: Epoch time: 40.0 s 
2024-11-27 10:18:23.161319:  
2024-11-27 10:18:23.161449: Epoch 829 
2024-11-27 10:18:23.161532: Current learning rate: 0.00204 
2024-11-27 10:19:03.203842: train_loss -0.9753 
2024-11-27 10:19:03.204019: val_loss -0.9107 
2024-11-27 10:19:03.204068: Pseudo dice [np.float32(0.9252)] 
2024-11-27 10:19:03.204120: Epoch time: 40.04 s 
2024-11-27 10:19:04.446821:  
2024-11-27 10:19:04.446984: Epoch 830 
2024-11-27 10:19:04.447052: Current learning rate: 0.00203 
2024-11-27 10:19:44.475219: train_loss -0.9752 
2024-11-27 10:19:44.475343: val_loss -0.9124 
2024-11-27 10:19:44.475397: Pseudo dice [np.float32(0.9274)] 
2024-11-27 10:19:44.475488: Epoch time: 40.03 s 
2024-11-27 10:19:45.379235:  
2024-11-27 10:19:45.379445: Epoch 831 
2024-11-27 10:19:45.379533: Current learning rate: 0.00202 
2024-11-27 10:20:25.433601: train_loss -0.9753 
2024-11-27 10:20:25.433711: val_loss -0.9095 
2024-11-27 10:20:25.433793: Pseudo dice [np.float32(0.926)] 
2024-11-27 10:20:25.433850: Epoch time: 40.06 s 
2024-11-27 10:20:26.349473:  
2024-11-27 10:20:26.349693: Epoch 832 
2024-11-27 10:20:26.349837: Current learning rate: 0.00201 
2024-11-27 10:21:06.338003: train_loss -0.9757 
2024-11-27 10:21:06.338112: val_loss -0.9101 
2024-11-27 10:21:06.338163: Pseudo dice [np.float32(0.9261)] 
2024-11-27 10:21:06.338220: Epoch time: 39.99 s 
2024-11-27 10:21:07.242013:  
2024-11-27 10:21:07.242182: Epoch 833 
2024-11-27 10:21:07.242253: Current learning rate: 0.002 
2024-11-27 10:21:47.288582: train_loss -0.9756 
2024-11-27 10:21:47.288721: val_loss -0.9134 
2024-11-27 10:21:47.288785: Pseudo dice [np.float32(0.9285)] 
2024-11-27 10:21:47.288857: Epoch time: 40.05 s 
2024-11-27 10:21:48.122324:  
2024-11-27 10:21:48.122552: Epoch 834 
2024-11-27 10:21:48.122649: Current learning rate: 0.00199 
2024-11-27 10:22:28.158401: train_loss -0.976 
2024-11-27 10:22:28.158511: val_loss -0.9088 
2024-11-27 10:22:28.158562: Pseudo dice [np.float32(0.9237)] 
2024-11-27 10:22:28.158618: Epoch time: 40.04 s 
2024-11-27 10:22:29.048696:  
2024-11-27 10:22:29.048935: Epoch 835 
2024-11-27 10:22:29.049053: Current learning rate: 0.00198 
2024-11-27 10:23:09.060799: train_loss -0.9758 
2024-11-27 10:23:09.060954: val_loss -0.9068 
2024-11-27 10:23:09.061022: Pseudo dice [np.float32(0.923)] 
2024-11-27 10:23:09.061075: Epoch time: 40.01 s 
2024-11-27 10:23:09.964297:  
2024-11-27 10:23:09.964445: Epoch 836 
2024-11-27 10:23:09.964513: Current learning rate: 0.00196 
2024-11-27 10:23:49.997223: train_loss -0.9755 
2024-11-27 10:23:49.997344: val_loss -0.91 
2024-11-27 10:23:49.997413: Pseudo dice [np.float32(0.9257)] 
2024-11-27 10:23:49.997488: Epoch time: 40.03 s 
2024-11-27 10:23:50.853379:  
2024-11-27 10:23:50.853546: Epoch 837 
2024-11-27 10:23:50.853657: Current learning rate: 0.00195 
2024-11-27 10:24:30.906173: train_loss -0.9759 
2024-11-27 10:24:30.906320: val_loss -0.907 
2024-11-27 10:24:30.906414: Pseudo dice [np.float32(0.9227)] 
2024-11-27 10:24:30.906469: Epoch time: 40.05 s 
2024-11-27 10:24:31.786508:  
2024-11-27 10:24:31.786757: Epoch 838 
2024-11-27 10:24:31.786830: Current learning rate: 0.00194 
2024-11-27 10:25:11.877953: train_loss -0.9762 
2024-11-27 10:25:11.878078: val_loss -0.9102 
2024-11-27 10:25:11.878130: Pseudo dice [np.float32(0.9256)] 
2024-11-27 10:25:11.878187: Epoch time: 40.09 s 
2024-11-27 10:25:12.744594:  
2024-11-27 10:25:12.744771: Epoch 839 
2024-11-27 10:25:12.744844: Current learning rate: 0.00193 
2024-11-27 10:25:52.793387: train_loss -0.9756 
2024-11-27 10:25:52.793494: val_loss -0.9132 
2024-11-27 10:25:52.793545: Pseudo dice [np.float32(0.9279)] 
2024-11-27 10:25:52.793599: Epoch time: 40.05 s 
2024-11-27 10:25:53.682861:  
2024-11-27 10:25:53.683116: Epoch 840 
2024-11-27 10:25:53.683184: Current learning rate: 0.00192 
2024-11-27 10:26:33.720261: train_loss -0.9759 
2024-11-27 10:26:33.720471: val_loss -0.9066 
2024-11-27 10:26:33.720524: Pseudo dice [np.float32(0.9228)] 
2024-11-27 10:26:33.720580: Epoch time: 40.04 s 
2024-11-27 10:26:34.563975:  
2024-11-27 10:26:34.564116: Epoch 841 
2024-11-27 10:26:34.564187: Current learning rate: 0.00191 
2024-11-27 10:27:14.605722: train_loss -0.9759 
2024-11-27 10:27:14.605842: val_loss -0.9152 
2024-11-27 10:27:14.605942: Pseudo dice [np.float32(0.9298)] 
2024-11-27 10:27:14.606040: Epoch time: 40.04 s 
2024-11-27 10:27:15.455040:  
2024-11-27 10:27:15.455179: Epoch 842 
2024-11-27 10:27:15.455276: Current learning rate: 0.0019 
2024-11-27 10:27:55.512823: train_loss -0.9758 
2024-11-27 10:27:55.513006: val_loss -0.9092 
2024-11-27 10:27:55.513060: Pseudo dice [np.float32(0.9235)] 
2024-11-27 10:27:55.513118: Epoch time: 40.06 s 
2024-11-27 10:27:56.376594:  
2024-11-27 10:27:56.376723: Epoch 843 
2024-11-27 10:27:56.376803: Current learning rate: 0.00189 
2024-11-27 10:28:36.430598: train_loss -0.9758 
2024-11-27 10:28:36.430711: val_loss -0.9113 
2024-11-27 10:28:36.430763: Pseudo dice [np.float32(0.9265)] 
2024-11-27 10:28:36.430823: Epoch time: 40.05 s 
2024-11-27 10:28:37.309460:  
2024-11-27 10:28:37.309610: Epoch 844 
2024-11-27 10:28:37.309685: Current learning rate: 0.00188 
2024-11-27 10:29:17.354876: train_loss -0.9767 
2024-11-27 10:29:17.354985: val_loss -0.9116 
2024-11-27 10:29:17.355036: Pseudo dice [np.float32(0.9262)] 
2024-11-27 10:29:17.355089: Epoch time: 40.05 s 
2024-11-27 10:29:18.233344:  
2024-11-27 10:29:18.233516: Epoch 845 
2024-11-27 10:29:18.233586: Current learning rate: 0.00187 
2024-11-27 10:29:58.269532: train_loss -0.9758 
2024-11-27 10:29:58.269657: val_loss -0.9095 
2024-11-27 10:29:58.269709: Pseudo dice [np.float32(0.9263)] 
2024-11-27 10:29:58.269763: Epoch time: 40.04 s 
2024-11-27 10:29:59.145689:  
2024-11-27 10:29:59.145815: Epoch 846 
2024-11-27 10:29:59.145927: Current learning rate: 0.00186 
2024-11-27 10:30:39.186846: train_loss -0.9757 
2024-11-27 10:30:39.187004: val_loss -0.9099 
2024-11-27 10:30:39.187057: Pseudo dice [np.float32(0.9247)] 
2024-11-27 10:30:39.187113: Epoch time: 40.04 s 
2024-11-27 10:30:40.056015:  
2024-11-27 10:30:40.056193: Epoch 847 
2024-11-27 10:30:40.056351: Current learning rate: 0.00185 
2024-11-27 10:31:20.097333: train_loss -0.9763 
2024-11-27 10:31:20.097460: val_loss -0.9112 
2024-11-27 10:31:20.097510: Pseudo dice [np.float32(0.9271)] 
2024-11-27 10:31:20.097564: Epoch time: 40.04 s 
2024-11-27 10:31:20.947445:  
2024-11-27 10:31:20.947581: Epoch 848 
2024-11-27 10:31:20.947649: Current learning rate: 0.00184 
2024-11-27 10:32:00.992558: train_loss -0.9763 
2024-11-27 10:32:00.992683: val_loss -0.9121 
2024-11-27 10:32:00.992736: Pseudo dice [np.float32(0.9278)] 
2024-11-27 10:32:00.992793: Epoch time: 40.05 s 
2024-11-27 10:32:02.287319:  
2024-11-27 10:32:02.287496: Epoch 849 
2024-11-27 10:32:02.287587: Current learning rate: 0.00182 
2024-11-27 10:32:42.376443: train_loss -0.9766 
2024-11-27 10:32:42.376554: val_loss -0.9107 
2024-11-27 10:32:42.376606: Pseudo dice [np.float32(0.9277)] 
2024-11-27 10:32:42.376662: Epoch time: 40.09 s 
2024-11-27 10:32:44.689270: Yayy! New best EMA pseudo Dice: 0.9261000156402588 
2024-11-27 10:32:47.939340:  
2024-11-27 10:32:47.939536: Epoch 850 
2024-11-27 10:32:47.939607: Current learning rate: 0.00181 
2024-11-27 10:33:27.879192: train_loss -0.9757 
2024-11-27 10:33:27.879422: val_loss -0.9075 
2024-11-27 10:33:27.879484: Pseudo dice [np.float32(0.9226)] 
2024-11-27 10:33:27.879539: Epoch time: 39.94 s 
2024-11-27 10:33:28.756699:  
2024-11-27 10:33:28.756861: Epoch 851 
2024-11-27 10:33:28.757000: Current learning rate: 0.0018 
2024-11-27 10:34:08.903980: train_loss -0.9762 
2024-11-27 10:34:08.904089: val_loss -0.9051 
2024-11-27 10:34:08.904139: Pseudo dice [np.float32(0.9212)] 
2024-11-27 10:34:08.904193: Epoch time: 40.15 s 
2024-11-27 10:34:09.727379:  
2024-11-27 10:34:09.727535: Epoch 852 
2024-11-27 10:34:09.727605: Current learning rate: 0.00179 
2024-11-27 10:34:49.750683: train_loss -0.9767 
2024-11-27 10:34:49.750795: val_loss -0.9096 
2024-11-27 10:34:49.750846: Pseudo dice [np.float32(0.9253)] 
2024-11-27 10:34:49.750949: Epoch time: 40.02 s 
2024-11-27 10:34:50.650691:  
2024-11-27 10:34:50.650916: Epoch 853 
2024-11-27 10:34:50.651002: Current learning rate: 0.00178 
2024-11-27 10:35:30.709491: train_loss -0.9762 
2024-11-27 10:35:30.709602: val_loss -0.9101 
2024-11-27 10:35:30.709655: Pseudo dice [np.float32(0.9253)] 
2024-11-27 10:35:30.709718: Epoch time: 40.06 s 
2024-11-27 10:35:31.545729:  
2024-11-27 10:35:31.545940: Epoch 854 
2024-11-27 10:35:31.546041: Current learning rate: 0.00177 
2024-11-27 10:36:11.629763: train_loss -0.9764 
2024-11-27 10:36:11.629895: val_loss -0.9117 
2024-11-27 10:36:11.629946: Pseudo dice [np.float32(0.9268)] 
2024-11-27 10:36:11.630000: Epoch time: 40.08 s 
2024-11-27 10:36:12.476354:  
2024-11-27 10:36:12.476520: Epoch 855 
2024-11-27 10:36:12.476612: Current learning rate: 0.00176 
2024-11-27 10:36:52.503510: train_loss -0.9761 
2024-11-27 10:36:52.503618: val_loss -0.9138 
2024-11-27 10:36:52.503668: Pseudo dice [np.float32(0.9282)] 
2024-11-27 10:36:52.503721: Epoch time: 40.03 s 
2024-11-27 10:36:53.354333:  
2024-11-27 10:36:53.354487: Epoch 856 
2024-11-27 10:36:53.354556: Current learning rate: 0.00175 
2024-11-27 10:37:33.432758: train_loss -0.9762 
2024-11-27 10:37:33.432876: val_loss -0.9091 
2024-11-27 10:37:33.432930: Pseudo dice [np.float32(0.9256)] 
2024-11-27 10:37:33.432988: Epoch time: 40.08 s 
2024-11-27 10:37:34.274457:  
2024-11-27 10:37:34.274636: Epoch 857 
2024-11-27 10:37:34.274708: Current learning rate: 0.00174 
2024-11-27 10:38:14.430786: train_loss -0.9763 
2024-11-27 10:38:14.430904: val_loss -0.9074 
2024-11-27 10:38:14.430984: Pseudo dice [np.float32(0.9235)] 
2024-11-27 10:38:14.431042: Epoch time: 40.16 s 
2024-11-27 10:38:15.314629:  
2024-11-27 10:38:15.314833: Epoch 858 
2024-11-27 10:38:15.314961: Current learning rate: 0.00173 
2024-11-27 10:38:55.329768: train_loss -0.9772 
2024-11-27 10:38:55.329929: val_loss -0.9089 
2024-11-27 10:38:55.330036: Pseudo dice [np.float32(0.9246)] 
2024-11-27 10:38:55.330146: Epoch time: 40.02 s 
2024-11-27 10:38:56.221155:  
2024-11-27 10:38:56.221330: Epoch 859 
2024-11-27 10:38:56.221469: Current learning rate: 0.00172 
2024-11-27 10:39:36.257157: train_loss -0.9756 
2024-11-27 10:39:36.257262: val_loss -0.9156 
2024-11-27 10:39:36.257321: Pseudo dice [np.float32(0.9297)] 
2024-11-27 10:39:36.257396: Epoch time: 40.04 s 
2024-11-27 10:39:37.138462:  
2024-11-27 10:39:37.138607: Epoch 860 
2024-11-27 10:39:37.138690: Current learning rate: 0.0017 
2024-11-27 10:40:17.204308: train_loss -0.9765 
2024-11-27 10:40:17.204440: val_loss -0.9063 
2024-11-27 10:40:17.204492: Pseudo dice [np.float32(0.9229)] 
2024-11-27 10:40:17.204545: Epoch time: 40.07 s 
2024-11-27 10:40:18.077643:  
2024-11-27 10:40:18.077881: Epoch 861 
2024-11-27 10:40:18.078061: Current learning rate: 0.00169 
2024-11-27 10:40:58.288816: train_loss -0.977 
2024-11-27 10:40:58.288976: val_loss -0.9152 
2024-11-27 10:40:58.289028: Pseudo dice [np.float32(0.9291)] 
2024-11-27 10:40:58.289085: Epoch time: 40.21 s 
2024-11-27 10:40:59.175553:  
2024-11-27 10:40:59.175731: Epoch 862 
2024-11-27 10:40:59.175802: Current learning rate: 0.00168 
2024-11-27 10:41:39.308237: train_loss -0.9766 
2024-11-27 10:41:39.308401: val_loss -0.9108 
2024-11-27 10:41:39.308473: Pseudo dice [np.float32(0.9266)] 
2024-11-27 10:41:39.308551: Epoch time: 40.13 s 
2024-11-27 10:41:40.216355:  
2024-11-27 10:41:40.216524: Epoch 863 
2024-11-27 10:41:40.216594: Current learning rate: 0.00167 
2024-11-27 10:42:20.259233: train_loss -0.9763 
2024-11-27 10:42:20.259365: val_loss -0.9129 
2024-11-27 10:42:20.259415: Pseudo dice [np.float32(0.928)] 
2024-11-27 10:42:20.259468: Epoch time: 40.04 s 
2024-11-27 10:42:20.259511: Yayy! New best EMA pseudo Dice: 0.9261999726295471 
2024-11-27 10:42:23.460938:  
2024-11-27 10:42:23.461111: Epoch 864 
2024-11-27 10:42:23.461197: Current learning rate: 0.00166 
2024-11-27 10:43:03.371725: train_loss -0.9768 
2024-11-27 10:43:03.371971: val_loss -0.9071 
2024-11-27 10:43:03.372108: Pseudo dice [np.float32(0.9226)] 
2024-11-27 10:43:03.372218: Epoch time: 39.91 s 
2024-11-27 10:43:04.221022:  
2024-11-27 10:43:04.221157: Epoch 865 
2024-11-27 10:43:04.221227: Current learning rate: 0.00165 
2024-11-27 10:43:44.242379: train_loss -0.9768 
2024-11-27 10:43:44.242511: val_loss -0.9123 
2024-11-27 10:43:44.242603: Pseudo dice [np.float32(0.9278)] 
2024-11-27 10:43:44.242694: Epoch time: 40.02 s 
2024-11-27 10:43:45.098654:  
2024-11-27 10:43:45.098784: Epoch 866 
2024-11-27 10:43:45.098924: Current learning rate: 0.00164 
2024-11-27 10:44:25.173314: train_loss -0.9773 
2024-11-27 10:44:25.173419: val_loss -0.9125 
2024-11-27 10:44:25.173469: Pseudo dice [np.float32(0.9269)] 
2024-11-27 10:44:25.173524: Epoch time: 40.08 s 
2024-11-27 10:44:26.085988:  
2024-11-27 10:44:26.086210: Epoch 867 
2024-11-27 10:44:26.086296: Current learning rate: 0.00163 
2024-11-27 10:45:06.203924: train_loss -0.9775 
2024-11-27 10:45:06.204081: val_loss -0.9068 
2024-11-27 10:45:06.204132: Pseudo dice [np.float32(0.9231)] 
2024-11-27 10:45:06.204186: Epoch time: 40.12 s 
2024-11-27 10:45:07.087764:  
2024-11-27 10:45:07.087983: Epoch 868 
2024-11-27 10:45:07.088127: Current learning rate: 0.00162 
2024-11-27 10:45:47.155810: train_loss -0.9763 
2024-11-27 10:45:47.155971: val_loss -0.9064 
2024-11-27 10:45:47.156024: Pseudo dice [np.float32(0.9216)] 
2024-11-27 10:45:47.156082: Epoch time: 40.07 s 
2024-11-27 10:45:48.508482:  
2024-11-27 10:45:48.508704: Epoch 869 
2024-11-27 10:45:48.508804: Current learning rate: 0.00161 
2024-11-27 10:46:28.508141: train_loss -0.9764 
2024-11-27 10:46:28.508263: val_loss -0.913 
2024-11-27 10:46:28.508314: Pseudo dice [np.float32(0.9287)] 
2024-11-27 10:46:28.508368: Epoch time: 40.0 s 
2024-11-27 10:46:29.411529:  
2024-11-27 10:46:29.411677: Epoch 870 
2024-11-27 10:46:29.411772: Current learning rate: 0.00159 
2024-11-27 10:47:09.539169: train_loss -0.977 
2024-11-27 10:47:09.539284: val_loss -0.9071 
2024-11-27 10:47:09.539335: Pseudo dice [np.float32(0.9221)] 
2024-11-27 10:47:09.539389: Epoch time: 40.13 s 
2024-11-27 10:47:10.442132:  
2024-11-27 10:47:10.442517: Epoch 871 
2024-11-27 10:47:10.442605: Current learning rate: 0.00158 
2024-11-27 10:47:50.525028: train_loss -0.9769 
2024-11-27 10:47:50.525162: val_loss -0.9117 
2024-11-27 10:47:50.525231: Pseudo dice [np.float32(0.9266)] 
2024-11-27 10:47:50.525351: Epoch time: 40.08 s 
2024-11-27 10:47:51.558061:  
2024-11-27 10:47:51.558232: Epoch 872 
2024-11-27 10:47:51.558307: Current learning rate: 0.00157 
2024-11-27 10:48:31.621158: train_loss -0.9772 
2024-11-27 10:48:31.621285: val_loss -0.9108 
2024-11-27 10:48:31.621338: Pseudo dice [np.float32(0.9271)] 
2024-11-27 10:48:31.621395: Epoch time: 40.06 s 
2024-11-27 10:48:32.639314:  
2024-11-27 10:48:32.639479: Epoch 873 
2024-11-27 10:48:32.639600: Current learning rate: 0.00156 
2024-11-27 10:49:12.673837: train_loss -0.9776 
2024-11-27 10:49:12.673963: val_loss -0.9072 
2024-11-27 10:49:12.674017: Pseudo dice [np.float32(0.9231)] 
2024-11-27 10:49:12.674074: Epoch time: 40.04 s 
2024-11-27 10:49:13.615317:  
2024-11-27 10:49:13.615475: Epoch 874 
2024-11-27 10:49:13.615545: Current learning rate: 0.00155 
2024-11-27 10:49:53.672434: train_loss -0.9774 
2024-11-27 10:49:53.672544: val_loss -0.9038 
2024-11-27 10:49:53.672598: Pseudo dice [np.float32(0.9194)] 
2024-11-27 10:49:53.672688: Epoch time: 40.06 s 
2024-11-27 10:49:54.539412:  
2024-11-27 10:49:54.539586: Epoch 875 
2024-11-27 10:49:54.539657: Current learning rate: 0.00154 
2024-11-27 10:50:34.661755: train_loss -0.9775 
2024-11-27 10:50:34.661902: val_loss -0.9065 
2024-11-27 10:50:34.661993: Pseudo dice [np.float32(0.9227)] 
2024-11-27 10:50:34.662050: Epoch time: 40.12 s 
2024-11-27 10:50:35.506742:  
2024-11-27 10:50:35.506888: Epoch 876 
2024-11-27 10:50:35.506961: Current learning rate: 0.00153 
2024-11-27 10:51:15.604106: train_loss -0.9768 
2024-11-27 10:51:15.604217: val_loss -0.9128 
2024-11-27 10:51:15.604270: Pseudo dice [np.float32(0.9278)] 
2024-11-27 10:51:15.604330: Epoch time: 40.1 s 
2024-11-27 10:51:16.532980:  
2024-11-27 10:51:16.533114: Epoch 877 
2024-11-27 10:51:16.533187: Current learning rate: 0.00152 
2024-11-27 10:51:56.556312: train_loss -0.9775 
2024-11-27 10:51:56.556419: val_loss -0.9109 
2024-11-27 10:51:56.556471: Pseudo dice [np.float32(0.9261)] 
2024-11-27 10:51:56.556527: Epoch time: 40.02 s 
2024-11-27 10:51:57.496924:  
2024-11-27 10:51:57.497121: Epoch 878 
2024-11-27 10:51:57.497248: Current learning rate: 0.00151 
2024-11-27 10:52:37.503605: train_loss -0.9774 
2024-11-27 10:52:37.503717: val_loss -0.9062 
2024-11-27 10:52:37.503805: Pseudo dice [np.float32(0.9233)] 
2024-11-27 10:52:37.503912: Epoch time: 40.01 s 
2024-11-27 10:52:38.375038:  
2024-11-27 10:52:38.375205: Epoch 879 
2024-11-27 10:52:38.375279: Current learning rate: 0.00149 
2024-11-27 10:53:18.392547: train_loss -0.977 
2024-11-27 10:53:18.392710: val_loss -0.908 
2024-11-27 10:53:18.392777: Pseudo dice [np.float32(0.9241)] 
2024-11-27 10:53:18.392847: Epoch time: 40.02 s 
2024-11-27 10:53:19.308606:  
2024-11-27 10:53:19.308745: Epoch 880 
2024-11-27 10:53:19.308813: Current learning rate: 0.00148 
2024-11-27 10:53:59.340221: train_loss -0.9772 
2024-11-27 10:53:59.340349: val_loss -0.906 
2024-11-27 10:53:59.340418: Pseudo dice [np.float32(0.9219)] 
2024-11-27 10:53:59.340477: Epoch time: 40.03 s 
2024-11-27 10:54:00.189923:  
2024-11-27 10:54:00.190093: Epoch 881 
2024-11-27 10:54:00.190164: Current learning rate: 0.00147 
2024-11-27 10:54:40.169966: train_loss -0.9777 
2024-11-27 10:54:40.170077: val_loss -0.9076 
2024-11-27 10:54:40.170130: Pseudo dice [np.float32(0.9243)] 
2024-11-27 10:54:40.170187: Epoch time: 39.98 s 
2024-11-27 10:54:41.105467:  
2024-11-27 10:54:41.105664: Epoch 882 
2024-11-27 10:54:41.105828: Current learning rate: 0.00146 
2024-11-27 10:55:21.089237: train_loss -0.9777 
2024-11-27 10:55:21.089409: val_loss -0.909 
2024-11-27 10:55:21.089534: Pseudo dice [np.float32(0.9242)] 
2024-11-27 10:55:21.089602: Epoch time: 39.98 s 
2024-11-27 10:55:22.075804:  
2024-11-27 10:55:22.076122: Epoch 883 
2024-11-27 10:55:22.076202: Current learning rate: 0.00145 
2024-11-27 10:56:02.062174: train_loss -0.9779 
2024-11-27 10:56:02.062280: val_loss -0.909 
2024-11-27 10:56:02.062329: Pseudo dice [np.float32(0.9262)] 
2024-11-27 10:56:02.062385: Epoch time: 39.99 s 
2024-11-27 10:56:02.888417:  
2024-11-27 10:56:02.888580: Epoch 884 
2024-11-27 10:56:02.888650: Current learning rate: 0.00144 
2024-11-27 10:56:42.893990: train_loss -0.9772 
2024-11-27 10:56:42.894094: val_loss -0.9117 
2024-11-27 10:56:42.894144: Pseudo dice [np.float32(0.9274)] 
2024-11-27 10:56:42.894229: Epoch time: 40.01 s 
2024-11-27 10:56:43.782352:  
2024-11-27 10:56:43.782589: Epoch 885 
2024-11-27 10:56:43.782699: Current learning rate: 0.00143 
2024-11-27 10:57:23.845418: train_loss -0.9772 
2024-11-27 10:57:23.845550: val_loss -0.9072 
2024-11-27 10:57:23.845604: Pseudo dice [np.float32(0.9238)] 
2024-11-27 10:57:23.845662: Epoch time: 40.06 s 
2024-11-27 10:57:24.697726:  
2024-11-27 10:57:24.697881: Epoch 886 
2024-11-27 10:57:24.697960: Current learning rate: 0.00142 
2024-11-27 10:58:04.706230: train_loss -0.9771 
2024-11-27 10:58:04.706369: val_loss -0.9102 
2024-11-27 10:58:04.706423: Pseudo dice [np.float32(0.9262)] 
2024-11-27 10:58:04.706479: Epoch time: 40.01 s 
2024-11-27 10:58:05.586325:  
2024-11-27 10:58:05.586459: Epoch 887 
2024-11-27 10:58:05.586531: Current learning rate: 0.00141 
2024-11-27 10:58:45.601635: train_loss -0.9778 
2024-11-27 10:58:45.601747: val_loss -0.9124 
2024-11-27 10:58:45.601800: Pseudo dice [np.float32(0.9276)] 
2024-11-27 10:58:45.601857: Epoch time: 40.02 s 
2024-11-27 10:58:46.475030:  
2024-11-27 10:58:46.475187: Epoch 888 
2024-11-27 10:58:46.475354: Current learning rate: 0.00139 
2024-11-27 10:59:26.463069: train_loss -0.9774 
2024-11-27 10:59:26.463230: val_loss -0.9132 
2024-11-27 10:59:26.463300: Pseudo dice [np.float32(0.9272)] 
2024-11-27 10:59:26.463373: Epoch time: 39.99 s 
2024-11-27 10:59:27.732097:  
2024-11-27 10:59:27.732305: Epoch 889 
2024-11-27 10:59:27.732435: Current learning rate: 0.00138 
2024-11-27 11:00:07.778671: train_loss -0.9776 
2024-11-27 11:00:07.778783: val_loss -0.9099 
2024-11-27 11:00:07.778834: Pseudo dice [np.float32(0.9251)] 
2024-11-27 11:00:07.778927: Epoch time: 40.05 s 
2024-11-27 11:00:08.607778:  
2024-11-27 11:00:08.608169: Epoch 890 
2024-11-27 11:00:08.608244: Current learning rate: 0.00137 
2024-11-27 11:00:48.660148: train_loss -0.9781 
2024-11-27 11:00:48.660262: val_loss -0.907 
2024-11-27 11:00:48.660311: Pseudo dice [np.float32(0.9237)] 
2024-11-27 11:00:48.660363: Epoch time: 40.05 s 
2024-11-27 11:00:49.512678:  
2024-11-27 11:00:49.512857: Epoch 891 
2024-11-27 11:00:49.513068: Current learning rate: 0.00136 
2024-11-27 11:01:29.602303: train_loss -0.9783 
2024-11-27 11:01:29.602413: val_loss -0.9113 
2024-11-27 11:01:29.602466: Pseudo dice [np.float32(0.9267)] 
2024-11-27 11:01:29.602558: Epoch time: 40.09 s 
2024-11-27 11:01:30.484267:  
2024-11-27 11:01:30.484477: Epoch 892 
2024-11-27 11:01:30.484551: Current learning rate: 0.00135 
2024-11-27 11:02:10.547788: train_loss -0.9782 
2024-11-27 11:02:10.547946: val_loss -0.9106 
2024-11-27 11:02:10.548053: Pseudo dice [np.float32(0.9272)] 
2024-11-27 11:02:10.548109: Epoch time: 40.06 s 
2024-11-27 11:02:11.480242:  
2024-11-27 11:02:11.480453: Epoch 893 
2024-11-27 11:02:11.480543: Current learning rate: 0.00134 
2024-11-27 11:02:51.551321: train_loss -0.9771 
2024-11-27 11:02:51.551450: val_loss -0.9096 
2024-11-27 11:02:51.551516: Pseudo dice [np.float32(0.9263)] 
2024-11-27 11:02:51.551595: Epoch time: 40.07 s 
2024-11-27 11:02:52.431939:  
2024-11-27 11:02:52.432096: Epoch 894 
2024-11-27 11:02:52.432192: Current learning rate: 0.00133 
2024-11-27 11:03:32.477535: train_loss -0.9782 
2024-11-27 11:03:32.477673: val_loss -0.9095 
2024-11-27 11:03:32.477809: Pseudo dice [np.float32(0.9258)] 
2024-11-27 11:03:32.477973: Epoch time: 40.05 s 
2024-11-27 11:03:33.358460:  
2024-11-27 11:03:33.358607: Epoch 895 
2024-11-27 11:03:33.358677: Current learning rate: 0.00132 
2024-11-27 11:04:13.428679: train_loss -0.9784 
2024-11-27 11:04:13.428937: val_loss -0.9105 
2024-11-27 11:04:13.429001: Pseudo dice [np.float32(0.9258)] 
2024-11-27 11:04:13.429075: Epoch time: 40.07 s 
2024-11-27 11:04:14.394165:  
2024-11-27 11:04:14.394325: Epoch 896 
2024-11-27 11:04:14.394408: Current learning rate: 0.0013 
2024-11-27 11:04:54.450968: train_loss -0.9786 
2024-11-27 11:04:54.451146: val_loss -0.9105 
2024-11-27 11:04:54.451200: Pseudo dice [np.float32(0.9251)] 
2024-11-27 11:04:54.451255: Epoch time: 40.06 s 
2024-11-27 11:04:55.350701:  
2024-11-27 11:04:55.350857: Epoch 897 
2024-11-27 11:04:55.350981: Current learning rate: 0.00129 
2024-11-27 11:05:35.437675: train_loss -0.9775 
2024-11-27 11:05:35.437874: val_loss -0.9128 
2024-11-27 11:05:35.437982: Pseudo dice [np.float32(0.9279)] 
2024-11-27 11:05:35.438058: Epoch time: 40.09 s 
2024-11-27 11:05:36.315479:  
2024-11-27 11:05:36.315662: Epoch 898 
2024-11-27 11:05:36.315755: Current learning rate: 0.00128 
2024-11-27 11:06:16.362300: train_loss -0.9783 
2024-11-27 11:06:16.362412: val_loss -0.9125 
2024-11-27 11:06:16.362465: Pseudo dice [np.float32(0.928)] 
2024-11-27 11:06:16.362523: Epoch time: 40.05 s 
2024-11-27 11:06:17.271932:  
2024-11-27 11:06:17.272120: Epoch 899 
2024-11-27 11:06:17.272216: Current learning rate: 0.00127 
2024-11-27 11:06:57.324115: train_loss -0.9776 
2024-11-27 11:06:57.324227: val_loss -0.9046 
2024-11-27 11:06:57.324278: Pseudo dice [np.float32(0.922)] 
2024-11-27 11:06:57.324333: Epoch time: 40.05 s 
2024-11-27 11:07:00.629115:  
2024-11-27 11:07:00.629433: Epoch 900 
2024-11-27 11:07:00.629507: Current learning rate: 0.00126 
2024-11-27 11:07:40.564987: train_loss -0.978 
2024-11-27 11:07:40.565097: val_loss -0.9047 
2024-11-27 11:07:40.565148: Pseudo dice [np.float32(0.9216)] 
2024-11-27 11:07:40.565204: Epoch time: 39.94 s 
2024-11-27 11:07:41.469515:  
2024-11-27 11:07:41.469654: Epoch 901 
2024-11-27 11:07:41.469725: Current learning rate: 0.00125 
2024-11-27 11:08:21.514374: train_loss -0.9779 
2024-11-27 11:08:21.514487: val_loss -0.9115 
2024-11-27 11:08:21.514541: Pseudo dice [np.float32(0.9272)] 
2024-11-27 11:08:21.514598: Epoch time: 40.05 s 
2024-11-27 11:08:22.354686:  
2024-11-27 11:08:22.354847: Epoch 902 
2024-11-27 11:08:22.354977: Current learning rate: 0.00124 
2024-11-27 11:09:02.393664: train_loss -0.9781 
2024-11-27 11:09:02.393802: val_loss -0.9053 
2024-11-27 11:09:02.393853: Pseudo dice [np.float32(0.9211)] 
2024-11-27 11:09:02.393975: Epoch time: 40.04 s 
2024-11-27 11:09:03.271515:  
2024-11-27 11:09:03.271645: Epoch 903 
2024-11-27 11:09:03.271713: Current learning rate: 0.00122 
2024-11-27 11:09:43.319594: train_loss -0.9784 
2024-11-27 11:09:43.319705: val_loss -0.9087 
2024-11-27 11:09:43.319756: Pseudo dice [np.float32(0.9255)] 
2024-11-27 11:09:43.319812: Epoch time: 40.05 s 
2024-11-27 11:09:44.223431:  
2024-11-27 11:09:44.223604: Epoch 904 
2024-11-27 11:09:44.223694: Current learning rate: 0.00121 
2024-11-27 11:10:24.300441: train_loss -0.9783 
2024-11-27 11:10:24.300647: val_loss -0.9077 
2024-11-27 11:10:24.300701: Pseudo dice [np.float32(0.924)] 
2024-11-27 11:10:24.300756: Epoch time: 40.08 s 
2024-11-27 11:10:25.192644:  
2024-11-27 11:10:25.192814: Epoch 905 
2024-11-27 11:10:25.192934: Current learning rate: 0.0012 
2024-11-27 11:11:05.207999: train_loss -0.9784 
2024-11-27 11:11:05.208111: val_loss -0.912 
2024-11-27 11:11:05.208164: Pseudo dice [np.float32(0.9283)] 
2024-11-27 11:11:05.208222: Epoch time: 40.02 s 
2024-11-27 11:11:06.099959:  
2024-11-27 11:11:06.100135: Epoch 906 
2024-11-27 11:11:06.100224: Current learning rate: 0.00119 
2024-11-27 11:11:46.110708: train_loss -0.9778 
2024-11-27 11:11:46.110823: val_loss -0.9099 
2024-11-27 11:11:46.110882: Pseudo dice [np.float32(0.926)] 
2024-11-27 11:11:46.110943: Epoch time: 40.01 s 
2024-11-27 11:11:47.007533:  
2024-11-27 11:11:47.007665: Epoch 907 
2024-11-27 11:11:47.007738: Current learning rate: 0.00118 
2024-11-27 11:12:27.086129: train_loss -0.9782 
2024-11-27 11:12:27.086350: val_loss -0.9095 
2024-11-27 11:12:27.086507: Pseudo dice [np.float32(0.9269)] 
2024-11-27 11:12:27.086620: Epoch time: 40.08 s 
2024-11-27 11:12:28.276210:  
2024-11-27 11:12:28.276351: Epoch 908 
2024-11-27 11:12:28.276471: Current learning rate: 0.00117 
2024-11-27 11:13:08.432032: train_loss -0.9787 
2024-11-27 11:13:08.432169: val_loss -0.9085 
2024-11-27 11:13:08.432519: Pseudo dice [np.float32(0.9251)] 
2024-11-27 11:13:08.432594: Epoch time: 40.16 s 
2024-11-27 11:13:09.786835:  
2024-11-27 11:13:09.787068: Epoch 909 
2024-11-27 11:13:09.787170: Current learning rate: 0.00116 
2024-11-27 11:13:49.943611: train_loss -0.9786 
2024-11-27 11:13:49.943783: val_loss -0.9107 
2024-11-27 11:13:49.943851: Pseudo dice [np.float32(0.9251)] 
2024-11-27 11:13:49.943929: Epoch time: 40.16 s 
2024-11-27 11:13:50.840895:  
2024-11-27 11:13:50.841062: Epoch 910 
2024-11-27 11:13:50.841135: Current learning rate: 0.00115 
2024-11-27 11:14:31.012978: train_loss -0.9787 
2024-11-27 11:14:31.013100: val_loss -0.9077 
2024-11-27 11:14:31.013170: Pseudo dice [np.float32(0.9232)] 
2024-11-27 11:14:31.013227: Epoch time: 40.17 s 
2024-11-27 11:14:31.931717:  
2024-11-27 11:14:31.931940: Epoch 911 
2024-11-27 11:14:31.932053: Current learning rate: 0.00113 
2024-11-27 11:15:12.106415: train_loss -0.9787 
2024-11-27 11:15:12.106575: val_loss -0.914 
2024-11-27 11:15:12.106629: Pseudo dice [np.float32(0.9272)] 
2024-11-27 11:15:12.106687: Epoch time: 40.18 s 
2024-11-27 11:15:12.988322:  
2024-11-27 11:15:12.988485: Epoch 912 
2024-11-27 11:15:12.988561: Current learning rate: 0.00112 
2024-11-27 11:15:53.212064: train_loss -0.9788 
2024-11-27 11:15:53.212230: val_loss -0.9085 
2024-11-27 11:15:53.212285: Pseudo dice [np.float32(0.9235)] 
2024-11-27 11:15:53.212342: Epoch time: 40.22 s 
2024-11-27 11:15:54.175642:  
2024-11-27 11:15:54.175831: Epoch 913 
2024-11-27 11:15:54.175928: Current learning rate: 0.00111 
2024-11-27 11:16:34.467686: train_loss -0.9786 
2024-11-27 11:16:34.467920: val_loss -0.9107 
2024-11-27 11:16:34.467997: Pseudo dice [np.float32(0.9271)] 
2024-11-27 11:16:34.468050: Epoch time: 40.29 s 
2024-11-27 11:16:35.351419:  
2024-11-27 11:16:35.351587: Epoch 914 
2024-11-27 11:16:35.351663: Current learning rate: 0.0011 
2024-11-27 11:17:15.588706: train_loss -0.9787 
2024-11-27 11:17:15.588852: val_loss -0.909 
2024-11-27 11:17:15.588930: Pseudo dice [np.float32(0.9248)] 
2024-11-27 11:17:15.589004: Epoch time: 40.24 s 
2024-11-27 11:17:16.518677:  
2024-11-27 11:17:16.519065: Epoch 915 
2024-11-27 11:17:16.519160: Current learning rate: 0.00109 
2024-11-27 11:17:56.579067: train_loss -0.9789 
2024-11-27 11:17:56.579186: val_loss -0.9088 
2024-11-27 11:17:56.579248: Pseudo dice [np.float32(0.9242)] 
2024-11-27 11:17:56.579311: Epoch time: 40.06 s 
2024-11-27 11:17:57.486239:  
2024-11-27 11:17:57.486461: Epoch 916 
2024-11-27 11:17:57.486548: Current learning rate: 0.00108 
2024-11-27 11:18:37.628086: train_loss -0.9789 
2024-11-27 11:18:37.628240: val_loss -0.9087 
2024-11-27 11:18:37.628292: Pseudo dice [np.float32(0.9238)] 
2024-11-27 11:18:37.628347: Epoch time: 40.14 s 
2024-11-27 11:18:38.511732:  
2024-11-27 11:18:38.511882: Epoch 917 
2024-11-27 11:18:38.512046: Current learning rate: 0.00106 
2024-11-27 11:19:18.625300: train_loss -0.9789 
2024-11-27 11:19:18.625491: val_loss -0.9126 
2024-11-27 11:19:18.625566: Pseudo dice [np.float32(0.9278)] 
2024-11-27 11:19:18.625642: Epoch time: 40.11 s 
2024-11-27 11:19:19.495348:  
2024-11-27 11:19:19.495579: Epoch 918 
2024-11-27 11:19:19.495677: Current learning rate: 0.00105 
2024-11-27 11:19:59.571217: train_loss -0.9789 
2024-11-27 11:19:59.571338: val_loss -0.9115 
2024-11-27 11:19:59.571392: Pseudo dice [np.float32(0.9277)] 
2024-11-27 11:19:59.571483: Epoch time: 40.08 s 
2024-11-27 11:20:00.416598:  
2024-11-27 11:20:00.416737: Epoch 919 
2024-11-27 11:20:00.416813: Current learning rate: 0.00104 
2024-11-27 11:20:40.488413: train_loss -0.9785 
2024-11-27 11:20:40.488522: val_loss -0.9123 
2024-11-27 11:20:40.488598: Pseudo dice [np.float32(0.9267)] 
2024-11-27 11:20:40.488752: Epoch time: 40.07 s 
2024-11-27 11:20:41.433166:  
2024-11-27 11:20:41.433321: Epoch 920 
2024-11-27 11:20:41.433395: Current learning rate: 0.00103 
2024-11-27 11:21:21.578685: train_loss -0.9785 
2024-11-27 11:21:21.578801: val_loss -0.9148 
2024-11-27 11:21:21.578852: Pseudo dice [np.float32(0.9301)] 
2024-11-27 11:21:21.578979: Epoch time: 40.15 s 
2024-11-27 11:21:22.454313:  
2024-11-27 11:21:22.454527: Epoch 921 
2024-11-27 11:21:22.454672: Current learning rate: 0.00102 
2024-11-27 11:22:02.573292: train_loss -0.9787 
2024-11-27 11:22:02.573430: val_loss -0.9086 
2024-11-27 11:22:02.573500: Pseudo dice [np.float32(0.9256)] 
2024-11-27 11:22:02.573573: Epoch time: 40.12 s 
2024-11-27 11:22:03.474760:  
2024-11-27 11:22:03.474893: Epoch 922 
2024-11-27 11:22:03.475024: Current learning rate: 0.00101 
2024-11-27 11:22:43.680517: train_loss -0.9797 
2024-11-27 11:22:43.680631: val_loss -0.9069 
2024-11-27 11:22:43.680684: Pseudo dice [np.float32(0.9237)] 
2024-11-27 11:22:43.680740: Epoch time: 40.21 s 
2024-11-27 11:22:44.589664:  
2024-11-27 11:22:44.589823: Epoch 923 
2024-11-27 11:22:44.589945: Current learning rate: 0.001 
2024-11-27 11:23:24.781198: train_loss -0.9791 
2024-11-27 11:23:24.781357: val_loss -0.9114 
2024-11-27 11:23:24.781429: Pseudo dice [np.float32(0.9258)] 
2024-11-27 11:23:24.781502: Epoch time: 40.19 s 
2024-11-27 11:23:25.681340:  
2024-11-27 11:23:25.681509: Epoch 924 
2024-11-27 11:23:25.681600: Current learning rate: 0.00098 
2024-11-27 11:24:05.850654: train_loss -0.9786 
2024-11-27 11:24:05.850772: val_loss -0.9094 
2024-11-27 11:24:05.850826: Pseudo dice [np.float32(0.9258)] 
2024-11-27 11:24:05.850935: Epoch time: 40.17 s 
2024-11-27 11:24:06.773271:  
2024-11-27 11:24:06.773429: Epoch 925 
2024-11-27 11:24:06.773504: Current learning rate: 0.00097 
2024-11-27 11:24:46.909542: train_loss -0.9791 
2024-11-27 11:24:46.909667: val_loss -0.9043 
2024-11-27 11:24:46.909737: Pseudo dice [np.float32(0.9216)] 
2024-11-27 11:24:46.909848: Epoch time: 40.14 s 
2024-11-27 11:24:47.852534:  
2024-11-27 11:24:47.852769: Epoch 926 
2024-11-27 11:24:47.852871: Current learning rate: 0.00096 
2024-11-27 11:25:27.963605: train_loss -0.979 
2024-11-27 11:25:27.963737: val_loss -0.9097 
2024-11-27 11:25:27.963824: Pseudo dice [np.float32(0.9263)] 
2024-11-27 11:25:27.963927: Epoch time: 40.11 s 
2024-11-27 11:25:28.852353:  
2024-11-27 11:25:28.852529: Epoch 927 
2024-11-27 11:25:28.852603: Current learning rate: 0.00095 
2024-11-27 11:26:09.013688: train_loss -0.9793 
2024-11-27 11:26:09.013819: val_loss -0.9094 
2024-11-27 11:26:09.013922: Pseudo dice [np.float32(0.9263)] 
2024-11-27 11:26:09.014020: Epoch time: 40.16 s 
2024-11-27 11:26:09.937851:  
2024-11-27 11:26:09.938080: Epoch 928 
2024-11-27 11:26:09.938154: Current learning rate: 0.00094 
2024-11-27 11:26:50.058675: train_loss -0.9784 
2024-11-27 11:26:50.058820: val_loss -0.9082 
2024-11-27 11:26:50.058899: Pseudo dice [np.float32(0.9231)] 
2024-11-27 11:26:50.058992: Epoch time: 40.12 s 
2024-11-27 11:26:51.410035:  
2024-11-27 11:26:51.410209: Epoch 929 
2024-11-27 11:26:51.410285: Current learning rate: 0.00092 
2024-11-27 11:27:31.623662: train_loss -0.9789 
2024-11-27 11:27:31.623776: val_loss -0.9095 
2024-11-27 11:27:31.623830: Pseudo dice [np.float32(0.925)] 
2024-11-27 11:27:31.623931: Epoch time: 40.21 s 
2024-11-27 11:27:32.579142:  
2024-11-27 11:27:32.579439: Epoch 930 
2024-11-27 11:27:32.579530: Current learning rate: 0.00091 
2024-11-27 11:28:12.783298: train_loss -0.9795 
2024-11-27 11:28:12.783472: val_loss -0.907 
2024-11-27 11:28:12.783543: Pseudo dice [np.float32(0.9239)] 
2024-11-27 11:28:12.783618: Epoch time: 40.21 s 
2024-11-27 11:28:13.736671:  
2024-11-27 11:28:13.736893: Epoch 931 
2024-11-27 11:28:13.736988: Current learning rate: 0.0009 
2024-11-27 11:28:53.990438: train_loss -0.9788 
2024-11-27 11:28:53.990568: val_loss -0.9109 
2024-11-27 11:28:53.990620: Pseudo dice [np.float32(0.927)] 
2024-11-27 11:28:53.990684: Epoch time: 40.25 s 
2024-11-27 11:28:54.924057:  
2024-11-27 11:28:54.924229: Epoch 932 
2024-11-27 11:28:54.924425: Current learning rate: 0.00089 
2024-11-27 11:29:35.144027: train_loss -0.979 
2024-11-27 11:29:35.144164: val_loss -0.908 
2024-11-27 11:29:35.144259: Pseudo dice [np.float32(0.9237)] 
2024-11-27 11:29:35.144347: Epoch time: 40.22 s 
2024-11-27 11:29:36.009604:  
2024-11-27 11:29:36.009787: Epoch 933 
2024-11-27 11:29:36.009863: Current learning rate: 0.00088 
2024-11-27 11:30:16.167548: train_loss -0.9789 
2024-11-27 11:30:16.167660: val_loss -0.9084 
2024-11-27 11:30:16.167711: Pseudo dice [np.float32(0.9243)] 
2024-11-27 11:30:16.167767: Epoch time: 40.16 s 
2024-11-27 11:30:17.063901:  
2024-11-27 11:30:17.064093: Epoch 934 
2024-11-27 11:30:17.064182: Current learning rate: 0.00087 
2024-11-27 11:30:57.250411: train_loss -0.9791 
2024-11-27 11:30:57.250524: val_loss -0.9066 
2024-11-27 11:30:57.250585: Pseudo dice [np.float32(0.923)] 
2024-11-27 11:30:57.250643: Epoch time: 40.19 s 
2024-11-27 11:30:58.213839:  
2024-11-27 11:30:58.214174: Epoch 935 
2024-11-27 11:30:58.214248: Current learning rate: 0.00085 
2024-11-27 11:31:38.384633: train_loss -0.9792 
2024-11-27 11:31:38.384848: val_loss -0.9082 
2024-11-27 11:31:38.384933: Pseudo dice [np.float32(0.9254)] 
2024-11-27 11:31:38.385010: Epoch time: 40.17 s 
2024-11-27 11:31:39.298651:  
2024-11-27 11:31:39.298852: Epoch 936 
2024-11-27 11:31:39.298952: Current learning rate: 0.00084 
2024-11-27 11:32:19.481431: train_loss -0.9796 
2024-11-27 11:32:19.481627: val_loss -0.9072 
2024-11-27 11:32:19.481681: Pseudo dice [np.float32(0.9247)] 
2024-11-27 11:32:19.481737: Epoch time: 40.18 s 
2024-11-27 11:32:20.424210:  
2024-11-27 11:32:20.424367: Epoch 937 
2024-11-27 11:32:20.424441: Current learning rate: 0.00083 
2024-11-27 11:33:00.618967: train_loss -0.9795 
2024-11-27 11:33:00.619095: val_loss -0.9062 
2024-11-27 11:33:00.619150: Pseudo dice [np.float32(0.9237)] 
2024-11-27 11:33:00.619207: Epoch time: 40.2 s 
2024-11-27 11:33:01.556399:  
2024-11-27 11:33:01.556578: Epoch 938 
2024-11-27 11:33:01.556654: Current learning rate: 0.00082 
2024-11-27 11:33:41.740565: train_loss -0.9791 
2024-11-27 11:33:41.740695: val_loss -0.9043 
2024-11-27 11:33:41.740750: Pseudo dice [np.float32(0.9224)] 
2024-11-27 11:33:41.740808: Epoch time: 40.19 s 
2024-11-27 11:33:42.624377:  
2024-11-27 11:33:42.624531: Epoch 939 
2024-11-27 11:33:42.624606: Current learning rate: 0.00081 
2024-11-27 11:34:22.864912: train_loss -0.9794 
2024-11-27 11:34:22.865024: val_loss -0.9119 
2024-11-27 11:34:22.865083: Pseudo dice [np.float32(0.9273)] 
2024-11-27 11:34:22.865138: Epoch time: 40.24 s 
2024-11-27 11:34:23.791865:  
2024-11-27 11:34:23.792097: Epoch 940 
2024-11-27 11:34:23.792178: Current learning rate: 0.00079 
2024-11-27 11:35:04.033237: train_loss -0.9795 
2024-11-27 11:35:04.033366: val_loss -0.9082 
2024-11-27 11:35:04.033425: Pseudo dice [np.float32(0.9249)] 
2024-11-27 11:35:04.033490: Epoch time: 40.24 s 
2024-11-27 11:35:05.014672:  
2024-11-27 11:35:05.014882: Epoch 941 
2024-11-27 11:35:05.014982: Current learning rate: 0.00078 
2024-11-27 11:35:45.192584: train_loss -0.98 
2024-11-27 11:35:45.192697: val_loss -0.9026 
2024-11-27 11:35:45.192747: Pseudo dice [np.float32(0.9206)] 
2024-11-27 11:35:45.192829: Epoch time: 40.18 s 
2024-11-27 11:35:46.085336:  
2024-11-27 11:35:46.085485: Epoch 942 
2024-11-27 11:35:46.085556: Current learning rate: 0.00077 
2024-11-27 11:36:26.227480: train_loss -0.9797 
2024-11-27 11:36:26.227588: val_loss -0.9053 
2024-11-27 11:36:26.227639: Pseudo dice [np.float32(0.9232)] 
2024-11-27 11:36:26.227695: Epoch time: 40.14 s 
2024-11-27 11:36:27.109395:  
2024-11-27 11:36:27.109585: Epoch 943 
2024-11-27 11:36:27.109674: Current learning rate: 0.00076 
2024-11-27 11:37:07.336637: train_loss -0.9796 
2024-11-27 11:37:07.336750: val_loss -0.9117 
2024-11-27 11:37:07.336841: Pseudo dice [np.float32(0.9278)] 
2024-11-27 11:37:07.336962: Epoch time: 40.23 s 
2024-11-27 11:37:08.273016:  
2024-11-27 11:37:08.273245: Epoch 944 
2024-11-27 11:37:08.273409: Current learning rate: 0.00075 
2024-11-27 11:37:48.456993: train_loss -0.9795 
2024-11-27 11:37:48.457217: val_loss -0.9086 
2024-11-27 11:37:48.457287: Pseudo dice [np.float32(0.9248)] 
2024-11-27 11:37:48.457434: Epoch time: 40.18 s 
2024-11-27 11:37:49.340523:  
2024-11-27 11:37:49.340720: Epoch 945 
2024-11-27 11:37:49.340797: Current learning rate: 0.00074 
2024-11-27 11:38:29.477573: train_loss -0.9801 
2024-11-27 11:38:29.477802: val_loss -0.909 
2024-11-27 11:38:29.477853: Pseudo dice [np.float32(0.9253)] 
2024-11-27 11:38:29.477978: Epoch time: 40.14 s 
2024-11-27 11:38:30.480009:  
2024-11-27 11:38:30.480177: Epoch 946 
2024-11-27 11:38:30.480266: Current learning rate: 0.00072 
2024-11-27 11:39:10.749446: train_loss -0.9794 
2024-11-27 11:39:10.749563: val_loss -0.907 
2024-11-27 11:39:10.749618: Pseudo dice [np.float32(0.9238)] 
2024-11-27 11:39:10.749691: Epoch time: 40.27 s 
2024-11-27 11:39:11.659742:  
2024-11-27 11:39:11.659952: Epoch 947 
2024-11-27 11:39:11.660028: Current learning rate: 0.00071 
2024-11-27 11:39:51.775344: train_loss -0.9795 
2024-11-27 11:39:51.775475: val_loss -0.9096 
2024-11-27 11:39:51.775528: Pseudo dice [np.float32(0.9255)] 
2024-11-27 11:39:51.775584: Epoch time: 40.12 s 
2024-11-27 11:39:52.656472:  
2024-11-27 11:39:52.656682: Epoch 948 
2024-11-27 11:39:52.656773: Current learning rate: 0.0007 
2024-11-27 11:40:32.799524: train_loss -0.9794 
2024-11-27 11:40:32.799641: val_loss -0.9091 
2024-11-27 11:40:32.799694: Pseudo dice [np.float32(0.9244)] 
2024-11-27 11:40:32.799750: Epoch time: 40.14 s 
2024-11-27 11:40:34.233697:  
2024-11-27 11:40:34.233915: Epoch 949 
2024-11-27 11:40:34.234039: Current learning rate: 0.00069 
2024-11-27 11:41:14.376285: train_loss -0.9794 
2024-11-27 11:41:14.376423: val_loss -0.907 
2024-11-27 11:41:14.376477: Pseudo dice [np.float32(0.9236)] 
2024-11-27 11:41:14.376535: Epoch time: 40.14 s 
2024-11-27 11:41:17.574049:  
2024-11-27 11:41:17.574289: Epoch 950 
2024-11-27 11:41:17.574386: Current learning rate: 0.00067 
2024-11-27 11:41:57.653700: train_loss -0.9801 
2024-11-27 11:41:57.653832: val_loss -0.9059 
2024-11-27 11:41:57.653935: Pseudo dice [np.float32(0.9233)] 
2024-11-27 11:41:57.654015: Epoch time: 40.08 s 
2024-11-27 11:41:58.581450:  
2024-11-27 11:41:58.581595: Epoch 951 
2024-11-27 11:41:58.581671: Current learning rate: 0.00066 
2024-11-27 11:42:38.716845: train_loss -0.9792 
2024-11-27 11:42:38.716967: val_loss -0.9092 
2024-11-27 11:42:38.717021: Pseudo dice [np.float32(0.9253)] 
2024-11-27 11:42:38.717087: Epoch time: 40.14 s 
2024-11-27 11:42:39.590369:  
2024-11-27 11:42:39.590591: Epoch 952 
2024-11-27 11:42:39.590673: Current learning rate: 0.00065 
2024-11-27 11:43:19.789225: train_loss -0.9793 
2024-11-27 11:43:19.789341: val_loss -0.9142 
2024-11-27 11:43:19.789415: Pseudo dice [np.float32(0.9297)] 
2024-11-27 11:43:19.789509: Epoch time: 40.2 s 
2024-11-27 11:43:20.701683:  
2024-11-27 11:43:20.701870: Epoch 953 
2024-11-27 11:43:20.701963: Current learning rate: 0.00064 
2024-11-27 11:44:00.851746: train_loss -0.9802 
2024-11-27 11:44:00.851909: val_loss -0.9115 
2024-11-27 11:44:00.851998: Pseudo dice [np.float32(0.9266)] 
2024-11-27 11:44:00.852090: Epoch time: 40.15 s 
2024-11-27 11:44:01.739129:  
2024-11-27 11:44:01.739473: Epoch 954 
2024-11-27 11:44:01.739570: Current learning rate: 0.00063 
2024-11-27 11:44:41.903973: train_loss -0.98 
2024-11-27 11:44:41.904084: val_loss -0.9087 
2024-11-27 11:44:41.904136: Pseudo dice [np.float32(0.926)] 
2024-11-27 11:44:41.904193: Epoch time: 40.17 s 
2024-11-27 11:44:42.853427:  
2024-11-27 11:44:42.853587: Epoch 955 
2024-11-27 11:44:42.853682: Current learning rate: 0.00061 
2024-11-27 11:45:23.077041: train_loss -0.9797 
2024-11-27 11:45:23.077156: val_loss -0.9112 
2024-11-27 11:45:23.077207: Pseudo dice [np.float32(0.9272)] 
2024-11-27 11:45:23.077262: Epoch time: 40.22 s 
2024-11-27 11:45:24.023998:  
2024-11-27 11:45:24.024150: Epoch 956 
2024-11-27 11:45:24.024224: Current learning rate: 0.0006 
2024-11-27 11:46:04.143250: train_loss -0.9802 
2024-11-27 11:46:04.143436: val_loss -0.9025 
2024-11-27 11:46:04.143487: Pseudo dice [np.float32(0.9193)] 
2024-11-27 11:46:04.143542: Epoch time: 40.12 s 
2024-11-27 11:46:05.020584:  
2024-11-27 11:46:05.020745: Epoch 957 
2024-11-27 11:46:05.020819: Current learning rate: 0.00059 
2024-11-27 11:46:45.172927: train_loss -0.9801 
2024-11-27 11:46:45.173098: val_loss -0.907 
2024-11-27 11:46:45.173149: Pseudo dice [np.float32(0.9246)] 
2024-11-27 11:46:45.173204: Epoch time: 40.15 s 
2024-11-27 11:46:46.049166:  
2024-11-27 11:46:46.049329: Epoch 958 
2024-11-27 11:46:46.049398: Current learning rate: 0.00058 
2024-11-27 11:47:26.237012: train_loss -0.9796 
2024-11-27 11:47:26.237125: val_loss -0.9072 
2024-11-27 11:47:26.237179: Pseudo dice [np.float32(0.9239)] 
2024-11-27 11:47:26.237237: Epoch time: 40.19 s 
2024-11-27 11:47:27.119077:  
2024-11-27 11:47:27.119352: Epoch 959 
2024-11-27 11:47:27.119427: Current learning rate: 0.00056 
2024-11-27 11:48:07.316584: train_loss -0.9803 
2024-11-27 11:48:07.316714: val_loss -0.9079 
2024-11-27 11:48:07.316777: Pseudo dice [np.float32(0.9239)] 
2024-11-27 11:48:07.316833: Epoch time: 40.2 s 
2024-11-27 11:48:08.240297:  
2024-11-27 11:48:08.240441: Epoch 960 
2024-11-27 11:48:08.240572: Current learning rate: 0.00055 
2024-11-27 11:48:48.416086: train_loss -0.9797 
2024-11-27 11:48:48.416199: val_loss -0.9059 
2024-11-27 11:48:48.416286: Pseudo dice [np.float32(0.9227)] 
2024-11-27 11:48:48.416399: Epoch time: 40.18 s 
2024-11-27 11:48:49.379968:  
2024-11-27 11:48:49.380467: Epoch 961 
2024-11-27 11:48:49.380558: Current learning rate: 0.00054 
2024-11-27 11:49:29.556528: train_loss -0.9802 
2024-11-27 11:49:29.556663: val_loss -0.9103 
2024-11-27 11:49:29.556771: Pseudo dice [np.float32(0.9266)] 
2024-11-27 11:49:29.556846: Epoch time: 40.18 s 
2024-11-27 11:49:30.493811:  
2024-11-27 11:49:30.493988: Epoch 962 
2024-11-27 11:49:30.494061: Current learning rate: 0.00053 
2024-11-27 11:50:10.693576: train_loss -0.9802 
2024-11-27 11:50:10.693723: val_loss -0.9128 
2024-11-27 11:50:10.693791: Pseudo dice [np.float32(0.9294)] 
2024-11-27 11:50:10.693865: Epoch time: 40.2 s 
2024-11-27 11:50:11.649328:  
2024-11-27 11:50:11.649598: Epoch 963 
2024-11-27 11:50:11.649694: Current learning rate: 0.00051 
2024-11-27 11:50:51.835609: train_loss -0.9801 
2024-11-27 11:50:51.835777: val_loss -0.9113 
2024-11-27 11:50:51.835845: Pseudo dice [np.float32(0.9277)] 
2024-11-27 11:50:51.835930: Epoch time: 40.19 s 
2024-11-27 11:50:52.750690:  
2024-11-27 11:50:52.750858: Epoch 964 
2024-11-27 11:50:52.751010: Current learning rate: 0.0005 
2024-11-27 11:51:32.923095: train_loss -0.9801 
2024-11-27 11:51:32.923229: val_loss -0.9069 
2024-11-27 11:51:32.923296: Pseudo dice [np.float32(0.9238)] 
2024-11-27 11:51:32.923369: Epoch time: 40.17 s 
2024-11-27 11:51:33.915950:  
2024-11-27 11:51:33.916098: Epoch 965 
2024-11-27 11:51:33.916170: Current learning rate: 0.00049 
2024-11-27 11:52:14.110486: train_loss -0.98 
2024-11-27 11:52:14.110648: val_loss -0.9068 
2024-11-27 11:52:14.110703: Pseudo dice [np.float32(0.9231)] 
2024-11-27 11:52:14.110762: Epoch time: 40.2 s 
2024-11-27 11:52:15.006902:  
2024-11-27 11:52:15.007075: Epoch 966 
2024-11-27 11:52:15.007155: Current learning rate: 0.00048 
2024-11-27 11:52:55.158975: train_loss -0.9807 
2024-11-27 11:52:55.159186: val_loss -0.9109 
2024-11-27 11:52:55.159264: Pseudo dice [np.float32(0.9276)] 
2024-11-27 11:52:55.159342: Epoch time: 40.15 s 
2024-11-27 11:52:56.106311:  
2024-11-27 11:52:56.106480: Epoch 967 
2024-11-27 11:52:56.106574: Current learning rate: 0.00046 
2024-11-27 11:53:36.235627: train_loss -0.9802 
2024-11-27 11:53:36.235736: val_loss -0.9064 
2024-11-27 11:53:36.235786: Pseudo dice [np.float32(0.923)] 
2024-11-27 11:53:36.235840: Epoch time: 40.13 s 
2024-11-27 11:53:37.607224:  
2024-11-27 11:53:37.607373: Epoch 968 
2024-11-27 11:53:37.607472: Current learning rate: 0.00045 
2024-11-27 11:54:17.849654: train_loss -0.9802 
2024-11-27 11:54:17.849828: val_loss -0.903 
2024-11-27 11:54:17.849980: Pseudo dice [np.float32(0.9195)] 
2024-11-27 11:54:17.850126: Epoch time: 40.24 s 
2024-11-27 11:54:18.817598:  
2024-11-27 11:54:18.817770: Epoch 969 
2024-11-27 11:54:18.817869: Current learning rate: 0.00044 
2024-11-27 11:54:59.004630: train_loss -0.98 
2024-11-27 11:54:59.004788: val_loss -0.9105 
2024-11-27 11:54:59.004854: Pseudo dice [np.float32(0.9262)] 
2024-11-27 11:54:59.004980: Epoch time: 40.19 s 
2024-11-27 11:54:59.892260:  
2024-11-27 11:54:59.892447: Epoch 970 
2024-11-27 11:54:59.892517: Current learning rate: 0.00043 
2024-11-27 11:55:40.056767: train_loss -0.9804 
2024-11-27 11:55:40.056914: val_loss -0.9095 
2024-11-27 11:55:40.056987: Pseudo dice [np.float32(0.925)] 
2024-11-27 11:55:40.057090: Epoch time: 40.17 s 
2024-11-27 11:55:41.015452:  
2024-11-27 11:55:41.015635: Epoch 971 
2024-11-27 11:55:41.015717: Current learning rate: 0.00041 
2024-11-27 11:56:21.283038: train_loss -0.9794 
2024-11-27 11:56:21.283151: val_loss -0.9082 
2024-11-27 11:56:21.283202: Pseudo dice [np.float32(0.9242)] 
2024-11-27 11:56:21.283257: Epoch time: 40.27 s 
2024-11-27 11:56:22.215534:  
2024-11-27 11:56:22.215736: Epoch 972 
2024-11-27 11:56:22.215831: Current learning rate: 0.0004 
2024-11-27 11:57:02.373415: train_loss -0.9802 
2024-11-27 11:57:02.373537: val_loss -0.9106 
2024-11-27 11:57:02.373622: Pseudo dice [np.float32(0.9279)] 
2024-11-27 11:57:02.373680: Epoch time: 40.16 s 
2024-11-27 11:57:03.356776:  
2024-11-27 11:57:03.356889: Epoch 973 
2024-11-27 11:57:03.357120: Current learning rate: 0.00039 
2024-11-27 11:57:43.547795: train_loss -0.9804 
2024-11-27 11:57:43.547978: val_loss -0.9061 
2024-11-27 11:57:43.548064: Pseudo dice [np.float32(0.9227)] 
2024-11-27 11:57:43.548119: Epoch time: 40.19 s 
2024-11-27 11:57:44.500220:  
2024-11-27 11:57:44.500371: Epoch 974 
2024-11-27 11:57:44.500444: Current learning rate: 0.00037 
2024-11-27 11:58:24.639180: train_loss -0.9803 
2024-11-27 11:58:24.639314: val_loss -0.9066 
2024-11-27 11:58:24.639427: Pseudo dice [np.float32(0.9244)] 
2024-11-27 11:58:24.639500: Epoch time: 40.14 s 
2024-11-27 11:58:25.633267:  
2024-11-27 11:58:25.633452: Epoch 975 
2024-11-27 11:58:25.633542: Current learning rate: 0.00036 
2024-11-27 11:59:05.822756: train_loss -0.9803 
2024-11-27 11:59:05.822874: val_loss -0.9062 
2024-11-27 11:59:05.822928: Pseudo dice [np.float32(0.9246)] 
2024-11-27 11:59:05.822985: Epoch time: 40.19 s 
2024-11-27 11:59:06.796562:  
2024-11-27 11:59:06.796706: Epoch 976 
2024-11-27 11:59:06.796781: Current learning rate: 0.00035 
2024-11-27 11:59:46.944782: train_loss -0.981 
2024-11-27 11:59:46.944961: val_loss -0.9128 
2024-11-27 11:59:46.945017: Pseudo dice [np.float32(0.9275)] 
2024-11-27 11:59:46.945130: Epoch time: 40.15 s 
2024-11-27 11:59:47.927610:  
2024-11-27 11:59:47.927819: Epoch 977 
2024-11-27 11:59:47.927931: Current learning rate: 0.00034 
2024-11-27 12:00:28.095684: train_loss -0.9803 
2024-11-27 12:00:28.095842: val_loss -0.9101 
2024-11-27 12:00:28.095922: Pseudo dice [np.float32(0.926)] 
2024-11-27 12:00:28.095998: Epoch time: 40.17 s 
2024-11-27 12:00:29.084562:  
2024-11-27 12:00:29.084803: Epoch 978 
2024-11-27 12:00:29.084921: Current learning rate: 0.00032 
2024-11-27 12:01:09.264843: train_loss -0.9805 
2024-11-27 12:01:09.265163: val_loss -0.9145 
2024-11-27 12:01:09.265219: Pseudo dice [np.float32(0.9297)] 
2024-11-27 12:01:09.265278: Epoch time: 40.18 s 
2024-11-27 12:01:10.163055:  
2024-11-27 12:01:10.163213: Epoch 979 
2024-11-27 12:01:10.163291: Current learning rate: 0.00031 
2024-11-27 12:01:50.369102: train_loss -0.9805 
2024-11-27 12:01:50.369242: val_loss -0.91 
2024-11-27 12:01:50.369302: Pseudo dice [np.float32(0.9262)] 
2024-11-27 12:01:50.369385: Epoch time: 40.21 s 
2024-11-27 12:01:51.497044:  
2024-11-27 12:01:51.497179: Epoch 980 
2024-11-27 12:01:51.497267: Current learning rate: 0.0003 
2024-11-27 12:02:31.661209: train_loss -0.9807 
2024-11-27 12:02:31.661321: val_loss -0.9078 
2024-11-27 12:02:31.661373: Pseudo dice [np.float32(0.9239)] 
2024-11-27 12:02:31.661428: Epoch time: 40.17 s 
2024-11-27 12:02:32.587282:  
2024-11-27 12:02:32.587507: Epoch 981 
2024-11-27 12:02:32.587597: Current learning rate: 0.00028 
2024-11-27 12:03:12.729770: train_loss -0.9806 
2024-11-27 12:03:12.729912: val_loss -0.9109 
2024-11-27 12:03:12.729983: Pseudo dice [np.float32(0.9273)] 
2024-11-27 12:03:12.730056: Epoch time: 40.14 s 
2024-11-27 12:03:13.723181:  
2024-11-27 12:03:13.723547: Epoch 982 
2024-11-27 12:03:13.723641: Current learning rate: 0.00027 
2024-11-27 12:03:53.903729: train_loss -0.9808 
2024-11-27 12:03:53.903859: val_loss -0.9122 
2024-11-27 12:03:53.904026: Pseudo dice [np.float32(0.9282)] 
2024-11-27 12:03:53.904243: Epoch time: 40.18 s 
2024-11-27 12:03:54.804218:  
2024-11-27 12:03:54.804401: Epoch 983 
2024-11-27 12:03:54.804516: Current learning rate: 0.00026 
2024-11-27 12:04:35.000545: train_loss -0.9812 
2024-11-27 12:04:35.000751: val_loss -0.9069 
2024-11-27 12:04:35.000808: Pseudo dice [np.float32(0.9233)] 
2024-11-27 12:04:35.000864: Epoch time: 40.2 s 
2024-11-27 12:04:36.028774:  
2024-11-27 12:04:36.028946: Epoch 984 
2024-11-27 12:04:36.029033: Current learning rate: 0.00024 
2024-11-27 12:05:16.232880: train_loss -0.981 
2024-11-27 12:05:16.232993: val_loss -0.9046 
2024-11-27 12:05:16.233046: Pseudo dice [np.float32(0.9218)] 
2024-11-27 12:05:16.233104: Epoch time: 40.21 s 
2024-11-27 12:05:17.205861:  
2024-11-27 12:05:17.206240: Epoch 985 
2024-11-27 12:05:17.206344: Current learning rate: 0.00023 
2024-11-27 12:05:57.333945: train_loss -0.9807 
2024-11-27 12:05:57.334125: val_loss -0.908 
2024-11-27 12:05:57.334195: Pseudo dice [np.float32(0.9249)] 
2024-11-27 12:05:57.334268: Epoch time: 40.13 s 
2024-11-27 12:05:58.252910:  
2024-11-27 12:05:58.253373: Epoch 986 
2024-11-27 12:05:58.253459: Current learning rate: 0.00021 
2024-11-27 12:06:38.442484: train_loss -0.981 
2024-11-27 12:06:38.442612: val_loss -0.9079 
2024-11-27 12:06:38.442677: Pseudo dice [np.float32(0.9248)] 
2024-11-27 12:06:38.442756: Epoch time: 40.19 s 
2024-11-27 12:06:39.775983:  
2024-11-27 12:06:39.776210: Epoch 987 
2024-11-27 12:06:39.776309: Current learning rate: 0.0002 
2024-11-27 12:07:19.983799: train_loss -0.9799 
2024-11-27 12:07:19.983958: val_loss -0.9066 
2024-11-27 12:07:19.984012: Pseudo dice [np.float32(0.9234)] 
2024-11-27 12:07:19.984067: Epoch time: 40.21 s 
2024-11-27 12:07:20.901154:  
2024-11-27 12:07:20.901349: Epoch 988 
2024-11-27 12:07:20.901439: Current learning rate: 0.00019 
2024-11-27 12:08:01.151116: train_loss -0.9809 
2024-11-27 12:08:01.151229: val_loss -0.9078 
2024-11-27 12:08:01.151281: Pseudo dice [np.float32(0.9241)] 
2024-11-27 12:08:01.151343: Epoch time: 40.25 s 
2024-11-27 12:08:02.099874:  
2024-11-27 12:08:02.100388: Epoch 989 
2024-11-27 12:08:02.100462: Current learning rate: 0.00017 
2024-11-27 12:08:42.319923: train_loss -0.9812 
2024-11-27 12:08:42.320390: val_loss -0.9092 
2024-11-27 12:08:42.320498: Pseudo dice [np.float32(0.9247)] 
2024-11-27 12:08:42.320571: Epoch time: 40.22 s 
2024-11-27 12:08:43.286853:  
2024-11-27 12:08:43.287088: Epoch 990 
2024-11-27 12:08:43.287203: Current learning rate: 0.00016 
2024-11-27 12:09:23.541324: train_loss -0.9813 
2024-11-27 12:09:23.541528: val_loss -0.9097 
2024-11-27 12:09:23.541613: Pseudo dice [np.float32(0.926)] 
2024-11-27 12:09:23.541674: Epoch time: 40.26 s 
2024-11-27 12:09:24.525460:  
2024-11-27 12:09:24.525651: Epoch 991 
2024-11-27 12:09:24.525748: Current learning rate: 0.00014 
2024-11-27 12:10:04.729213: train_loss -0.9811 
2024-11-27 12:10:04.729347: val_loss -0.9112 
2024-11-27 12:10:04.729400: Pseudo dice [np.float32(0.9264)] 
2024-11-27 12:10:04.729457: Epoch time: 40.2 s 
2024-11-27 12:10:05.703155:  
2024-11-27 12:10:05.703356: Epoch 992 
2024-11-27 12:10:05.703431: Current learning rate: 0.00013 
2024-11-27 12:10:45.898195: train_loss -0.9809 
2024-11-27 12:10:45.898313: val_loss -0.9155 
2024-11-27 12:10:45.898366: Pseudo dice [np.float32(0.9305)] 
2024-11-27 12:10:45.898424: Epoch time: 40.2 s 
2024-11-27 12:10:46.878973:  
2024-11-27 12:10:46.879211: Epoch 993 
2024-11-27 12:10:46.879302: Current learning rate: 0.00011 
2024-11-27 12:11:27.050324: train_loss -0.9809 
2024-11-27 12:11:27.050459: val_loss -0.9065 
2024-11-27 12:11:27.050528: Pseudo dice [np.float32(0.9229)] 
2024-11-27 12:11:27.050602: Epoch time: 40.17 s 
2024-11-27 12:11:28.025151:  
2024-11-27 12:11:28.025274: Epoch 994 
2024-11-27 12:11:28.025348: Current learning rate: 0.0001 
2024-11-27 12:12:08.193914: train_loss -0.9812 
2024-11-27 12:12:08.194055: val_loss -0.9117 
2024-11-27 12:12:08.194110: Pseudo dice [np.float32(0.9274)] 
2024-11-27 12:12:08.194172: Epoch time: 40.17 s 
2024-11-27 12:12:09.093678:  
2024-11-27 12:12:09.093840: Epoch 995 
2024-11-27 12:12:09.093960: Current learning rate: 8e-05 
2024-11-27 12:12:49.276488: train_loss -0.9811 
2024-11-27 12:12:49.276634: val_loss -0.9103 
2024-11-27 12:12:49.276689: Pseudo dice [np.float32(0.9267)] 
2024-11-27 12:12:49.276777: Epoch time: 40.18 s 
2024-11-27 12:12:50.195041:  
2024-11-27 12:12:50.195192: Epoch 996 
2024-11-27 12:12:50.195305: Current learning rate: 7e-05 
2024-11-27 12:13:30.338124: train_loss -0.9813 
2024-11-27 12:13:30.338248: val_loss -0.9103 
2024-11-27 12:13:30.338303: Pseudo dice [np.float32(0.926)] 
2024-11-27 12:13:30.338361: Epoch time: 40.14 s 
2024-11-27 12:13:31.238195:  
2024-11-27 12:13:31.238326: Epoch 997 
2024-11-27 12:13:31.238402: Current learning rate: 5e-05 
2024-11-27 12:14:11.471812: train_loss -0.9817 
2024-11-27 12:14:11.472015: val_loss -0.9109 
2024-11-27 12:14:11.472141: Pseudo dice [np.float32(0.9263)] 
2024-11-27 12:14:11.472283: Epoch time: 40.23 s 
2024-11-27 12:14:12.424172:  
2024-11-27 12:14:12.424323: Epoch 998 
2024-11-27 12:14:12.424421: Current learning rate: 4e-05 
2024-11-27 12:14:52.683645: train_loss -0.981 
2024-11-27 12:14:52.683766: val_loss -0.9092 
2024-11-27 12:14:52.683840: Pseudo dice [np.float32(0.925)] 
2024-11-27 12:14:52.683941: Epoch time: 40.26 s 
2024-11-27 12:14:53.594722:  
2024-11-27 12:14:53.594985: Epoch 999 
2024-11-27 12:14:53.595090: Current learning rate: 2e-05 
2024-11-27 12:15:33.817586: train_loss -0.9814 
2024-11-27 12:15:33.817777: val_loss -0.9101 
2024-11-27 12:15:33.817881: Pseudo dice [np.float32(0.9276)] 
2024-11-27 12:15:33.817981: Epoch time: 40.22 s 
2024-11-27 12:15:37.241038: Training done. 
2024-11-27 12:15:37.308789: Using splits from existing split file: /home/ran/data/deeplearning/nnUNet_preprocessed/Dataset003/splits_final.json 
2024-11-27 12:15:37.368601: The split file contains 5 splits. 
2024-11-27 12:15:37.368698: Desired fold for training: 0 
2024-11-27 12:15:37.368742: This split has 3143 training and 786 validation cases. 
2024-11-27 12:15:37.399268: predicting TCGA_CS_4941_19960909_10 
2024-11-27 12:15:37.399936: TCGA_CS_4941_19960909_10, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:47.854769: predicting TCGA_CS_4941_19960909_11 
2024-11-27 12:15:47.857026: TCGA_CS_4941_19960909_11, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:47.873528: predicting TCGA_CS_4941_19960909_3 
2024-11-27 12:15:47.874804: TCGA_CS_4941_19960909_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:47.894469: predicting TCGA_CS_4941_19960909_4 
2024-11-27 12:15:47.895232: TCGA_CS_4941_19960909_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:47.955537: predicting TCGA_CS_4941_19960909_9 
2024-11-27 12:15:47.956334: TCGA_CS_4941_19960909_9, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:48.003463: predicting TCGA_CS_4942_19970222_10 
2024-11-27 12:15:48.004497: TCGA_CS_4942_19970222_10, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:48.119231: predicting TCGA_CS_4942_19970222_14 
2024-11-27 12:15:48.120061: TCGA_CS_4942_19970222_14, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:48.181920: predicting TCGA_CS_4942_19970222_18 
2024-11-27 12:15:48.182984: TCGA_CS_4942_19970222_18, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:48.227804: predicting TCGA_CS_4942_19970222_19 
2024-11-27 12:15:48.228814: TCGA_CS_4942_19970222_19, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:48.296731: predicting TCGA_CS_4942_19970222_9 
2024-11-27 12:15:48.299219: TCGA_CS_4942_19970222_9, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:48.359924: predicting TCGA_CS_4943_20000902_17 
2024-11-27 12:15:48.360974: TCGA_CS_4943_20000902_17, shape torch.Size([3, 1, 256, 197]), rank 0 
2024-11-27 12:15:48.418165: predicting TCGA_CS_4943_20000902_18 
2024-11-27 12:15:48.420806: TCGA_CS_4943_20000902_18, shape torch.Size([3, 1, 256, 197]), rank 0 
2024-11-27 12:15:48.504045: predicting TCGA_CS_4943_20000902_20 
2024-11-27 12:15:48.504947: TCGA_CS_4943_20000902_20, shape torch.Size([3, 1, 256, 196]), rank 0 
2024-11-27 12:15:48.539517: predicting TCGA_CS_4944_20010208_1 
2024-11-27 12:15:48.540300: TCGA_CS_4944_20010208_1, shape torch.Size([3, 1, 256, 201]), rank 0 
2024-11-27 12:15:48.567730: predicting TCGA_CS_4944_20010208_10 
2024-11-27 12:15:48.568371: TCGA_CS_4944_20010208_10, shape torch.Size([3, 1, 256, 204]), rank 0 
2024-11-27 12:15:48.601171: predicting TCGA_CS_4944_20010208_13 
2024-11-27 12:15:48.601775: TCGA_CS_4944_20010208_13, shape torch.Size([3, 1, 256, 204]), rank 0 
2024-11-27 12:15:48.675418: predicting TCGA_CS_4944_20010208_18 
2024-11-27 12:15:48.676485: TCGA_CS_4944_20010208_18, shape torch.Size([3, 1, 256, 203]), rank 0 
2024-11-27 12:15:48.718255: predicting TCGA_CS_4944_20010208_19 
2024-11-27 12:15:48.719280: TCGA_CS_4944_20010208_19, shape torch.Size([3, 1, 256, 204]), rank 0 
2024-11-27 12:15:48.774946: predicting TCGA_CS_4944_20010208_20 
2024-11-27 12:15:48.782212: TCGA_CS_4944_20010208_20, shape torch.Size([3, 1, 256, 196]), rank 0 
2024-11-27 12:15:48.822128: predicting TCGA_CS_4944_20010208_3 
2024-11-27 12:15:48.823513: TCGA_CS_4944_20010208_3, shape torch.Size([3, 1, 256, 204]), rank 0 
2024-11-27 12:15:48.857563: predicting TCGA_CS_5393_19990606_18 
2024-11-27 12:15:48.861368: TCGA_CS_5393_19990606_18, shape torch.Size([3, 1, 256, 195]), rank 0 
2024-11-27 12:15:48.909184: predicting TCGA_CS_5393_19990606_20 
2024-11-27 12:15:48.909795: TCGA_CS_5393_19990606_20, shape torch.Size([3, 1, 256, 194]), rank 0 
2024-11-27 12:15:48.960248: predicting TCGA_CS_5393_19990606_6 
2024-11-27 12:15:48.966655: TCGA_CS_5393_19990606_6, shape torch.Size([3, 1, 256, 195]), rank 0 
2024-11-27 12:15:49.001390: predicting TCGA_CS_5393_19990606_8 
2024-11-27 12:15:49.001996: TCGA_CS_5393_19990606_8, shape torch.Size([3, 1, 256, 195]), rank 0 
2024-11-27 12:15:49.032055: predicting TCGA_CS_5395_19981004_20 
2024-11-27 12:15:49.032655: TCGA_CS_5395_19981004_20, shape torch.Size([3, 1, 256, 210]), rank 0 
2024-11-27 12:15:49.073115: predicting TCGA_CS_5396_20010302_10 
2024-11-27 12:15:49.074056: TCGA_CS_5396_20010302_10, shape torch.Size([3, 1, 256, 249]), rank 0 
2024-11-27 12:15:49.106268: predicting TCGA_CS_5396_20010302_12 
2024-11-27 12:15:49.107025: TCGA_CS_5396_20010302_12, shape torch.Size([3, 1, 256, 249]), rank 0 
2024-11-27 12:15:49.185472: predicting TCGA_CS_5396_20010302_14 
2024-11-27 12:15:49.186116: TCGA_CS_5396_20010302_14, shape torch.Size([3, 1, 256, 249]), rank 0 
2024-11-27 12:15:49.239930: predicting TCGA_CS_5396_20010302_16 
2024-11-27 12:15:49.240821: TCGA_CS_5396_20010302_16, shape torch.Size([3, 1, 256, 249]), rank 0 
2024-11-27 12:15:49.305082: predicting TCGA_CS_5396_20010302_19 
2024-11-27 12:15:49.305721: TCGA_CS_5396_20010302_19, shape torch.Size([3, 1, 256, 250]), rank 0 
2024-11-27 12:15:49.359713: predicting TCGA_CS_5396_20010302_21 
2024-11-27 12:15:49.360728: TCGA_CS_5396_20010302_21, shape torch.Size([3, 1, 256, 250]), rank 0 
2024-11-27 12:15:49.388317: predicting TCGA_CS_5396_20010302_23 
2024-11-27 12:15:49.388962: TCGA_CS_5396_20010302_23, shape torch.Size([3, 1, 256, 250]), rank 0 
2024-11-27 12:15:49.424773: predicting TCGA_CS_5396_20010302_3 
2024-11-27 12:15:49.425683: TCGA_CS_5396_20010302_3, shape torch.Size([3, 1, 256, 250]), rank 0 
2024-11-27 12:15:49.478937: predicting TCGA_CS_5396_20010302_9 
2024-11-27 12:15:49.479598: TCGA_CS_5396_20010302_9, shape torch.Size([3, 1, 256, 249]), rank 0 
2024-11-27 12:15:49.562172: predicting TCGA_CS_5397_20010315_12 
2024-11-27 12:15:49.565626: TCGA_CS_5397_20010315_12, shape torch.Size([3, 1, 256, 202]), rank 0 
2024-11-27 12:15:49.597648: predicting TCGA_CS_5397_20010315_16 
2024-11-27 12:15:49.598250: TCGA_CS_5397_20010315_16, shape torch.Size([3, 1, 256, 202]), rank 0 
2024-11-27 12:15:49.658932: predicting TCGA_CS_5397_20010315_21 
2024-11-27 12:15:49.659733: TCGA_CS_5397_20010315_21, shape torch.Size([3, 1, 256, 203]), rank 0 
2024-11-27 12:15:49.695208: predicting TCGA_CS_5397_20010315_7 
2024-11-27 12:15:49.697670: TCGA_CS_5397_20010315_7, shape torch.Size([3, 1, 256, 202]), rank 0 
2024-11-27 12:15:49.736940: predicting TCGA_CS_6186_20000601_12 
2024-11-27 12:15:49.737964: TCGA_CS_6186_20000601_12, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:49.791942: predicting TCGA_CS_6186_20000601_14 
2024-11-27 12:15:49.798450: TCGA_CS_6186_20000601_14, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:49.844861: predicting TCGA_CS_6186_20000601_23 
2024-11-27 12:15:49.845507: TCGA_CS_6186_20000601_23, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:49.896723: predicting TCGA_CS_6186_20000601_25 
2024-11-27 12:15:49.902890: TCGA_CS_6186_20000601_25, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:49.952040: predicting TCGA_CS_6186_20000601_3 
2024-11-27 12:15:49.954141: TCGA_CS_6186_20000601_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:49.982102: predicting TCGA_CS_6186_20000601_4 
2024-11-27 12:15:49.982856: TCGA_CS_6186_20000601_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:50.028759: predicting TCGA_CS_6188_20010812_16 
2024-11-27 12:15:50.029654: TCGA_CS_6188_20010812_16, shape torch.Size([3, 1, 256, 245]), rank 0 
2024-11-27 12:15:50.081225: predicting TCGA_CS_6188_20010812_22 
2024-11-27 12:15:50.082047: TCGA_CS_6188_20010812_22, shape torch.Size([3, 1, 256, 244]), rank 0 
2024-11-27 12:15:50.127770: predicting TCGA_CS_6188_20010812_7 
2024-11-27 12:15:50.131621: TCGA_CS_6188_20010812_7, shape torch.Size([3, 1, 256, 244]), rank 0 
2024-11-27 12:15:50.184304: predicting TCGA_CS_6290_20000917_13 
2024-11-27 12:15:50.185225: TCGA_CS_6290_20000917_13, shape torch.Size([3, 1, 256, 195]), rank 0 
2024-11-27 12:15:50.224960: predicting TCGA_CS_6290_20000917_14 
2024-11-27 12:15:50.225831: TCGA_CS_6290_20000917_14, shape torch.Size([3, 1, 256, 195]), rank 0 
2024-11-27 12:15:50.286774: predicting TCGA_CS_6290_20000917_8 
2024-11-27 12:15:50.287690: TCGA_CS_6290_20000917_8, shape torch.Size([3, 1, 256, 195]), rank 0 
2024-11-27 12:15:50.382192: predicting TCGA_CS_6665_20010817_11 
2024-11-27 12:15:50.385649: TCGA_CS_6665_20010817_11, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:50.414102: predicting TCGA_CS_6665_20010817_15 
2024-11-27 12:15:50.414907: TCGA_CS_6665_20010817_15, shape torch.Size([3, 1, 256, 249]), rank 0 
2024-11-27 12:15:50.447614: predicting TCGA_CS_6665_20010817_16 
2024-11-27 12:15:50.448428: TCGA_CS_6665_20010817_16, shape torch.Size([3, 1, 256, 242]), rank 0 
2024-11-27 12:15:50.499611: predicting TCGA_CS_6665_20010817_19 
2024-11-27 12:15:50.500956: TCGA_CS_6665_20010817_19, shape torch.Size([3, 1, 256, 244]), rank 0 
2024-11-27 12:15:50.559771: predicting TCGA_CS_6665_20010817_20 
2024-11-27 12:15:50.560508: TCGA_CS_6665_20010817_20, shape torch.Size([3, 1, 256, 244]), rank 0 
2024-11-27 12:15:50.617652: predicting TCGA_CS_6665_20010817_8 
2024-11-27 12:15:50.622427: TCGA_CS_6665_20010817_8, shape torch.Size([3, 1, 256, 252]), rank 0 
2024-11-27 12:15:50.668332: predicting TCGA_CS_6666_20011109_12 
2024-11-27 12:15:50.668953: TCGA_CS_6666_20011109_12, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:50.721549: predicting TCGA_CS_6666_20011109_13 
2024-11-27 12:15:50.724074: TCGA_CS_6666_20011109_13, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:50.759805: predicting TCGA_CS_6666_20011109_19 
2024-11-27 12:15:50.760458: TCGA_CS_6666_20011109_19, shape torch.Size([3, 1, 256, 236]), rank 0 
2024-11-27 12:15:50.809613: predicting TCGA_CS_6666_20011109_20 
2024-11-27 12:15:50.814886: TCGA_CS_6666_20011109_20, shape torch.Size([3, 1, 256, 236]), rank 0 
2024-11-27 12:15:50.867925: predicting TCGA_CS_6666_20011109_24 
2024-11-27 12:15:50.869252: TCGA_CS_6666_20011109_24, shape torch.Size([3, 1, 256, 244]), rank 0 
2024-11-27 12:15:50.927388: predicting TCGA_CS_6667_20011105_12 
2024-11-27 12:15:50.934148: TCGA_CS_6667_20011105_12, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:50.984514: predicting TCGA_CS_6667_20011105_19 
2024-11-27 12:15:50.989399: TCGA_CS_6667_20011105_19, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:51.041940: predicting TCGA_CS_6667_20011105_20 
2024-11-27 12:15:51.052237: TCGA_CS_6667_20011105_20, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:51.102419: predicting TCGA_CS_6667_20011105_4 
2024-11-27 12:15:51.108717: TCGA_CS_6667_20011105_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:51.146411: predicting TCGA_CS_6667_20011105_5 
2024-11-27 12:15:51.147830: TCGA_CS_6667_20011105_5, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:51.205066: predicting TCGA_CS_6668_20011025_11 
2024-11-27 12:15:51.205733: TCGA_CS_6668_20011025_11, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:51.232373: predicting TCGA_CS_6668_20011025_15 
2024-11-27 12:15:51.235043: TCGA_CS_6668_20011025_15, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:51.339263: predicting TCGA_CS_6668_20011025_18 
2024-11-27 12:15:51.342166: TCGA_CS_6668_20011025_18, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:51.373947: predicting TCGA_CS_6668_20011025_21 
2024-11-27 12:15:51.374929: TCGA_CS_6668_20011025_21, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:51.417354: predicting TCGA_CS_6668_20011025_24 
2024-11-27 12:15:51.418029: TCGA_CS_6668_20011025_24, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:15:51.485302: predicting TCGA_CS_6668_20011025_25 
2024-11-27 12:15:51.486012: TCGA_CS_6668_20011025_25, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:51.552156: predicting TCGA_CS_6668_20011025_5 
2024-11-27 12:15:51.553310: TCGA_CS_6668_20011025_5, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:15:51.596796: predicting TCGA_CS_6668_20011025_6 
2024-11-27 12:15:51.599395: TCGA_CS_6668_20011025_6, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:15:51.654543: predicting TCGA_CS_6669_20020102_1 
2024-11-27 12:15:51.657143: TCGA_CS_6669_20020102_1, shape torch.Size([3, 1, 256, 244]), rank 0 
2024-11-27 12:15:51.686372: predicting TCGA_CS_6669_20020102_15 
2024-11-27 12:15:51.687257: TCGA_CS_6669_20020102_15, shape torch.Size([3, 1, 255, 242]), rank 0 
2024-11-27 12:15:51.737269: predicting TCGA_CS_6669_20020102_18 
2024-11-27 12:15:51.737948: TCGA_CS_6669_20020102_18, shape torch.Size([3, 1, 256, 243]), rank 0 
2024-11-27 12:15:51.787974: predicting TCGA_DU_5849_19950405_10 
2024-11-27 12:15:51.788888: TCGA_DU_5849_19950405_10, shape torch.Size([3, 1, 250, 253]), rank 0 
2024-11-27 12:15:51.865958: predicting TCGA_DU_5849_19950405_11 
2024-11-27 12:15:51.866716: TCGA_DU_5849_19950405_11, shape torch.Size([3, 1, 249, 252]), rank 0 
2024-11-27 12:15:51.935333: predicting TCGA_DU_5849_19950405_20 
2024-11-27 12:15:51.936820: TCGA_DU_5849_19950405_20, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-27 12:15:51.975430: predicting TCGA_DU_5849_19950405_22 
2024-11-27 12:15:51.976500: TCGA_DU_5849_19950405_22, shape torch.Size([3, 1, 246, 249]), rank 0 
2024-11-27 12:15:52.020964: predicting TCGA_DU_5849_19950405_30 
2024-11-27 12:15:52.021927: TCGA_DU_5849_19950405_30, shape torch.Size([3, 1, 250, 254]), rank 0 
2024-11-27 12:15:52.073566: predicting TCGA_DU_5849_19950405_32 
2024-11-27 12:15:52.079264: TCGA_DU_5849_19950405_32, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:15:52.150644: predicting TCGA_DU_5849_19950405_35 
2024-11-27 12:15:52.151606: TCGA_DU_5849_19950405_35, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:15:52.193525: predicting TCGA_DU_5849_19950405_4 
2024-11-27 12:15:52.194133: TCGA_DU_5849_19950405_4, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:15:52.232821: predicting TCGA_DU_5849_19950405_6 
2024-11-27 12:15:52.233779: TCGA_DU_5849_19950405_6, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-27 12:15:52.273959: predicting TCGA_DU_5849_19950405_8 
2024-11-27 12:15:52.274566: TCGA_DU_5849_19950405_8, shape torch.Size([3, 1, 251, 255]), rank 0 
2024-11-27 12:15:52.334973: predicting TCGA_DU_5849_19950405_9 
2024-11-27 12:15:52.335709: TCGA_DU_5849_19950405_9, shape torch.Size([3, 1, 251, 255]), rank 0 
2024-11-27 12:15:52.411125: predicting TCGA_DU_5851_19950428_13 
2024-11-27 12:15:52.411766: TCGA_DU_5851_19950428_13, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:52.439442: predicting TCGA_DU_5851_19950428_19 
2024-11-27 12:15:52.441536: TCGA_DU_5851_19950428_19, shape torch.Size([3, 1, 253, 254]), rank 0 
2024-11-27 12:15:52.482511: predicting TCGA_DU_5851_19950428_26 
2024-11-27 12:15:52.487190: TCGA_DU_5851_19950428_26, shape torch.Size([3, 1, 253, 254]), rank 0 
2024-11-27 12:15:52.549384: predicting TCGA_DU_5851_19950428_31 
2024-11-27 12:15:52.552191: TCGA_DU_5851_19950428_31, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:15:52.579704: predicting TCGA_DU_5851_19950428_32 
2024-11-27 12:15:52.581810: TCGA_DU_5851_19950428_32, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:52.634964: predicting TCGA_DU_5851_19950428_4 
2024-11-27 12:15:52.635599: TCGA_DU_5851_19950428_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:52.675130: predicting TCGA_DU_5851_19950428_6 
2024-11-27 12:15:52.681442: TCGA_DU_5851_19950428_6, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:52.752978: predicting TCGA_DU_5852_19950709_15 
2024-11-27 12:15:52.753645: TCGA_DU_5852_19950709_15, shape torch.Size([3, 1, 247, 249]), rank 0 
2024-11-27 12:15:52.786966: predicting TCGA_DU_5852_19950709_2 
2024-11-27 12:15:52.787561: TCGA_DU_5852_19950709_2, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:15:52.821595: predicting TCGA_DU_5852_19950709_20 
2024-11-27 12:15:52.822253: TCGA_DU_5852_19950709_20, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-27 12:15:52.887947: predicting TCGA_DU_5852_19950709_25 
2024-11-27 12:15:52.888527: TCGA_DU_5852_19950709_25, shape torch.Size([3, 1, 249, 250]), rank 0 
2024-11-27 12:15:52.926363: predicting TCGA_DU_5852_19950709_28 
2024-11-27 12:15:52.927174: TCGA_DU_5852_19950709_28, shape torch.Size([3, 1, 250, 253]), rank 0 
2024-11-27 12:15:52.974932: predicting TCGA_DU_5852_19950709_30 
2024-11-27 12:15:52.975726: TCGA_DU_5852_19950709_30, shape torch.Size([3, 1, 251, 255]), rank 0 
2024-11-27 12:15:53.013351: predicting TCGA_DU_5852_19950709_34 
2024-11-27 12:15:53.013970: TCGA_DU_5852_19950709_34, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:15:53.070368: predicting TCGA_DU_5852_19950709_7 
2024-11-27 12:15:53.074487: TCGA_DU_5852_19950709_7, shape torch.Size([3, 1, 252, 255]), rank 0 
2024-11-27 12:15:53.126750: predicting TCGA_DU_5853_19950823_15 
2024-11-27 12:15:53.127548: TCGA_DU_5853_19950823_15, shape torch.Size([3, 1, 247, 249]), rank 0 
2024-11-27 12:15:53.164629: predicting TCGA_DU_5853_19950823_2 
2024-11-27 12:15:53.167222: TCGA_DU_5853_19950823_2, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:53.202988: predicting TCGA_DU_5853_19950823_23 
2024-11-27 12:15:53.203997: TCGA_DU_5853_19950823_23, shape torch.Size([3, 1, 247, 249]), rank 0 
2024-11-27 12:15:53.256977: predicting TCGA_DU_5853_19950823_25 
2024-11-27 12:15:53.257851: TCGA_DU_5853_19950823_25, shape torch.Size([3, 1, 248, 250]), rank 0 
2024-11-27 12:15:53.324799: predicting TCGA_DU_5853_19950823_29 
2024-11-27 12:15:53.325680: TCGA_DU_5853_19950823_29, shape torch.Size([3, 1, 251, 254]), rank 0 
2024-11-27 12:15:53.355865: predicting TCGA_DU_5854_19951104_10 
2024-11-27 12:15:53.356860: TCGA_DU_5854_19951104_10, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:15:53.404979: predicting TCGA_DU_5854_19951104_12 
2024-11-27 12:15:53.405812: TCGA_DU_5854_19951104_12, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:53.451972: predicting TCGA_DU_5854_19951104_14 
2024-11-27 12:15:53.452769: TCGA_DU_5854_19951104_14, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:53.483984: predicting TCGA_DU_5854_19951104_21 
2024-11-27 12:15:53.484646: TCGA_DU_5854_19951104_21, shape torch.Size([3, 1, 253, 253]), rank 0 
2024-11-27 12:15:53.533609: predicting TCGA_DU_5854_19951104_22 
2024-11-27 12:15:53.534471: TCGA_DU_5854_19951104_22, shape torch.Size([3, 1, 253, 254]), rank 0 
2024-11-27 12:15:53.570116: predicting TCGA_DU_5854_19951104_23 
2024-11-27 12:15:53.570796: TCGA_DU_5854_19951104_23, shape torch.Size([3, 1, 253, 254]), rank 0 
2024-11-27 12:15:53.645335: predicting TCGA_DU_5854_19951104_34 
2024-11-27 12:15:53.646180: TCGA_DU_5854_19951104_34, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:53.710853: predicting TCGA_DU_5854_19951104_5 
2024-11-27 12:15:53.711487: TCGA_DU_5854_19951104_5, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-27 12:15:53.739680: predicting TCGA_DU_5854_19951104_7 
2024-11-27 12:15:53.740265: TCGA_DU_5854_19951104_7, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-27 12:15:53.776572: predicting TCGA_DU_5854_19951104_8 
2024-11-27 12:15:53.779639: TCGA_DU_5854_19951104_8, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-27 12:15:53.853166: predicting TCGA_DU_5855_19951217_1 
2024-11-27 12:15:53.853980: TCGA_DU_5855_19951217_1, shape torch.Size([3, 1, 218, 211]), rank 0 
2024-11-27 12:15:53.907658: predicting TCGA_DU_5855_19951217_12 
2024-11-27 12:15:53.910310: TCGA_DU_5855_19951217_12, shape torch.Size([3, 1, 241, 215]), rank 0 
2024-11-27 12:15:53.937433: predicting TCGA_DU_5855_19951217_16 
2024-11-27 12:15:53.938025: TCGA_DU_5855_19951217_16, shape torch.Size([3, 1, 240, 215]), rank 0 
2024-11-27 12:15:53.986987: predicting TCGA_DU_5855_19951217_22 
2024-11-27 12:15:53.987859: TCGA_DU_5855_19951217_22, shape torch.Size([3, 1, 197, 213]), rank 0 
2024-11-27 12:15:54.036044: predicting TCGA_DU_5855_19951217_3 
2024-11-27 12:15:54.037066: TCGA_DU_5855_19951217_3, shape torch.Size([3, 1, 226, 215]), rank 0 
2024-11-27 12:15:54.078993: predicting TCGA_DU_5855_19951217_8 
2024-11-27 12:15:54.079819: TCGA_DU_5855_19951217_8, shape torch.Size([3, 1, 255, 215]), rank 0 
2024-11-27 12:15:54.156995: predicting TCGA_DU_5871_19941206_10 
2024-11-27 12:15:54.161964: TCGA_DU_5871_19941206_10, shape torch.Size([3, 1, 251, 252]), rank 0 
2024-11-27 12:15:54.197394: predicting TCGA_DU_5871_19941206_18 
2024-11-27 12:15:54.198000: TCGA_DU_5871_19941206_18, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-27 12:15:54.242364: predicting TCGA_DU_5871_19941206_26 
2024-11-27 12:15:54.242983: TCGA_DU_5871_19941206_26, shape torch.Size([3, 1, 250, 252]), rank 0 
2024-11-27 12:15:54.275455: predicting TCGA_DU_5871_19941206_29 
2024-11-27 12:15:54.276494: TCGA_DU_5871_19941206_29, shape torch.Size([3, 1, 253, 254]), rank 0 
2024-11-27 12:15:54.343917: predicting TCGA_DU_5871_19941206_32 
2024-11-27 12:15:54.344932: TCGA_DU_5871_19941206_32, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:54.395249: predicting TCGA_DU_5871_19941206_7 
2024-11-27 12:15:54.399567: TCGA_DU_5871_19941206_7, shape torch.Size([3, 1, 254, 255]), rank 0 
2024-11-27 12:15:54.428383: predicting TCGA_DU_5871_19941206_8 
2024-11-27 12:15:54.430759: TCGA_DU_5871_19941206_8, shape torch.Size([3, 1, 253, 254]), rank 0 
2024-11-27 12:15:54.480932: predicting TCGA_DU_5872_19950223_16 
2024-11-27 12:15:54.481530: TCGA_DU_5872_19950223_16, shape torch.Size([3, 1, 255, 253]), rank 0 
2024-11-27 12:15:54.516515: predicting TCGA_DU_5872_19950223_18 
2024-11-27 12:15:54.517110: TCGA_DU_5872_19950223_18, shape torch.Size([3, 1, 255, 253]), rank 0 
2024-11-27 12:15:54.557755: predicting TCGA_DU_5872_19950223_26 
2024-11-27 12:15:54.558759: TCGA_DU_5872_19950223_26, shape torch.Size([3, 1, 254, 252]), rank 0 
2024-11-27 12:15:54.613490: predicting TCGA_DU_5872_19950223_38 
2024-11-27 12:15:54.621707: TCGA_DU_5872_19950223_38, shape torch.Size([3, 1, 256, 252]), rank 0 
2024-11-27 12:15:54.668519: predicting TCGA_DU_5872_19950223_39 
2024-11-27 12:15:54.669152: TCGA_DU_5872_19950223_39, shape torch.Size([3, 1, 256, 252]), rank 0 
2024-11-27 12:15:54.736354: predicting TCGA_DU_5872_19950223_41 
2024-11-27 12:15:54.737487: TCGA_DU_5872_19950223_41, shape torch.Size([3, 1, 256, 252]), rank 0 
2024-11-27 12:15:54.771821: predicting TCGA_DU_5872_19950223_50 
2024-11-27 12:15:54.772457: TCGA_DU_5872_19950223_50, shape torch.Size([3, 1, 256, 253]), rank 0 
2024-11-27 12:15:54.802874: predicting TCGA_DU_5872_19950223_53 
2024-11-27 12:15:54.809161: TCGA_DU_5872_19950223_53, shape torch.Size([3, 1, 256, 253]), rank 0 
2024-11-27 12:15:54.853781: predicting TCGA_DU_5872_19950223_54 
2024-11-27 12:15:54.857463: TCGA_DU_5872_19950223_54, shape torch.Size([3, 1, 256, 253]), rank 0 
2024-11-27 12:15:54.921991: predicting TCGA_DU_5872_19950223_55 
2024-11-27 12:15:54.922817: TCGA_DU_5872_19950223_55, shape torch.Size([3, 1, 256, 253]), rank 0 
2024-11-27 12:15:54.964339: predicting TCGA_DU_5872_19950223_58 
2024-11-27 12:15:54.966883: TCGA_DU_5872_19950223_58, shape torch.Size([3, 1, 256, 254]), rank 0 
2024-11-27 12:15:55.010222: predicting TCGA_DU_5872_19950223_60 
2024-11-27 12:15:55.014191: TCGA_DU_5872_19950223_60, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-27 12:15:55.084537: predicting TCGA_DU_5872_19950223_69 
2024-11-27 12:15:55.088445: TCGA_DU_5872_19950223_69, shape torch.Size([3, 1, 256, 254]), rank 0 
2024-11-27 12:15:55.123360: predicting TCGA_DU_5872_19950223_70 
2024-11-27 12:15:55.124286: TCGA_DU_5872_19950223_70, shape torch.Size([3, 1, 256, 254]), rank 0 
2024-11-27 12:15:55.187244: predicting TCGA_DU_5872_19950223_71 
2024-11-27 12:15:55.190033: TCGA_DU_5872_19950223_71, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-27 12:15:55.222539: predicting TCGA_DU_5874_19950510_20 
2024-11-27 12:15:55.223150: TCGA_DU_5874_19950510_20, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-27 12:15:55.254014: predicting TCGA_DU_5874_19950510_3 
2024-11-27 12:15:55.254583: TCGA_DU_5874_19950510_3, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:15:55.291015: predicting TCGA_DU_5874_19950510_4 
2024-11-27 12:15:55.294066: TCGA_DU_5874_19950510_4, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:15:55.326716: predicting TCGA_DU_5874_19950510_5 
2024-11-27 12:15:55.327361: TCGA_DU_5874_19950510_5, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:15:55.384155: predicting TCGA_DU_6399_19830416_10 
2024-11-27 12:15:55.392568: TCGA_DU_6399_19830416_10, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:15:55.468487: predicting TCGA_DU_6399_19830416_11 
2024-11-27 12:15:55.469564: TCGA_DU_6399_19830416_11, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:55.512020: predicting TCGA_DU_6399_19830416_14 
2024-11-27 12:15:55.512940: TCGA_DU_6399_19830416_14, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:55.556466: predicting TCGA_DU_6399_19830416_15 
2024-11-27 12:15:55.565141: TCGA_DU_6399_19830416_15, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:55.641647: predicting TCGA_DU_6399_19830416_18 
2024-11-27 12:15:55.646706: TCGA_DU_6399_19830416_18, shape torch.Size([3, 1, 253, 254]), rank 0 
2024-11-27 12:15:55.686076: predicting TCGA_DU_6399_19830416_28 
2024-11-27 12:15:55.688564: TCGA_DU_6399_19830416_28, shape torch.Size([3, 1, 253, 253]), rank 0 
2024-11-27 12:15:55.714801: predicting TCGA_DU_6399_19830416_38 
2024-11-27 12:15:55.717604: TCGA_DU_6399_19830416_38, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:15:55.755008: predicting TCGA_DU_6399_19830416_4 
2024-11-27 12:15:55.755838: TCGA_DU_6399_19830416_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:55.822930: predicting TCGA_DU_6399_19830416_41 
2024-11-27 12:15:55.825366: TCGA_DU_6399_19830416_41, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:15:55.862638: predicting TCGA_DU_6399_19830416_44 
2024-11-27 12:15:55.863257: TCGA_DU_6399_19830416_44, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:55.902772: predicting TCGA_DU_6399_19830416_53 
2024-11-27 12:15:55.905129: TCGA_DU_6399_19830416_53, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:55.968875: predicting TCGA_DU_6399_19830416_9 
2024-11-27 12:15:55.972024: TCGA_DU_6399_19830416_9, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:56.016782: predicting TCGA_DU_6400_19830518_11 
2024-11-27 12:15:56.019398: TCGA_DU_6400_19830518_11, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:56.076409: predicting TCGA_DU_6400_19830518_29 
2024-11-27 12:15:56.077238: TCGA_DU_6400_19830518_29, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:56.121567: predicting TCGA_DU_6400_19830518_30 
2024-11-27 12:15:56.122222: TCGA_DU_6400_19830518_30, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:56.175333: predicting TCGA_DU_6400_19830518_36 
2024-11-27 12:15:56.175931: TCGA_DU_6400_19830518_36, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:56.205714: predicting TCGA_DU_6400_19830518_41 
2024-11-27 12:15:56.206353: TCGA_DU_6400_19830518_41, shape torch.Size([3, 1, 254, 255]), rank 0 
2024-11-27 12:15:56.245077: predicting TCGA_DU_6400_19830518_42 
2024-11-27 12:15:56.249662: TCGA_DU_6400_19830518_42, shape torch.Size([3, 1, 254, 255]), rank 0 
2024-11-27 12:15:56.315044: predicting TCGA_DU_6400_19830518_48 
2024-11-27 12:15:56.319713: TCGA_DU_6400_19830518_48, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:56.349025: predicting TCGA_DU_6401_19831001_11 
2024-11-27 12:15:56.349755: TCGA_DU_6401_19831001_11, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:56.381913: predicting TCGA_DU_6401_19831001_23 
2024-11-27 12:15:56.384236: TCGA_DU_6401_19831001_23, shape torch.Size([3, 1, 254, 255]), rank 0 
2024-11-27 12:15:56.414962: predicting TCGA_DU_6401_19831001_25 
2024-11-27 12:15:56.420037: TCGA_DU_6401_19831001_25, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:56.481385: predicting TCGA_DU_6401_19831001_31 
2024-11-27 12:15:56.483837: TCGA_DU_6401_19831001_31, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:56.527012: predicting TCGA_DU_6401_19831001_32 
2024-11-27 12:15:56.527823: TCGA_DU_6401_19831001_32, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:56.568361: predicting TCGA_DU_6401_19831001_42 
2024-11-27 12:15:56.569009: TCGA_DU_6401_19831001_42, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:56.624018: predicting TCGA_DU_6401_19831001_45 
2024-11-27 12:15:56.624649: TCGA_DU_6401_19831001_45, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:56.683859: predicting TCGA_DU_6401_19831001_47 
2024-11-27 12:15:56.684510: TCGA_DU_6401_19831001_47, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:56.743689: predicting TCGA_DU_6401_19831001_5 
2024-11-27 12:15:56.744659: TCGA_DU_6401_19831001_5, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:56.770411: predicting TCGA_DU_6404_19850629_13 
2024-11-27 12:15:56.771302: TCGA_DU_6404_19850629_13, shape torch.Size([3, 1, 256, 254]), rank 0 
2024-11-27 12:15:56.826427: predicting TCGA_DU_6404_19850629_14 
2024-11-27 12:15:56.827102: TCGA_DU_6404_19850629_14, shape torch.Size([3, 1, 256, 254]), rank 0 
2024-11-27 12:15:56.883135: predicting TCGA_DU_6404_19850629_2 
2024-11-27 12:15:56.883930: TCGA_DU_6404_19850629_2, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:56.937069: predicting TCGA_DU_6404_19850629_20 
2024-11-27 12:15:56.942455: TCGA_DU_6404_19850629_20, shape torch.Size([3, 1, 255, 252]), rank 0 
2024-11-27 12:15:56.981381: predicting TCGA_DU_6404_19850629_27 
2024-11-27 12:15:56.982121: TCGA_DU_6404_19850629_27, shape torch.Size([3, 1, 255, 252]), rank 0 
2024-11-27 12:15:57.031832: predicting TCGA_DU_6404_19850629_28 
2024-11-27 12:15:57.034231: TCGA_DU_6404_19850629_28, shape torch.Size([3, 1, 255, 252]), rank 0 
2024-11-27 12:15:57.077243: predicting TCGA_DU_6404_19850629_42 
2024-11-27 12:15:57.077854: TCGA_DU_6404_19850629_42, shape torch.Size([3, 1, 256, 254]), rank 0 
2024-11-27 12:15:57.137900: predicting TCGA_DU_6404_19850629_43 
2024-11-27 12:15:57.140483: TCGA_DU_6404_19850629_43, shape torch.Size([3, 1, 256, 254]), rank 0 
2024-11-27 12:15:57.202476: predicting TCGA_DU_6404_19850629_49 
2024-11-27 12:15:57.203326: TCGA_DU_6404_19850629_49, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:57.237685: predicting TCGA_DU_6404_19850629_51 
2024-11-27 12:15:57.238494: TCGA_DU_6404_19850629_51, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:57.276292: predicting TCGA_DU_6405_19851005_15 
2024-11-27 12:15:57.277061: TCGA_DU_6405_19851005_15, shape torch.Size([3, 1, 254, 255]), rank 0 
2024-11-27 12:15:57.308516: predicting TCGA_DU_6405_19851005_16 
2024-11-27 12:15:57.326735: TCGA_DU_6405_19851005_16, shape torch.Size([3, 1, 254, 255]), rank 0 
2024-11-27 12:15:57.402313: predicting TCGA_DU_6405_19851005_21 
2024-11-27 12:15:57.408942: TCGA_DU_6405_19851005_21, shape torch.Size([3, 1, 253, 253]), rank 0 
2024-11-27 12:15:57.446718: predicting TCGA_DU_6405_19851005_24 
2024-11-27 12:15:57.447290: TCGA_DU_6405_19851005_24, shape torch.Size([3, 1, 253, 254]), rank 0 
2024-11-27 12:15:57.481895: predicting TCGA_DU_6405_19851005_25 
2024-11-27 12:15:57.482660: TCGA_DU_6405_19851005_25, shape torch.Size([3, 1, 253, 254]), rank 0 
2024-11-27 12:15:57.533077: predicting TCGA_DU_6405_19851005_26 
2024-11-27 12:15:57.535354: TCGA_DU_6405_19851005_26, shape torch.Size([3, 1, 253, 254]), rank 0 
2024-11-27 12:15:57.572469: predicting TCGA_DU_6405_19851005_33 
2024-11-27 12:15:57.573255: TCGA_DU_6405_19851005_33, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:57.620845: predicting TCGA_DU_6405_19851005_34 
2024-11-27 12:15:57.621456: TCGA_DU_6405_19851005_34, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:15:57.678748: predicting TCGA_DU_6405_19851005_35 
2024-11-27 12:15:57.679634: TCGA_DU_6405_19851005_35, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:15:57.756792: predicting TCGA_DU_6405_19851005_39 
2024-11-27 12:15:57.757915: TCGA_DU_6405_19851005_39, shape torch.Size([3, 1, 256, 254]), rank 0 
2024-11-27 12:15:57.788702: predicting TCGA_DU_6405_19851005_4 
2024-11-27 12:15:57.791513: TCGA_DU_6405_19851005_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:57.852170: predicting TCGA_DU_6405_19851005_44 
2024-11-27 12:15:57.856147: TCGA_DU_6405_19851005_44, shape torch.Size([3, 1, 256, 254]), rank 0 
2024-11-27 12:15:57.896172: predicting TCGA_DU_6405_19851005_45 
2024-11-27 12:15:57.901904: TCGA_DU_6405_19851005_45, shape torch.Size([3, 1, 256, 254]), rank 0 
2024-11-27 12:15:57.938850: predicting TCGA_DU_6405_19851005_50 
2024-11-27 12:15:57.939473: TCGA_DU_6405_19851005_50, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:57.967487: predicting TCGA_DU_6405_19851005_56 
2024-11-27 12:15:57.969939: TCGA_DU_6405_19851005_56, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:58.013160: predicting TCGA_DU_6405_19851005_58 
2024-11-27 12:15:58.013801: TCGA_DU_6405_19851005_58, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:58.070102: predicting TCGA_DU_6405_19851005_6 
2024-11-27 12:15:58.070700: TCGA_DU_6405_19851005_6, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:58.141975: predicting TCGA_DU_6405_19851005_8 
2024-11-27 12:15:58.144338: TCGA_DU_6405_19851005_8, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:58.177321: predicting TCGA_DU_6407_19860514_10 
2024-11-27 12:15:58.181431: TCGA_DU_6407_19860514_10, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:58.228060: predicting TCGA_DU_6407_19860514_19 
2024-11-27 12:15:58.228988: TCGA_DU_6407_19860514_19, shape torch.Size([3, 1, 255, 255]), rank 0 
2024-11-27 12:15:58.282038: predicting TCGA_DU_6407_19860514_21 
2024-11-27 12:15:58.282686: TCGA_DU_6407_19860514_21, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:15:58.344309: predicting TCGA_DU_6407_19860514_28 
2024-11-27 12:15:58.347514: TCGA_DU_6407_19860514_28, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:15:58.374941: predicting TCGA_DU_6407_19860514_29 
2024-11-27 12:15:58.377801: TCGA_DU_6407_19860514_29, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:15:58.407021: predicting TCGA_DU_6407_19860514_32 
2024-11-27 12:15:58.408189: TCGA_DU_6407_19860514_32, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:15:58.470138: predicting TCGA_DU_6407_19860514_37 
2024-11-27 12:15:58.473074: TCGA_DU_6407_19860514_37, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:15:58.536694: predicting TCGA_DU_6407_19860514_38 
2024-11-27 12:15:58.537473: TCGA_DU_6407_19860514_38, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:15:58.568106: predicting TCGA_DU_6407_19860514_40 
2024-11-27 12:15:58.569277: TCGA_DU_6407_19860514_40, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:15:58.625283: predicting TCGA_DU_6407_19860514_41 
2024-11-27 12:15:58.629170: TCGA_DU_6407_19860514_41, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:15:58.698977: predicting TCGA_DU_6408_19860521_19 
2024-11-27 12:15:58.706379: TCGA_DU_6408_19860521_19, shape torch.Size([3, 1, 255, 255]), rank 0 
2024-11-27 12:15:58.739038: predicting TCGA_DU_6408_19860521_20 
2024-11-27 12:15:58.740063: TCGA_DU_6408_19860521_20, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:58.786153: predicting TCGA_DU_6408_19860521_24 
2024-11-27 12:15:58.790921: TCGA_DU_6408_19860521_24, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:58.834374: predicting TCGA_DU_6408_19860521_25 
2024-11-27 12:15:58.839746: TCGA_DU_6408_19860521_25, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:58.875029: predicting TCGA_DU_6408_19860521_26 
2024-11-27 12:15:58.876196: TCGA_DU_6408_19860521_26, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:58.925094: predicting TCGA_DU_6408_19860521_31 
2024-11-27 12:15:58.926085: TCGA_DU_6408_19860521_31, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:58.980736: predicting TCGA_DU_6408_19860521_33 
2024-11-27 12:15:58.981493: TCGA_DU_6408_19860521_33, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:59.040384: predicting TCGA_DU_6408_19860521_37 
2024-11-27 12:15:59.041208: TCGA_DU_6408_19860521_37, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:59.109355: predicting TCGA_DU_6408_19860521_38 
2024-11-27 12:15:59.112530: TCGA_DU_6408_19860521_38, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:15:59.138488: predicting TCGA_DU_6408_19860521_4 
2024-11-27 12:15:59.141105: TCGA_DU_6408_19860521_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:59.180180: predicting TCGA_DU_6408_19860521_40 
2024-11-27 12:15:59.180789: TCGA_DU_6408_19860521_40, shape torch.Size([3, 1, 255, 255]), rank 0 
2024-11-27 12:15:59.222944: predicting TCGA_DU_6408_19860521_41 
2024-11-27 12:15:59.223571: TCGA_DU_6408_19860521_41, shape torch.Size([3, 1, 255, 255]), rank 0 
2024-11-27 12:15:59.265139: predicting TCGA_DU_6408_19860521_5 
2024-11-27 12:15:59.265920: TCGA_DU_6408_19860521_5, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:59.313123: predicting TCGA_DU_6408_19860521_52 
2024-11-27 12:15:59.315689: TCGA_DU_6408_19860521_52, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:59.374557: predicting TCGA_DU_6408_19860521_55 
2024-11-27 12:15:59.377542: TCGA_DU_6408_19860521_55, shape torch.Size([3, 1, 256, 253]), rank 0 
2024-11-27 12:15:59.427240: predicting TCGA_DU_6408_19860521_56 
2024-11-27 12:15:59.427994: TCGA_DU_6408_19860521_56, shape torch.Size([3, 1, 256, 252]), rank 0 
2024-11-27 12:15:59.512011: predicting TCGA_DU_6408_19860521_6 
2024-11-27 12:15:59.514445: TCGA_DU_6408_19860521_6, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:59.540353: predicting TCGA_DU_6408_19860521_9 
2024-11-27 12:15:59.542718: TCGA_DU_6408_19860521_9, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:59.578862: predicting TCGA_DU_7008_19830723_13 
2024-11-27 12:15:59.579482: TCGA_DU_7008_19830723_13, shape torch.Size([3, 1, 255, 255]), rank 0 
2024-11-27 12:15:59.643051: predicting TCGA_DU_7008_19830723_17 
2024-11-27 12:15:59.643677: TCGA_DU_7008_19830723_17, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:15:59.689563: predicting TCGA_DU_7008_19830723_2 
2024-11-27 12:15:59.690166: TCGA_DU_7008_19830723_2, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:59.720591: predicting TCGA_DU_7008_19830723_26 
2024-11-27 12:15:59.721251: TCGA_DU_7008_19830723_26, shape torch.Size([3, 1, 253, 254]), rank 0 
2024-11-27 12:15:59.757258: predicting TCGA_DU_7008_19830723_32 
2024-11-27 12:15:59.758063: TCGA_DU_7008_19830723_32, shape torch.Size([3, 1, 252, 254]), rank 0 
2024-11-27 12:15:59.785675: predicting TCGA_DU_7008_19830723_39 
2024-11-27 12:15:59.786427: TCGA_DU_7008_19830723_39, shape torch.Size([3, 1, 254, 255]), rank 0 
2024-11-27 12:15:59.834072: predicting TCGA_DU_7008_19830723_44 
2024-11-27 12:15:59.834829: TCGA_DU_7008_19830723_44, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:15:59.892053: predicting TCGA_DU_7008_19830723_45 
2024-11-27 12:15:59.893440: TCGA_DU_7008_19830723_45, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:15:59.990054: predicting TCGA_DU_7008_19830723_47 
2024-11-27 12:15:59.990970: TCGA_DU_7008_19830723_47, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:00.022587: predicting TCGA_DU_7008_19830723_5 
2024-11-27 12:16:00.023587: TCGA_DU_7008_19830723_5, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:00.076714: predicting TCGA_DU_7008_19830723_6 
2024-11-27 12:16:00.077742: TCGA_DU_7008_19830723_6, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:00.127033: predicting TCGA_DU_7010_19860307_10 
2024-11-27 12:16:00.127658: TCGA_DU_7010_19860307_10, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:00.165170: predicting TCGA_DU_7010_19860307_15 
2024-11-27 12:16:00.165780: TCGA_DU_7010_19860307_15, shape torch.Size([3, 1, 254, 255]), rank 0 
2024-11-27 12:16:00.244817: predicting TCGA_DU_7010_19860307_17 
2024-11-27 12:16:00.247104: TCGA_DU_7010_19860307_17, shape torch.Size([3, 1, 254, 255]), rank 0 
2024-11-27 12:16:00.274967: predicting TCGA_DU_7010_19860307_21 
2024-11-27 12:16:00.275725: TCGA_DU_7010_19860307_21, shape torch.Size([3, 1, 254, 253]), rank 0 
2024-11-27 12:16:00.311070: predicting TCGA_DU_7010_19860307_24 
2024-11-27 12:16:00.311745: TCGA_DU_7010_19860307_24, shape torch.Size([3, 1, 253, 253]), rank 0 
2024-11-27 12:16:00.360069: predicting TCGA_DU_7010_19860307_25 
2024-11-27 12:16:00.360882: TCGA_DU_7010_19860307_25, shape torch.Size([3, 1, 253, 253]), rank 0 
2024-11-27 12:16:00.424068: predicting TCGA_DU_7010_19860307_30 
2024-11-27 12:16:00.424705: TCGA_DU_7010_19860307_30, shape torch.Size([3, 1, 253, 253]), rank 0 
2024-11-27 12:16:00.464346: predicting TCGA_DU_7010_19860307_32 
2024-11-27 12:16:00.468053: TCGA_DU_7010_19860307_32, shape torch.Size([3, 1, 253, 253]), rank 0 
2024-11-27 12:16:00.532193: predicting TCGA_DU_7010_19860307_35 
2024-11-27 12:16:00.532870: TCGA_DU_7010_19860307_35, shape torch.Size([3, 1, 253, 253]), rank 0 
2024-11-27 12:16:00.577096: predicting TCGA_DU_7010_19860307_41 
2024-11-27 12:16:00.577988: TCGA_DU_7010_19860307_41, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:16:00.608096: predicting TCGA_DU_7010_19860307_46 
2024-11-27 12:16:00.608922: TCGA_DU_7010_19860307_46, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:16:00.653968: predicting TCGA_DU_7010_19860307_50 
2024-11-27 12:16:00.656431: TCGA_DU_7010_19860307_50, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-27 12:16:00.703983: predicting TCGA_DU_7010_19860307_54 
2024-11-27 12:16:00.704952: TCGA_DU_7010_19860307_54, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:00.745264: predicting TCGA_DU_7010_19860307_9 
2024-11-27 12:16:00.750561: TCGA_DU_7010_19860307_9, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:00.826607: predicting TCGA_DU_7013_19860523_16 
2024-11-27 12:16:00.827221: TCGA_DU_7013_19860523_16, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:16:00.853766: predicting TCGA_DU_7013_19860523_17 
2024-11-27 12:16:00.854368: TCGA_DU_7013_19860523_17, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:16:00.883784: predicting TCGA_DU_7013_19860523_29 
2024-11-27 12:16:00.886134: TCGA_DU_7013_19860523_29, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:16:00.919948: predicting TCGA_DU_7013_19860523_38 
2024-11-27 12:16:00.920593: TCGA_DU_7013_19860523_38, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:00.981126: predicting TCGA_DU_7013_19860523_4 
2024-11-27 12:16:00.981718: TCGA_DU_7013_19860523_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:01.022626: predicting TCGA_DU_7013_19860523_40 
2024-11-27 12:16:01.025285: TCGA_DU_7013_19860523_40, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:01.068494: predicting TCGA_DU_7013_19860523_41 
2024-11-27 12:16:01.069098: TCGA_DU_7013_19860523_41, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:01.125643: predicting TCGA_DU_7013_19860523_46 
2024-11-27 12:16:01.126453: TCGA_DU_7013_19860523_46, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:01.183580: predicting TCGA_DU_7013_19860523_8 
2024-11-27 12:16:01.189229: TCGA_DU_7013_19860523_8, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:01.231733: predicting TCGA_DU_7014_19860618_1 
2024-11-27 12:16:01.232322: TCGA_DU_7014_19860618_1, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:01.272670: predicting TCGA_DU_7014_19860618_11 
2024-11-27 12:16:01.275220: TCGA_DU_7014_19860618_11, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:01.308210: predicting TCGA_DU_7014_19860618_16 
2024-11-27 12:16:01.308979: TCGA_DU_7014_19860618_16, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:01.341812: predicting TCGA_DU_7014_19860618_20 
2024-11-27 12:16:01.344435: TCGA_DU_7014_19860618_20, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:01.405083: predicting TCGA_DU_7014_19860618_24 
2024-11-27 12:16:01.406077: TCGA_DU_7014_19860618_24, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:16:01.498825: predicting TCGA_DU_7014_19860618_37 
2024-11-27 12:16:01.499492: TCGA_DU_7014_19860618_37, shape torch.Size([3, 1, 255, 255]), rank 0 
2024-11-27 12:16:01.539155: predicting TCGA_DU_7014_19860618_39 
2024-11-27 12:16:01.541778: TCGA_DU_7014_19860618_39, shape torch.Size([3, 1, 255, 255]), rank 0 
2024-11-27 12:16:01.579218: predicting TCGA_DU_7014_19860618_40 
2024-11-27 12:16:01.585213: TCGA_DU_7014_19860618_40, shape torch.Size([3, 1, 255, 255]), rank 0 
2024-11-27 12:16:01.642412: predicting TCGA_DU_7014_19860618_55 
2024-11-27 12:16:01.643029: TCGA_DU_7014_19860618_55, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:01.683118: predicting TCGA_DU_7014_19860618_56 
2024-11-27 12:16:01.683700: TCGA_DU_7014_19860618_56, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:01.725073: predicting TCGA_DU_7014_19860618_60 
2024-11-27 12:16:01.725655: TCGA_DU_7014_19860618_60, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-27 12:16:01.802729: predicting TCGA_DU_7018_19911220_11 
2024-11-27 12:16:01.807377: TCGA_DU_7018_19911220_11, shape torch.Size([3, 1, 250, 251]), rank 0 
2024-11-27 12:16:01.850268: predicting TCGA_DU_7018_19911220_15 
2024-11-27 12:16:01.851323: TCGA_DU_7018_19911220_15, shape torch.Size([3, 1, 248, 249]), rank 0 
2024-11-27 12:16:01.882413: predicting TCGA_DU_7018_19911220_20 
2024-11-27 12:16:01.883581: TCGA_DU_7018_19911220_20, shape torch.Size([3, 1, 248, 248]), rank 0 
2024-11-27 12:16:01.910748: predicting TCGA_DU_7018_19911220_21 
2024-11-27 12:16:01.913576: TCGA_DU_7018_19911220_21, shape torch.Size([3, 1, 248, 248]), rank 0 
2024-11-27 12:16:01.961736: predicting TCGA_DU_7018_19911220_24 
2024-11-27 12:16:01.968575: TCGA_DU_7018_19911220_24, shape torch.Size([3, 1, 248, 250]), rank 0 
2024-11-27 12:16:02.049326: predicting TCGA_DU_7018_19911220_7 
2024-11-27 12:16:02.052177: TCGA_DU_7018_19911220_7, shape torch.Size([3, 1, 253, 255]), rank 0 
2024-11-27 12:16:02.090153: predicting TCGA_DU_7018_19911220_9 
2024-11-27 12:16:02.090982: TCGA_DU_7018_19911220_9, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-27 12:16:02.124842: predicting TCGA_DU_7019_19940908_11 
2024-11-27 12:16:02.125451: TCGA_DU_7019_19940908_11, shape torch.Size([3, 1, 248, 253]), rank 0 
2024-11-27 12:16:02.173090: predicting TCGA_DU_7019_19940908_19 
2024-11-27 12:16:02.173686: TCGA_DU_7019_19940908_19, shape torch.Size([3, 1, 247, 249]), rank 0 
2024-11-27 12:16:02.244889: predicting TCGA_DU_7019_19940908_21 
2024-11-27 12:16:02.245559: TCGA_DU_7019_19940908_21, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-27 12:16:02.294007: predicting TCGA_DU_7019_19940908_22 
2024-11-27 12:16:02.296412: TCGA_DU_7019_19940908_22, shape torch.Size([3, 1, 246, 249]), rank 0 
2024-11-27 12:16:02.345825: predicting TCGA_DU_7019_19940908_35 
2024-11-27 12:16:02.346424: TCGA_DU_7019_19940908_35, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:16:02.397935: predicting TCGA_DU_7294_19890104_10 
2024-11-27 12:16:02.398702: TCGA_DU_7294_19890104_10, shape torch.Size([3, 1, 252, 252]), rank 0 
2024-11-27 12:16:02.448066: predicting TCGA_DU_7294_19890104_12 
2024-11-27 12:16:02.448724: TCGA_DU_7294_19890104_12, shape torch.Size([3, 1, 251, 252]), rank 0 
2024-11-27 12:16:02.495767: predicting TCGA_DU_7294_19890104_17 
2024-11-27 12:16:02.496389: TCGA_DU_7294_19890104_17, shape torch.Size([3, 1, 248, 249]), rank 0 
2024-11-27 12:16:02.533997: predicting TCGA_DU_7294_19890104_22 
2024-11-27 12:16:02.538652: TCGA_DU_7294_19890104_22, shape torch.Size([3, 1, 248, 250]), rank 0 
2024-11-27 12:16:02.588277: predicting TCGA_DU_7294_19890104_27 
2024-11-27 12:16:02.588941: TCGA_DU_7294_19890104_27, shape torch.Size([3, 1, 252, 254]), rank 0 
2024-11-27 12:16:02.633532: predicting TCGA_DU_7294_19890104_32 
2024-11-27 12:16:02.634484: TCGA_DU_7294_19890104_32, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:02.697289: predicting TCGA_DU_7294_19890104_34 
2024-11-27 12:16:02.700302: TCGA_DU_7294_19890104_34, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:02.726964: predicting TCGA_DU_7294_19890104_5 
2024-11-27 12:16:02.729688: TCGA_DU_7294_19890104_5, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:02.791668: predicting TCGA_DU_7298_19910324_1 
2024-11-27 12:16:02.792307: TCGA_DU_7298_19910324_1, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:02.828926: predicting TCGA_DU_7298_19910324_17 
2024-11-27 12:16:02.830246: TCGA_DU_7298_19910324_17, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-27 12:16:02.885273: predicting TCGA_DU_7298_19910324_19 
2024-11-27 12:16:02.891247: TCGA_DU_7298_19910324_19, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-27 12:16:02.923095: predicting TCGA_DU_7298_19910324_2 
2024-11-27 12:16:02.923723: TCGA_DU_7298_19910324_2, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:02.990347: predicting TCGA_DU_7298_19910324_20 
2024-11-27 12:16:02.995370: TCGA_DU_7298_19910324_20, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-27 12:16:03.026421: predicting TCGA_DU_7298_19910324_22 
2024-11-27 12:16:03.028427: TCGA_DU_7298_19910324_22, shape torch.Size([3, 1, 254, 253]), rank 0 
2024-11-27 12:16:03.068049: predicting TCGA_DU_7298_19910324_23 
2024-11-27 12:16:03.068650: TCGA_DU_7298_19910324_23, shape torch.Size([3, 1, 254, 253]), rank 0 
2024-11-27 12:16:03.108871: predicting TCGA_DU_7298_19910324_25 
2024-11-27 12:16:03.111698: TCGA_DU_7298_19910324_25, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:16:03.178642: predicting TCGA_DU_7298_19910324_26 
2024-11-27 12:16:03.181188: TCGA_DU_7298_19910324_26, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:16:03.211933: predicting TCGA_DU_7298_19910324_3 
2024-11-27 12:16:03.212957: TCGA_DU_7298_19910324_3, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:03.243976: predicting TCGA_DU_7298_19910324_4 
2024-11-27 12:16:03.248620: TCGA_DU_7298_19910324_4, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:03.320730: predicting TCGA_DU_7299_19910417_25 
2024-11-27 12:16:03.322962: TCGA_DU_7299_19910417_25, shape torch.Size([3, 1, 249, 251]), rank 0 
2024-11-27 12:16:03.353076: predicting TCGA_DU_7299_19910417_26 
2024-11-27 12:16:03.353675: TCGA_DU_7299_19910417_26, shape torch.Size([3, 1, 249, 251]), rank 0 
2024-11-27 12:16:03.410129: predicting TCGA_DU_7299_19910417_29 
2024-11-27 12:16:03.410846: TCGA_DU_7299_19910417_29, shape torch.Size([3, 1, 251, 254]), rank 0 
2024-11-27 12:16:03.475332: predicting TCGA_DU_7299_19910417_31 
2024-11-27 12:16:03.476483: TCGA_DU_7299_19910417_31, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-27 12:16:03.507405: predicting TCGA_DU_7299_19910417_33 
2024-11-27 12:16:03.508090: TCGA_DU_7299_19910417_33, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:16:03.540941: predicting TCGA_DU_7299_19910417_34 
2024-11-27 12:16:03.541527: TCGA_DU_7299_19910417_34, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:03.580493: predicting TCGA_DU_7299_19910417_9 
2024-11-27 12:16:03.581115: TCGA_DU_7299_19910417_9, shape torch.Size([3, 1, 251, 253]), rank 0 
2024-11-27 12:16:03.621135: predicting TCGA_DU_7300_19910814_10 
2024-11-27 12:16:03.622207: TCGA_DU_7300_19910814_10, shape torch.Size([3, 1, 249, 252]), rank 0 
2024-11-27 12:16:03.690891: predicting TCGA_DU_7300_19910814_12 
2024-11-27 12:16:03.692237: TCGA_DU_7300_19910814_12, shape torch.Size([3, 1, 249, 250]), rank 0 
2024-11-27 12:16:03.747100: predicting TCGA_DU_7300_19910814_21 
2024-11-27 12:16:03.748139: TCGA_DU_7300_19910814_21, shape torch.Size([3, 1, 247, 249]), rank 0 
2024-11-27 12:16:03.777477: predicting TCGA_DU_7300_19910814_22 
2024-11-27 12:16:03.782647: TCGA_DU_7300_19910814_22, shape torch.Size([3, 1, 247, 249]), rank 0 
2024-11-27 12:16:03.818099: predicting TCGA_DU_7300_19910814_30 
2024-11-27 12:16:03.819111: TCGA_DU_7300_19910814_30, shape torch.Size([3, 1, 241, 255]), rank 0 
2024-11-27 12:16:03.887314: predicting TCGA_DU_7300_19910814_33 
2024-11-27 12:16:03.887919: TCGA_DU_7300_19910814_33, shape torch.Size([3, 1, 243, 256]), rank 0 
2024-11-27 12:16:03.954167: predicting TCGA_DU_7300_19910814_6 
2024-11-27 12:16:03.955341: TCGA_DU_7300_19910814_6, shape torch.Size([3, 1, 251, 255]), rank 0 
2024-11-27 12:16:03.985965: predicting TCGA_DU_7301_19911112_10 
2024-11-27 12:16:03.986536: TCGA_DU_7301_19911112_10, shape torch.Size([3, 1, 249, 251]), rank 0 
2024-11-27 12:16:04.038547: predicting TCGA_DU_7301_19911112_20 
2024-11-27 12:16:04.041149: TCGA_DU_7301_19911112_20, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-27 12:16:04.114300: predicting TCGA_DU_7301_19911112_24 
2024-11-27 12:16:04.115259: TCGA_DU_7301_19911112_24, shape torch.Size([3, 1, 247, 250]), rank 0 
2024-11-27 12:16:04.161761: predicting TCGA_DU_7301_19911112_27 
2024-11-27 12:16:04.162701: TCGA_DU_7301_19911112_27, shape torch.Size([3, 1, 249, 252]), rank 0 
2024-11-27 12:16:04.204106: predicting TCGA_DU_7301_19911112_29 
2024-11-27 12:16:04.204700: TCGA_DU_7301_19911112_29, shape torch.Size([3, 1, 250, 254]), rank 0 
2024-11-27 12:16:04.252103: predicting TCGA_DU_7301_19911112_3 
2024-11-27 12:16:04.252994: TCGA_DU_7301_19911112_3, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-27 12:16:04.309121: predicting TCGA_DU_7301_19911112_30 
2024-11-27 12:16:04.309978: TCGA_DU_7301_19911112_30, shape torch.Size([3, 1, 251, 255]), rank 0 
2024-11-27 12:16:04.346755: predicting TCGA_DU_7301_19911112_31 
2024-11-27 12:16:04.347321: TCGA_DU_7301_19911112_31, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:04.418132: predicting TCGA_DU_7301_19911112_32 
2024-11-27 12:16:04.422431: TCGA_DU_7301_19911112_32, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:04.466261: predicting TCGA_DU_7301_19911112_5 
2024-11-27 12:16:04.468856: TCGA_DU_7301_19911112_5, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-27 12:16:04.508009: predicting TCGA_DU_7301_19911112_7 
2024-11-27 12:16:04.508560: TCGA_DU_7301_19911112_7, shape torch.Size([3, 1, 251, 255]), rank 0 
2024-11-27 12:16:04.545326: predicting TCGA_DU_7302_19911203_11 
2024-11-27 12:16:04.552213: TCGA_DU_7302_19911203_11, shape torch.Size([3, 1, 250, 252]), rank 0 
2024-11-27 12:16:04.600107: predicting TCGA_DU_7302_19911203_15 
2024-11-27 12:16:04.600911: TCGA_DU_7302_19911203_15, shape torch.Size([3, 1, 248, 249]), rank 0 
2024-11-27 12:16:04.677125: predicting TCGA_DU_7302_19911203_16 
2024-11-27 12:16:04.677750: TCGA_DU_7302_19911203_16, shape torch.Size([3, 1, 248, 248]), rank 0 
2024-11-27 12:16:04.710557: predicting TCGA_DU_7302_19911203_24 
2024-11-27 12:16:04.711366: TCGA_DU_7302_19911203_24, shape torch.Size([3, 1, 248, 250]), rank 0 
2024-11-27 12:16:04.744736: predicting TCGA_DU_7302_19911203_7 
2024-11-27 12:16:04.745526: TCGA_DU_7302_19911203_7, shape torch.Size([3, 1, 252, 254]), rank 0 
2024-11-27 12:16:04.825231: predicting TCGA_DU_7304_19930325_16 
2024-11-27 12:16:04.826669: TCGA_DU_7304_19930325_16, shape torch.Size([3, 1, 248, 249]), rank 0 
2024-11-27 12:16:04.856175: predicting TCGA_DU_7304_19930325_25 
2024-11-27 12:16:04.858941: TCGA_DU_7304_19930325_25, shape torch.Size([3, 1, 249, 251]), rank 0 
2024-11-27 12:16:04.908341: predicting TCGA_DU_7304_19930325_28 
2024-11-27 12:16:04.915025: TCGA_DU_7304_19930325_28, shape torch.Size([3, 1, 251, 253]), rank 0 
2024-11-27 12:16:04.980790: predicting TCGA_DU_7304_19930325_5 
2024-11-27 12:16:04.981726: TCGA_DU_7304_19930325_5, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:05.023468: predicting TCGA_DU_7304_19930325_6 
2024-11-27 12:16:05.024218: TCGA_DU_7304_19930325_6, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:16:05.063112: predicting TCGA_DU_7306_19930512_2 
2024-11-27 12:16:05.063828: TCGA_DU_7306_19930512_2, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-27 12:16:05.116287: predicting TCGA_DU_7306_19930512_29 
2024-11-27 12:16:05.118963: TCGA_DU_7306_19930512_29, shape torch.Size([3, 1, 249, 252]), rank 0 
2024-11-27 12:16:05.153761: predicting TCGA_DU_7306_19930512_36 
2024-11-27 12:16:05.154350: TCGA_DU_7306_19930512_36, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:05.203018: predicting TCGA_DU_7306_19930512_41 
2024-11-27 12:16:05.206205: TCGA_DU_7306_19930512_41, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:05.257162: predicting TCGA_DU_7306_19930512_42 
2024-11-27 12:16:05.258013: TCGA_DU_7306_19930512_42, shape torch.Size([3, 1, 255, 216]), rank 0 
2024-11-27 12:16:05.294425: predicting TCGA_DU_7306_19930512_7 
2024-11-27 12:16:05.297565: TCGA_DU_7306_19930512_7, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:05.353146: predicting TCGA_DU_7306_19930512_8 
2024-11-27 12:16:05.353992: TCGA_DU_7306_19930512_8, shape torch.Size([3, 1, 251, 256]), rank 0 
2024-11-27 12:16:05.396399: predicting TCGA_DU_7309_19960831_11 
2024-11-27 12:16:05.397145: TCGA_DU_7309_19960831_11, shape torch.Size([3, 1, 250, 253]), rank 0 
2024-11-27 12:16:05.446110: predicting TCGA_DU_7309_19960831_13 
2024-11-27 12:16:05.448490: TCGA_DU_7309_19960831_13, shape torch.Size([3, 1, 250, 251]), rank 0 
2024-11-27 12:16:05.520302: predicting TCGA_DU_7309_19960831_15 
2024-11-27 12:16:05.523165: TCGA_DU_7309_19960831_15, shape torch.Size([3, 1, 250, 250]), rank 0 
2024-11-27 12:16:05.565156: predicting TCGA_DU_7309_19960831_18 
2024-11-27 12:16:05.566160: TCGA_DU_7309_19960831_18, shape torch.Size([3, 1, 248, 249]), rank 0 
2024-11-27 12:16:05.635082: predicting TCGA_DU_7309_19960831_2 
2024-11-27 12:16:05.636031: TCGA_DU_7309_19960831_2, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:05.682160: predicting TCGA_DU_7309_19960831_26 
2024-11-27 12:16:05.684766: TCGA_DU_7309_19960831_26, shape torch.Size([3, 1, 249, 250]), rank 0 
2024-11-27 12:16:05.744698: predicting TCGA_DU_7309_19960831_28 
2024-11-27 12:16:05.746112: TCGA_DU_7309_19960831_28, shape torch.Size([3, 1, 250, 251]), rank 0 
2024-11-27 12:16:05.774512: predicting TCGA_DU_7309_19960831_39 
2024-11-27 12:16:05.777395: TCGA_DU_7309_19960831_39, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-27 12:16:05.815126: predicting TCGA_DU_7309_19960831_4 
2024-11-27 12:16:05.815800: TCGA_DU_7309_19960831_4, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-27 12:16:05.865170: predicting TCGA_DU_7309_19960831_40 
2024-11-27 12:16:05.865890: TCGA_DU_7309_19960831_40, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-27 12:16:05.916019: predicting TCGA_DU_7309_19960831_8 
2024-11-27 12:16:05.916890: TCGA_DU_7309_19960831_8, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-27 12:16:05.972180: predicting TCGA_DU_8162_19961029_1 
2024-11-27 12:16:05.975014: TCGA_DU_8162_19961029_1, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:06.031683: predicting TCGA_DU_8162_19961029_2 
2024-11-27 12:16:06.034265: TCGA_DU_8162_19961029_2, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:06.067713: predicting TCGA_DU_8162_19961029_24 
2024-11-27 12:16:06.068405: TCGA_DU_8162_19961029_24, shape torch.Size([3, 1, 249, 250]), rank 0 
2024-11-27 12:16:06.100776: predicting TCGA_DU_8162_19961029_3 
2024-11-27 12:16:06.101508: TCGA_DU_8162_19961029_3, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:06.134200: predicting TCGA_DU_8162_19961029_33 
2024-11-27 12:16:06.134809: TCGA_DU_8162_19961029_33, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:06.177438: predicting TCGA_DU_8162_19961029_34 
2024-11-27 12:16:06.178035: TCGA_DU_8162_19961029_34, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-27 12:16:06.228132: predicting TCGA_DU_8162_19961029_35 
2024-11-27 12:16:06.230656: TCGA_DU_8162_19961029_35, shape torch.Size([3, 1, 256, 255]), rank 0 
2024-11-27 12:16:06.294971: predicting TCGA_DU_8162_19961029_4 
2024-11-27 12:16:06.295670: TCGA_DU_8162_19961029_4, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:16:06.375001: predicting TCGA_DU_8162_19961029_7 
2024-11-27 12:16:06.376859: TCGA_DU_8162_19961029_7, shape torch.Size([3, 1, 252, 255]), rank 0 
2024-11-27 12:16:06.418495: predicting TCGA_DU_8162_19961029_8 
2024-11-27 12:16:06.420686: TCGA_DU_8162_19961029_8, shape torch.Size([3, 1, 254, 255]), rank 0 
2024-11-27 12:16:06.447425: predicting TCGA_DU_8163_19961119_1 
2024-11-27 12:16:06.448015: TCGA_DU_8163_19961119_1, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:06.516564: predicting TCGA_DU_8163_19961119_12 
2024-11-27 12:16:06.517175: TCGA_DU_8163_19961119_12, shape torch.Size([3, 1, 247, 252]), rank 0 
2024-11-27 12:16:06.568029: predicting TCGA_DU_8163_19961119_22 
2024-11-27 12:16:06.570783: TCGA_DU_8163_19961119_22, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-27 12:16:06.596755: predicting TCGA_DU_8163_19961119_3 
2024-11-27 12:16:06.597340: TCGA_DU_8163_19961119_3, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:16:06.637659: predicting TCGA_DU_8163_19961119_30 
2024-11-27 12:16:06.638300: TCGA_DU_8163_19961119_30, shape torch.Size([3, 1, 250, 254]), rank 0 
2024-11-27 12:16:06.683132: predicting TCGA_DU_8163_19961119_36 
2024-11-27 12:16:06.684012: TCGA_DU_8163_19961119_36, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:06.725460: predicting TCGA_DU_8164_19970111_20 
2024-11-27 12:16:06.728197: TCGA_DU_8164_19970111_20, shape torch.Size([3, 1, 247, 249]), rank 0 
2024-11-27 12:16:06.813025: predicting TCGA_DU_8164_19970111_21 
2024-11-27 12:16:06.814008: TCGA_DU_8164_19970111_21, shape torch.Size([3, 1, 248, 249]), rank 0 
2024-11-27 12:16:06.845241: predicting TCGA_DU_8164_19970111_22 
2024-11-27 12:16:06.846238: TCGA_DU_8164_19970111_22, shape torch.Size([3, 1, 247, 249]), rank 0 
2024-11-27 12:16:06.894496: predicting TCGA_DU_8164_19970111_27 
2024-11-27 12:16:06.895365: TCGA_DU_8164_19970111_27, shape torch.Size([3, 1, 249, 252]), rank 0 
2024-11-27 12:16:06.945094: predicting TCGA_DU_8164_19970111_28 
2024-11-27 12:16:06.945763: TCGA_DU_8164_19970111_28, shape torch.Size([3, 1, 249, 253]), rank 0 
2024-11-27 12:16:06.982921: predicting TCGA_DU_8164_19970111_29 
2024-11-27 12:16:06.985372: TCGA_DU_8164_19970111_29, shape torch.Size([3, 1, 250, 254]), rank 0 
2024-11-27 12:16:07.035168: predicting TCGA_DU_8164_19970111_36 
2024-11-27 12:16:07.035882: TCGA_DU_8164_19970111_36, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:07.089986: predicting TCGA_DU_8164_19970111_7 
2024-11-27 12:16:07.092365: TCGA_DU_8164_19970111_7, shape torch.Size([3, 1, 252, 255]), rank 0 
2024-11-27 12:16:07.135522: predicting TCGA_DU_8165_19970205_1 
2024-11-27 12:16:07.138090: TCGA_DU_8165_19970205_1, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:07.176652: predicting TCGA_DU_8165_19970205_10 
2024-11-27 12:16:07.177193: TCGA_DU_8165_19970205_10, shape torch.Size([3, 1, 249, 252]), rank 0 
2024-11-27 12:16:07.217797: predicting TCGA_DU_8165_19970205_15 
2024-11-27 12:16:07.218456: TCGA_DU_8165_19970205_15, shape torch.Size([3, 1, 247, 249]), rank 0 
2024-11-27 12:16:07.291566: predicting TCGA_DU_8165_19970205_23 
2024-11-27 12:16:07.295202: TCGA_DU_8165_19970205_23, shape torch.Size([3, 1, 248, 249]), rank 0 
2024-11-27 12:16:07.349314: predicting TCGA_DU_8165_19970205_24 
2024-11-27 12:16:07.349957: TCGA_DU_8165_19970205_24, shape torch.Size([3, 1, 248, 249]), rank 0 
2024-11-27 12:16:07.379751: predicting TCGA_DU_8165_19970205_33 
2024-11-27 12:16:07.380480: TCGA_DU_8165_19970205_33, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:07.407430: predicting TCGA_DU_8165_19970205_35 
2024-11-27 12:16:07.407933: TCGA_DU_8165_19970205_35, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:07.448467: predicting TCGA_DU_8165_19970205_8 
2024-11-27 12:16:07.449099: TCGA_DU_8165_19970205_8, shape torch.Size([3, 1, 250, 254]), rank 0 
2024-11-27 12:16:07.483270: predicting TCGA_DU_8166_19970322_13 
2024-11-27 12:16:07.483998: TCGA_DU_8166_19970322_13, shape torch.Size([3, 1, 249, 250]), rank 0 
2024-11-27 12:16:07.547907: predicting TCGA_DU_8166_19970322_23 
2024-11-27 12:16:07.551442: TCGA_DU_8166_19970322_23, shape torch.Size([3, 1, 249, 249]), rank 0 
2024-11-27 12:16:07.601514: predicting TCGA_DU_8166_19970322_27 
2024-11-27 12:16:07.605364: TCGA_DU_8166_19970322_27, shape torch.Size([3, 1, 251, 252]), rank 0 
2024-11-27 12:16:07.662910: predicting TCGA_DU_8166_19970322_28 
2024-11-27 12:16:07.663486: TCGA_DU_8166_19970322_28, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-27 12:16:07.699659: predicting TCGA_DU_8166_19970322_4 
2024-11-27 12:16:07.700401: TCGA_DU_8166_19970322_4, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:07.752275: predicting TCGA_DU_8166_19970322_5 
2024-11-27 12:16:07.754791: TCGA_DU_8166_19970322_5, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:16:07.791139: predicting TCGA_DU_8166_19970322_6 
2024-11-27 12:16:07.791926: TCGA_DU_8166_19970322_6, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-27 12:16:07.855259: predicting TCGA_DU_8166_19970322_8 
2024-11-27 12:16:07.857773: TCGA_DU_8166_19970322_8, shape torch.Size([3, 1, 252, 254]), rank 0 
2024-11-27 12:16:07.897130: predicting TCGA_DU_8167_19970402_14 
2024-11-27 12:16:07.897782: TCGA_DU_8167_19970402_14, shape torch.Size([3, 1, 248, 249]), rank 0 
2024-11-27 12:16:07.954355: predicting TCGA_DU_8167_19970402_18 
2024-11-27 12:16:07.956840: TCGA_DU_8167_19970402_18, shape torch.Size([3, 1, 246, 248]), rank 0 
2024-11-27 12:16:08.013090: predicting TCGA_DU_8167_19970402_20 
2024-11-27 12:16:08.013892: TCGA_DU_8167_19970402_20, shape torch.Size([3, 1, 246, 248]), rank 0 
2024-11-27 12:16:08.048390: predicting TCGA_DU_8167_19970402_27 
2024-11-27 12:16:08.052291: TCGA_DU_8167_19970402_27, shape torch.Size([3, 1, 250, 251]), rank 0 
2024-11-27 12:16:08.100758: predicting TCGA_DU_8168_19970503_12 
2024-11-27 12:16:08.103425: TCGA_DU_8168_19970503_12, shape torch.Size([3, 1, 250, 251]), rank 0 
2024-11-27 12:16:08.153694: predicting TCGA_DU_8168_19970503_21 
2024-11-27 12:16:08.154466: TCGA_DU_8168_19970503_21, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-27 12:16:08.182446: predicting TCGA_DU_8168_19970503_33 
2024-11-27 12:16:08.184983: TCGA_DU_8168_19970503_33, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-27 12:16:08.237152: predicting TCGA_DU_8168_19970503_35 
2024-11-27 12:16:08.237790: TCGA_DU_8168_19970503_35, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:08.270489: predicting TCGA_DU_A5TP_19970614_13 
2024-11-27 12:16:08.271037: TCGA_DU_A5TP_19970614_13, shape torch.Size([3, 1, 247, 250]), rank 0 
2024-11-27 12:16:08.306332: predicting TCGA_DU_A5TP_19970614_20 
2024-11-27 12:16:08.309542: TCGA_DU_A5TP_19970614_20, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-27 12:16:08.365153: predicting TCGA_DU_A5TP_19970614_22 
2024-11-27 12:16:08.365778: TCGA_DU_A5TP_19970614_22, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-27 12:16:08.416146: predicting TCGA_DU_A5TP_19970614_26 
2024-11-27 12:16:08.418702: TCGA_DU_A5TP_19970614_26, shape torch.Size([3, 1, 244, 251]), rank 0 
2024-11-27 12:16:08.471233: predicting TCGA_DU_A5TP_19970614_34 
2024-11-27 12:16:08.472092: TCGA_DU_A5TP_19970614_34, shape torch.Size([3, 1, 250, 256]), rank 0 
2024-11-27 12:16:08.548367: predicting TCGA_DU_A5TP_19970614_36 
2024-11-27 12:16:08.552635: TCGA_DU_A5TP_19970614_36, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:08.582484: predicting TCGA_DU_A5TP_19970614_4 
2024-11-27 12:16:08.584881: TCGA_DU_A5TP_19970614_4, shape torch.Size([3, 1, 250, 256]), rank 0 
2024-11-27 12:16:08.629137: predicting TCGA_DU_A5TR_19970726_1 
2024-11-27 12:16:08.629865: TCGA_DU_A5TR_19970726_1, shape torch.Size([3, 1, 256, 219]), rank 0 
2024-11-27 12:16:08.675717: predicting TCGA_DU_A5TR_19970726_14 
2024-11-27 12:16:08.679389: TCGA_DU_A5TR_19970726_14, shape torch.Size([3, 1, 249, 250]), rank 0 
2024-11-27 12:16:08.736401: predicting TCGA_DU_A5TR_19970726_15 
2024-11-27 12:16:08.739413: TCGA_DU_A5TR_19970726_15, shape torch.Size([3, 1, 249, 250]), rank 0 
2024-11-27 12:16:08.770004: predicting TCGA_DU_A5TR_19970726_2 
2024-11-27 12:16:08.770662: TCGA_DU_A5TR_19970726_2, shape torch.Size([3, 1, 256, 254]), rank 0 
2024-11-27 12:16:08.819713: predicting TCGA_DU_A5TR_19970726_20 
2024-11-27 12:16:08.822070: TCGA_DU_A5TR_19970726_20, shape torch.Size([3, 1, 249, 248]), rank 0 
2024-11-27 12:16:08.878536: predicting TCGA_DU_A5TR_19970726_25 
2024-11-27 12:16:08.888393: TCGA_DU_A5TR_19970726_25, shape torch.Size([3, 1, 249, 250]), rank 0 
2024-11-27 12:16:08.959755: predicting TCGA_DU_A5TR_19970726_35 
2024-11-27 12:16:08.960535: TCGA_DU_A5TR_19970726_35, shape torch.Size([3, 1, 254, 255]), rank 0 
2024-11-27 12:16:08.997030: predicting TCGA_DU_A5TR_19970726_6 
2024-11-27 12:16:08.997544: TCGA_DU_A5TR_19970726_6, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:16:09.024620: predicting TCGA_DU_A5TR_19970726_9 
2024-11-27 12:16:09.025148: TCGA_DU_A5TR_19970726_9, shape torch.Size([3, 1, 253, 254]), rank 0 
2024-11-27 12:16:09.075719: predicting TCGA_DU_A5TS_19970726_10 
2024-11-27 12:16:09.078311: TCGA_DU_A5TS_19970726_10, shape torch.Size([3, 1, 250, 255]), rank 0 
2024-11-27 12:16:09.135154: predicting TCGA_DU_A5TS_19970726_11 
2024-11-27 12:16:09.135748: TCGA_DU_A5TS_19970726_11, shape torch.Size([3, 1, 250, 254]), rank 0 
2024-11-27 12:16:09.210165: predicting TCGA_DU_A5TS_19970726_15 
2024-11-27 12:16:09.210910: TCGA_DU_A5TS_19970726_15, shape torch.Size([3, 1, 250, 254]), rank 0 
2024-11-27 12:16:09.272590: predicting TCGA_DU_A5TS_19970726_27 
2024-11-27 12:16:09.273333: TCGA_DU_A5TS_19970726_27, shape torch.Size([3, 1, 251, 255]), rank 0 
2024-11-27 12:16:09.304933: predicting TCGA_DU_A5TS_19970726_32 
2024-11-27 12:16:09.309321: TCGA_DU_A5TS_19970726_32, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:09.349799: predicting TCGA_DU_A5TS_19970726_33 
2024-11-27 12:16:09.352388: TCGA_DU_A5TS_19970726_33, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:09.405846: predicting TCGA_DU_A5TT_19980318_14 
2024-11-27 12:16:09.406476: TCGA_DU_A5TT_19980318_14, shape torch.Size([3, 1, 247, 203]), rank 0 
2024-11-27 12:16:09.478896: predicting TCGA_DU_A5TT_19980318_17 
2024-11-27 12:16:09.479531: TCGA_DU_A5TT_19980318_17, shape torch.Size([3, 1, 248, 204]), rank 0 
2024-11-27 12:16:09.544502: predicting TCGA_DU_A5TT_19980318_2 
2024-11-27 12:16:09.545430: TCGA_DU_A5TT_19980318_2, shape torch.Size([3, 1, 255, 203]), rank 0 
2024-11-27 12:16:09.596322: predicting TCGA_DU_A5TT_19980318_23 
2024-11-27 12:16:09.597076: TCGA_DU_A5TT_19980318_23, shape torch.Size([3, 1, 251, 204]), rank 0 
2024-11-27 12:16:09.665515: predicting TCGA_DU_A5TT_19980318_32 
2024-11-27 12:16:09.667907: TCGA_DU_A5TT_19980318_32, shape torch.Size([3, 1, 255, 204]), rank 0 
2024-11-27 12:16:09.715415: predicting TCGA_DU_A5TT_19980318_38 
2024-11-27 12:16:09.716417: TCGA_DU_A5TT_19980318_38, shape torch.Size([3, 1, 255, 205]), rank 0 
2024-11-27 12:16:09.742598: predicting TCGA_DU_A5TT_19980318_49 
2024-11-27 12:16:09.744947: TCGA_DU_A5TT_19980318_49, shape torch.Size([3, 1, 233, 205]), rank 0 
2024-11-27 12:16:09.782753: predicting TCGA_DU_A5TT_19980318_50 
2024-11-27 12:16:09.783531: TCGA_DU_A5TT_19980318_50, shape torch.Size([3, 1, 243, 205]), rank 0 
2024-11-27 12:16:09.826013: predicting TCGA_DU_A5TT_19980318_53 
2024-11-27 12:16:09.826691: TCGA_DU_A5TT_19980318_53, shape torch.Size([3, 1, 238, 205]), rank 0 
2024-11-27 12:16:09.907491: predicting TCGA_DU_A5TT_19980318_54 
2024-11-27 12:16:09.908544: TCGA_DU_A5TT_19980318_54, shape torch.Size([3, 1, 241, 205]), rank 0 
2024-11-27 12:16:09.945269: predicting TCGA_DU_A5TT_19980318_55 
2024-11-27 12:16:09.946166: TCGA_DU_A5TT_19980318_55, shape torch.Size([3, 1, 238, 204]), rank 0 
2024-11-27 12:16:09.995102: predicting TCGA_DU_A5TT_19980318_6 
2024-11-27 12:16:09.995700: TCGA_DU_A5TT_19980318_6, shape torch.Size([3, 1, 251, 203]), rank 0 
2024-11-27 12:16:10.031829: predicting TCGA_DU_A5TT_19980318_7 
2024-11-27 12:16:10.035056: TCGA_DU_A5TT_19980318_7, shape torch.Size([3, 1, 249, 203]), rank 0 
2024-11-27 12:16:10.065146: predicting TCGA_DU_A5TU_19980312_10 
2024-11-27 12:16:10.065732: TCGA_DU_A5TU_19980312_10, shape torch.Size([3, 1, 256, 241]), rank 0 
2024-11-27 12:16:10.119755: predicting TCGA_DU_A5TU_19980312_19 
2024-11-27 12:16:10.120461: TCGA_DU_A5TU_19980312_19, shape torch.Size([3, 1, 256, 243]), rank 0 
2024-11-27 12:16:10.182945: predicting TCGA_DU_A5TU_19980312_2 
2024-11-27 12:16:10.183546: TCGA_DU_A5TU_19980312_2, shape torch.Size([3, 1, 256, 241]), rank 0 
2024-11-27 12:16:10.219319: predicting TCGA_DU_A5TU_19980312_22 
2024-11-27 12:16:10.219978: TCGA_DU_A5TU_19980312_22, shape torch.Size([3, 1, 256, 240]), rank 0 
2024-11-27 12:16:10.254662: predicting TCGA_DU_A5TU_19980312_4 
2024-11-27 12:16:10.257741: TCGA_DU_A5TU_19980312_4, shape torch.Size([3, 1, 256, 241]), rank 0 
2024-11-27 12:16:10.306717: predicting TCGA_DU_A5TU_19980312_7 
2024-11-27 12:16:10.307723: TCGA_DU_A5TU_19980312_7, shape torch.Size([3, 1, 256, 241]), rank 0 
2024-11-27 12:16:10.358109: predicting TCGA_DU_A5TW_19980228_11 
2024-11-27 12:16:10.358960: TCGA_DU_A5TW_19980228_11, shape torch.Size([3, 1, 256, 247]), rank 0 
2024-11-27 12:16:10.396175: predicting TCGA_DU_A5TW_19980228_13 
2024-11-27 12:16:10.397031: TCGA_DU_A5TW_19980228_13, shape torch.Size([3, 1, 256, 245]), rank 0 
2024-11-27 12:16:10.432391: predicting TCGA_DU_A5TW_19980228_16 
2024-11-27 12:16:10.433265: TCGA_DU_A5TW_19980228_16, shape torch.Size([3, 1, 256, 242]), rank 0 
2024-11-27 12:16:10.480664: predicting TCGA_DU_A5TW_19980228_18 
2024-11-27 12:16:10.481478: TCGA_DU_A5TW_19980228_18, shape torch.Size([3, 1, 256, 231]), rank 0 
2024-11-27 12:16:10.538649: predicting TCGA_DU_A5TW_19980228_19 
2024-11-27 12:16:10.541245: TCGA_DU_A5TW_19980228_19, shape torch.Size([3, 1, 256, 230]), rank 0 
2024-11-27 12:16:10.623888: predicting TCGA_DU_A5TW_19980228_2 
2024-11-27 12:16:10.626551: TCGA_DU_A5TW_19980228_2, shape torch.Size([3, 1, 256, 225]), rank 0 
2024-11-27 12:16:10.670164: predicting TCGA_DU_A5TW_19980228_23 
2024-11-27 12:16:10.672399: TCGA_DU_A5TW_19980228_23, shape torch.Size([3, 1, 256, 228]), rank 0 
2024-11-27 12:16:10.698406: predicting TCGA_DU_A5TW_19980228_6 
2024-11-27 12:16:10.702926: TCGA_DU_A5TW_19980228_6, shape torch.Size([3, 1, 256, 226]), rank 0 
2024-11-27 12:16:10.731716: predicting TCGA_DU_A5TW_19980228_7 
2024-11-27 12:16:10.734272: TCGA_DU_A5TW_19980228_7, shape torch.Size([3, 1, 256, 226]), rank 0 
2024-11-27 12:16:10.801679: predicting TCGA_DU_A5TY_19970709_15 
2024-11-27 12:16:10.802261: TCGA_DU_A5TY_19970709_15, shape torch.Size([3, 1, 247, 249]), rank 0 
2024-11-27 12:16:10.838210: predicting TCGA_DU_A5TY_19970709_19 
2024-11-27 12:16:10.838896: TCGA_DU_A5TY_19970709_19, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-27 12:16:10.880178: predicting TCGA_DU_A5TY_19970709_2 
2024-11-27 12:16:10.880788: TCGA_DU_A5TY_19970709_2, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:10.935191: predicting TCGA_DU_A5TY_19970709_26 
2024-11-27 12:16:10.935824: TCGA_DU_A5TY_19970709_26, shape torch.Size([3, 1, 250, 251]), rank 0 
2024-11-27 12:16:10.979352: predicting TCGA_DU_A5TY_19970709_30 
2024-11-27 12:16:10.980241: TCGA_DU_A5TY_19970709_30, shape torch.Size([3, 1, 253, 255]), rank 0 
2024-11-27 12:16:11.017100: predicting TCGA_DU_A5TY_19970709_33 
2024-11-27 12:16:11.018178: TCGA_DU_A5TY_19970709_33, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:11.089744: predicting TCGA_DU_A5TY_19970709_35 
2024-11-27 12:16:11.090488: TCGA_DU_A5TY_19970709_35, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:11.121150: predicting TCGA_DU_A5TY_19970709_36 
2024-11-27 12:16:11.121766: TCGA_DU_A5TY_19970709_36, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:11.175205: predicting TCGA_EZ_7264_20010816_12 
2024-11-27 12:16:11.175784: TCGA_EZ_7264_20010816_12, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:16:11.218860: predicting TCGA_EZ_7264_20010816_14 
2024-11-27 12:16:11.219469: TCGA_EZ_7264_20010816_14, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:16:11.256550: predicting TCGA_EZ_7264_20010816_19 
2024-11-27 12:16:11.262496: TCGA_EZ_7264_20010816_19, shape torch.Size([3, 1, 256, 254]), rank 0 
2024-11-27 12:16:11.303193: predicting TCGA_EZ_7264_20010816_2 
2024-11-27 12:16:11.303884: TCGA_EZ_7264_20010816_2, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:16:11.362409: predicting TCGA_EZ_7264_20010816_20 
2024-11-27 12:16:11.363078: TCGA_EZ_7264_20010816_20, shape torch.Size([3, 1, 256, 254]), rank 0 
2024-11-27 12:16:11.394317: predicting TCGA_EZ_7264_20010816_5 
2024-11-27 12:16:11.396975: TCGA_EZ_7264_20010816_5, shape torch.Size([3, 1, 255, 254]), rank 0 
2024-11-27 12:16:11.466081: predicting TCGA_FG_5962_20000626_10 
2024-11-27 12:16:11.472536: TCGA_FG_5962_20000626_10, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:11.537992: predicting TCGA_FG_5962_20000626_23 
2024-11-27 12:16:11.539028: TCGA_FG_5962_20000626_23, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:11.566303: predicting TCGA_FG_5962_20000626_25 
2024-11-27 12:16:11.567064: TCGA_FG_5962_20000626_25, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:11.621510: predicting TCGA_FG_5962_20000626_26 
2024-11-27 12:16:11.623615: TCGA_FG_5962_20000626_26, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:11.677485: predicting TCGA_FG_5962_20000626_3 
2024-11-27 12:16:11.678187: TCGA_FG_5962_20000626_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:11.725184: predicting TCGA_FG_5962_20000626_43 
2024-11-27 12:16:11.726533: TCGA_FG_5962_20000626_43, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:11.775147: predicting TCGA_FG_5962_20000626_47 
2024-11-27 12:16:11.782454: TCGA_FG_5962_20000626_47, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:11.811982: predicting TCGA_FG_5962_20000626_51 
2024-11-27 12:16:11.812774: TCGA_FG_5962_20000626_51, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:11.890716: predicting TCGA_FG_5964_20010511_2 
2024-11-27 12:16:11.891575: TCGA_FG_5964_20010511_2, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:11.917075: predicting TCGA_FG_5964_20010511_8 
2024-11-27 12:16:11.919623: TCGA_FG_5964_20010511_8, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:11.949639: predicting TCGA_FG_6688_20020215_14 
2024-11-27 12:16:11.952211: TCGA_FG_6688_20020215_14, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:12.015227: predicting TCGA_FG_6688_20020215_16 
2024-11-27 12:16:12.021101: TCGA_FG_6688_20020215_16, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:12.059428: predicting TCGA_FG_6688_20020215_18 
2024-11-27 12:16:12.060203: TCGA_FG_6688_20020215_18, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:12.091049: predicting TCGA_FG_6688_20020215_3 
2024-11-27 12:16:12.093622: TCGA_FG_6688_20020215_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:12.143735: predicting TCGA_FG_6688_20020215_32 
2024-11-27 12:16:12.144789: TCGA_FG_6688_20020215_32, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:12.197077: predicting TCGA_FG_6688_20020215_35 
2024-11-27 12:16:12.197665: TCGA_FG_6688_20020215_35, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:12.231424: predicting TCGA_FG_6689_20020326_12 
2024-11-27 12:16:12.232101: TCGA_FG_6689_20020326_12, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:12.276226: predicting TCGA_FG_6689_20020326_15 
2024-11-27 12:16:12.278717: TCGA_FG_6689_20020326_15, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:12.332229: predicting TCGA_FG_6689_20020326_21 
2024-11-27 12:16:12.332870: TCGA_FG_6689_20020326_21, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:12.398893: predicting TCGA_FG_6689_20020326_23 
2024-11-27 12:16:12.399768: TCGA_FG_6689_20020326_23, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:12.468050: predicting TCGA_FG_6689_20020326_3 
2024-11-27 12:16:12.469042: TCGA_FG_6689_20020326_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:12.498424: predicting TCGA_FG_6689_20020326_31 
2024-11-27 12:16:12.501113: TCGA_FG_6689_20020326_31, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:12.537082: predicting TCGA_FG_6689_20020326_39 
2024-11-27 12:16:12.537831: TCGA_FG_6689_20020326_39, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:12.587181: predicting TCGA_FG_6689_20020326_42 
2024-11-27 12:16:12.591442: TCGA_FG_6689_20020326_42, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:12.637619: predicting TCGA_FG_6690_20020226_10 
2024-11-27 12:16:12.643275: TCGA_FG_6690_20020226_10, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:12.680750: predicting TCGA_FG_6690_20020226_17 
2024-11-27 12:16:12.681507: TCGA_FG_6690_20020226_17, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:12.718326: predicting TCGA_FG_6690_20020226_19 
2024-11-27 12:16:12.721097: TCGA_FG_6690_20020226_19, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:16:12.795486: predicting TCGA_FG_6690_20020226_27 
2024-11-27 12:16:12.796422: TCGA_FG_6690_20020226_27, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:16:12.849523: predicting TCGA_FG_6690_20020226_37 
2024-11-27 12:16:12.851249: TCGA_FG_6690_20020226_37, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:16:12.879208: predicting TCGA_FG_6690_20020226_42 
2024-11-27 12:16:12.879801: TCGA_FG_6690_20020226_42, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:16:12.910028: predicting TCGA_FG_6690_20020226_44 
2024-11-27 12:16:12.915705: TCGA_FG_6690_20020226_44, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:16:12.977598: predicting TCGA_FG_6690_20020226_51 
2024-11-27 12:16:12.978824: TCGA_FG_6690_20020226_51, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:16:13.035725: predicting TCGA_FG_6691_20020405_14 
2024-11-27 12:16:13.042410: TCGA_FG_6691_20020405_14, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:13.108629: predicting TCGA_FG_6691_20020405_19 
2024-11-27 12:16:13.112623: TCGA_FG_6691_20020405_19, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:13.149518: predicting TCGA_FG_6691_20020405_24 
2024-11-27 12:16:13.150686: TCGA_FG_6691_20020405_24, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:13.181920: predicting TCGA_FG_6691_20020405_29 
2024-11-27 12:16:13.182735: TCGA_FG_6691_20020405_29, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:13.226717: predicting TCGA_FG_6691_20020405_3 
2024-11-27 12:16:13.230475: TCGA_FG_6691_20020405_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:13.273158: predicting TCGA_FG_6691_20020405_30 
2024-11-27 12:16:13.273946: TCGA_FG_6691_20020405_30, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:13.308218: predicting TCGA_FG_6691_20020405_32 
2024-11-27 12:16:13.308930: TCGA_FG_6691_20020405_32, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:13.354732: predicting TCGA_FG_6691_20020405_36 
2024-11-27 12:16:13.355446: TCGA_FG_6691_20020405_36, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:13.404661: predicting TCGA_FG_6691_20020405_39 
2024-11-27 12:16:13.405738: TCGA_FG_6691_20020405_39, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:13.455241: predicting TCGA_FG_6691_20020405_40 
2024-11-27 12:16:13.459453: TCGA_FG_6691_20020405_40, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:13.515366: predicting TCGA_FG_6691_20020405_8 
2024-11-27 12:16:13.518864: TCGA_FG_6691_20020405_8, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:13.560594: predicting TCGA_FG_6692_20020606_11 
2024-11-27 12:16:13.561169: TCGA_FG_6692_20020606_11, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:13.599717: predicting TCGA_FG_6692_20020606_14 
2024-11-27 12:16:13.600446: TCGA_FG_6692_20020606_14, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:13.680601: predicting TCGA_FG_6692_20020606_18 
2024-11-27 12:16:13.684305: TCGA_FG_6692_20020606_18, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:13.719219: predicting TCGA_FG_6692_20020606_19 
2024-11-27 12:16:13.719923: TCGA_FG_6692_20020606_19, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:13.783854: predicting TCGA_FG_6692_20020606_8 
2024-11-27 12:16:13.784448: TCGA_FG_6692_20020606_8, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:13.813389: predicting TCGA_FG_7634_20000128_11 
2024-11-27 12:16:13.813991: TCGA_FG_7634_20000128_11, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:13.852232: predicting TCGA_FG_7634_20000128_13 
2024-11-27 12:16:13.852789: TCGA_FG_7634_20000128_13, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:13.913610: predicting TCGA_FG_7634_20000128_18 
2024-11-27 12:16:13.919475: TCGA_FG_7634_20000128_18, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:13.956712: predicting TCGA_FG_7634_20000128_22 
2024-11-27 12:16:13.959174: TCGA_FG_7634_20000128_22, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:13.987187: predicting TCGA_FG_7634_20000128_23 
2024-11-27 12:16:13.987801: TCGA_FG_7634_20000128_23, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.028691: predicting TCGA_FG_7634_20000128_24 
2024-11-27 12:16:14.029812: TCGA_FG_7634_20000128_24, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.101258: predicting TCGA_FG_7634_20000128_3 
2024-11-27 12:16:14.102032: TCGA_FG_7634_20000128_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.136658: predicting TCGA_FG_7634_20000128_6 
2024-11-27 12:16:14.137566: TCGA_FG_7634_20000128_6, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.169631: predicting TCGA_FG_7637_20000922_15 
2024-11-27 12:16:14.172175: TCGA_FG_7637_20000922_15, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.237927: predicting TCGA_FG_7637_20000922_16 
2024-11-27 12:16:14.238538: TCGA_FG_7637_20000922_16, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.282043: predicting TCGA_FG_7637_20000922_18 
2024-11-27 12:16:14.288074: TCGA_FG_7637_20000922_18, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.343477: predicting TCGA_FG_7637_20000922_27 
2024-11-27 12:16:14.345458: TCGA_FG_7637_20000922_27, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.370357: predicting TCGA_FG_7637_20000922_4 
2024-11-27 12:16:14.371029: TCGA_FG_7637_20000922_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.413587: predicting TCGA_FG_7637_20000922_47 
2024-11-27 12:16:14.414179: TCGA_FG_7637_20000922_47, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.475245: predicting TCGA_FG_7637_20000922_51 
2024-11-27 12:16:14.475834: TCGA_FG_7637_20000922_51, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.529227: predicting TCGA_FG_7637_20000922_6 
2024-11-27 12:16:14.531924: TCGA_FG_7637_20000922_6, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.567911: predicting TCGA_FG_7643_20021104_12 
2024-11-27 12:16:14.570560: TCGA_FG_7643_20021104_12, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.618031: predicting TCGA_FG_7643_20021104_13 
2024-11-27 12:16:14.618735: TCGA_FG_7643_20021104_13, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.668020: predicting TCGA_FG_7643_20021104_14 
2024-11-27 12:16:14.670572: TCGA_FG_7643_20021104_14, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.708289: predicting TCGA_FG_7643_20021104_18 
2024-11-27 12:16:14.713396: TCGA_FG_7643_20021104_18, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.750854: predicting TCGA_FG_7643_20021104_19 
2024-11-27 12:16:14.751438: TCGA_FG_7643_20021104_19, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.802239: predicting TCGA_FG_7643_20021104_20 
2024-11-27 12:16:14.804705: TCGA_FG_7643_20021104_20, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.874701: predicting TCGA_FG_7643_20021104_27 
2024-11-27 12:16:14.877187: TCGA_FG_7643_20021104_27, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.918239: predicting TCGA_FG_7643_20021104_29 
2024-11-27 12:16:14.919054: TCGA_FG_7643_20021104_29, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.948815: predicting TCGA_FG_7643_20021104_31 
2024-11-27 12:16:14.952437: TCGA_FG_7643_20021104_31, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:14.987457: predicting TCGA_FG_7643_20021104_44 
2024-11-27 12:16:14.988282: TCGA_FG_7643_20021104_44, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:15.031474: predicting TCGA_FG_7643_20021104_8 
2024-11-27 12:16:15.032073: TCGA_FG_7643_20021104_8, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:15.083942: predicting TCGA_FG_8189_20030516_14 
2024-11-27 12:16:15.084515: TCGA_FG_8189_20030516_14, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:15.137985: predicting TCGA_FG_8189_20030516_18 
2024-11-27 12:16:15.138584: TCGA_FG_8189_20030516_18, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:15.180574: predicting TCGA_FG_8189_20030516_27 
2024-11-27 12:16:15.181212: TCGA_FG_8189_20030516_27, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:15.251381: predicting TCGA_FG_8189_20030516_30 
2024-11-27 12:16:15.257000: TCGA_FG_8189_20030516_30, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:15.293715: predicting TCGA_FG_8189_20030516_33 
2024-11-27 12:16:15.298157: TCGA_FG_8189_20030516_33, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:15.354635: predicting TCGA_FG_8189_20030516_4 
2024-11-27 12:16:15.359494: TCGA_FG_8189_20030516_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:15.387920: predicting TCGA_FG_8189_20030516_41 
2024-11-27 12:16:15.390204: TCGA_FG_8189_20030516_41, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:15.442208: predicting TCGA_FG_8189_20030516_54 
2024-11-27 12:16:15.442800: TCGA_FG_8189_20030516_54, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:15.479438: predicting TCGA_FG_8189_20030516_57 
2024-11-27 12:16:15.480218: TCGA_FG_8189_20030516_57, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:15.512029: predicting TCGA_FG_8189_20030516_58 
2024-11-27 12:16:15.512758: TCGA_FG_8189_20030516_58, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:15.566238: predicting TCGA_FG_A4MT_20020212_12 
2024-11-27 12:16:15.567006: TCGA_FG_A4MT_20020212_12, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:15.622042: predicting TCGA_FG_A4MT_20020212_14 
2024-11-27 12:16:15.625086: TCGA_FG_A4MT_20020212_14, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:15.661031: predicting TCGA_FG_A4MT_20020212_3 
2024-11-27 12:16:15.666305: TCGA_FG_A4MT_20020212_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:15.733859: predicting TCGA_FG_A4MT_20020212_36 
2024-11-27 12:16:15.735770: TCGA_FG_A4MT_20020212_36, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:15.790066: predicting TCGA_FG_A4MT_20020212_47 
2024-11-27 12:16:15.792759: TCGA_FG_A4MT_20020212_47, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:15.840845: predicting TCGA_FG_A4MT_20020212_7 
2024-11-27 12:16:15.841717: TCGA_FG_A4MT_20020212_7, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:15.868583: predicting TCGA_FG_A4MU_20030903_15 
2024-11-27 12:16:15.869501: TCGA_FG_A4MU_20030903_15, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:15.913674: predicting TCGA_FG_A4MU_20030903_20 
2024-11-27 12:16:15.920181: TCGA_FG_A4MU_20030903_20, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:15.952709: predicting TCGA_FG_A4MU_20030903_22 
2024-11-27 12:16:15.957196: TCGA_FG_A4MU_20030903_22, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:16.030163: predicting TCGA_FG_A4MU_20030903_28 
2024-11-27 12:16:16.031928: TCGA_FG_A4MU_20030903_28, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:16.070203: predicting TCGA_FG_A4MU_20030903_30 
2024-11-27 12:16:16.070800: TCGA_FG_A4MU_20030903_30, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:16.107231: predicting TCGA_FG_A4MU_20030903_8 
2024-11-27 12:16:16.111359: TCGA_FG_A4MU_20030903_8, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:16.151240: predicting TCGA_FG_A60K_20040224_12 
2024-11-27 12:16:16.151908: TCGA_FG_A60K_20040224_12, shape torch.Size([3, 1, 241, 162]), rank 0 
2024-11-27 12:16:16.208747: predicting TCGA_FG_A60K_20040224_14 
2024-11-27 12:16:16.211578: TCGA_FG_A60K_20040224_14, shape torch.Size([3, 1, 241, 162]), rank 0 
2024-11-27 12:16:16.253768: predicting TCGA_FG_A60K_20040224_2 
2024-11-27 12:16:16.256598: TCGA_FG_A60K_20040224_2, shape torch.Size([3, 1, 241, 160]), rank 0 
2024-11-27 12:16:16.312267: predicting TCGA_FG_A60K_20040224_21 
2024-11-27 12:16:16.316878: TCGA_FG_A60K_20040224_21, shape torch.Size([3, 1, 241, 162]), rank 0 
2024-11-27 12:16:16.373796: predicting TCGA_FG_A60K_20040224_22 
2024-11-27 12:16:16.374453: TCGA_FG_A60K_20040224_22, shape torch.Size([3, 1, 241, 162]), rank 0 
2024-11-27 12:16:16.446427: predicting TCGA_FG_A60K_20040224_32 
2024-11-27 12:16:16.447660: TCGA_FG_A60K_20040224_32, shape torch.Size([3, 1, 241, 162]), rank 0 
2024-11-27 12:16:16.486598: predicting TCGA_FG_A60K_20040224_34 
2024-11-27 12:16:16.490373: TCGA_FG_A60K_20040224_34, shape torch.Size([3, 1, 240, 160]), rank 0 
2024-11-27 12:16:16.520396: predicting TCGA_FG_A60K_20040224_42 
2024-11-27 12:16:16.523063: TCGA_FG_A60K_20040224_42, shape torch.Size([3, 1, 241, 160]), rank 0 
2024-11-27 12:16:16.571245: predicting TCGA_FG_A60K_20040224_43 
2024-11-27 12:16:16.571863: TCGA_FG_A60K_20040224_43, shape torch.Size([3, 1, 240, 160]), rank 0 
2024-11-27 12:16:16.624275: predicting TCGA_FG_A60K_20040224_44 
2024-11-27 12:16:16.624936: TCGA_FG_A60K_20040224_44, shape torch.Size([3, 1, 241, 160]), rank 0 
2024-11-27 12:16:16.705814: predicting TCGA_FG_A60K_20040224_47 
2024-11-27 12:16:16.710667: TCGA_FG_A60K_20040224_47, shape torch.Size([3, 1, 241, 160]), rank 0 
2024-11-27 12:16:16.747727: predicting TCGA_FG_A60K_20040224_48 
2024-11-27 12:16:16.748379: TCGA_FG_A60K_20040224_48, shape torch.Size([3, 1, 240, 160]), rank 0 
2024-11-27 12:16:16.798330: predicting TCGA_FG_A60K_20040224_5 
2024-11-27 12:16:16.799027: TCGA_FG_A60K_20040224_5, shape torch.Size([3, 1, 241, 162]), rank 0 
2024-11-27 12:16:16.876368: predicting TCGA_FG_A60K_20040224_53 
2024-11-27 12:16:16.879601: TCGA_FG_A60K_20040224_53, shape torch.Size([3, 1, 240, 160]), rank 0 
2024-11-27 12:16:16.913495: predicting TCGA_FG_A60K_20040224_62 
2024-11-27 12:16:16.916579: TCGA_FG_A60K_20040224_62, shape torch.Size([3, 1, 241, 160]), rank 0 
2024-11-27 12:16:16.950804: predicting TCGA_FG_A60K_20040224_64 
2024-11-27 12:16:16.953418: TCGA_FG_A60K_20040224_64, shape torch.Size([3, 1, 240, 160]), rank 0 
2024-11-27 12:16:17.033208: predicting TCGA_FG_A60K_20040224_68 
2024-11-27 12:16:17.035605: TCGA_FG_A60K_20040224_68, shape torch.Size([3, 1, 240, 160]), rank 0 
2024-11-27 12:16:17.090018: predicting TCGA_FG_A60K_20040224_72 
2024-11-27 12:16:17.092719: TCGA_FG_A60K_20040224_72, shape torch.Size([3, 1, 238, 160]), rank 0 
2024-11-27 12:16:17.122989: predicting TCGA_HT_7473_19970826_3 
2024-11-27 12:16:17.126976: TCGA_HT_7473_19970826_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:17.184928: predicting TCGA_HT_7473_19970826_32 
2024-11-27 12:16:17.190468: TCGA_HT_7473_19970826_32, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:17.227630: predicting TCGA_HT_7475_19970918_14 
2024-11-27 12:16:17.228292: TCGA_HT_7475_19970918_14, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:17.287553: predicting TCGA_HT_7475_19970918_17 
2024-11-27 12:16:17.290255: TCGA_HT_7475_19970918_17, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-27 12:16:17.318040: predicting TCGA_HT_7475_19970918_2 
2024-11-27 12:16:17.318851: TCGA_HT_7475_19970918_2, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:17.378900: predicting TCGA_HT_7475_19970918_21 
2024-11-27 12:16:17.381006: TCGA_HT_7475_19970918_21, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-27 12:16:17.450558: predicting TCGA_HT_7475_19970918_4 
2024-11-27 12:16:17.451219: TCGA_HT_7475_19970918_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:17.517611: predicting TCGA_HT_7475_19970918_6 
2024-11-27 12:16:17.520292: TCGA_HT_7475_19970918_6, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:17.566227: predicting TCGA_HT_7475_19970918_8 
2024-11-27 12:16:17.566849: TCGA_HT_7475_19970918_8, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:17.595535: predicting TCGA_HT_7475_19970918_9 
2024-11-27 12:16:17.597468: TCGA_HT_7475_19970918_9, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:17.634789: predicting TCGA_HT_7602_19951103_1 
2024-11-27 12:16:17.635617: TCGA_HT_7602_19951103_1, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:17.673800: predicting TCGA_HT_7602_19951103_4 
2024-11-27 12:16:17.678206: TCGA_HT_7602_19951103_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:17.747609: predicting TCGA_HT_7605_19950916_18 
2024-11-27 12:16:17.748494: TCGA_HT_7605_19950916_18, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:17.784482: predicting TCGA_HT_7605_19950916_2 
2024-11-27 12:16:17.789367: TCGA_HT_7605_19950916_2, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:17.830271: predicting TCGA_HT_7605_19950916_22 
2024-11-27 12:16:17.830900: TCGA_HT_7605_19950916_22, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:17.886587: predicting TCGA_HT_7605_19950916_27 
2024-11-27 12:16:17.892238: TCGA_HT_7605_19950916_27, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:17.957332: predicting TCGA_HT_7605_19950916_28 
2024-11-27 12:16:17.959481: TCGA_HT_7605_19950916_28, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:18.001631: predicting TCGA_HT_7605_19950916_3 
2024-11-27 12:16:18.002406: TCGA_HT_7605_19950916_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:18.048122: predicting TCGA_HT_7605_19950916_30 
2024-11-27 12:16:18.048758: TCGA_HT_7605_19950916_30, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:18.099776: predicting TCGA_HT_7605_19950916_7 
2024-11-27 12:16:18.100398: TCGA_HT_7605_19950916_7, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:18.176006: predicting TCGA_HT_7605_19950916_8 
2024-11-27 12:16:18.177744: TCGA_HT_7605_19950916_8, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:18.222523: predicting TCGA_HT_7605_19950916_9 
2024-11-27 12:16:18.223138: TCGA_HT_7605_19950916_9, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:18.271097: predicting TCGA_HT_7608_19940304_1 
2024-11-27 12:16:18.275306: TCGA_HT_7608_19940304_1, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:18.335493: predicting TCGA_HT_7608_19940304_18 
2024-11-27 12:16:18.336184: TCGA_HT_7608_19940304_18, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:18.374797: predicting TCGA_HT_7608_19940304_20 
2024-11-27 12:16:18.375616: TCGA_HT_7608_19940304_20, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:18.435716: predicting TCGA_HT_7608_19940304_21 
2024-11-27 12:16:18.436653: TCGA_HT_7608_19940304_21, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:18.496111: predicting TCGA_HT_7608_19940304_26 
2024-11-27 12:16:18.496835: TCGA_HT_7608_19940304_26, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:18.557084: predicting TCGA_HT_7608_19940304_28 
2024-11-27 12:16:18.557726: TCGA_HT_7608_19940304_28, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:18.608073: predicting TCGA_HT_7616_19940813_1 
2024-11-27 12:16:18.608753: TCGA_HT_7616_19940813_1, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:18.667206: predicting TCGA_HT_7616_19940813_10 
2024-11-27 12:16:18.669388: TCGA_HT_7616_19940813_10, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:18.725875: predicting TCGA_HT_7616_19940813_23 
2024-11-27 12:16:18.729362: TCGA_HT_7616_19940813_23, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:18.763839: predicting TCGA_HT_7616_19940813_5 
2024-11-27 12:16:18.766064: TCGA_HT_7616_19940813_5, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:18.797448: predicting TCGA_HT_7680_19970202_13 
2024-11-27 12:16:18.798018: TCGA_HT_7680_19970202_13, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:16:18.837290: predicting TCGA_HT_7680_19970202_18 
2024-11-27 12:16:18.837885: TCGA_HT_7680_19970202_18, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:18.892367: predicting TCGA_HT_7680_19970202_2 
2024-11-27 12:16:18.893003: TCGA_HT_7680_19970202_2, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:18.945131: predicting TCGA_HT_7680_19970202_3 
2024-11-27 12:16:18.945698: TCGA_HT_7680_19970202_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:18.981291: predicting TCGA_HT_7680_19970202_5 
2024-11-27 12:16:18.983638: TCGA_HT_7680_19970202_5, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:19.043847: predicting TCGA_HT_7684_19950816_1 
2024-11-27 12:16:19.044766: TCGA_HT_7684_19950816_1, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:19.109430: predicting TCGA_HT_7684_19950816_16 
2024-11-27 12:16:19.110318: TCGA_HT_7684_19950816_16, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:19.164854: predicting TCGA_HT_7684_19950816_3 
2024-11-27 12:16:19.165697: TCGA_HT_7684_19950816_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:19.199861: predicting TCGA_HT_7684_19950816_9 
2024-11-27 12:16:19.200500: TCGA_HT_7684_19950816_9, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:19.252709: predicting TCGA_HT_7686_19950629_1 
2024-11-27 12:16:19.253303: TCGA_HT_7686_19950629_1, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:19.308731: predicting TCGA_HT_7686_19950629_3 
2024-11-27 12:16:19.311169: TCGA_HT_7686_19950629_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:19.356267: predicting TCGA_HT_7686_19950629_9 
2024-11-27 12:16:19.356900: TCGA_HT_7686_19950629_9, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:19.405286: predicting TCGA_HT_7690_19960312_12 
2024-11-27 12:16:19.405897: TCGA_HT_7690_19960312_12, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-27 12:16:19.483776: predicting TCGA_HT_7690_19960312_13 
2024-11-27 12:16:19.484413: TCGA_HT_7690_19960312_13, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-27 12:16:19.511693: predicting TCGA_HT_7690_19960312_20 
2024-11-27 12:16:19.512326: TCGA_HT_7690_19960312_20, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:19.571738: predicting TCGA_HT_7690_19960312_21 
2024-11-27 12:16:19.574208: TCGA_HT_7690_19960312_21, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:19.613577: predicting TCGA_HT_7690_19960312_8 
2024-11-27 12:16:19.616183: TCGA_HT_7690_19960312_8, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:19.653085: predicting TCGA_HT_7692_19960724_11 
2024-11-27 12:16:19.653687: TCGA_HT_7692_19960724_11, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:19.706988: predicting TCGA_HT_7692_19960724_12 
2024-11-27 12:16:19.707572: TCGA_HT_7692_19960724_12, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:19.750217: predicting TCGA_HT_7693_19950520_11 
2024-11-27 12:16:19.750828: TCGA_HT_7693_19950520_11, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:19.809957: predicting TCGA_HT_7693_19950520_12 
2024-11-27 12:16:19.810592: TCGA_HT_7693_19950520_12, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:19.879456: predicting TCGA_HT_7693_19950520_17 
2024-11-27 12:16:19.880368: TCGA_HT_7693_19950520_17, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:19.917350: predicting TCGA_HT_7693_19950520_7 
2024-11-27 12:16:19.918285: TCGA_HT_7693_19950520_7, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:16:19.953024: predicting TCGA_HT_7694_19950404_12 
2024-11-27 12:16:19.954750: TCGA_HT_7694_19950404_12, shape torch.Size([3, 1, 255, 240]), rank 0 
2024-11-27 12:16:20.019625: predicting TCGA_HT_7694_19950404_15 
2024-11-27 12:16:20.020323: TCGA_HT_7694_19950404_15, shape torch.Size([3, 1, 256, 240]), rank 0 
2024-11-27 12:16:20.059299: predicting TCGA_HT_7694_19950404_4 
2024-11-27 12:16:20.061722: TCGA_HT_7694_19950404_4, shape torch.Size([3, 1, 256, 239]), rank 0 
2024-11-27 12:16:20.105842: predicting TCGA_HT_7855_19951020_1 
2024-11-27 12:16:20.106440: TCGA_HT_7855_19951020_1, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:20.166405: predicting TCGA_HT_7855_19951020_15 
2024-11-27 12:16:20.167212: TCGA_HT_7855_19951020_15, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:20.212520: predicting TCGA_HT_7855_19951020_17 
2024-11-27 12:16:20.213125: TCGA_HT_7855_19951020_17, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:20.244373: predicting TCGA_HT_7855_19951020_8 
2024-11-27 12:16:20.244979: TCGA_HT_7855_19951020_8, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:20.276488: predicting TCGA_HT_7856_19950831_21 
2024-11-27 12:16:20.277128: TCGA_HT_7856_19950831_21, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:20.334293: predicting TCGA_HT_7856_19950831_23 
2024-11-27 12:16:20.334928: TCGA_HT_7856_19950831_23, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:20.369534: predicting TCGA_HT_7856_19950831_27 
2024-11-27 12:16:20.376187: TCGA_HT_7856_19950831_27, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:20.440754: predicting TCGA_HT_7856_19950831_30 
2024-11-27 12:16:20.441368: TCGA_HT_7856_19950831_30, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:20.505606: predicting TCGA_HT_7856_19950831_31 
2024-11-27 12:16:20.508015: TCGA_HT_7856_19950831_31, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:20.557504: predicting TCGA_HT_7856_19950831_9 
2024-11-27 12:16:20.563739: TCGA_HT_7856_19950831_9, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:20.630232: predicting TCGA_HT_7860_19960513_1 
2024-11-27 12:16:20.630812: TCGA_HT_7860_19960513_1, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:20.668061: predicting TCGA_HT_7860_19960513_12 
2024-11-27 12:16:20.670595: TCGA_HT_7860_19960513_12, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:20.716413: predicting TCGA_HT_7860_19960513_3 
2024-11-27 12:16:20.719168: TCGA_HT_7860_19960513_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:20.755056: predicting TCGA_HT_7874_19950902_10 
2024-11-27 12:16:20.755687: TCGA_HT_7874_19950902_10, shape torch.Size([3, 1, 255, 253]), rank 0 
2024-11-27 12:16:20.805299: predicting TCGA_HT_7874_19950902_11 
2024-11-27 12:16:20.811090: TCGA_HT_7874_19950902_11, shape torch.Size([3, 1, 255, 255]), rank 0 
2024-11-27 12:16:20.863834: predicting TCGA_HT_7874_19950902_18 
2024-11-27 12:16:20.866487: TCGA_HT_7874_19950902_18, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:20.896987: predicting TCGA_HT_7874_19950902_19 
2024-11-27 12:16:20.899433: TCGA_HT_7874_19950902_19, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:20.952801: predicting TCGA_HT_7874_19950902_20 
2024-11-27 12:16:20.953388: TCGA_HT_7874_19950902_20, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:20.989610: predicting TCGA_HT_7874_19950902_4 
2024-11-27 12:16:20.990284: TCGA_HT_7874_19950902_4, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:16:21.062809: predicting TCGA_HT_7877_19980917_10 
2024-11-27 12:16:21.063418: TCGA_HT_7877_19980917_10, shape torch.Size([3, 1, 249, 249]), rank 0 
2024-11-27 12:16:21.111291: predicting TCGA_HT_7877_19980917_12 
2024-11-27 12:16:21.112042: TCGA_HT_7877_19980917_12, shape torch.Size([3, 1, 248, 249]), rank 0 
2024-11-27 12:16:21.168946: predicting TCGA_HT_7877_19980917_13 
2024-11-27 12:16:21.169542: TCGA_HT_7877_19980917_13, shape torch.Size([3, 1, 248, 249]), rank 0 
2024-11-27 12:16:21.203956: predicting TCGA_HT_7877_19980917_15 
2024-11-27 12:16:21.206588: TCGA_HT_7877_19980917_15, shape torch.Size([3, 1, 247, 248]), rank 0 
2024-11-27 12:16:21.245370: predicting TCGA_HT_7877_19980917_23 
2024-11-27 12:16:21.246049: TCGA_HT_7877_19980917_23, shape torch.Size([3, 1, 249, 251]), rank 0 
2024-11-27 12:16:21.291608: predicting TCGA_HT_7877_19980917_24 
2024-11-27 12:16:21.295452: TCGA_HT_7877_19980917_24, shape torch.Size([3, 1, 249, 253]), rank 0 
2024-11-27 12:16:21.340639: predicting TCGA_HT_7877_19980917_8 
2024-11-27 12:16:21.345285: TCGA_HT_7877_19980917_8, shape torch.Size([3, 1, 250, 251]), rank 0 
2024-11-27 12:16:21.416341: predicting TCGA_HT_7879_19981009_19 
2024-11-27 12:16:21.418872: TCGA_HT_7879_19981009_19, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-27 12:16:21.455844: predicting TCGA_HT_7879_19981009_26 
2024-11-27 12:16:21.456723: TCGA_HT_7879_19981009_26, shape torch.Size([3, 1, 251, 256]), rank 0 
2024-11-27 12:16:21.512162: predicting TCGA_HT_7881_19981015_16 
2024-11-27 12:16:21.516288: TCGA_HT_7881_19981015_16, shape torch.Size([3, 1, 252, 254]), rank 0 
2024-11-27 12:16:21.559212: predicting TCGA_HT_7881_19981015_23 
2024-11-27 12:16:21.560661: TCGA_HT_7881_19981015_23, shape torch.Size([3, 1, 252, 254]), rank 0 
2024-11-27 12:16:21.590709: predicting TCGA_HT_7881_19981015_24 
2024-11-27 12:16:21.593676: TCGA_HT_7881_19981015_24, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-27 12:16:21.652570: predicting TCGA_HT_7881_19981015_29 
2024-11-27 12:16:21.653578: TCGA_HT_7881_19981015_29, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-27 12:16:21.721310: predicting TCGA_HT_7881_19981015_36 
2024-11-27 12:16:21.721986: TCGA_HT_7881_19981015_36, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-27 12:16:21.749204: predicting TCGA_HT_7881_19981015_37 
2024-11-27 12:16:21.751619: TCGA_HT_7881_19981015_37, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-27 12:16:21.780471: predicting TCGA_HT_7881_19981015_45 
2024-11-27 12:16:21.781325: TCGA_HT_7881_19981015_45, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-27 12:16:21.834509: predicting TCGA_HT_7881_19981015_46 
2024-11-27 12:16:21.836708: TCGA_HT_7881_19981015_46, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-27 12:16:21.884832: predicting TCGA_HT_7881_19981015_47 
2024-11-27 12:16:21.885696: TCGA_HT_7881_19981015_47, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-27 12:16:21.943773: predicting TCGA_HT_7881_19981015_49 
2024-11-27 12:16:21.948054: TCGA_HT_7881_19981015_49, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-27 12:16:22.018325: predicting TCGA_HT_7881_19981015_50 
2024-11-27 12:16:22.019330: TCGA_HT_7881_19981015_50, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-27 12:16:22.044508: predicting TCGA_HT_7881_19981015_54 
2024-11-27 12:16:22.046887: TCGA_HT_7881_19981015_54, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-27 12:16:22.084284: predicting TCGA_HT_7881_19981015_57 
2024-11-27 12:16:22.085011: TCGA_HT_7881_19981015_57, shape torch.Size([3, 1, 252, 253]), rank 0 
2024-11-27 12:16:22.123383: predicting TCGA_HT_7881_19981015_59 
2024-11-27 12:16:22.124163: TCGA_HT_7881_19981015_59, shape torch.Size([3, 1, 252, 254]), rank 0 
2024-11-27 12:16:22.188322: predicting TCGA_HT_7881_19981015_60 
2024-11-27 12:16:22.196397: TCGA_HT_7881_19981015_60, shape torch.Size([3, 1, 252, 254]), rank 0 
2024-11-27 12:16:22.261539: predicting TCGA_HT_7881_19981015_62 
2024-11-27 12:16:22.266817: TCGA_HT_7881_19981015_62, shape torch.Size([3, 1, 252, 254]), rank 0 
2024-11-27 12:16:22.299243: predicting TCGA_HT_7881_19981015_67 
2024-11-27 12:16:22.300069: TCGA_HT_7881_19981015_67, shape torch.Size([3, 1, 252, 254]), rank 0 
2024-11-27 12:16:22.352959: predicting TCGA_HT_7881_19981015_74 
2024-11-27 12:16:22.355776: TCGA_HT_7881_19981015_74, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:22.398023: predicting TCGA_HT_7881_19981015_79 
2024-11-27 12:16:22.398854: TCGA_HT_7881_19981015_79, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:22.429831: predicting TCGA_HT_7881_19981015_9 
2024-11-27 12:16:22.430590: TCGA_HT_7881_19981015_9, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:22.469308: predicting TCGA_HT_7882_19970125_10 
2024-11-27 12:16:22.470084: TCGA_HT_7882_19970125_10, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:22.499563: predicting TCGA_HT_7882_19970125_21 
2024-11-27 12:16:22.500130: TCGA_HT_7882_19970125_21, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:22.561303: predicting TCGA_HT_7882_19970125_22 
2024-11-27 12:16:22.561930: TCGA_HT_7882_19970125_22, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:22.630570: predicting TCGA_HT_7882_19970125_24 
2024-11-27 12:16:22.631441: TCGA_HT_7882_19970125_24, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:22.679212: predicting TCGA_HT_7882_19970125_29 
2024-11-27 12:16:22.681706: TCGA_HT_7882_19970125_29, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:22.724803: predicting TCGA_HT_7882_19970125_4 
2024-11-27 12:16:22.727454: TCGA_HT_7882_19970125_4, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:22.780033: predicting TCGA_HT_7884_19980913_11 
2024-11-27 12:16:22.783653: TCGA_HT_7884_19980913_11, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:22.854712: predicting TCGA_HT_7884_19980913_12 
2024-11-27 12:16:22.857221: TCGA_HT_7884_19980913_12, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:22.887424: predicting TCGA_HT_7884_19980913_14 
2024-11-27 12:16:22.888167: TCGA_HT_7884_19980913_14, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:22.944837: predicting TCGA_HT_7884_19980913_16 
2024-11-27 12:16:22.945391: TCGA_HT_7884_19980913_16, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:22.972390: predicting TCGA_HT_7884_19980913_18 
2024-11-27 12:16:22.974643: TCGA_HT_7884_19980913_18, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:23.005053: predicting TCGA_HT_7884_19980913_3 
2024-11-27 12:16:23.017065: TCGA_HT_7884_19980913_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:23.088309: predicting TCGA_HT_7884_19980913_6 
2024-11-27 12:16:23.088910: TCGA_HT_7884_19980913_6, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:23.149304: predicting TCGA_HT_7884_19980913_8 
2024-11-27 12:16:23.150037: TCGA_HT_7884_19980913_8, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:23.216099: predicting TCGA_HT_7884_19980913_9 
2024-11-27 12:16:23.218495: TCGA_HT_7884_19980913_9, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:23.244943: predicting TCGA_HT_8018_19970411_15 
2024-11-27 12:16:23.249153: TCGA_HT_8018_19970411_15, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:23.278261: predicting TCGA_HT_8018_19970411_16 
2024-11-27 12:16:23.287743: TCGA_HT_8018_19970411_16, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:23.332817: predicting TCGA_HT_8018_19970411_3 
2024-11-27 12:16:23.333682: TCGA_HT_8018_19970411_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:23.378938: predicting TCGA_HT_8018_19970411_6 
2024-11-27 12:16:23.379725: TCGA_HT_8018_19970411_6, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:23.414217: predicting TCGA_HT_8105_19980826_15 
2024-11-27 12:16:23.415007: TCGA_HT_8105_19980826_15, shape torch.Size([3, 1, 248, 253]), rank 0 
2024-11-27 12:16:23.464963: predicting TCGA_HT_8105_19980826_17 
2024-11-27 12:16:23.466662: TCGA_HT_8105_19980826_17, shape torch.Size([3, 1, 248, 253]), rank 0 
2024-11-27 12:16:23.532976: predicting TCGA_HT_8105_19980826_18 
2024-11-27 12:16:23.534417: TCGA_HT_8105_19980826_18, shape torch.Size([3, 1, 248, 253]), rank 0 
2024-11-27 12:16:23.566917: predicting TCGA_HT_8105_19980826_22 
2024-11-27 12:16:23.570499: TCGA_HT_8105_19980826_22, shape torch.Size([3, 1, 249, 253]), rank 0 
2024-11-27 12:16:23.626255: predicting TCGA_HT_8105_19980826_25 
2024-11-27 12:16:23.629920: TCGA_HT_8105_19980826_25, shape torch.Size([3, 1, 249, 255]), rank 0 
2024-11-27 12:16:23.667898: predicting TCGA_HT_8105_19980826_26 
2024-11-27 12:16:23.670326: TCGA_HT_8105_19980826_26, shape torch.Size([3, 1, 250, 255]), rank 0 
2024-11-27 12:16:23.730299: predicting TCGA_HT_8105_19980826_27 
2024-11-27 12:16:23.730974: TCGA_HT_8105_19980826_27, shape torch.Size([3, 1, 250, 255]), rank 0 
2024-11-27 12:16:23.763937: predicting TCGA_HT_8105_19980826_31 
2024-11-27 12:16:23.767379: TCGA_HT_8105_19980826_31, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:23.844766: predicting TCGA_HT_8106_19970727_17 
2024-11-27 12:16:23.849473: TCGA_HT_8106_19970727_17, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:23.902425: predicting TCGA_HT_8106_19970727_18 
2024-11-27 12:16:23.904670: TCGA_HT_8106_19970727_18, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:23.929732: predicting TCGA_HT_8106_19970727_20 
2024-11-27 12:16:23.930308: TCGA_HT_8106_19970727_20, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:23.974851: predicting TCGA_HT_8106_19970727_6 
2024-11-27 12:16:23.979335: TCGA_HT_8106_19970727_6, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:24.009311: predicting TCGA_HT_8107_19980708_10 
2024-11-27 12:16:24.010251: TCGA_HT_8107_19980708_10, shape torch.Size([3, 1, 254, 256]), rank 0 
2024-11-27 12:16:24.054592: predicting TCGA_HT_8107_19980708_18 
2024-11-27 12:16:24.056248: TCGA_HT_8107_19980708_18, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:24.131853: predicting TCGA_HT_8107_19980708_3 
2024-11-27 12:16:24.133518: TCGA_HT_8107_19980708_3, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:24.159564: predicting TCGA_HT_8107_19980708_5 
2024-11-27 12:16:24.161525: TCGA_HT_8107_19980708_5, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:24.191845: predicting TCGA_HT_8107_19980708_8 
2024-11-27 12:16:24.192437: TCGA_HT_8107_19980708_8, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:24.220278: predicting TCGA_HT_8111_19980330_14 
2024-11-27 12:16:24.220906: TCGA_HT_8111_19980330_14, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:24.269252: predicting TCGA_HT_8111_19980330_2 
2024-11-27 12:16:24.273083: TCGA_HT_8111_19980330_2, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:24.329418: predicting TCGA_HT_8111_19980330_21 
2024-11-27 12:16:24.333367: TCGA_HT_8111_19980330_21, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:24.377614: predicting TCGA_HT_8111_19980330_9 
2024-11-27 12:16:24.378456: TCGA_HT_8111_19980330_9, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:24.419312: predicting TCGA_HT_8113_19930809_1 
2024-11-27 12:16:24.419820: TCGA_HT_8113_19930809_1, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:24.489992: predicting TCGA_HT_8114_19981030_1 
2024-11-27 12:16:24.494383: TCGA_HT_8114_19981030_1, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:24.560485: predicting TCGA_HT_8114_19981030_10 
2024-11-27 12:16:24.564443: TCGA_HT_8114_19981030_10, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:24.614822: predicting TCGA_HT_8114_19981030_11 
2024-11-27 12:16:24.617918: TCGA_HT_8114_19981030_11, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:24.648829: predicting TCGA_HT_8114_19981030_12 
2024-11-27 12:16:24.651203: TCGA_HT_8114_19981030_12, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:24.687149: predicting TCGA_HT_8114_19981030_18 
2024-11-27 12:16:24.687942: TCGA_HT_8114_19981030_18, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:24.751171: predicting TCGA_HT_8114_19981030_6 
2024-11-27 12:16:24.751750: TCGA_HT_8114_19981030_6, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:24.805450: predicting TCGA_HT_8563_19981209_10 
2024-11-27 12:16:24.806235: TCGA_HT_8563_19981209_10, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:24.839130: predicting TCGA_HT_8563_19981209_19 
2024-11-27 12:16:24.841132: TCGA_HT_8563_19981209_19, shape torch.Size([3, 1, 256, 256]), rank 0 
2024-11-27 12:16:24.897232: predicting TCGA_HT_8563_19981209_2 
2024-11-27 12:16:24.911657: TCGA_HT_8563_19981209_2, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:24.980380: predicting TCGA_HT_8563_19981209_9 
2024-11-27 12:16:24.983153: TCGA_HT_8563_19981209_9, shape torch.Size([3, 1, 255, 256]), rank 0 
2024-11-27 12:16:25.040758: predicting TCGA_HT_A5RC_19990831_2 
2024-11-27 12:16:25.042808: TCGA_HT_A5RC_19990831_2, shape torch.Size([3, 1, 252, 256]), rank 0 
2024-11-27 12:16:25.069552: predicting TCGA_HT_A616_19991226_1 
2024-11-27 12:16:25.070247: TCGA_HT_A616_19991226_1, shape torch.Size([3, 1, 251, 256]), rank 0 
2024-11-27 12:16:25.126376: predicting TCGA_HT_A616_19991226_18 
2024-11-27 12:16:25.127095: TCGA_HT_A616_19991226_18, shape torch.Size([3, 1, 248, 248]), rank 0 
2024-11-27 12:16:25.169981: predicting TCGA_HT_A616_19991226_25 
2024-11-27 12:16:25.170592: TCGA_HT_A616_19991226_25, shape torch.Size([3, 1, 254, 254]), rank 0 
2024-11-27 12:16:25.228158: predicting TCGA_HT_A616_19991226_27 
2024-11-27 12:16:25.228784: TCGA_HT_A616_19991226_27, shape torch.Size([3, 1, 255, 255]), rank 0 
2024-11-27 12:16:25.302384: predicting TCGA_HT_A616_19991226_9 
2024-11-27 12:16:25.303043: TCGA_HT_A616_19991226_9, shape torch.Size([3, 1, 248, 250]), rank 0 
2024-11-27 12:16:25.359850: predicting TCGA_HT_A61A_20000127_13 
2024-11-27 12:16:25.364413: TCGA_HT_A61A_20000127_13, shape torch.Size([3, 1, 247, 256]), rank 0 
2024-11-27 12:16:25.395308: predicting TCGA_HT_A61A_20000127_18 
2024-11-27 12:16:25.396038: TCGA_HT_A61A_20000127_18, shape torch.Size([3, 1, 246, 255]), rank 0 
2024-11-27 12:16:25.440691: predicting TCGA_HT_A61A_20000127_23 
2024-11-27 12:16:25.441302: TCGA_HT_A61A_20000127_23, shape torch.Size([3, 1, 244, 253]), rank 0 
2024-11-27 12:16:25.484637: predicting TCGA_HT_A61A_20000127_26 
2024-11-27 12:16:25.485240: TCGA_HT_A61A_20000127_26, shape torch.Size([3, 1, 244, 252]), rank 0 
2024-11-27 12:16:25.544011: predicting TCGA_HT_A61A_20000127_34 
2024-11-27 12:16:25.544862: TCGA_HT_A61A_20000127_34, shape torch.Size([3, 1, 243, 250]), rank 0 
2024-11-27 12:16:25.581367: predicting TCGA_HT_A61A_20000127_39 
2024-11-27 12:16:25.584013: TCGA_HT_A61A_20000127_39, shape torch.Size([3, 1, 242, 250]), rank 0 
2024-11-27 12:16:25.638974: predicting TCGA_HT_A61A_20000127_40 
2024-11-27 12:16:25.639765: TCGA_HT_A61A_20000127_40, shape torch.Size([3, 1, 243, 250]), rank 0 
2024-11-27 12:16:25.690572: predicting TCGA_HT_A61A_20000127_46 
2024-11-27 12:16:25.693478: TCGA_HT_A61A_20000127_46, shape torch.Size([3, 1, 243, 250]), rank 0 
2024-11-27 12:16:25.737190: predicting TCGA_HT_A61A_20000127_6 
2024-11-27 12:16:25.738037: TCGA_HT_A61A_20000127_6, shape torch.Size([3, 1, 249, 256]), rank 0 
2024-11-27 12:16:25.808747: predicting TCGA_HT_A61A_20000127_63 
2024-11-27 12:16:25.811103: TCGA_HT_A61A_20000127_63, shape torch.Size([3, 1, 245, 253]), rank 0 
2024-11-27 12:16:25.837191: predicting TCGA_HT_A61A_20000127_65 
2024-11-27 12:16:25.839756: TCGA_HT_A61A_20000127_65, shape torch.Size([3, 1, 245, 253]), rank 0 
2024-11-27 12:16:25.879812: predicting TCGA_HT_A61A_20000127_69 
2024-11-27 12:16:25.883986: TCGA_HT_A61A_20000127_69, shape torch.Size([3, 1, 247, 255]), rank 0 
2024-11-27 12:16:25.920347: predicting TCGA_HT_A61A_20000127_72 
2024-11-27 12:16:25.920956: TCGA_HT_A61A_20000127_72, shape torch.Size([3, 1, 248, 256]), rank 0 
2024-11-27 12:16:25.996360: predicting TCGA_HT_A61A_20000127_73 
2024-11-27 12:16:25.997154: TCGA_HT_A61A_20000127_73, shape torch.Size([3, 1, 248, 256]), rank 0 
2024-11-27 12:16:26.054751: predicting TCGA_HT_A61A_20000127_76 
2024-11-27 12:16:26.056422: TCGA_HT_A61A_20000127_76, shape torch.Size([3, 1, 249, 256]), rank 0 
2024-11-27 12:16:26.085223: predicting TCGA_HT_A61A_20000127_81 
2024-11-27 12:16:26.085837: TCGA_HT_A61A_20000127_81, shape torch.Size([3, 1, 251, 256]), rank 0 
2024-11-27 12:16:26.115225: predicting TCGA_HT_A61A_20000127_85 
2024-11-27 12:16:26.116007: TCGA_HT_A61A_20000127_85, shape torch.Size([3, 1, 253, 256]), rank 0 
2024-11-27 12:16:26.179365: predicting TCGA_HT_A61A_20000127_87 
2024-11-27 12:16:26.182267: TCGA_HT_A61A_20000127_87, shape torch.Size([3, 1, 251, 256]), rank 0 
2024-11-27 12:16:26.242705: predicting TCGA_HT_A61B_19991127_11 
2024-11-27 12:16:26.243309: TCGA_HT_A61B_19991127_11, shape torch.Size([3, 1, 249, 256]), rank 0 
2024-11-27 12:16:26.270974: predicting TCGA_HT_A61B_19991127_13 
2024-11-27 12:16:26.271553: TCGA_HT_A61B_19991127_13, shape torch.Size([3, 1, 248, 254]), rank 0 
2024-11-27 12:16:26.305361: predicting TCGA_HT_A61B_19991127_18 
2024-11-27 12:16:26.305925: TCGA_HT_A61B_19991127_18, shape torch.Size([3, 1, 247, 253]), rank 0 
2024-11-27 12:16:26.372624: predicting TCGA_HT_A61B_19991127_26 
2024-11-27 12:16:26.376641: TCGA_HT_A61B_19991127_26, shape torch.Size([3, 1, 245, 249]), rank 0 
2024-11-27 12:16:26.412298: predicting TCGA_HT_A61B_19991127_40 
2024-11-27 12:16:26.413112: TCGA_HT_A61B_19991127_40, shape torch.Size([3, 1, 244, 247]), rank 0 
2024-11-27 12:16:26.449497: predicting TCGA_HT_A61B_19991127_44 
2024-11-27 12:16:26.450262: TCGA_HT_A61B_19991127_44, shape torch.Size([3, 1, 244, 247]), rank 0 
2024-11-27 12:16:26.501210: predicting TCGA_HT_A61B_19991127_47 
2024-11-27 12:16:26.503897: TCGA_HT_A61B_19991127_47, shape torch.Size([3, 1, 244, 247]), rank 0 
2024-11-27 12:16:26.553635: predicting TCGA_HT_A61B_19991127_49 
2024-11-27 12:16:26.555622: TCGA_HT_A61B_19991127_49, shape torch.Size([3, 1, 244, 247]), rank 0 
2024-11-27 12:16:26.599904: predicting TCGA_HT_A61B_19991127_52 
2024-11-27 12:16:26.601270: TCGA_HT_A61B_19991127_52, shape torch.Size([3, 1, 244, 247]), rank 0 
2024-11-27 12:16:26.631127: predicting TCGA_HT_A61B_19991127_58 
2024-11-27 12:16:26.634543: TCGA_HT_A61B_19991127_58, shape torch.Size([3, 1, 245, 249]), rank 0 
2024-11-27 12:16:26.672926: predicting TCGA_HT_A61B_19991127_6 
2024-11-27 12:16:26.675719: TCGA_HT_A61B_19991127_6, shape torch.Size([3, 1, 251, 256]), rank 0 
2024-11-27 12:16:26.765499: predicting TCGA_HT_A61B_19991127_75 
2024-11-27 12:16:26.766182: TCGA_HT_A61B_19991127_75, shape torch.Size([3, 1, 248, 254]), rank 0 
2024-11-27 12:16:26.832714: predicting TCGA_HT_A61B_19991127_76 
2024-11-27 12:16:26.835093: TCGA_HT_A61B_19991127_76, shape torch.Size([3, 1, 248, 254]), rank 0 
2024-11-27 12:16:26.866767: predicting TCGA_HT_A61B_19991127_81 
2024-11-27 12:16:26.869429: TCGA_HT_A61B_19991127_81, shape torch.Size([3, 1, 250, 256]), rank 0 
2024-11-27 12:16:26.899809: predicting TCGA_HT_A61B_19991127_82 
2024-11-27 12:16:26.900330: TCGA_HT_A61B_19991127_82, shape torch.Size([3, 1, 250, 256]), rank 0 
2024-11-27 12:16:35.030774: Validation complete 
2024-11-27 12:16:35.030837: Mean Validation Dice:  0.8438334229548288 
